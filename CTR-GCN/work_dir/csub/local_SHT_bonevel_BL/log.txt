[ Wed Nov  9 10:28:33 2022 ] using warm up, epoch: 5
[ Wed Nov  9 10:30:21 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHTg_bonevel_BL', 'model_saved_name': 'work_dir/ntu120/csub/local_SHTg_bonevel_BL/runs', 'config': 'config/nturgbd120-cross-subject/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Nov  9 10:30:21 2022 ] # Parameters: 2141090
[ Wed Nov  9 10:30:21 2022 ] Training epoch: 1
[ Wed Nov  9 10:40:02 2022 ] 	Mean training loss: 3.4652.  Mean training acc: 16.75%.
[ Wed Nov  9 10:40:02 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 10:40:02 2022 ] Eval epoch: 1
[ Wed Nov  9 10:44:34 2022 ] 	Mean test loss of 796 batches: 2.779676516750949.
[ Wed Nov  9 10:44:35 2022 ] 	Top1: 25.29%
[ Wed Nov  9 10:44:36 2022 ] 	Top5: 58.59%
[ Wed Nov  9 10:44:36 2022 ] Training epoch: 2
[ Wed Nov  9 10:54:00 2022 ] 	Mean training loss: 2.1988.  Mean training acc: 39.63%.
[ Wed Nov  9 10:54:00 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Wed Nov  9 10:54:00 2022 ] Eval epoch: 2
[ Wed Nov  9 10:58:37 2022 ] 	Mean test loss of 796 batches: 2.1262319636105294.
[ Wed Nov  9 10:58:38 2022 ] 	Top1: 40.83%
[ Wed Nov  9 10:58:39 2022 ] 	Top5: 76.06%
[ Wed Nov  9 10:58:39 2022 ] Training epoch: 3
[ Wed Nov  9 11:08:01 2022 ] 	Mean training loss: 1.7217.  Mean training acc: 51.24%.
[ Wed Nov  9 11:08:01 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:08:01 2022 ] Eval epoch: 3
[ Wed Nov  9 11:12:37 2022 ] 	Mean test loss of 796 batches: 2.1575811030577174.
[ Wed Nov  9 11:12:38 2022 ] 	Top1: 41.54%
[ Wed Nov  9 11:12:39 2022 ] 	Top5: 74.65%
[ Wed Nov  9 11:12:39 2022 ] Training epoch: 4
[ Wed Nov  9 11:22:04 2022 ] 	Mean training loss: 1.5265.  Mean training acc: 56.42%.
[ Wed Nov  9 11:22:04 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:22:04 2022 ] Eval epoch: 4
[ Wed Nov  9 11:26:41 2022 ] 	Mean test loss of 796 batches: 1.7261677791724852.
[ Wed Nov  9 11:26:41 2022 ] 	Top1: 50.35%
[ Wed Nov  9 11:26:43 2022 ] 	Top5: 84.00%
[ Wed Nov  9 11:26:43 2022 ] Training epoch: 5
[ Wed Nov  9 11:36:03 2022 ] 	Mean training loss: 1.4298.  Mean training acc: 58.89%.
[ Wed Nov  9 11:36:03 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:36:03 2022 ] Eval epoch: 5
[ Wed Nov  9 11:40:45 2022 ] 	Mean test loss of 796 batches: 2.1095770595960284.
[ Wed Nov  9 11:40:47 2022 ] 	Top1: 43.24%
[ Wed Nov  9 11:40:49 2022 ] 	Top5: 77.73%
[ Wed Nov  9 11:40:49 2022 ] Training epoch: 6
[ Wed Nov  9 11:50:10 2022 ] 	Mean training loss: 1.3182.  Mean training acc: 62.06%.
[ Wed Nov  9 11:50:10 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 11:50:10 2022 ] Eval epoch: 6
[ Wed Nov  9 11:54:44 2022 ] 	Mean test loss of 796 batches: 1.5085614365548943.
[ Wed Nov  9 11:54:45 2022 ] 	Top1: 56.11%
[ Wed Nov  9 11:54:46 2022 ] 	Top5: 86.88%
[ Wed Nov  9 11:54:46 2022 ] Training epoch: 7
[ Wed Nov  9 12:04:02 2022 ] 	Mean training loss: 1.2337.  Mean training acc: 64.09%.
[ Wed Nov  9 12:04:02 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Wed Nov  9 12:04:02 2022 ] Eval epoch: 7
[ Wed Nov  9 12:08:37 2022 ] 	Mean test loss of 796 batches: 2.303589061426757.
[ Wed Nov  9 12:08:39 2022 ] 	Top1: 44.13%
[ Wed Nov  9 12:08:40 2022 ] 	Top5: 77.42%
[ Wed Nov  9 12:08:40 2022 ] Training epoch: 8
[ Wed Nov  9 12:18:06 2022 ] 	Mean training loss: 1.1839.  Mean training acc: 65.69%.
[ Wed Nov  9 12:18:06 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 12:18:06 2022 ] Eval epoch: 8
[ Wed Nov  9 12:22:39 2022 ] 	Mean test loss of 796 batches: 1.8476615395378229.
[ Wed Nov  9 12:22:40 2022 ] 	Top1: 49.27%
[ Wed Nov  9 12:22:41 2022 ] 	Top5: 79.73%
[ Wed Nov  9 12:22:41 2022 ] Training epoch: 9
[ Wed Nov  9 12:31:57 2022 ] 	Mean training loss: 1.1473.  Mean training acc: 66.35%.
[ Wed Nov  9 12:31:57 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:31:57 2022 ] Eval epoch: 9
[ Wed Nov  9 12:36:34 2022 ] 	Mean test loss of 796 batches: 1.8009328103844244.
[ Wed Nov  9 12:36:35 2022 ] 	Top1: 52.25%
[ Wed Nov  9 12:36:36 2022 ] 	Top5: 79.93%
[ Wed Nov  9 12:36:36 2022 ] Training epoch: 10
[ Wed Nov  9 12:45:52 2022 ] 	Mean training loss: 1.1109.  Mean training acc: 67.46%.
[ Wed Nov  9 12:45:52 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:45:52 2022 ] Eval epoch: 10
[ Wed Nov  9 12:50:26 2022 ] 	Mean test loss of 796 batches: 1.4990921558896502.
[ Wed Nov  9 12:50:28 2022 ] 	Top1: 57.74%
[ Wed Nov  9 12:50:28 2022 ] 	Top5: 86.00%
[ Wed Nov  9 12:50:29 2022 ] Training epoch: 11
[ Wed Nov  9 12:59:47 2022 ] 	Mean training loss: 1.0895.  Mean training acc: 68.04%.
[ Wed Nov  9 12:59:47 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:59:47 2022 ] Eval epoch: 11
[ Wed Nov  9 13:04:29 2022 ] 	Mean test loss of 796 batches: 1.5616231264181473.
[ Wed Nov  9 13:04:31 2022 ] 	Top1: 55.75%
[ Wed Nov  9 13:04:32 2022 ] 	Top5: 86.42%
[ Wed Nov  9 13:04:32 2022 ] Training epoch: 12
[ Wed Nov  9 13:13:45 2022 ] 	Mean training loss: 1.0635.  Mean training acc: 68.95%.
[ Wed Nov  9 13:13:45 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:13:45 2022 ] Eval epoch: 12
[ Wed Nov  9 13:18:25 2022 ] 	Mean test loss of 796 batches: 1.3171913847701633.
[ Wed Nov  9 13:18:26 2022 ] 	Top1: 61.83%
[ Wed Nov  9 13:18:28 2022 ] 	Top5: 88.99%
[ Wed Nov  9 13:18:28 2022 ] Training epoch: 13
[ Wed Nov  9 13:27:41 2022 ] 	Mean training loss: 1.0355.  Mean training acc: 69.63%.
[ Wed Nov  9 13:27:41 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:27:41 2022 ] Eval epoch: 13
[ Wed Nov  9 13:32:19 2022 ] 	Mean test loss of 796 batches: 1.558105079897085.
[ Wed Nov  9 13:32:21 2022 ] 	Top1: 56.01%
[ Wed Nov  9 13:32:22 2022 ] 	Top5: 85.60%
[ Wed Nov  9 13:32:22 2022 ] Training epoch: 14
[ Wed Nov  9 13:41:30 2022 ] 	Mean training loss: 1.0229.  Mean training acc: 69.93%.
[ Wed Nov  9 13:41:30 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 13:41:30 2022 ] Eval epoch: 14
[ Wed Nov  9 13:46:08 2022 ] 	Mean test loss of 796 batches: 1.2938420271978306.
[ Wed Nov  9 13:46:09 2022 ] 	Top1: 63.34%
[ Wed Nov  9 13:46:11 2022 ] 	Top5: 89.04%
[ Wed Nov  9 13:46:11 2022 ] Training epoch: 15
[ Wed Nov  9 13:55:21 2022 ] 	Mean training loss: 1.0088.  Mean training acc: 70.22%.
[ Wed Nov  9 13:55:21 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:55:21 2022 ] Eval epoch: 15
[ Wed Nov  9 13:59:55 2022 ] 	Mean test loss of 796 batches: 1.7707412983454651.
[ Wed Nov  9 13:59:56 2022 ] 	Top1: 54.31%
[ Wed Nov  9 13:59:57 2022 ] 	Top5: 82.71%
[ Wed Nov  9 13:59:57 2022 ] Training epoch: 16
[ Wed Nov  9 14:09:05 2022 ] 	Mean training loss: 0.9902.  Mean training acc: 70.89%.
[ Wed Nov  9 14:09:05 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:09:05 2022 ] Eval epoch: 16
[ Wed Nov  9 14:13:38 2022 ] 	Mean test loss of 796 batches: 1.3521444418996422.
[ Wed Nov  9 14:13:39 2022 ] 	Top1: 62.01%
[ Wed Nov  9 14:13:40 2022 ] 	Top5: 88.10%
[ Wed Nov  9 14:13:41 2022 ] Training epoch: 17
[ Wed Nov  9 14:22:45 2022 ] 	Mean training loss: 0.9804.  Mean training acc: 71.17%.
[ Wed Nov  9 14:22:45 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 14:22:45 2022 ] Eval epoch: 17
[ Wed Nov  9 14:27:28 2022 ] 	Mean test loss of 796 batches: 1.5049782475484677.
[ Wed Nov  9 14:27:29 2022 ] 	Top1: 59.44%
[ Wed Nov  9 14:27:30 2022 ] 	Top5: 86.68%
[ Wed Nov  9 14:27:30 2022 ] Training epoch: 18
[ Wed Nov  9 14:36:42 2022 ] 	Mean training loss: 0.9678.  Mean training acc: 71.70%.
[ Wed Nov  9 14:36:42 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 14:36:42 2022 ] Eval epoch: 18
[ Wed Nov  9 14:41:19 2022 ] 	Mean test loss of 796 batches: 1.3854002508910457.
[ Wed Nov  9 14:41:20 2022 ] 	Top1: 62.38%
[ Wed Nov  9 14:41:21 2022 ] 	Top5: 87.27%
[ Wed Nov  9 14:41:21 2022 ] Training epoch: 19
[ Wed Nov  9 14:50:23 2022 ] 	Mean training loss: 0.9568.  Mean training acc: 71.85%.
[ Wed Nov  9 14:50:23 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Nov  9 14:50:23 2022 ] Eval epoch: 19
[ Wed Nov  9 14:54:55 2022 ] 	Mean test loss of 796 batches: 1.473663033103224.
[ Wed Nov  9 14:54:56 2022 ] 	Top1: 60.94%
[ Wed Nov  9 14:54:57 2022 ] 	Top5: 85.80%
[ Wed Nov  9 14:54:58 2022 ] Training epoch: 20
[ Wed Nov  9 15:04:03 2022 ] 	Mean training loss: 0.9469.  Mean training acc: 72.10%.
[ Wed Nov  9 15:04:03 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 15:04:03 2022 ] Eval epoch: 20
[ Wed Nov  9 15:08:42 2022 ] 	Mean test loss of 796 batches: 1.3318906062511942.
[ Wed Nov  9 15:08:43 2022 ] 	Top1: 61.96%
[ Wed Nov  9 15:08:44 2022 ] 	Top5: 88.18%
[ Wed Nov  9 15:08:44 2022 ] Training epoch: 21
[ Tue Jan  3 16:34:10 2023 ] Load weights from work_dir/csub/local_SHTg_bonevel_BL/runs-20-19680.pt.
[ Tue Jan  3 16:34:14 2023 ] using warm up, epoch: 5
[ Tue Jan  3 16:34:28 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHTg_bonevel_BL', 'model_saved_name': 'work_dir/csub/local_SHTg_bonevel_BL/runs', 'config': 'work_dir/csub/local_SHTg_bonevel_BL/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': True, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': True, 'window_size': 64}, 'model': 'model.local_SHTg.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/csub/local_SHTg_bonevel_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 16:34:28 2023 ] # Parameters: 2141090
[ Tue Jan  3 16:34:28 2023 ] Training epoch: 21
[ Tue Jan  3 16:38:49 2023 ] Load weights from work_dir/csub/local_SHTg_bonevel_BL/runs-20-19680.pt.
[ Tue Jan  3 16:38:53 2023 ] using warm up, epoch: 5
[ Tue Jan  3 16:39:10 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHTg_bonevel_BL', 'model_saved_name': 'work_dir/csub/local_SHTg_bonevel_BL/runs', 'config': 'work_dir/csub/local_SHTg_bonevel_BL/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': True, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': True, 'window_size': 64}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/csub/local_SHTg_bonevel_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 16:39:10 2023 ] # Parameters: 2141090
[ Tue Jan  3 16:39:10 2023 ] Training epoch: 21
[ Tue Jan  3 16:48:51 2023 ] 	Mean training loss: 0.9345.  Mean training acc: 72.50%.
[ Tue Jan  3 16:48:51 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan  3 16:48:51 2023 ] Eval epoch: 21
[ Tue Jan  3 16:52:03 2023 ] 	Mean test loss of 796 batches: 1.2600391984135662.
[ Tue Jan  3 16:52:03 2023 ] 	Top1: 64.37%
[ Tue Jan  3 16:52:04 2023 ] 	Top5: 89.73%
[ Tue Jan  3 16:52:04 2023 ] Training epoch: 22
[ Tue Jan  3 17:01:27 2023 ] 	Mean training loss: 0.9322.  Mean training acc: 72.52%.
[ Tue Jan  3 17:01:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:01:27 2023 ] Eval epoch: 22
[ Tue Jan  3 17:04:36 2023 ] 	Mean test loss of 796 batches: 1.2438685898505264.
[ Tue Jan  3 17:04:37 2023 ] 	Top1: 64.29%
[ Tue Jan  3 17:04:37 2023 ] 	Top5: 89.78%
[ Tue Jan  3 17:04:37 2023 ] Training epoch: 23
[ Tue Jan  3 17:14:25 2023 ] 	Mean training loss: 0.9203.  Mean training acc: 72.87%.
[ Tue Jan  3 17:14:25 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:14:25 2023 ] Eval epoch: 23
[ Tue Jan  3 17:17:36 2023 ] 	Mean test loss of 796 batches: 1.3208832448750885.
[ Tue Jan  3 17:17:37 2023 ] 	Top1: 61.69%
[ Tue Jan  3 17:17:37 2023 ] 	Top5: 89.17%
[ Tue Jan  3 17:17:37 2023 ] Training epoch: 24
[ Tue Jan  3 17:27:23 2023 ] 	Mean training loss: 0.9225.  Mean training acc: 72.90%.
[ Tue Jan  3 17:27:23 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:27:23 2023 ] Eval epoch: 24
[ Tue Jan  3 17:30:39 2023 ] 	Mean test loss of 796 batches: 1.7455287239509611.
[ Tue Jan  3 17:30:40 2023 ] 	Top1: 56.13%
[ Tue Jan  3 17:30:41 2023 ] 	Top5: 82.79%
[ Tue Jan  3 17:30:41 2023 ] Training epoch: 25
[ Tue Jan  3 17:40:37 2023 ] 	Mean training loss: 0.9146.  Mean training acc: 73.15%.
[ Tue Jan  3 17:40:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 17:40:37 2023 ] Eval epoch: 25
[ Tue Jan  3 17:44:14 2023 ] 	Mean test loss of 796 batches: 1.3787876735605187.
[ Tue Jan  3 17:44:14 2023 ] 	Top1: 60.94%
[ Tue Jan  3 17:44:15 2023 ] 	Top5: 88.81%
[ Tue Jan  3 17:44:15 2023 ] Training epoch: 26
[ Tue Jan  3 17:54:19 2023 ] 	Mean training loss: 0.9090.  Mean training acc: 73.38%.
[ Tue Jan  3 17:54:19 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 17:54:19 2023 ] Eval epoch: 26
[ Tue Jan  3 17:58:07 2023 ] 	Mean test loss of 796 batches: 1.273349990384962.
[ Tue Jan  3 17:58:09 2023 ] 	Top1: 63.83%
[ Tue Jan  3 17:58:10 2023 ] 	Top5: 90.04%
[ Tue Jan  3 17:58:10 2023 ] Training epoch: 27
[ Tue Jan  3 18:07:53 2023 ] 	Mean training loss: 0.8950.  Mean training acc: 73.49%.
[ Tue Jan  3 18:07:53 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:07:53 2023 ] Eval epoch: 27
[ Tue Jan  3 18:11:28 2023 ] 	Mean test loss of 796 batches: 1.7014031511305565.
[ Tue Jan  3 18:11:28 2023 ] 	Top1: 56.32%
[ Tue Jan  3 18:11:29 2023 ] 	Top5: 85.23%
[ Tue Jan  3 18:11:29 2023 ] Training epoch: 28
[ Tue Jan  3 18:21:01 2023 ] 	Mean training loss: 0.8912.  Mean training acc: 73.72%.
[ Tue Jan  3 18:21:01 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:21:01 2023 ] Eval epoch: 28
[ Tue Jan  3 18:24:28 2023 ] 	Mean test loss of 796 batches: 1.3237152835307409.
[ Tue Jan  3 18:24:28 2023 ] 	Top1: 63.16%
[ Tue Jan  3 18:24:29 2023 ] 	Top5: 89.54%
[ Tue Jan  3 18:24:29 2023 ] Training epoch: 29
[ Tue Jan  3 18:34:02 2023 ] 	Mean training loss: 0.8838.  Mean training acc: 73.90%.
[ Tue Jan  3 18:34:02 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:34:02 2023 ] Eval epoch: 29
[ Tue Jan  3 18:37:29 2023 ] 	Mean test loss of 796 batches: 1.4378357464868818.
[ Tue Jan  3 18:37:30 2023 ] 	Top1: 60.78%
[ Tue Jan  3 18:37:31 2023 ] 	Top5: 86.80%
[ Tue Jan  3 18:37:31 2023 ] Training epoch: 30
[ Tue Jan  3 18:46:42 2023 ] 	Mean training loss: 0.8833.  Mean training acc: 73.84%.
[ Tue Jan  3 18:46:42 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:46:42 2023 ] Eval epoch: 30
[ Tue Jan  3 18:50:16 2023 ] 	Mean test loss of 796 batches: 1.2651507365119516.
[ Tue Jan  3 18:50:17 2023 ] 	Top1: 64.80%
[ Tue Jan  3 18:50:18 2023 ] 	Top5: 89.83%
[ Tue Jan  3 18:50:18 2023 ] Training epoch: 31
[ Tue Jan  3 18:59:25 2023 ] 	Mean training loss: 0.8785.  Mean training acc: 73.93%.
[ Tue Jan  3 18:59:25 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:59:25 2023 ] Eval epoch: 31
[ Tue Jan  3 19:03:05 2023 ] 	Mean test loss of 796 batches: 1.2693543965792535.
[ Tue Jan  3 19:03:06 2023 ] 	Top1: 64.99%
[ Tue Jan  3 19:03:06 2023 ] 	Top5: 89.64%
[ Tue Jan  3 19:03:06 2023 ] Training epoch: 32
[ Tue Jan  3 19:12:07 2023 ] 	Mean training loss: 0.8753.  Mean training acc: 74.12%.
[ Tue Jan  3 19:12:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:12:08 2023 ] Eval epoch: 32
[ Tue Jan  3 19:15:51 2023 ] 	Mean test loss of 796 batches: 1.2585078868734179.
[ Tue Jan  3 19:15:52 2023 ] 	Top1: 63.91%
[ Tue Jan  3 19:15:53 2023 ] 	Top5: 89.76%
[ Tue Jan  3 19:15:53 2023 ] Training epoch: 33
[ Tue Jan  3 19:24:46 2023 ] 	Mean training loss: 0.8732.  Mean training acc: 74.17%.
[ Tue Jan  3 19:24:46 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:24:46 2023 ] Eval epoch: 33
[ Tue Jan  3 19:28:31 2023 ] 	Mean test loss of 796 batches: 1.4276994863646713.
[ Tue Jan  3 19:28:31 2023 ] 	Top1: 60.55%
[ Tue Jan  3 19:28:32 2023 ] 	Top5: 87.90%
[ Tue Jan  3 19:28:32 2023 ] Training epoch: 34
[ Tue Jan  3 19:37:31 2023 ] 	Mean training loss: 0.8691.  Mean training acc: 74.20%.
[ Tue Jan  3 19:37:31 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:37:31 2023 ] Eval epoch: 34
[ Tue Jan  3 19:41:34 2023 ] 	Mean test loss of 796 batches: 1.227282159255078.
[ Tue Jan  3 19:41:35 2023 ] 	Top1: 65.54%
[ Tue Jan  3 19:41:36 2023 ] 	Top5: 90.05%
[ Tue Jan  3 19:41:36 2023 ] Training epoch: 35
[ Tue Jan  3 19:50:55 2023 ] 	Mean training loss: 0.8700.  Mean training acc: 74.22%.
[ Tue Jan  3 19:50:55 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:50:55 2023 ] Eval epoch: 35
[ Tue Jan  3 19:54:59 2023 ] 	Mean test loss of 796 batches: 1.2483711613332806.
[ Tue Jan  3 19:54:59 2023 ] 	Top1: 63.79%
[ Tue Jan  3 19:55:00 2023 ] 	Top5: 89.79%
[ Tue Jan  3 19:55:00 2023 ] Training epoch: 36
[ Tue Jan  3 20:04:04 2023 ] 	Mean training loss: 0.5064.  Mean training acc: 84.98%.
[ Tue Jan  3 20:04:04 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:04:04 2023 ] Eval epoch: 36
[ Tue Jan  3 20:07:50 2023 ] 	Mean test loss of 796 batches: 0.6900945167670298.
[ Tue Jan  3 20:07:51 2023 ] 	Top1: 79.14%
[ Tue Jan  3 20:07:52 2023 ] 	Top5: 95.70%
[ Tue Jan  3 20:07:52 2023 ] Training epoch: 37
[ Tue Jan  3 20:16:35 2023 ] 	Mean training loss: 0.4130.  Mean training acc: 87.95%.
[ Tue Jan  3 20:16:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:16:36 2023 ] Eval epoch: 37
[ Tue Jan  3 20:20:40 2023 ] 	Mean test loss of 796 batches: 0.6893938923413729.
[ Tue Jan  3 20:20:41 2023 ] 	Top1: 79.33%
[ Tue Jan  3 20:20:41 2023 ] 	Top5: 95.76%
[ Tue Jan  3 20:20:41 2023 ] Training epoch: 38
[ Tue Jan  3 20:29:53 2023 ] 	Mean training loss: 0.3699.  Mean training acc: 89.15%.
[ Tue Jan  3 20:29:53 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:29:53 2023 ] Eval epoch: 38
[ Tue Jan  3 20:34:01 2023 ] 	Mean test loss of 796 batches: 0.6765828909417942.
[ Tue Jan  3 20:34:01 2023 ] 	Top1: 79.93%
[ Tue Jan  3 20:34:02 2023 ] 	Top5: 95.92%
[ Tue Jan  3 20:34:02 2023 ] Training epoch: 39
[ Tue Jan  3 20:43:18 2023 ] 	Mean training loss: 0.3340.  Mean training acc: 90.29%.
[ Tue Jan  3 20:43:18 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:43:18 2023 ] Eval epoch: 39
[ Tue Jan  3 20:47:28 2023 ] 	Mean test loss of 796 batches: 0.7265629817698919.
[ Tue Jan  3 20:47:29 2023 ] 	Top1: 78.61%
[ Tue Jan  3 20:47:30 2023 ] 	Top5: 95.49%
[ Tue Jan  3 20:47:30 2023 ] Training epoch: 40
[ Tue Jan  3 20:56:41 2023 ] 	Mean training loss: 0.3077.  Mean training acc: 91.09%.
[ Tue Jan  3 20:56:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:56:42 2023 ] Eval epoch: 40
[ Tue Jan  3 21:00:44 2023 ] 	Mean test loss of 796 batches: 0.6903239035950833.
[ Tue Jan  3 21:00:44 2023 ] 	Top1: 79.71%
[ Tue Jan  3 21:00:45 2023 ] 	Top5: 95.80%
[ Tue Jan  3 21:00:45 2023 ] Training epoch: 41
[ Tue Jan  3 21:09:32 2023 ] 	Mean training loss: 0.2799.  Mean training acc: 92.01%.
[ Tue Jan  3 21:09:33 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:09:34 2023 ] Eval epoch: 41
[ Tue Jan  3 21:13:36 2023 ] 	Mean test loss of 796 batches: 0.7607447246473339.
[ Tue Jan  3 21:13:37 2023 ] 	Top1: 78.16%
[ Tue Jan  3 21:13:38 2023 ] 	Top5: 95.38%
[ Tue Jan  3 21:13:38 2023 ] Training epoch: 42
[ Tue Jan  3 21:22:51 2023 ] 	Mean training loss: 0.2645.  Mean training acc: 92.42%.
[ Tue Jan  3 21:22:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:22:51 2023 ] Eval epoch: 42
[ Tue Jan  3 21:26:59 2023 ] 	Mean test loss of 796 batches: 0.713188907215793.
[ Tue Jan  3 21:27:00 2023 ] 	Top1: 79.21%
[ Tue Jan  3 21:27:01 2023 ] 	Top5: 95.59%
[ Tue Jan  3 21:27:01 2023 ] Training epoch: 43
[ Tue Jan  3 21:36:14 2023 ] 	Mean training loss: 0.2475.  Mean training acc: 93.13%.
[ Tue Jan  3 21:36:14 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:36:14 2023 ] Eval epoch: 43
[ Tue Jan  3 21:40:24 2023 ] 	Mean test loss of 796 batches: 0.7562312338051934.
[ Tue Jan  3 21:40:25 2023 ] 	Top1: 78.64%
[ Tue Jan  3 21:40:26 2023 ] 	Top5: 95.27%
[ Tue Jan  3 21:40:26 2023 ] Training epoch: 44
[ Tue Jan  3 21:49:38 2023 ] 	Mean training loss: 0.2333.  Mean training acc: 93.43%.
[ Tue Jan  3 21:49:38 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:49:38 2023 ] Eval epoch: 44
[ Tue Jan  3 21:53:40 2023 ] 	Mean test loss of 796 batches: 0.744646715056432.
[ Tue Jan  3 21:53:41 2023 ] 	Top1: 78.94%
[ Tue Jan  3 21:53:42 2023 ] 	Top5: 95.33%
[ Tue Jan  3 21:53:42 2023 ] Training epoch: 45
[ Tue Jan  3 22:02:49 2023 ] 	Mean training loss: 0.2291.  Mean training acc: 93.66%.
[ Tue Jan  3 22:02:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:02:50 2023 ] Eval epoch: 45
[ Tue Jan  3 22:06:38 2023 ] 	Mean test loss of 796 batches: 0.787562320392635.
[ Tue Jan  3 22:06:39 2023 ] 	Top1: 77.87%
[ Tue Jan  3 22:06:39 2023 ] 	Top5: 95.08%
[ Tue Jan  3 22:06:39 2023 ] Training epoch: 46
[ Tue Jan  3 22:15:27 2023 ] 	Mean training loss: 0.2196.  Mean training acc: 93.94%.
[ Tue Jan  3 22:15:27 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:15:27 2023 ] Eval epoch: 46
[ Tue Jan  3 22:19:17 2023 ] 	Mean test loss of 796 batches: 0.7672195020482768.
[ Tue Jan  3 22:19:18 2023 ] 	Top1: 78.68%
[ Tue Jan  3 22:19:19 2023 ] 	Top5: 95.26%
[ Tue Jan  3 22:19:19 2023 ] Training epoch: 47
[ Tue Jan  3 22:28:23 2023 ] 	Mean training loss: 0.2135.  Mean training acc: 94.07%.
[ Tue Jan  3 22:28:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:28:24 2023 ] Eval epoch: 47
[ Tue Jan  3 22:32:10 2023 ] 	Mean test loss of 796 batches: 0.8295314555622675.
[ Tue Jan  3 22:32:11 2023 ] 	Top1: 77.25%
[ Tue Jan  3 22:32:12 2023 ] 	Top5: 94.56%
[ Tue Jan  3 22:32:12 2023 ] Training epoch: 48
[ Tue Jan  3 22:41:42 2023 ] 	Mean training loss: 0.2088.  Mean training acc: 94.27%.
[ Tue Jan  3 22:41:42 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:41:42 2023 ] Eval epoch: 48
[ Tue Jan  3 22:45:33 2023 ] 	Mean test loss of 796 batches: 0.7979746601689401.
[ Tue Jan  3 22:45:33 2023 ] 	Top1: 78.37%
[ Tue Jan  3 22:45:34 2023 ] 	Top5: 95.18%
[ Tue Jan  3 22:45:34 2023 ] Training epoch: 49
[ Tue Jan  3 22:55:08 2023 ] 	Mean training loss: 0.2037.  Mean training acc: 94.42%.
[ Tue Jan  3 22:55:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:55:08 2023 ] Eval epoch: 49
[ Tue Jan  3 22:59:00 2023 ] 	Mean test loss of 796 batches: 0.8010347789368737.
[ Tue Jan  3 22:59:01 2023 ] 	Top1: 78.16%
[ Tue Jan  3 22:59:01 2023 ] 	Top5: 94.84%
[ Tue Jan  3 22:59:01 2023 ] Training epoch: 50
[ Tue Jan  3 23:08:45 2023 ] 	Mean training loss: 0.2059.  Mean training acc: 94.40%.
[ Tue Jan  3 23:08:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:08:45 2023 ] Eval epoch: 50
[ Tue Jan  3 23:12:35 2023 ] 	Mean test loss of 796 batches: 0.9003272510634445.
[ Tue Jan  3 23:12:36 2023 ] 	Top1: 76.34%
[ Tue Jan  3 23:12:37 2023 ] 	Top5: 93.80%
[ Tue Jan  3 23:12:37 2023 ] Training epoch: 51
[ Tue Jan  3 23:22:16 2023 ] 	Mean training loss: 0.2003.  Mean training acc: 94.52%.
[ Tue Jan  3 23:22:16 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:22:16 2023 ] Eval epoch: 51
[ Tue Jan  3 23:26:06 2023 ] 	Mean test loss of 796 batches: 0.8155866336245933.
[ Tue Jan  3 23:26:07 2023 ] 	Top1: 77.76%
[ Tue Jan  3 23:26:08 2023 ] 	Top5: 94.84%
[ Tue Jan  3 23:26:08 2023 ] Training epoch: 52
[ Tue Jan  3 23:35:51 2023 ] 	Mean training loss: 0.2031.  Mean training acc: 94.52%.
[ Tue Jan  3 23:35:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:35:51 2023 ] Eval epoch: 52
[ Tue Jan  3 23:39:26 2023 ] 	Mean test loss of 796 batches: 0.8224377795941566.
[ Tue Jan  3 23:39:27 2023 ] 	Top1: 78.04%
[ Tue Jan  3 23:39:27 2023 ] 	Top5: 94.85%
[ Tue Jan  3 23:39:27 2023 ] Training epoch: 53
[ Tue Jan  3 23:48:57 2023 ] 	Mean training loss: 0.2010.  Mean training acc: 94.52%.
[ Tue Jan  3 23:48:57 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:48:57 2023 ] Eval epoch: 53
[ Tue Jan  3 23:52:23 2023 ] 	Mean test loss of 796 batches: 0.8745097107810891.
[ Tue Jan  3 23:52:24 2023 ] 	Top1: 76.30%
[ Tue Jan  3 23:52:25 2023 ] 	Top5: 94.34%
[ Tue Jan  3 23:52:25 2023 ] Training epoch: 54
[ Wed Jan  4 00:02:08 2023 ] 	Mean training loss: 0.2021.  Mean training acc: 94.44%.
[ Wed Jan  4 00:02:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:02:09 2023 ] Eval epoch: 54
[ Wed Jan  4 00:05:41 2023 ] 	Mean test loss of 796 batches: 0.865009763956669.
[ Wed Jan  4 00:05:41 2023 ] 	Top1: 76.71%
[ Wed Jan  4 00:05:42 2023 ] 	Top5: 94.40%
[ Wed Jan  4 00:05:42 2023 ] Training epoch: 55
[ Wed Jan  4 00:15:11 2023 ] 	Mean training loss: 0.1922.  Mean training acc: 94.79%.
[ Wed Jan  4 00:15:11 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:15:11 2023 ] Eval epoch: 55
[ Wed Jan  4 00:18:31 2023 ] 	Mean test loss of 796 batches: 0.9263582251142317.
[ Wed Jan  4 00:18:31 2023 ] 	Top1: 75.95%
[ Wed Jan  4 00:18:32 2023 ] 	Top5: 93.51%
[ Wed Jan  4 00:18:32 2023 ] Training epoch: 56
[ Wed Jan  4 00:28:15 2023 ] 	Mean training loss: 0.1155.  Mean training acc: 97.28%.
[ Wed Jan  4 00:28:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:28:16 2023 ] Eval epoch: 56
[ Wed Jan  4 00:31:38 2023 ] 	Mean test loss of 796 batches: 0.7629047438371271.
[ Wed Jan  4 00:31:39 2023 ] 	Top1: 79.52%
[ Wed Jan  4 00:31:39 2023 ] 	Top5: 95.33%
[ Wed Jan  4 00:31:39 2023 ] Training epoch: 57
[ Wed Jan  4 00:41:23 2023 ] 	Mean training loss: 0.0855.  Mean training acc: 98.21%.
[ Wed Jan  4 00:41:23 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:41:23 2023 ] Eval epoch: 57
[ Wed Jan  4 00:44:38 2023 ] 	Mean test loss of 796 batches: 0.761833456153022.
[ Wed Jan  4 00:44:39 2023 ] 	Top1: 79.80%
[ Wed Jan  4 00:44:40 2023 ] 	Top5: 95.35%
[ Wed Jan  4 00:44:40 2023 ] Training epoch: 58
[ Wed Jan  4 00:54:29 2023 ] 	Mean training loss: 0.0769.  Mean training acc: 98.45%.
[ Wed Jan  4 00:54:29 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:54:29 2023 ] Eval epoch: 58
[ Wed Jan  4 00:57:57 2023 ] 	Mean test loss of 796 batches: 0.774236270502659.
[ Wed Jan  4 00:57:58 2023 ] 	Top1: 79.59%
[ Wed Jan  4 00:57:59 2023 ] 	Top5: 95.28%
[ Wed Jan  4 00:57:59 2023 ] Training epoch: 59
[ Wed Jan  4 01:07:40 2023 ] 	Mean training loss: 0.0681.  Mean training acc: 98.66%.
[ Wed Jan  4 01:07:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:07:41 2023 ] Eval epoch: 59
[ Wed Jan  4 01:11:11 2023 ] 	Mean test loss of 796 batches: 0.7654594320186119.
[ Wed Jan  4 01:11:12 2023 ] 	Top1: 79.71%
[ Wed Jan  4 01:11:13 2023 ] 	Top5: 95.28%
[ Wed Jan  4 01:11:13 2023 ] Training epoch: 60
[ Wed Jan  4 01:20:30 2023 ] 	Mean training loss: 0.0645.  Mean training acc: 98.80%.
[ Wed Jan  4 01:20:30 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:20:30 2023 ] Eval epoch: 60
[ Wed Jan  4 01:23:56 2023 ] 	Mean test loss of 796 batches: 0.772479600717674.
[ Wed Jan  4 01:23:57 2023 ] 	Top1: 79.62%
[ Wed Jan  4 01:23:58 2023 ] 	Top5: 95.30%
[ Wed Jan  4 01:23:58 2023 ] Training epoch: 61
[ Wed Jan  4 01:33:16 2023 ] 	Mean training loss: 0.0631.  Mean training acc: 98.81%.
[ Wed Jan  4 01:33:16 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:33:16 2023 ] Eval epoch: 61
[ Wed Jan  4 01:36:57 2023 ] 	Mean test loss of 796 batches: 0.7658338435649422.
[ Wed Jan  4 01:36:58 2023 ] 	Top1: 80.02%
[ Wed Jan  4 01:36:59 2023 ] 	Top5: 95.37%
[ Wed Jan  4 01:36:59 2023 ] Training epoch: 62
[ Wed Jan  4 01:46:37 2023 ] 	Mean training loss: 0.0582.  Mean training acc: 99.00%.
[ Wed Jan  4 01:46:38 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:46:38 2023 ] Eval epoch: 62
[ Wed Jan  4 01:50:19 2023 ] 	Mean test loss of 796 batches: 0.7716198440491404.
[ Wed Jan  4 01:50:20 2023 ] 	Top1: 79.97%
[ Wed Jan  4 01:50:20 2023 ] 	Top5: 95.25%
[ Wed Jan  4 01:50:20 2023 ] Training epoch: 63
[ Wed Jan  4 01:59:45 2023 ] 	Mean training loss: 0.0567.  Mean training acc: 99.01%.
[ Wed Jan  4 01:59:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:59:46 2023 ] Eval epoch: 63
[ Wed Jan  4 02:03:27 2023 ] 	Mean test loss of 796 batches: 0.773933668475804.
[ Wed Jan  4 02:03:27 2023 ] 	Top1: 79.83%
[ Wed Jan  4 02:03:28 2023 ] 	Top5: 95.26%
[ Wed Jan  4 02:03:28 2023 ] Training epoch: 64
[ Wed Jan  4 02:12:40 2023 ] 	Mean training loss: 0.0523.  Mean training acc: 99.14%.
[ Wed Jan  4 02:12:40 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:12:40 2023 ] Eval epoch: 64
[ Wed Jan  4 02:16:32 2023 ] 	Mean test loss of 796 batches: 0.7653036704801734.
[ Wed Jan  4 02:16:33 2023 ] 	Top1: 80.05%
[ Wed Jan  4 02:16:34 2023 ] 	Top5: 95.39%
[ Wed Jan  4 02:16:34 2023 ] Training epoch: 65
[ Wed Jan  4 02:25:29 2023 ] 	Mean training loss: 0.0526.  Mean training acc: 99.09%.
[ Wed Jan  4 02:25:29 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:25:30 2023 ] Eval epoch: 65
[ Wed Jan  4 02:28:57 2023 ] 	Mean test loss of 796 batches: 0.7692836209214363.
[ Wed Jan  4 02:28:58 2023 ] 	Top1: 80.01%
[ Wed Jan  4 02:28:58 2023 ] 	Top5: 95.30%
[ Wed Jan  4 02:32:08 2023 ] Best accuracy: 0.8007227164712583
[ Wed Jan  4 02:32:09 2023 ] Epoch number: 1
[ Wed Jan  4 02:32:09 2023 ] Model name: work_dir/csub/local_SHTg_bonevel_BL
[ Wed Jan  4 02:32:09 2023 ] Model total number of params: 2141090
[ Wed Jan  4 02:32:09 2023 ] Weight decay: 0.0004
[ Wed Jan  4 02:32:09 2023 ] Base LR: 0.1
[ Wed Jan  4 02:32:09 2023 ] Batch Size: 64
[ Wed Jan  4 02:32:09 2023 ] Test Batch Size: 64
[ Wed Jan  4 02:32:09 2023 ] seed: 1
[ Fri Jan 13 18:30:35 2023 ] Load weights from work_dir/csub/local_SHT_bonevel_BL/runs-20-19680.pt.
[ Fri Jan 13 18:30:39 2023 ] using warm up, epoch: 0
[ Fri Jan 13 18:30:53 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bonevel_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bonevel_BL/runs', 'config': 'config/nturgbd120-cross-subject/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/local_SHT_bonevel_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [5], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Fri Jan 13 18:30:53 2023 ] # Parameters: 2141090
[ Fri Jan 13 18:30:53 2023 ] Training epoch: 21
[ Fri Jan 13 18:35:46 2023 ] 	Mean training loss: 0.9363.  Mean training acc: 72.52%.
[ Fri Jan 13 18:35:46 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 18:35:46 2023 ] Eval epoch: 21
[ Fri Jan 13 18:37:55 2023 ] 	Mean test loss of 796 batches: 1.3355164837897124.
[ Fri Jan 13 18:37:56 2023 ] 	Top1: 63.03%
[ Fri Jan 13 18:37:56 2023 ] 	Top5: 87.92%
[ Fri Jan 13 18:37:57 2023 ] Training epoch: 22
[ Fri Jan 13 18:43:11 2023 ] 	Mean training loss: 0.9289.  Mean training acc: 72.59%.
[ Fri Jan 13 18:43:11 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 18:43:11 2023 ] Eval epoch: 22
[ Fri Jan 13 18:45:27 2023 ] 	Mean test loss of 796 batches: 1.1815369775771496.
[ Fri Jan 13 18:45:28 2023 ] 	Top1: 65.39%
[ Fri Jan 13 18:45:28 2023 ] 	Top5: 91.00%
[ Fri Jan 13 18:45:28 2023 ] Training epoch: 23
[ Fri Jan 13 18:50:49 2023 ] 	Mean training loss: 0.9225.  Mean training acc: 72.61%.
[ Fri Jan 13 18:50:49 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 18:50:49 2023 ] Eval epoch: 23
[ Fri Jan 13 18:52:57 2023 ] 	Mean test loss of 796 batches: 1.3593007199578548.
[ Fri Jan 13 18:52:58 2023 ] 	Top1: 60.60%
[ Fri Jan 13 18:52:58 2023 ] 	Top5: 88.26%
[ Fri Jan 13 18:52:58 2023 ] Training epoch: 24
[ Fri Jan 13 18:57:47 2023 ] 	Mean training loss: 0.9216.  Mean training acc: 72.81%.
[ Fri Jan 13 18:57:47 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 18:57:47 2023 ] Eval epoch: 24
[ Fri Jan 13 18:59:47 2023 ] 	Mean test loss of 796 batches: 1.5250902399046338.
[ Fri Jan 13 18:59:48 2023 ] 	Top1: 59.00%
[ Fri Jan 13 18:59:48 2023 ] 	Top5: 86.54%
[ Fri Jan 13 18:59:48 2023 ] Training epoch: 25
[ Fri Jan 13 19:04:37 2023 ] 	Mean training loss: 0.9136.  Mean training acc: 72.98%.
[ Fri Jan 13 19:04:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:04:37 2023 ] Eval epoch: 25
[ Fri Jan 13 19:06:44 2023 ] 	Mean test loss of 796 batches: 1.532298895993724.
[ Fri Jan 13 19:06:44 2023 ] 	Top1: 57.90%
[ Fri Jan 13 19:06:45 2023 ] 	Top5: 86.58%
[ Fri Jan 13 19:06:45 2023 ] Training epoch: 26
[ Fri Jan 13 19:11:57 2023 ] 	Mean training loss: 0.9058.  Mean training acc: 73.32%.
[ Fri Jan 13 19:11:57 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:11:57 2023 ] Eval epoch: 26
[ Fri Jan 13 19:14:04 2023 ] 	Mean test loss of 796 batches: 1.137058349298173.
[ Fri Jan 13 19:14:05 2023 ] 	Top1: 67.55%
[ Fri Jan 13 19:14:05 2023 ] 	Top5: 91.35%
[ Fri Jan 13 19:14:05 2023 ] Training epoch: 27
[ Fri Jan 13 19:19:13 2023 ] 	Mean training loss: 0.8923.  Mean training acc: 73.49%.
[ Fri Jan 13 19:19:13 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:19:13 2023 ] Eval epoch: 27
[ Fri Jan 13 19:21:16 2023 ] 	Mean test loss of 796 batches: 1.3937311619145787.
[ Fri Jan 13 19:21:17 2023 ] 	Top1: 61.02%
[ Fri Jan 13 19:21:17 2023 ] 	Top5: 89.10%
[ Fri Jan 13 19:21:17 2023 ] Training epoch: 28
[ Fri Jan 13 19:26:03 2023 ] 	Mean training loss: 0.8914.  Mean training acc: 73.67%.
[ Fri Jan 13 19:26:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:26:03 2023 ] Eval epoch: 28
[ Fri Jan 13 19:28:06 2023 ] 	Mean test loss of 796 batches: 1.4847605293195452.
[ Fri Jan 13 19:28:06 2023 ] 	Top1: 60.01%
[ Fri Jan 13 19:28:07 2023 ] 	Top5: 86.79%
[ Fri Jan 13 19:28:07 2023 ] Training epoch: 29
[ Fri Jan 13 19:33:03 2023 ] 	Mean training loss: 0.8876.  Mean training acc: 73.70%.
[ Fri Jan 13 19:33:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:33:03 2023 ] Eval epoch: 29
[ Fri Jan 13 19:35:09 2023 ] 	Mean test loss of 796 batches: 1.8109782919587203.
[ Fri Jan 13 19:35:10 2023 ] 	Top1: 54.18%
[ Fri Jan 13 19:35:10 2023 ] 	Top5: 81.94%
[ Fri Jan 13 19:35:10 2023 ] Training epoch: 30
[ Fri Jan 13 19:40:24 2023 ] 	Mean training loss: 0.8883.  Mean training acc: 73.84%.
[ Fri Jan 13 19:40:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:40:24 2023 ] Eval epoch: 30
[ Fri Jan 13 19:42:32 2023 ] 	Mean test loss of 796 batches: 1.2381063740906404.
[ Fri Jan 13 19:42:32 2023 ] 	Top1: 65.68%
[ Fri Jan 13 19:42:33 2023 ] 	Top5: 89.83%
[ Fri Jan 13 19:42:33 2023 ] Training epoch: 31
[ Fri Jan 13 19:47:37 2023 ] 	Mean training loss: 0.8810.  Mean training acc: 73.82%.
[ Fri Jan 13 19:47:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:47:37 2023 ] Eval epoch: 31
[ Fri Jan 13 19:49:38 2023 ] 	Mean test loss of 796 batches: 1.1114613690118693.
[ Fri Jan 13 19:49:38 2023 ] 	Top1: 67.77%
[ Fri Jan 13 19:49:39 2023 ] 	Top5: 91.33%
[ Fri Jan 13 19:49:39 2023 ] Training epoch: 32
[ Fri Jan 13 19:54:27 2023 ] 	Mean training loss: 0.8807.  Mean training acc: 73.94%.
[ Fri Jan 13 19:54:27 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 19:54:27 2023 ] Eval epoch: 32
[ Fri Jan 13 19:56:27 2023 ] 	Mean test loss of 796 batches: 1.2195263075169607.
[ Fri Jan 13 19:56:28 2023 ] 	Top1: 64.37%
[ Fri Jan 13 19:56:28 2023 ] 	Top5: 90.08%
[ Fri Jan 13 19:56:28 2023 ] Training epoch: 33
[ Fri Jan 13 20:01:29 2023 ] 	Mean training loss: 0.8687.  Mean training acc: 74.43%.
[ Fri Jan 13 20:01:29 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:01:29 2023 ] Eval epoch: 33
[ Fri Jan 13 20:03:39 2023 ] 	Mean test loss of 796 batches: 1.3377386283260495.
[ Fri Jan 13 20:03:39 2023 ] 	Top1: 62.34%
[ Fri Jan 13 20:03:40 2023 ] 	Top5: 88.56%
[ Fri Jan 13 20:03:40 2023 ] Training epoch: 34
[ Fri Jan 13 20:08:53 2023 ] 	Mean training loss: 0.8665.  Mean training acc: 74.43%.
[ Fri Jan 13 20:08:53 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:08:53 2023 ] Eval epoch: 34
[ Fri Jan 13 20:11:00 2023 ] 	Mean test loss of 796 batches: 1.1648493564533229.
[ Fri Jan 13 20:11:01 2023 ] 	Top1: 65.95%
[ Fri Jan 13 20:11:01 2023 ] 	Top5: 91.31%
[ Fri Jan 13 20:11:01 2023 ] Training epoch: 35
[ Fri Jan 13 20:16:00 2023 ] 	Mean training loss: 0.8668.  Mean training acc: 74.45%.
[ Fri Jan 13 20:16:00 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:16:01 2023 ] Eval epoch: 35
[ Fri Jan 13 20:18:00 2023 ] 	Mean test loss of 796 batches: 1.1405874121204094.
[ Fri Jan 13 20:18:01 2023 ] 	Top1: 66.66%
[ Fri Jan 13 20:18:01 2023 ] 	Top5: 91.11%
[ Fri Jan 13 20:18:01 2023 ] Training epoch: 36
[ Fri Jan 13 20:22:44 2023 ] 	Mean training loss: 0.5079.  Mean training acc: 85.11%.
[ Fri Jan 13 20:22:44 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:22:44 2023 ] Eval epoch: 36
[ Fri Jan 13 20:24:46 2023 ] 	Mean test loss of 796 batches: 0.6947647053093168.
[ Fri Jan 13 20:24:46 2023 ] 	Top1: 78.96%
[ Fri Jan 13 20:24:47 2023 ] 	Top5: 95.76%
[ Fri Jan 13 20:24:47 2023 ] Training epoch: 37
[ Fri Jan 13 20:29:55 2023 ] 	Mean training loss: 0.4123.  Mean training acc: 87.97%.
[ Fri Jan 13 20:29:55 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:29:55 2023 ] Eval epoch: 37
[ Fri Jan 13 20:32:04 2023 ] 	Mean test loss of 796 batches: 0.6890758326717058.
[ Fri Jan 13 20:32:04 2023 ] 	Top1: 79.28%
[ Fri Jan 13 20:32:05 2023 ] 	Top5: 95.84%
[ Fri Jan 13 20:32:05 2023 ] Training epoch: 38
[ Fri Jan 13 20:37:20 2023 ] 	Mean training loss: 0.3697.  Mean training acc: 89.07%.
[ Fri Jan 13 20:37:20 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:37:20 2023 ] Eval epoch: 38
[ Fri Jan 13 20:39:26 2023 ] 	Mean test loss of 796 batches: 0.6805072107993478.
[ Fri Jan 13 20:39:26 2023 ] 	Top1: 79.78%
[ Fri Jan 13 20:39:27 2023 ] 	Top5: 95.97%
[ Fri Jan 13 20:39:27 2023 ] Training epoch: 39
[ Fri Jan 13 20:44:15 2023 ] 	Mean training loss: 0.3341.  Mean training acc: 90.21%.
[ Fri Jan 13 20:44:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:44:15 2023 ] Eval epoch: 39
[ Fri Jan 13 20:46:14 2023 ] 	Mean test loss of 796 batches: 0.6998833916220234.
[ Fri Jan 13 20:46:14 2023 ] 	Top1: 79.12%
[ Fri Jan 13 20:46:14 2023 ] 	Top5: 95.71%
[ Fri Jan 13 20:46:14 2023 ] Training epoch: 40
[ Fri Jan 13 20:50:58 2023 ] 	Mean training loss: 0.3060.  Mean training acc: 91.20%.
[ Fri Jan 13 20:50:58 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:50:58 2023 ] Eval epoch: 40
[ Fri Jan 13 20:52:55 2023 ] 	Mean test loss of 796 batches: 0.7001142438089278.
[ Fri Jan 13 20:52:56 2023 ] 	Top1: 79.51%
[ Fri Jan 13 20:52:56 2023 ] 	Top5: 95.78%
[ Fri Jan 13 20:52:56 2023 ] Training epoch: 41
[ Fri Jan 13 20:58:12 2023 ] 	Mean training loss: 0.2809.  Mean training acc: 91.97%.
[ Fri Jan 13 20:58:12 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 20:58:12 2023 ] Eval epoch: 41
[ Fri Jan 13 21:00:20 2023 ] 	Mean test loss of 796 batches: 0.7494813845441419.
[ Fri Jan 13 21:00:20 2023 ] 	Top1: 78.40%
[ Fri Jan 13 21:00:21 2023 ] 	Top5: 95.45%
[ Fri Jan 13 21:00:21 2023 ] Training epoch: 42
[ Fri Jan 13 21:05:34 2023 ] 	Mean training loss: 0.2634.  Mean training acc: 92.49%.
[ Fri Jan 13 21:05:34 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:05:34 2023 ] Eval epoch: 42
[ Fri Jan 13 21:07:40 2023 ] 	Mean test loss of 796 batches: 0.7010498267210009.
[ Fri Jan 13 21:07:40 2023 ] 	Top1: 79.40%
[ Fri Jan 13 21:07:41 2023 ] 	Top5: 95.86%
[ Fri Jan 13 21:07:41 2023 ] Training epoch: 43
[ Fri Jan 13 21:12:22 2023 ] 	Mean training loss: 0.2471.  Mean training acc: 93.05%.
[ Fri Jan 13 21:12:22 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:12:22 2023 ] Eval epoch: 43
[ Fri Jan 13 21:14:20 2023 ] 	Mean test loss of 796 batches: 0.7418944373277564.
[ Fri Jan 13 21:14:20 2023 ] 	Top1: 78.85%
[ Fri Jan 13 21:14:21 2023 ] 	Top5: 95.22%
[ Fri Jan 13 21:14:21 2023 ] Training epoch: 44
[ Fri Jan 13 21:19:04 2023 ] 	Mean training loss: 0.2340.  Mean training acc: 93.47%.
[ Fri Jan 13 21:19:04 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:19:04 2023 ] Eval epoch: 44
[ Fri Jan 13 21:21:10 2023 ] 	Mean test loss of 796 batches: 0.7686590831352389.
[ Fri Jan 13 21:21:10 2023 ] 	Top1: 78.41%
[ Fri Jan 13 21:21:11 2023 ] 	Top5: 95.16%
[ Fri Jan 13 21:21:11 2023 ] Training epoch: 45
[ Fri Jan 13 21:26:26 2023 ] 	Mean training loss: 0.2278.  Mean training acc: 93.72%.
[ Fri Jan 13 21:26:26 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:26:26 2023 ] Eval epoch: 45
[ Fri Jan 13 21:28:34 2023 ] 	Mean test loss of 796 batches: 0.784756550574722.
[ Fri Jan 13 21:28:35 2023 ] 	Top1: 78.09%
[ Fri Jan 13 21:28:35 2023 ] 	Top5: 95.16%
[ Fri Jan 13 21:28:35 2023 ] Training epoch: 46
[ Fri Jan 13 21:33:48 2023 ] 	Mean training loss: 0.2189.  Mean training acc: 94.01%.
[ Fri Jan 13 21:33:48 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:33:48 2023 ] Eval epoch: 46
[ Fri Jan 13 21:35:50 2023 ] 	Mean test loss of 796 batches: 0.9206758864298837.
[ Fri Jan 13 21:35:51 2023 ] 	Top1: 75.38%
[ Fri Jan 13 21:35:51 2023 ] 	Top5: 93.81%
[ Fri Jan 13 21:35:51 2023 ] Training epoch: 47
[ Fri Jan 13 21:40:37 2023 ] 	Mean training loss: 0.2125.  Mean training acc: 94.19%.
[ Fri Jan 13 21:40:38 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:40:38 2023 ] Eval epoch: 47
[ Fri Jan 13 21:42:39 2023 ] 	Mean test loss of 796 batches: 0.832771021928919.
[ Fri Jan 13 21:42:39 2023 ] 	Top1: 76.58%
[ Fri Jan 13 21:42:40 2023 ] 	Top5: 94.89%
[ Fri Jan 13 21:42:40 2023 ] Training epoch: 48
[ Fri Jan 13 21:47:31 2023 ] 	Mean training loss: 0.2083.  Mean training acc: 94.26%.
[ Fri Jan 13 21:47:31 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:47:31 2023 ] Eval epoch: 48
[ Fri Jan 13 21:49:39 2023 ] 	Mean test loss of 796 batches: 0.8031255579249343.
[ Fri Jan 13 21:49:39 2023 ] 	Top1: 77.80%
[ Fri Jan 13 21:49:40 2023 ] 	Top5: 94.98%
[ Fri Jan 13 21:49:40 2023 ] Training epoch: 49
[ Fri Jan 13 21:54:53 2023 ] 	Mean training loss: 0.2057.  Mean training acc: 94.25%.
[ Fri Jan 13 21:54:53 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 21:54:53 2023 ] Eval epoch: 49
[ Fri Jan 13 21:56:59 2023 ] 	Mean test loss of 796 batches: 0.8054024687776314.
[ Fri Jan 13 21:57:00 2023 ] 	Top1: 77.86%
[ Fri Jan 13 21:57:00 2023 ] 	Top5: 94.79%
[ Fri Jan 13 21:57:00 2023 ] Training epoch: 50
[ Fri Jan 13 22:02:11 2023 ] 	Mean training loss: 0.2077.  Mean training acc: 94.26%.
[ Fri Jan 13 22:02:11 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:02:11 2023 ] Eval epoch: 50
[ Fri Jan 13 22:04:12 2023 ] 	Mean test loss of 796 batches: 0.8343748024491658.
[ Fri Jan 13 22:04:13 2023 ] 	Top1: 77.47%
[ Fri Jan 13 22:04:13 2023 ] 	Top5: 94.45%
[ Fri Jan 13 22:04:13 2023 ] Training epoch: 51
[ Fri Jan 13 22:09:01 2023 ] 	Mean training loss: 0.2049.  Mean training acc: 94.33%.
[ Fri Jan 13 22:09:01 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:09:01 2023 ] Eval epoch: 51
[ Fri Jan 13 22:11:05 2023 ] 	Mean test loss of 796 batches: 0.8595010495309404.
[ Fri Jan 13 22:11:05 2023 ] 	Top1: 76.91%
[ Fri Jan 13 22:11:06 2023 ] 	Top5: 94.37%
[ Fri Jan 13 22:11:06 2023 ] Training epoch: 52
[ Fri Jan 13 22:16:00 2023 ] 	Mean training loss: 0.2008.  Mean training acc: 94.58%.
[ Fri Jan 13 22:16:00 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:16:00 2023 ] Eval epoch: 52
[ Fri Jan 13 22:18:06 2023 ] 	Mean test loss of 796 batches: 0.8515281512509638.
[ Fri Jan 13 22:18:07 2023 ] 	Top1: 76.81%
[ Fri Jan 13 22:18:07 2023 ] 	Top5: 94.73%
[ Fri Jan 13 22:18:07 2023 ] Training epoch: 53
[ Fri Jan 13 22:23:23 2023 ] 	Mean training loss: 0.2005.  Mean training acc: 94.53%.
[ Fri Jan 13 22:23:23 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:23:23 2023 ] Eval epoch: 53
[ Fri Jan 13 22:25:29 2023 ] 	Mean test loss of 796 batches: 0.8607693451208684.
[ Fri Jan 13 22:25:29 2023 ] 	Top1: 77.16%
[ Fri Jan 13 22:25:29 2023 ] 	Top5: 94.21%
[ Fri Jan 13 22:25:30 2023 ] Training epoch: 54
[ Fri Jan 13 22:30:35 2023 ] 	Mean training loss: 0.2038.  Mean training acc: 94.33%.
[ Fri Jan 13 22:30:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:30:35 2023 ] Eval epoch: 54
[ Fri Jan 13 22:32:38 2023 ] 	Mean test loss of 796 batches: 0.8799637816097569.
[ Fri Jan 13 22:32:39 2023 ] 	Top1: 76.87%
[ Fri Jan 13 22:32:39 2023 ] 	Top5: 94.15%
[ Fri Jan 13 22:32:39 2023 ] Training epoch: 55
[ Fri Jan 13 22:37:28 2023 ] 	Mean training loss: 0.1943.  Mean training acc: 94.73%.
[ Fri Jan 13 22:37:28 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:37:28 2023 ] Eval epoch: 55
[ Fri Jan 13 22:39:29 2023 ] 	Mean test loss of 796 batches: 0.8597084825493433.
[ Fri Jan 13 22:39:30 2023 ] 	Top1: 76.93%
[ Fri Jan 13 22:39:30 2023 ] 	Top5: 94.19%
[ Fri Jan 13 22:39:30 2023 ] Training epoch: 56
[ Fri Jan 13 22:44:29 2023 ] 	Mean training loss: 0.1158.  Mean training acc: 97.40%.
[ Fri Jan 13 22:44:29 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:44:29 2023 ] Eval epoch: 56
[ Fri Jan 13 22:46:34 2023 ] 	Mean test loss of 796 batches: 0.7517512489634393.
[ Fri Jan 13 22:46:34 2023 ] 	Top1: 79.52%
[ Fri Jan 13 22:46:35 2023 ] 	Top5: 95.42%
[ Fri Jan 13 22:46:35 2023 ] Training epoch: 57
[ Fri Jan 13 22:51:45 2023 ] 	Mean training loss: 0.0866.  Mean training acc: 98.18%.
[ Fri Jan 13 22:51:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:51:45 2023 ] Eval epoch: 57
[ Fri Jan 13 22:53:50 2023 ] 	Mean test loss of 796 batches: 0.7502432364184204.
[ Fri Jan 13 22:53:50 2023 ] 	Top1: 79.86%
[ Fri Jan 13 22:53:51 2023 ] 	Top5: 95.47%
[ Fri Jan 13 22:53:51 2023 ] Training epoch: 58
[ Fri Jan 13 22:58:52 2023 ] 	Mean training loss: 0.0770.  Mean training acc: 98.49%.
[ Fri Jan 13 22:58:52 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 22:58:52 2023 ] Eval epoch: 58
[ Fri Jan 13 23:00:53 2023 ] 	Mean test loss of 796 batches: 0.7567373904956496.
[ Fri Jan 13 23:00:54 2023 ] 	Top1: 79.61%
[ Fri Jan 13 23:00:54 2023 ] 	Top5: 95.34%
[ Fri Jan 13 23:00:54 2023 ] Training epoch: 59
[ Fri Jan 13 23:05:43 2023 ] 	Mean training loss: 0.0689.  Mean training acc: 98.67%.
[ Fri Jan 13 23:05:43 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:05:43 2023 ] Eval epoch: 59
[ Fri Jan 13 23:07:47 2023 ] 	Mean test loss of 796 batches: 0.753629135632485.
[ Fri Jan 13 23:07:47 2023 ] 	Top1: 79.67%
[ Fri Jan 13 23:07:48 2023 ] 	Top5: 95.43%
[ Fri Jan 13 23:07:48 2023 ] Training epoch: 60
[ Fri Jan 13 23:12:50 2023 ] 	Mean training loss: 0.0645.  Mean training acc: 98.81%.
[ Fri Jan 13 23:12:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:12:50 2023 ] Eval epoch: 60
[ Fri Jan 13 23:14:56 2023 ] 	Mean test loss of 796 batches: 0.7559952286713237.
[ Fri Jan 13 23:14:56 2023 ] 	Top1: 79.81%
[ Fri Jan 13 23:14:56 2023 ] 	Top5: 95.36%
[ Fri Jan 13 23:14:57 2023 ] Training epoch: 61
[ Fri Jan 13 23:20:09 2023 ] 	Mean training loss: 0.0642.  Mean training acc: 98.77%.
[ Fri Jan 13 23:20:09 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jan 13 23:20:09 2023 ] Eval epoch: 61
[ Fri Jan 13 23:22:12 2023 ] 	Mean test loss of 796 batches: 0.7558056639423173.
[ Fri Jan 13 23:22:13 2023 ] 	Top1: 79.83%
[ Fri Jan 13 23:22:13 2023 ] 	Top5: 95.43%
[ Fri Jan 13 23:22:13 2023 ] Training epoch: 62
[ Fri Jan 13 23:27:08 2023 ] 	Mean training loss: 0.0587.  Mean training acc: 98.96%.
[ Fri Jan 13 23:27:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:27:08 2023 ] Eval epoch: 62
[ Fri Jan 13 23:29:11 2023 ] 	Mean test loss of 796 batches: 0.7681236638776471.
[ Fri Jan 13 23:29:11 2023 ] 	Top1: 79.78%
[ Fri Jan 13 23:29:12 2023 ] 	Top5: 95.19%
[ Fri Jan 13 23:29:12 2023 ] Training epoch: 63
[ Fri Jan 13 23:33:59 2023 ] 	Mean training loss: 0.0574.  Mean training acc: 98.98%.
[ Fri Jan 13 23:33:59 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:33:59 2023 ] Eval epoch: 63
[ Fri Jan 13 23:35:59 2023 ] 	Mean test loss of 796 batches: 0.7645152888995543.
[ Fri Jan 13 23:36:00 2023 ] 	Top1: 79.84%
[ Fri Jan 13 23:36:00 2023 ] 	Top5: 95.38%
[ Fri Jan 13 23:36:00 2023 ] Training epoch: 64
[ Fri Jan 13 23:41:12 2023 ] 	Mean training loss: 0.0539.  Mean training acc: 99.08%.
[ Fri Jan 13 23:41:12 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:41:12 2023 ] Eval epoch: 64
[ Fri Jan 13 23:43:18 2023 ] 	Mean test loss of 796 batches: 0.756912836786266.
[ Fri Jan 13 23:43:18 2023 ] 	Top1: 79.92%
[ Fri Jan 13 23:43:19 2023 ] 	Top5: 95.41%
[ Fri Jan 13 23:43:19 2023 ] Training epoch: 65
[ Fri Jan 13 23:48:32 2023 ] 	Mean training loss: 0.0520.  Mean training acc: 99.13%.
[ Fri Jan 13 23:48:32 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Fri Jan 13 23:48:32 2023 ] Eval epoch: 65
[ Fri Jan 13 23:50:39 2023 ] 	Mean test loss of 796 batches: 0.7615931516503869.
[ Fri Jan 13 23:50:40 2023 ] 	Top1: 79.85%
[ Fri Jan 13 23:50:40 2023 ] 	Top5: 95.32%
[ Fri Jan 13 23:52:44 2023 ] Best accuracy: 0.7999175160549108
[ Fri Jan 13 23:52:44 2023 ] Epoch number: 1
[ Fri Jan 13 23:52:44 2023 ] Model name: work_dir/csub/local_SHT_bonevel_BL
[ Fri Jan 13 23:52:44 2023 ] Model total number of params: 2141090
[ Fri Jan 13 23:52:44 2023 ] Weight decay: 0.0004
[ Fri Jan 13 23:52:44 2023 ] Base LR: 0.1
[ Fri Jan 13 23:52:44 2023 ] Batch Size: 64
[ Fri Jan 13 23:52:44 2023 ] Test Batch Size: 64
[ Fri Jan 13 23:52:44 2023 ] seed: 1
[ Mon Jan 30 13:12:42 2023 ] using warm up, epoch: 5
[ Mon Jan 30 13:12:57 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bonevel_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bonevel_BL/runs', 'config': 'config/nturgbd120-cross-subject/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan 30 13:12:57 2023 ] # Parameters: 2141090
[ Mon Jan 30 13:12:57 2023 ] Training epoch: 1
[ Mon Jan 30 13:16:58 2023 ] 	Mean training loss: 3.4694.  Mean training acc: 16.80%.
[ Mon Jan 30 13:16:58 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:16:58 2023 ] Eval epoch: 1
[ Mon Jan 30 13:18:28 2023 ] 	Mean test loss of 796 batches: 2.7783252797534117.
[ Mon Jan 30 13:18:29 2023 ] 	Top1: 25.87%
[ Mon Jan 30 13:18:29 2023 ] 	Top5: 59.73%
[ Mon Jan 30 13:18:29 2023 ] Training epoch: 2
[ Mon Jan 30 13:22:30 2023 ] 	Mean training loss: 2.2131.  Mean training acc: 39.37%.
[ Mon Jan 30 13:22:30 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:22:30 2023 ] Eval epoch: 2
[ Mon Jan 30 13:23:59 2023 ] 	Mean test loss of 796 batches: 2.5551275742712933.
[ Mon Jan 30 13:24:00 2023 ] 	Top1: 35.40%
[ Mon Jan 30 13:24:00 2023 ] 	Top5: 69.39%
[ Mon Jan 30 13:24:00 2023 ] Training epoch: 3
[ Mon Jan 30 13:28:01 2023 ] 	Mean training loss: 1.7227.  Mean training acc: 51.20%.
[ Mon Jan 30 13:28:01 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:28:01 2023 ] Eval epoch: 3
[ Mon Jan 30 13:29:32 2023 ] 	Mean test loss of 796 batches: 1.9758256260474123.
[ Mon Jan 30 13:29:32 2023 ] 	Top1: 45.47%
[ Mon Jan 30 13:29:32 2023 ] 	Top5: 78.90%
[ Mon Jan 30 13:29:33 2023 ] Training epoch: 4
[ Mon Jan 30 13:33:34 2023 ] 	Mean training loss: 1.5144.  Mean training acc: 56.75%.
[ Mon Jan 30 13:33:34 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:33:34 2023 ] Eval epoch: 4
[ Mon Jan 30 13:35:08 2023 ] 	Mean test loss of 796 batches: 1.6804751104595672.
[ Mon Jan 30 13:35:08 2023 ] 	Top1: 50.87%
[ Mon Jan 30 13:35:08 2023 ] 	Top5: 84.59%
[ Mon Jan 30 13:35:08 2023 ] Training epoch: 5
[ Mon Jan 30 13:39:12 2023 ] 	Mean training loss: 1.4052.  Mean training acc: 59.49%.
[ Mon Jan 30 13:39:12 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:39:13 2023 ] Eval epoch: 5
[ Mon Jan 30 13:40:46 2023 ] 	Mean test loss of 796 batches: 1.717305943145225.
[ Mon Jan 30 13:40:46 2023 ] 	Top1: 50.86%
[ Mon Jan 30 13:40:47 2023 ] 	Top5: 84.03%
[ Mon Jan 30 13:40:47 2023 ] Training epoch: 6
[ Mon Jan 30 13:44:51 2023 ] 	Mean training loss: 1.2893.  Mean training acc: 62.80%.
[ Mon Jan 30 13:44:52 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:44:52 2023 ] Eval epoch: 6
[ Mon Jan 30 13:46:25 2023 ] 	Mean test loss of 796 batches: 1.6639295129021208.
[ Mon Jan 30 13:46:25 2023 ] 	Top1: 53.60%
[ Mon Jan 30 13:46:26 2023 ] 	Top5: 83.83%
[ Mon Jan 30 13:46:26 2023 ] Training epoch: 7
[ Mon Jan 30 13:50:30 2023 ] 	Mean training loss: 1.2045.  Mean training acc: 64.97%.
[ Mon Jan 30 13:50:30 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:50:30 2023 ] Eval epoch: 7
[ Mon Jan 30 13:52:03 2023 ] 	Mean test loss of 796 batches: 1.4668549264046415.
[ Mon Jan 30 13:52:04 2023 ] 	Top1: 58.47%
[ Mon Jan 30 13:52:04 2023 ] 	Top5: 87.68%
[ Mon Jan 30 13:52:05 2023 ] Training epoch: 8
[ Mon Jan 30 13:56:09 2023 ] 	Mean training loss: 1.1615.  Mean training acc: 66.19%.
[ Mon Jan 30 13:56:09 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 13:57:17 2023 ] Eval epoch: 8
[ Mon Jan 30 13:59:08 2023 ] 	Mean test loss of 796 batches: 2.064363584521428.
[ Mon Jan 30 13:59:09 2023 ] 	Top1: 46.16%
[ Mon Jan 30 13:59:09 2023 ] 	Top5: 79.45%
[ Mon Jan 30 13:59:09 2023 ] Training epoch: 9
[ Mon Jan 30 14:04:29 2023 ] 	Mean training loss: 1.1186.  Mean training acc: 67.33%.
[ Mon Jan 30 14:04:30 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 14:04:30 2023 ] Eval epoch: 9
[ Mon Jan 30 14:07:10 2023 ] 	Mean test loss of 796 batches: 1.954454234871433.
[ Mon Jan 30 14:07:11 2023 ] 	Top1: 48.36%
[ Mon Jan 30 14:07:11 2023 ] 	Top5: 78.14%
[ Mon Jan 30 14:07:11 2023 ] Training epoch: 10
[ Mon Jan 30 14:14:38 2023 ] 	Mean training loss: 1.0963.  Mean training acc: 68.02%.
[ Mon Jan 30 14:14:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 14:14:38 2023 ] Eval epoch: 10
[ Mon Jan 30 14:17:03 2023 ] 	Mean test loss of 796 batches: 1.321190816635762.
[ Mon Jan 30 14:17:03 2023 ] 	Top1: 61.19%
[ Mon Jan 30 14:17:04 2023 ] 	Top5: 88.73%
[ Mon Jan 30 14:17:04 2023 ] Training epoch: 11
[ Mon Jan 30 14:24:36 2023 ] 	Mean training loss: 1.0661.  Mean training acc: 68.69%.
[ Mon Jan 30 14:24:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 14:24:36 2023 ] Eval epoch: 11
[ Mon Jan 30 14:27:17 2023 ] 	Mean test loss of 796 batches: 1.5600174182473714.
[ Mon Jan 30 14:27:17 2023 ] 	Top1: 56.46%
[ Mon Jan 30 14:27:17 2023 ] 	Top5: 85.94%
[ Mon Jan 30 14:27:18 2023 ] Training epoch: 12
[ Mon Jan 30 14:35:19 2023 ] 	Mean training loss: 1.0432.  Mean training acc: 69.39%.
[ Mon Jan 30 14:35:19 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 14:35:19 2023 ] Eval epoch: 12
[ Mon Jan 30 14:37:47 2023 ] 	Mean test loss of 796 batches: 1.4186913931190068.
[ Mon Jan 30 14:37:47 2023 ] 	Top1: 58.67%
[ Mon Jan 30 14:37:48 2023 ] 	Top5: 88.10%
[ Mon Jan 30 14:37:48 2023 ] Training epoch: 13
[ Mon Jan 30 14:44:50 2023 ] 	Mean training loss: 1.0269.  Mean training acc: 69.99%.
[ Mon Jan 30 14:44:50 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 14:44:50 2023 ] Eval epoch: 13
[ Mon Jan 30 14:47:25 2023 ] 	Mean test loss of 796 batches: 1.3525560891358697.
[ Mon Jan 30 14:47:25 2023 ] 	Top1: 60.89%
[ Mon Jan 30 14:47:25 2023 ] 	Top5: 88.38%
[ Mon Jan 30 14:47:25 2023 ] Training epoch: 14
[ Mon Jan 30 14:55:35 2023 ] 	Mean training loss: 1.0063.  Mean training acc: 70.56%.
[ Mon Jan 30 14:55:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 14:55:35 2023 ] Eval epoch: 14
[ Mon Jan 30 14:58:14 2023 ] 	Mean test loss of 796 batches: 1.259455125610433.
[ Mon Jan 30 14:58:15 2023 ] 	Top1: 63.41%
[ Mon Jan 30 14:58:15 2023 ] 	Top5: 89.33%
[ Mon Jan 30 14:58:15 2023 ] Training epoch: 15
[ Mon Jan 30 15:05:37 2023 ] 	Mean training loss: 1.0001.  Mean training acc: 70.51%.
[ Mon Jan 30 15:05:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 15:05:37 2023 ] Eval epoch: 15
[ Mon Jan 30 15:08:00 2023 ] 	Mean test loss of 796 batches: 1.2674601489874586.
[ Mon Jan 30 15:08:01 2023 ] 	Top1: 63.95%
[ Mon Jan 30 15:08:01 2023 ] 	Top5: 89.24%
[ Mon Jan 30 15:08:01 2023 ] Training epoch: 16
[ Mon Jan 30 15:15:56 2023 ] 	Mean training loss: 0.9905.  Mean training acc: 70.97%.
[ Mon Jan 30 15:15:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 15:15:56 2023 ] Eval epoch: 16
[ Mon Jan 30 15:18:29 2023 ] 	Mean test loss of 796 batches: 1.4787606411243803.
[ Mon Jan 30 15:18:30 2023 ] 	Top1: 58.73%
[ Mon Jan 30 15:18:30 2023 ] 	Top5: 86.19%
[ Mon Jan 30 15:18:30 2023 ] Training epoch: 17
[ Mon Jan 30 15:26:44 2023 ] 	Mean training loss: 0.9792.  Mean training acc: 71.24%.
[ Mon Jan 30 15:26:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 15:26:44 2023 ] Eval epoch: 17
[ Mon Jan 30 15:29:04 2023 ] 	Mean test loss of 796 batches: 1.5408459232380642.
[ Mon Jan 30 15:29:04 2023 ] 	Top1: 58.82%
[ Mon Jan 30 15:29:05 2023 ] 	Top5: 86.47%
[ Mon Jan 30 15:29:05 2023 ] Training epoch: 18
[ Mon Jan 30 15:36:49 2023 ] 	Mean training loss: 0.9758.  Mean training acc: 71.41%.
[ Mon Jan 30 15:36:49 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 15:36:49 2023 ] Eval epoch: 18
[ Mon Jan 30 15:39:16 2023 ] 	Mean test loss of 796 batches: 1.2523953575809397.
[ Mon Jan 30 15:39:17 2023 ] 	Top1: 63.25%
[ Mon Jan 30 15:39:17 2023 ] 	Top5: 89.66%
[ Mon Jan 30 15:39:17 2023 ] Training epoch: 19
[ Mon Jan 30 15:47:44 2023 ] 	Mean training loss: 0.9550.  Mean training acc: 71.81%.
[ Mon Jan 30 15:47:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 15:47:44 2023 ] Eval epoch: 19
[ Mon Jan 30 15:50:08 2023 ] 	Mean test loss of 796 batches: 1.5286257003419963.
[ Mon Jan 30 15:50:08 2023 ] 	Top1: 59.86%
[ Mon Jan 30 15:50:09 2023 ] 	Top5: 86.71%
[ Mon Jan 30 15:50:09 2023 ] Training epoch: 20
[ Mon Jan 30 15:57:32 2023 ] 	Mean training loss: 0.9475.  Mean training acc: 71.91%.
[ Mon Jan 30 15:57:32 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 15:57:32 2023 ] Eval epoch: 20
[ Mon Jan 30 15:59:58 2023 ] 	Mean test loss of 796 batches: 1.237848853158891.
[ Mon Jan 30 15:59:59 2023 ] 	Top1: 63.72%
[ Mon Jan 30 15:59:59 2023 ] 	Top5: 90.02%
[ Mon Jan 30 15:59:59 2023 ] Training epoch: 21
[ Mon Jan 30 16:08:16 2023 ] 	Mean training loss: 0.9399.  Mean training acc: 72.38%.
[ Mon Jan 30 16:08:16 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 16:08:16 2023 ] Eval epoch: 21
[ Mon Jan 30 16:10:55 2023 ] 	Mean test loss of 796 batches: 1.2113875890496988.
[ Mon Jan 30 16:10:56 2023 ] 	Top1: 64.80%
[ Mon Jan 30 16:10:56 2023 ] 	Top5: 90.20%
[ Mon Jan 30 16:10:56 2023 ] Training epoch: 22
[ Mon Jan 30 16:18:23 2023 ] 	Mean training loss: 0.9331.  Mean training acc: 72.48%.
[ Mon Jan 30 16:18:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 16:18:23 2023 ] Eval epoch: 22
[ Mon Jan 30 16:20:50 2023 ] 	Mean test loss of 796 batches: 1.9350750136315522.
[ Mon Jan 30 16:20:51 2023 ] 	Top1: 55.35%
[ Mon Jan 30 16:20:51 2023 ] 	Top5: 79.87%
[ Mon Jan 30 16:20:51 2023 ] Training epoch: 23
[ Mon Jan 30 16:28:45 2023 ] 	Mean training loss: 0.9263.  Mean training acc: 72.69%.
[ Mon Jan 30 16:28:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 16:28:45 2023 ] Eval epoch: 23
[ Mon Jan 30 16:31:26 2023 ] 	Mean test loss of 796 batches: 1.3383244756777681.
[ Mon Jan 30 16:31:27 2023 ] 	Top1: 61.36%
[ Mon Jan 30 16:31:27 2023 ] 	Top5: 88.81%
[ Mon Jan 30 16:31:27 2023 ] Training epoch: 24
[ Mon Jan 30 16:39:28 2023 ] 	Mean training loss: 0.9146.  Mean training acc: 73.16%.
[ Mon Jan 30 16:39:28 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 16:39:28 2023 ] Eval epoch: 24
[ Mon Jan 30 16:41:55 2023 ] 	Mean test loss of 796 batches: 1.4374808323143715.
[ Mon Jan 30 16:41:56 2023 ] 	Top1: 60.33%
[ Mon Jan 30 16:41:56 2023 ] 	Top5: 87.05%
[ Mon Jan 30 16:41:56 2023 ] Training epoch: 25
[ Mon Jan 30 16:49:22 2023 ] 	Mean training loss: 0.9158.  Mean training acc: 72.94%.
[ Mon Jan 30 16:49:22 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 16:49:22 2023 ] Eval epoch: 25
[ Mon Jan 30 16:52:04 2023 ] 	Mean test loss of 796 batches: 1.301796773682587.
[ Mon Jan 30 16:52:04 2023 ] 	Top1: 62.56%
[ Mon Jan 30 16:52:05 2023 ] 	Top5: 89.13%
[ Mon Jan 30 16:52:05 2023 ] Training epoch: 26
[ Mon Jan 30 17:00:14 2023 ] 	Mean training loss: 0.9036.  Mean training acc: 73.42%.
[ Mon Jan 30 17:00:14 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:00:14 2023 ] Eval epoch: 26
[ Mon Jan 30 17:02:49 2023 ] 	Mean test loss of 796 batches: 1.256960254518231.
[ Mon Jan 30 17:02:49 2023 ] 	Top1: 64.54%
[ Mon Jan 30 17:02:50 2023 ] 	Top5: 89.61%
[ Mon Jan 30 17:02:50 2023 ] Training epoch: 27
[ Mon Jan 30 17:10:03 2023 ] 	Mean training loss: 0.9035.  Mean training acc: 73.42%.
[ Mon Jan 30 17:10:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:10:03 2023 ] Eval epoch: 27
[ Mon Jan 30 17:12:30 2023 ] 	Mean test loss of 796 batches: 1.5485829602009686.
[ Mon Jan 30 17:12:31 2023 ] 	Top1: 56.74%
[ Mon Jan 30 17:12:31 2023 ] 	Top5: 86.25%
[ Mon Jan 30 17:12:31 2023 ] Training epoch: 28
[ Mon Jan 30 17:20:52 2023 ] 	Mean training loss: 0.8958.  Mean training acc: 73.45%.
[ Mon Jan 30 17:20:52 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:20:52 2023 ] Eval epoch: 28
[ Mon Jan 30 17:23:24 2023 ] 	Mean test loss of 796 batches: 1.3506507947292161.
[ Mon Jan 30 17:23:24 2023 ] 	Top1: 62.39%
[ Mon Jan 30 17:23:25 2023 ] 	Top5: 88.85%
[ Mon Jan 30 17:23:25 2023 ] Training epoch: 29
[ Mon Jan 30 17:31:11 2023 ] 	Mean training loss: 0.8937.  Mean training acc: 73.58%.
[ Mon Jan 30 17:31:11 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:31:11 2023 ] Eval epoch: 29
[ Mon Jan 30 17:33:26 2023 ] 	Mean test loss of 796 batches: 1.4252465142302178.
[ Mon Jan 30 17:33:26 2023 ] 	Top1: 60.46%
[ Mon Jan 30 17:33:27 2023 ] 	Top5: 88.46%
[ Mon Jan 30 17:33:27 2023 ] Training epoch: 30
[ Mon Jan 30 17:41:34 2023 ] 	Mean training loss: 0.8898.  Mean training acc: 74.01%.
[ Mon Jan 30 17:41:34 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:41:34 2023 ] Eval epoch: 30
[ Mon Jan 30 17:44:01 2023 ] 	Mean test loss of 796 batches: 1.2638605107089982.
[ Mon Jan 30 17:44:01 2023 ] 	Top1: 64.82%
[ Mon Jan 30 17:44:02 2023 ] 	Top5: 89.66%
[ Mon Jan 30 17:44:02 2023 ] Training epoch: 31
[ Mon Jan 30 17:52:13 2023 ] 	Mean training loss: 0.8800.  Mean training acc: 73.89%.
[ Mon Jan 30 17:52:13 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 17:52:13 2023 ] Eval epoch: 31
[ Mon Jan 30 17:54:30 2023 ] 	Mean test loss of 796 batches: 1.285993457102596.
[ Mon Jan 30 17:54:30 2023 ] 	Top1: 63.45%
[ Mon Jan 30 17:54:31 2023 ] 	Top5: 89.31%
[ Mon Jan 30 17:54:31 2023 ] Training epoch: 32
[ Mon Jan 30 18:02:05 2023 ] 	Mean training loss: 0.8803.  Mean training acc: 73.92%.
[ Mon Jan 30 18:02:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 18:02:05 2023 ] Eval epoch: 32
[ Mon Jan 30 18:04:40 2023 ] 	Mean test loss of 796 batches: 1.15026044108011.
[ Mon Jan 30 18:04:40 2023 ] 	Top1: 66.33%
[ Mon Jan 30 18:04:41 2023 ] 	Top5: 91.15%
[ Mon Jan 30 18:04:41 2023 ] Training epoch: 33
[ Mon Jan 30 18:12:54 2023 ] 	Mean training loss: 0.8783.  Mean training acc: 73.96%.
[ Mon Jan 30 18:12:54 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 18:12:54 2023 ] Eval epoch: 33
[ Mon Jan 30 18:15:29 2023 ] 	Mean test loss of 796 batches: 1.2164353112779072.
[ Mon Jan 30 18:15:29 2023 ] 	Top1: 66.17%
[ Mon Jan 30 18:15:30 2023 ] 	Top5: 89.98%
[ Mon Jan 30 18:15:30 2023 ] Training epoch: 34
[ Mon Jan 30 18:22:41 2023 ] 	Mean training loss: 0.8784.  Mean training acc: 74.03%.
[ Mon Jan 30 18:22:41 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Jan 30 18:22:41 2023 ] Eval epoch: 34
[ Mon Jan 30 18:25:11 2023 ] 	Mean test loss of 796 batches: 1.3040904650586334.
[ Mon Jan 30 18:25:11 2023 ] 	Top1: 63.24%
[ Mon Jan 30 18:25:12 2023 ] 	Top5: 89.09%
[ Mon Jan 30 18:25:12 2023 ] Training epoch: 35
[ Mon Jan 30 18:33:21 2023 ] 	Mean training loss: 0.8715.  Mean training acc: 74.08%.
[ Mon Jan 30 18:33:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 18:33:21 2023 ] Eval epoch: 35
[ Mon Jan 30 18:36:02 2023 ] 	Mean test loss of 796 batches: 1.3337705769206412.
[ Mon Jan 30 18:36:02 2023 ] 	Top1: 62.48%
[ Mon Jan 30 18:36:03 2023 ] 	Top5: 88.48%
[ Mon Jan 30 18:36:03 2023 ] Training epoch: 36
[ Mon Jan 30 18:43:35 2023 ] 	Mean training loss: 0.5196.  Mean training acc: 84.59%.
[ Mon Jan 30 18:43:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 18:43:35 2023 ] Eval epoch: 36
[ Mon Jan 30 18:46:01 2023 ] 	Mean test loss of 796 batches: 0.6873126917111514.
[ Mon Jan 30 18:46:01 2023 ] 	Top1: 79.17%
[ Mon Jan 30 18:46:02 2023 ] 	Top5: 95.63%
[ Mon Jan 30 18:46:02 2023 ] Training epoch: 37
[ Mon Jan 30 18:53:44 2023 ] 	Mean training loss: 0.4151.  Mean training acc: 87.67%.
[ Mon Jan 30 18:53:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 18:53:44 2023 ] Eval epoch: 37
[ Mon Jan 30 18:56:26 2023 ] 	Mean test loss of 796 batches: 0.6705167502277161.
[ Mon Jan 30 18:56:26 2023 ] 	Top1: 79.69%
[ Mon Jan 30 18:56:26 2023 ] 	Top5: 95.87%
[ Mon Jan 30 18:56:26 2023 ] Training epoch: 38
[ Mon Jan 30 19:04:30 2023 ] 	Mean training loss: 0.3756.  Mean training acc: 88.97%.
[ Mon Jan 30 19:04:30 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:04:30 2023 ] Eval epoch: 38
[ Mon Jan 30 19:06:55 2023 ] 	Mean test loss of 796 batches: 0.6887752435464954.
[ Mon Jan 30 19:06:56 2023 ] 	Top1: 79.42%
[ Mon Jan 30 19:06:56 2023 ] 	Top5: 95.68%
[ Mon Jan 30 19:06:56 2023 ] Training epoch: 39
[ Mon Jan 30 19:14:11 2023 ] 	Mean training loss: 0.3391.  Mean training acc: 90.02%.
[ Mon Jan 30 19:14:11 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:14:11 2023 ] Eval epoch: 39
[ Mon Jan 30 19:16:50 2023 ] 	Mean test loss of 796 batches: 0.6842831266510426.
[ Mon Jan 30 19:16:50 2023 ] 	Top1: 79.49%
[ Mon Jan 30 19:16:51 2023 ] 	Top5: 95.85%
[ Mon Jan 30 19:16:51 2023 ] Training epoch: 40
[ Mon Jan 30 19:25:11 2023 ] 	Mean training loss: 0.3145.  Mean training acc: 90.77%.
[ Mon Jan 30 19:25:11 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:25:11 2023 ] Eval epoch: 40
[ Mon Jan 30 19:27:43 2023 ] 	Mean test loss of 796 batches: 0.6877270981332465.
[ Mon Jan 30 19:27:44 2023 ] 	Top1: 79.67%
[ Mon Jan 30 19:27:44 2023 ] 	Top5: 95.84%
[ Mon Jan 30 19:27:44 2023 ] Training epoch: 41
[ Mon Jan 30 19:35:12 2023 ] 	Mean training loss: 0.2912.  Mean training acc: 91.56%.
[ Mon Jan 30 19:35:12 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:35:12 2023 ] Eval epoch: 41
[ Mon Jan 30 19:37:28 2023 ] 	Mean test loss of 796 batches: 0.7165161031649341.
[ Mon Jan 30 19:37:28 2023 ] 	Top1: 78.80%
[ Mon Jan 30 19:37:28 2023 ] 	Top5: 95.64%
[ Mon Jan 30 19:37:29 2023 ] Training epoch: 42
[ Mon Jan 30 19:45:52 2023 ] 	Mean training loss: 0.2736.  Mean training acc: 92.21%.
[ Mon Jan 30 19:45:52 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:45:52 2023 ] Eval epoch: 42
[ Mon Jan 30 19:48:22 2023 ] 	Mean test loss of 796 batches: 0.7127455653594666.
[ Mon Jan 30 19:48:22 2023 ] 	Top1: 79.22%
[ Mon Jan 30 19:48:22 2023 ] 	Top5: 95.56%
[ Mon Jan 30 19:48:22 2023 ] Training epoch: 43
[ Mon Jan 30 19:56:15 2023 ] 	Mean training loss: 0.2608.  Mean training acc: 92.62%.
[ Mon Jan 30 19:56:15 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 19:56:15 2023 ] Eval epoch: 43
[ Mon Jan 30 19:58:35 2023 ] 	Mean test loss of 796 batches: 0.7432761072045445.
[ Mon Jan 30 19:58:35 2023 ] 	Top1: 78.73%
[ Mon Jan 30 19:58:35 2023 ] 	Top5: 95.33%
[ Mon Jan 30 19:58:36 2023 ] Training epoch: 44
[ Mon Jan 30 20:06:31 2023 ] 	Mean training loss: 0.2435.  Mean training acc: 93.18%.
[ Mon Jan 30 20:06:31 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:06:31 2023 ] Eval epoch: 44
[ Mon Jan 30 20:09:09 2023 ] 	Mean test loss of 796 batches: 0.728457291268898.
[ Mon Jan 30 20:09:09 2023 ] 	Top1: 79.05%
[ Mon Jan 30 20:09:09 2023 ] 	Top5: 95.58%
[ Mon Jan 30 20:09:09 2023 ] Training epoch: 45
[ Mon Jan 30 20:17:12 2023 ] 	Mean training loss: 0.2341.  Mean training acc: 93.29%.
[ Mon Jan 30 20:17:12 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:17:12 2023 ] Eval epoch: 45
[ Mon Jan 30 20:19:39 2023 ] 	Mean test loss of 796 batches: 0.7858510195141911.
[ Mon Jan 30 20:19:40 2023 ] 	Top1: 77.93%
[ Mon Jan 30 20:19:40 2023 ] 	Top5: 94.96%
[ Mon Jan 30 20:19:40 2023 ] Training epoch: 46
[ Mon Jan 30 20:26:54 2023 ] 	Mean training loss: 0.2238.  Mean training acc: 93.78%.
[ Mon Jan 30 20:26:54 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:26:54 2023 ] Eval epoch: 46
[ Mon Jan 30 20:29:35 2023 ] 	Mean test loss of 796 batches: 0.7912118472346109.
[ Mon Jan 30 20:29:35 2023 ] 	Top1: 78.03%
[ Mon Jan 30 20:29:36 2023 ] 	Top5: 95.03%
[ Mon Jan 30 20:29:36 2023 ] Training epoch: 47
[ Mon Jan 30 20:37:45 2023 ] 	Mean training loss: 0.2167.  Mean training acc: 93.92%.
[ Mon Jan 30 20:37:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:37:45 2023 ] Eval epoch: 47
[ Mon Jan 30 20:40:27 2023 ] 	Mean test loss of 796 batches: 0.7666015018283123.
[ Mon Jan 30 20:40:28 2023 ] 	Top1: 79.06%
[ Mon Jan 30 20:40:28 2023 ] 	Top5: 95.06%
[ Mon Jan 30 20:40:28 2023 ] Training epoch: 48
[ Mon Jan 30 20:47:39 2023 ] 	Mean training loss: 0.2148.  Mean training acc: 94.07%.
[ Mon Jan 30 20:47:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:47:39 2023 ] Eval epoch: 48
[ Mon Jan 30 20:50:05 2023 ] 	Mean test loss of 796 batches: 0.8084044687768173.
[ Mon Jan 30 20:50:06 2023 ] 	Top1: 77.78%
[ Mon Jan 30 20:50:06 2023 ] 	Top5: 94.61%
[ Mon Jan 30 20:50:06 2023 ] Training epoch: 49
[ Mon Jan 30 20:58:16 2023 ] 	Mean training loss: 0.2176.  Mean training acc: 93.93%.
[ Mon Jan 30 20:58:16 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 20:58:16 2023 ] Eval epoch: 49
[ Mon Jan 30 21:00:57 2023 ] 	Mean test loss of 796 batches: 0.8138657327385703.
[ Mon Jan 30 21:00:57 2023 ] 	Top1: 77.98%
[ Mon Jan 30 21:00:57 2023 ] 	Top5: 94.68%
[ Mon Jan 30 21:00:57 2023 ] Training epoch: 50
[ Mon Jan 30 21:08:33 2023 ] 	Mean training loss: 0.2130.  Mean training acc: 94.16%.
[ Mon Jan 30 21:08:33 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 21:08:33 2023 ] Eval epoch: 50
[ Mon Jan 30 21:10:57 2023 ] 	Mean test loss of 796 batches: 0.8013780131636552.
[ Mon Jan 30 21:10:58 2023 ] 	Top1: 78.13%
[ Mon Jan 30 21:10:58 2023 ] 	Top5: 94.91%
[ Mon Jan 30 21:10:58 2023 ] Training epoch: 51
[ Mon Jan 30 21:18:44 2023 ] 	Mean training loss: 0.2070.  Mean training acc: 94.25%.
[ Mon Jan 30 21:18:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 21:18:44 2023 ] Eval epoch: 51
[ Mon Jan 30 21:21:19 2023 ] 	Mean test loss of 796 batches: 0.8402404272226832.
[ Mon Jan 30 21:21:19 2023 ] 	Top1: 77.42%
[ Mon Jan 30 21:21:20 2023 ] 	Top5: 94.55%
[ Mon Jan 30 21:21:20 2023 ] Training epoch: 52
[ Mon Jan 30 21:29:39 2023 ] 	Mean training loss: 0.2058.  Mean training acc: 94.34%.
[ Mon Jan 30 21:29:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 21:29:39 2023 ] Eval epoch: 52
[ Mon Jan 30 21:31:57 2023 ] 	Mean test loss of 796 batches: 0.880485611457621.
[ Mon Jan 30 21:31:58 2023 ] 	Top1: 76.30%
[ Mon Jan 30 21:31:58 2023 ] 	Top5: 94.30%
[ Mon Jan 30 21:31:58 2023 ] Training epoch: 53
[ Mon Jan 30 21:39:37 2023 ] 	Mean training loss: 0.2067.  Mean training acc: 94.27%.
[ Mon Jan 30 21:39:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 21:39:37 2023 ] Eval epoch: 53
[ Mon Jan 30 21:42:04 2023 ] 	Mean test loss of 796 batches: 0.8405071094482388.
[ Mon Jan 30 21:42:05 2023 ] 	Top1: 77.42%
[ Mon Jan 30 21:42:05 2023 ] 	Top5: 94.71%
[ Mon Jan 30 21:42:05 2023 ] Training epoch: 54
[ Mon Jan 30 21:50:35 2023 ] 	Mean training loss: 0.2054.  Mean training acc: 94.31%.
[ Mon Jan 30 21:50:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 21:50:35 2023 ] Eval epoch: 54
[ Mon Jan 30 21:53:03 2023 ] 	Mean test loss of 796 batches: 0.8358132613626257.
[ Mon Jan 30 21:53:03 2023 ] 	Top1: 77.67%
[ Mon Jan 30 21:53:04 2023 ] 	Top5: 94.77%
[ Mon Jan 30 21:53:04 2023 ] Training epoch: 55
[ Mon Jan 30 22:00:31 2023 ] 	Mean training loss: 0.1995.  Mean training acc: 94.45%.
[ Mon Jan 30 22:00:31 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:00:31 2023 ] Eval epoch: 55
[ Mon Jan 30 22:02:56 2023 ] 	Mean test loss of 796 batches: 0.8354028345895322.
[ Mon Jan 30 22:02:57 2023 ] 	Top1: 77.42%
[ Mon Jan 30 22:02:57 2023 ] 	Top5: 94.81%
[ Mon Jan 30 22:02:57 2023 ] Training epoch: 56
[ Mon Jan 30 22:11:17 2023 ] 	Mean training loss: 0.1203.  Mean training acc: 97.13%.
[ Mon Jan 30 22:11:17 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:11:17 2023 ] Eval epoch: 56
[ Mon Jan 30 22:13:55 2023 ] 	Mean test loss of 796 batches: 0.7480943337803585.
[ Mon Jan 30 22:13:56 2023 ] 	Top1: 79.80%
[ Mon Jan 30 22:13:56 2023 ] 	Top5: 95.51%
[ Mon Jan 30 22:13:56 2023 ] Training epoch: 57
[ Mon Jan 30 22:21:26 2023 ] 	Mean training loss: 0.0910.  Mean training acc: 98.12%.
[ Mon Jan 30 22:21:26 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:21:26 2023 ] Eval epoch: 57
[ Mon Jan 30 22:23:54 2023 ] 	Mean test loss of 796 batches: 0.7482552164837942.
[ Mon Jan 30 22:23:54 2023 ] 	Top1: 79.97%
[ Mon Jan 30 22:23:55 2023 ] 	Top5: 95.52%
[ Mon Jan 30 22:23:55 2023 ] Training epoch: 58
[ Mon Jan 30 22:31:50 2023 ] 	Mean training loss: 0.0797.  Mean training acc: 98.38%.
[ Mon Jan 30 22:31:50 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:31:50 2023 ] Eval epoch: 58
[ Mon Jan 30 22:34:31 2023 ] 	Mean test loss of 796 batches: 0.7498606092684982.
[ Mon Jan 30 22:34:32 2023 ] 	Top1: 79.83%
[ Mon Jan 30 22:34:32 2023 ] 	Top5: 95.53%
[ Mon Jan 30 22:34:33 2023 ] Training epoch: 59
[ Mon Jan 30 22:42:29 2023 ] 	Mean training loss: 0.0725.  Mean training acc: 98.55%.
[ Mon Jan 30 22:42:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:42:29 2023 ] Eval epoch: 59
[ Mon Jan 30 22:44:55 2023 ] 	Mean test loss of 796 batches: 0.7458204310948975.
[ Mon Jan 30 22:44:56 2023 ] 	Top1: 80.04%
[ Mon Jan 30 22:44:56 2023 ] 	Top5: 95.57%
[ Mon Jan 30 22:44:56 2023 ] Training epoch: 60
[ Mon Jan 30 22:52:18 2023 ] 	Mean training loss: 0.0688.  Mean training acc: 98.65%.
[ Mon Jan 30 22:52:18 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 22:52:18 2023 ] Eval epoch: 60
[ Mon Jan 30 22:54:59 2023 ] 	Mean test loss of 796 batches: 0.7479485840672374.
[ Mon Jan 30 22:54:59 2023 ] 	Top1: 80.13%
[ Mon Jan 30 22:54:59 2023 ] 	Top5: 95.60%
[ Mon Jan 30 22:54:59 2023 ] Training epoch: 61
[ Mon Jan 30 23:03:12 2023 ] 	Mean training loss: 0.0660.  Mean training acc: 98.73%.
[ Mon Jan 30 23:03:12 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 23:03:12 2023 ] Eval epoch: 61
[ Mon Jan 30 23:05:47 2023 ] 	Mean test loss of 796 batches: 0.7457751968229686.
[ Mon Jan 30 23:05:48 2023 ] 	Top1: 80.23%
[ Mon Jan 30 23:05:48 2023 ] 	Top5: 95.51%
[ Mon Jan 30 23:05:48 2023 ] Training epoch: 62
[ Mon Jan 30 23:12:58 2023 ] 	Mean training loss: 0.0610.  Mean training acc: 98.88%.
[ Mon Jan 30 23:12:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 23:12:59 2023 ] Eval epoch: 62
[ Mon Jan 30 23:15:27 2023 ] 	Mean test loss of 796 batches: 0.7562385223824625.
[ Mon Jan 30 23:15:28 2023 ] 	Top1: 80.05%
[ Mon Jan 30 23:15:28 2023 ] 	Top5: 95.49%
[ Mon Jan 30 23:15:28 2023 ] Training epoch: 63
[ Mon Jan 30 23:23:45 2023 ] 	Mean training loss: 0.0596.  Mean training acc: 98.90%.
[ Mon Jan 30 23:23:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 23:23:45 2023 ] Eval epoch: 63
[ Mon Jan 30 23:26:18 2023 ] 	Mean test loss of 796 batches: 0.7540991042071401.
[ Mon Jan 30 23:26:18 2023 ] 	Top1: 80.18%
[ Mon Jan 30 23:26:18 2023 ] 	Top5: 95.48%
[ Mon Jan 30 23:26:19 2023 ] Training epoch: 64
[ Mon Jan 30 23:33:59 2023 ] 	Mean training loss: 0.0578.  Mean training acc: 98.94%.
[ Mon Jan 30 23:33:59 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 23:33:59 2023 ] Eval epoch: 64
[ Mon Jan 30 23:36:17 2023 ] 	Mean test loss of 796 batches: 0.7615616371452658.
[ Mon Jan 30 23:36:17 2023 ] 	Top1: 80.06%
[ Mon Jan 30 23:36:18 2023 ] 	Top5: 95.44%
[ Mon Jan 30 23:36:18 2023 ] Training epoch: 65
[ Mon Jan 30 23:44:27 2023 ] 	Mean training loss: 0.0543.  Mean training acc: 99.09%.
[ Mon Jan 30 23:44:27 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan 30 23:44:27 2023 ] Eval epoch: 65
[ Mon Jan 30 23:46:55 2023 ] 	Mean test loss of 796 batches: 0.7510342923409525.
[ Mon Jan 30 23:46:55 2023 ] 	Top1: 80.32%
[ Mon Jan 30 23:46:56 2023 ] 	Top5: 95.47%
[ Mon Jan 30 23:49:37 2023 ] Best accuracy: 0.8031579567548459
[ Mon Jan 30 23:49:37 2023 ] Epoch number: 65
[ Mon Jan 30 23:49:37 2023 ] Model name: work_dir/csub/local_SHT_bonevel_BL
[ Mon Jan 30 23:49:37 2023 ] Model total number of params: 2141090
[ Mon Jan 30 23:49:37 2023 ] Weight decay: 0.0004
[ Mon Jan 30 23:49:37 2023 ] Base LR: 0.1
[ Mon Jan 30 23:49:37 2023 ] Batch Size: 64
[ Mon Jan 30 23:49:37 2023 ] Test Batch Size: 64
[ Mon Jan 30 23:49:37 2023 ] seed: 1
