[ Mon Jan  9 16:06:06 2023 ] using warm up, epoch: 5
[ Mon Jan  9 16:07:56 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan  9 16:07:56 2023 ] # Parameters: 1508876
[ Mon Jan  9 16:07:56 2023 ] Training epoch: 1
[ Mon Jan  9 16:26:07 2023 ] 	Mean training loss: 3.3925.  Mean training acc: 18.02%.
[ Mon Jan  9 16:26:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 16:26:08 2023 ] Eval epoch: 1
[ Mon Jan  9 16:38:42 2023 ] 	Mean test loss of 796 batches: 2.69046626947633.
[ Mon Jan  9 16:38:44 2023 ] 	Top1: 27.24%
[ Mon Jan  9 16:38:44 2023 ] 	Top5: 62.29%
[ Mon Jan  9 16:38:44 2023 ] Training epoch: 2
[ Mon Jan  9 17:06:37 2023 ] 	Mean training loss: 2.1020.  Mean training acc: 41.90%.
[ Mon Jan  9 17:06:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 17:06:39 2023 ] Eval epoch: 2
[ Mon Jan  9 17:21:12 2023 ] 	Mean test loss of 796 batches: 1.7399542408073367.
[ Mon Jan  9 17:21:13 2023 ] 	Top1: 49.98%
[ Mon Jan  9 17:21:13 2023 ] 	Top5: 82.43%
[ Mon Jan  9 17:21:14 2023 ] Training epoch: 3
[ Mon Jan  9 17:49:36 2023 ] 	Mean training loss: 1.5552.  Mean training acc: 55.42%.
[ Mon Jan  9 17:49:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 17:49:56 2023 ] Eval epoch: 3
[ Mon Jan  9 18:05:24 2023 ] 	Mean test loss of 796 batches: 1.5306492638797615.
[ Mon Jan  9 18:05:26 2023 ] 	Top1: 56.04%
[ Mon Jan  9 18:05:26 2023 ] 	Top5: 86.55%
[ Mon Jan  9 18:05:26 2023 ] Training epoch: 4
[ Mon Jan  9 18:33:38 2023 ] 	Mean training loss: 1.3291.  Mean training acc: 61.41%.
[ Mon Jan  9 18:33:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 18:33:41 2023 ] Eval epoch: 4
[ Mon Jan  9 18:48:46 2023 ] 	Mean test loss of 796 batches: 1.5991568891846355.
[ Mon Jan  9 18:48:48 2023 ] 	Top1: 55.33%
[ Mon Jan  9 18:48:48 2023 ] 	Top5: 85.75%
[ Mon Jan  9 18:48:49 2023 ] Training epoch: 5
[ Mon Jan  9 19:17:11 2023 ] 	Mean training loss: 1.2365.  Mean training acc: 63.67%.
[ Mon Jan  9 19:17:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 19:17:12 2023 ] Eval epoch: 5
[ Mon Jan  9 19:31:41 2023 ] 	Mean test loss of 796 batches: 1.4470458939746396.
[ Mon Jan  9 19:31:42 2023 ] 	Top1: 57.30%
[ Mon Jan  9 19:31:42 2023 ] 	Top5: 87.79%
[ Mon Jan  9 19:31:43 2023 ] Training epoch: 6
[ Mon Jan  9 20:00:35 2023 ] 	Mean training loss: 1.0993.  Mean training acc: 67.40%.
[ Mon Jan  9 20:00:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan  9 20:00:37 2023 ] Eval epoch: 6
[ Mon Jan  9 20:15:03 2023 ] 	Mean test loss of 796 batches: 1.866064881035431.
[ Mon Jan  9 20:15:05 2023 ] 	Top1: 53.35%
[ Mon Jan  9 20:15:05 2023 ] 	Top5: 83.99%
[ Mon Jan  9 20:15:06 2023 ] Training epoch: 7
[ Mon Jan  9 20:43:42 2023 ] 	Mean training loss: 1.0280.  Mean training acc: 69.49%.
[ Mon Jan  9 20:43:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 20:43:44 2023 ] Eval epoch: 7
[ Mon Jan  9 20:58:02 2023 ] 	Mean test loss of 796 batches: 1.2014359175484983.
[ Mon Jan  9 20:58:06 2023 ] 	Top1: 64.85%
[ Mon Jan  9 20:58:06 2023 ] 	Top5: 91.54%
[ Mon Jan  9 20:58:07 2023 ] Training epoch: 8
[ Mon Jan  9 21:27:31 2023 ] 	Mean training loss: 0.9775.  Mean training acc: 70.89%.
[ Mon Jan  9 21:27:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 21:27:32 2023 ] Eval epoch: 8
[ Mon Jan  9 21:41:58 2023 ] 	Mean test loss of 796 batches: 1.177736516836001.
[ Mon Jan  9 21:42:00 2023 ] 	Top1: 65.22%
[ Mon Jan  9 21:42:00 2023 ] 	Top5: 91.42%
[ Mon Jan  9 21:42:00 2023 ] Training epoch: 9
[ Mon Jan  9 22:11:58 2023 ] 	Mean training loss: 0.9310.  Mean training acc: 72.29%.
[ Mon Jan  9 22:11:58 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 22:12:00 2023 ] Eval epoch: 9
[ Mon Jan  9 22:27:25 2023 ] 	Mean test loss of 796 batches: 1.2715531887870337.
[ Mon Jan  9 22:27:26 2023 ] 	Top1: 62.31%
[ Mon Jan  9 22:27:27 2023 ] 	Top5: 90.49%
[ Mon Jan  9 22:27:27 2023 ] Training epoch: 10
[ Mon Jan  9 22:56:34 2023 ] 	Mean training loss: 0.9047.  Mean training acc: 72.93%.
[ Mon Jan  9 22:56:34 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 22:56:35 2023 ] Eval epoch: 10
[ Mon Jan  9 23:11:47 2023 ] 	Mean test loss of 796 batches: 1.1364753645418877.
[ Mon Jan  9 23:11:50 2023 ] 	Top1: 67.37%
[ Mon Jan  9 23:11:51 2023 ] 	Top5: 92.01%
[ Mon Jan  9 23:11:51 2023 ] Training epoch: 11
[ Mon Jan  9 23:40:39 2023 ] 	Mean training loss: 0.8770.  Mean training acc: 73.68%.
[ Mon Jan  9 23:40:39 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 23:40:40 2023 ] Eval epoch: 11
[ Mon Jan  9 23:56:07 2023 ] 	Mean test loss of 796 batches: 1.1653004021725464.
[ Mon Jan  9 23:56:13 2023 ] 	Top1: 67.16%
[ Mon Jan  9 23:56:14 2023 ] 	Top5: 92.06%
[ Mon Jan  9 23:56:14 2023 ] Training epoch: 12
[ Tue Jan 10 00:24:37 2023 ] 	Mean training loss: 0.8557.  Mean training acc: 74.45%.
[ Tue Jan 10 00:24:37 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 00:24:38 2023 ] Eval epoch: 12
[ Tue Jan 10 00:40:08 2023 ] 	Mean test loss of 796 batches: 0.9932212089773399.
[ Tue Jan 10 00:40:09 2023 ] 	Top1: 69.65%
[ Tue Jan 10 00:40:10 2023 ] 	Top5: 93.75%
[ Tue Jan 10 00:40:10 2023 ] Training epoch: 13
[ Tue Jan 10 01:08:35 2023 ] 	Mean training loss: 0.8425.  Mean training acc: 74.83%.
[ Tue Jan 10 01:08:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 01:08:37 2023 ] Eval epoch: 13
[ Tue Jan 10 01:23:55 2023 ] 	Mean test loss of 796 batches: 1.1410113040676069.
[ Tue Jan 10 01:23:58 2023 ] 	Top1: 67.49%
[ Tue Jan 10 01:23:58 2023 ] 	Top5: 91.43%
[ Tue Jan 10 01:23:59 2023 ] Training epoch: 14
[ Tue Jan 10 01:52:16 2023 ] 	Mean training loss: 0.8287.  Mean training acc: 75.11%.
[ Tue Jan 10 01:52:18 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 01:52:19 2023 ] Eval epoch: 14
[ Tue Jan 10 02:07:25 2023 ] 	Mean test loss of 796 batches: 0.9684629084252233.
[ Tue Jan 10 02:07:27 2023 ] 	Top1: 71.31%
[ Tue Jan 10 02:07:27 2023 ] 	Top5: 93.46%
[ Tue Jan 10 02:07:28 2023 ] Training epoch: 15
[ Tue Jan 10 02:35:51 2023 ] 	Mean training loss: 0.8116.  Mean training acc: 75.62%.
[ Tue Jan 10 02:35:51 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 02:35:51 2023 ] Eval epoch: 15
[ Tue Jan 10 02:50:42 2023 ] 	Mean test loss of 796 batches: 1.0137138759071505.
[ Tue Jan 10 02:50:43 2023 ] 	Top1: 70.43%
[ Tue Jan 10 02:50:44 2023 ] 	Top5: 93.00%
[ Tue Jan 10 02:50:44 2023 ] Training epoch: 16
[ Tue Jan 10 03:19:22 2023 ] 	Mean training loss: 0.8038.  Mean training acc: 75.71%.
[ Tue Jan 10 03:19:24 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 03:19:25 2023 ] Eval epoch: 16
[ Tue Jan 10 03:34:23 2023 ] 	Mean test loss of 796 batches: 1.2234525309136166.
[ Tue Jan 10 03:34:23 2023 ] 	Top1: 64.22%
[ Tue Jan 10 03:34:24 2023 ] 	Top5: 91.01%
[ Tue Jan 10 03:34:24 2023 ] Training epoch: 17
[ Tue Jan 10 04:02:48 2023 ] 	Mean training loss: 0.7957.  Mean training acc: 76.29%.
[ Tue Jan 10 04:02:48 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 04:03:00 2023 ] Eval epoch: 17
[ Tue Jan 10 04:17:23 2023 ] 	Mean test loss of 796 batches: 1.1639360291274947.
[ Tue Jan 10 04:17:27 2023 ] 	Top1: 67.20%
[ Tue Jan 10 04:17:28 2023 ] 	Top5: 90.77%
[ Tue Jan 10 04:17:29 2023 ] Training epoch: 18
[ Tue Jan 10 04:45:54 2023 ] 	Mean training loss: 0.7853.  Mean training acc: 76.53%.
[ Tue Jan 10 04:45:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 04:45:55 2023 ] Eval epoch: 18
[ Tue Jan 10 05:00:50 2023 ] 	Mean test loss of 796 batches: 1.1768577078254379.
[ Tue Jan 10 05:00:56 2023 ] 	Top1: 66.13%
[ Tue Jan 10 05:00:56 2023 ] 	Top5: 91.27%
[ Tue Jan 10 05:00:57 2023 ] Training epoch: 19
[ Tue Jan 10 05:29:20 2023 ] 	Mean training loss: 0.7767.  Mean training acc: 76.82%.
[ Tue Jan 10 05:29:20 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 05:29:21 2023 ] Eval epoch: 19
[ Tue Jan 10 05:44:21 2023 ] 	Mean test loss of 796 batches: 1.062390650037545.
[ Tue Jan 10 05:44:22 2023 ] 	Top1: 69.36%
[ Tue Jan 10 05:44:22 2023 ] 	Top5: 92.28%
[ Tue Jan 10 05:44:23 2023 ] Training epoch: 20
[ Tue Jan 10 06:12:39 2023 ] 	Mean training loss: 0.7765.  Mean training acc: 76.42%.
[ Tue Jan 10 06:12:39 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 06:12:39 2023 ] Eval epoch: 20
[ Tue Jan 10 06:27:47 2023 ] 	Mean test loss of 796 batches: 1.0694457008011977.
[ Tue Jan 10 06:27:48 2023 ] 	Top1: 68.85%
[ Tue Jan 10 06:27:48 2023 ] 	Top5: 93.02%
[ Tue Jan 10 06:27:49 2023 ] Training epoch: 21
[ Tue Jan 10 06:56:07 2023 ] 	Mean training loss: 0.7641.  Mean training acc: 77.08%.
[ Tue Jan 10 06:56:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 06:56:08 2023 ] Eval epoch: 21
[ Tue Jan 10 07:11:27 2023 ] 	Mean test loss of 796 batches: 1.0686813261940251.
[ Tue Jan 10 07:11:29 2023 ] 	Top1: 68.27%
[ Tue Jan 10 07:11:29 2023 ] 	Top5: 93.00%
[ Tue Jan 10 07:11:29 2023 ] Training epoch: 22
[ Tue Jan 10 07:39:27 2023 ] 	Mean training loss: 0.7631.  Mean training acc: 76.97%.
[ Tue Jan 10 07:39:28 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 07:39:29 2023 ] Eval epoch: 22
[ Tue Jan 10 07:54:11 2023 ] 	Mean test loss of 796 batches: 0.9539009758912439.
[ Tue Jan 10 07:54:12 2023 ] 	Top1: 71.90%
[ Tue Jan 10 07:54:13 2023 ] 	Top5: 94.14%
[ Tue Jan 10 07:54:14 2023 ] Training epoch: 23
[ Tue Jan 10 08:22:35 2023 ] 	Mean training loss: 0.7680.  Mean training acc: 76.91%.
[ Tue Jan 10 08:22:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 08:22:36 2023 ] Eval epoch: 23
[ Tue Jan 10 08:37:19 2023 ] 	Mean test loss of 796 batches: 0.9478402618861678.
[ Tue Jan 10 08:37:33 2023 ] 	Top1: 72.01%
[ Tue Jan 10 08:37:33 2023 ] 	Top5: 93.70%
[ Tue Jan 10 08:37:34 2023 ] Training epoch: 24
[ Tue Jan 10 08:59:52 2023 ] 	Mean training loss: 0.7569.  Mean training acc: 77.10%.
[ Tue Jan 10 08:59:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 08:59:59 2023 ] Eval epoch: 24
[ Tue Jan 10 09:12:29 2023 ] 	Mean test loss of 796 batches: 1.0189750079608442.
[ Tue Jan 10 09:12:31 2023 ] 	Top1: 69.83%
[ Tue Jan 10 09:12:32 2023 ] 	Top5: 92.77%
[ Tue Jan 10 09:12:33 2023 ] Training epoch: 25
[ Tue Jan 10 09:34:10 2023 ] 	Mean training loss: 0.7529.  Mean training acc: 77.32%.
[ Tue Jan 10 09:34:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:34:12 2023 ] Eval epoch: 25
[ Tue Jan 10 09:48:05 2023 ] 	Mean test loss of 796 batches: 1.052597267843371.
[ Tue Jan 10 09:48:06 2023 ] 	Top1: 70.14%
[ Tue Jan 10 09:48:06 2023 ] 	Top5: 92.07%
[ Tue Jan 10 09:48:07 2023 ] Training epoch: 26
[ Tue Jan 10 10:10:04 2023 ] 	Mean training loss: 0.7516.  Mean training acc: 77.39%.
[ Tue Jan 10 10:10:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:10:07 2023 ] Eval epoch: 26
[ Tue Jan 10 10:23:55 2023 ] 	Mean test loss of 796 batches: 1.033688613705.
[ Tue Jan 10 10:23:56 2023 ] 	Top1: 69.86%
[ Tue Jan 10 10:23:56 2023 ] 	Top5: 92.95%
[ Tue Jan 10 10:23:57 2023 ] Training epoch: 27
[ Tue Jan 10 10:45:13 2023 ] 	Mean training loss: 0.7552.  Mean training acc: 77.26%.
[ Tue Jan 10 10:45:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:45:15 2023 ] Eval epoch: 27
[ Tue Jan 10 10:58:07 2023 ] 	Mean test loss of 796 batches: 1.0171469807924338.
[ Tue Jan 10 10:58:08 2023 ] 	Top1: 71.02%
[ Tue Jan 10 10:58:09 2023 ] 	Top5: 93.15%
[ Tue Jan 10 10:58:09 2023 ] Training epoch: 28
[ Tue Jan 10 11:20:09 2023 ] 	Mean training loss: 0.7494.  Mean training acc: 77.26%.
[ Tue Jan 10 11:20:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:20:11 2023 ] Eval epoch: 28
[ Tue Jan 10 11:32:15 2023 ] 	Mean test loss of 796 batches: 1.0822398020094963.
[ Tue Jan 10 11:32:16 2023 ] 	Top1: 69.64%
[ Tue Jan 10 11:32:16 2023 ] 	Top5: 92.11%
[ Tue Jan 10 11:32:17 2023 ] Training epoch: 29
[ Tue Jan 10 11:54:39 2023 ] 	Mean training loss: 0.7468.  Mean training acc: 77.63%.
[ Tue Jan 10 11:54:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:54:41 2023 ] Eval epoch: 29
[ Tue Jan 10 12:08:56 2023 ] 	Mean test loss of 796 batches: 0.9860386560909712.
[ Tue Jan 10 12:08:57 2023 ] 	Top1: 71.69%
[ Tue Jan 10 12:08:58 2023 ] 	Top5: 93.04%
[ Tue Jan 10 12:08:58 2023 ] Training epoch: 30
[ Tue Jan 10 12:31:30 2023 ] 	Mean training loss: 0.7415.  Mean training acc: 77.82%.
[ Tue Jan 10 12:31:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:31:32 2023 ] Eval epoch: 30
[ Tue Jan 10 12:45:57 2023 ] 	Mean test loss of 796 batches: 0.9384622734844984.
[ Tue Jan 10 12:45:59 2023 ] 	Top1: 71.70%
[ Tue Jan 10 12:45:59 2023 ] 	Top5: 94.02%
[ Tue Jan 10 12:46:00 2023 ] Training epoch: 31
[ Tue Jan 10 13:08:43 2023 ] 	Mean training loss: 0.7426.  Mean training acc: 77.77%.
[ Tue Jan 10 13:08:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:08:46 2023 ] Eval epoch: 31
[ Tue Jan 10 13:22:55 2023 ] 	Mean test loss of 796 batches: 1.00757201289262.
[ Tue Jan 10 13:22:56 2023 ] 	Top1: 71.09%
[ Tue Jan 10 13:22:56 2023 ] 	Top5: 92.90%
[ Tue Jan 10 13:22:57 2023 ] Training epoch: 32
[ Tue Jan 10 13:45:35 2023 ] 	Mean training loss: 0.7471.  Mean training acc: 77.35%.
[ Tue Jan 10 13:45:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:45:43 2023 ] Eval epoch: 32
[ Tue Jan 10 14:03:09 2023 ] 	Mean test loss of 796 batches: 1.0210210722894524.
[ Tue Jan 10 14:03:12 2023 ] 	Top1: 70.08%
[ Tue Jan 10 14:03:13 2023 ] 	Top5: 93.48%
[ Tue Jan 10 14:03:15 2023 ] Training epoch: 33
[ Tue Jan 10 14:37:25 2023 ] 	Mean training loss: 0.7343.  Mean training acc: 77.99%.
[ Tue Jan 10 14:37:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 14:38:07 2023 ] Eval epoch: 33
[ Tue Jan 10 14:56:21 2023 ] 	Mean test loss of 796 batches: 1.0128636823302537.
[ Tue Jan 10 14:56:23 2023 ] 	Top1: 70.00%
[ Tue Jan 10 14:56:23 2023 ] 	Top5: 93.01%
[ Tue Jan 10 14:56:25 2023 ] Training epoch: 34
[ Tue Jan 10 15:30:34 2023 ] 	Mean training loss: 0.7263.  Mean training acc: 78.22%.
[ Tue Jan 10 15:30:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:30:40 2023 ] Eval epoch: 34
[ Tue Jan 10 15:49:04 2023 ] 	Mean test loss of 796 batches: 1.0421736705018647.
[ Tue Jan 10 15:49:07 2023 ] 	Top1: 70.24%
[ Tue Jan 10 15:49:08 2023 ] 	Top5: 92.90%
[ Tue Jan 10 15:49:10 2023 ] Training epoch: 35
[ Tue Jan 10 16:23:26 2023 ] 	Mean training loss: 0.7308.  Mean training acc: 77.93%.
[ Tue Jan 10 16:23:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 16:23:29 2023 ] Eval epoch: 35
[ Tue Jan 10 16:42:10 2023 ] 	Mean test loss of 796 batches: 1.0978750004690496.
[ Tue Jan 10 16:42:14 2023 ] 	Top1: 67.74%
[ Tue Jan 10 16:42:15 2023 ] 	Top5: 92.59%
[ Tue Jan 10 16:42:16 2023 ] Training epoch: 36
[ Tue Jan 10 17:20:04 2023 ] 	Mean training loss: 0.4102.  Mean training acc: 87.78%.
[ Tue Jan 10 17:20:10 2023 ] 	Time consumption: [Data]00%, [Network]91%
[ Tue Jan 10 17:20:17 2023 ] Eval epoch: 36
[ Tue Jan 10 17:38:21 2023 ] 	Mean test loss of 796 batches: 0.5258984915144629.
[ Tue Jan 10 17:38:25 2023 ] 	Top1: 84.06%
[ Tue Jan 10 17:38:25 2023 ] 	Top5: 97.24%
[ Tue Jan 10 17:38:28 2023 ] Training epoch: 37
[ Tue Jan 10 18:15:27 2023 ] 	Mean training loss: 0.3177.  Mean training acc: 90.51%.
[ Tue Jan 10 18:15:28 2023 ] 	Time consumption: [Data]01%, [Network]95%
[ Tue Jan 10 18:15:30 2023 ] Eval epoch: 37
[ Tue Jan 10 18:36:43 2023 ] 	Mean test loss of 796 batches: 0.5201074658242527.
[ Tue Jan 10 18:36:47 2023 ] 	Top1: 84.37%
[ Tue Jan 10 18:36:47 2023 ] 	Top5: 97.28%
[ Tue Jan 10 18:36:48 2023 ] Training epoch: 38
[ Tue Jan 10 19:15:16 2023 ] 	Mean training loss: 0.2848.  Mean training acc: 91.33%.
[ Tue Jan 10 19:15:18 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 19:15:20 2023 ] Eval epoch: 38
[ Tue Jan 10 19:37:31 2023 ] 	Mean test loss of 796 batches: 0.502441572989501.
[ Tue Jan 10 19:37:32 2023 ] 	Top1: 84.99%
[ Tue Jan 10 19:37:33 2023 ] 	Top5: 97.52%
[ Tue Jan 10 19:37:34 2023 ] Training epoch: 39
[ Tue Jan 10 20:16:02 2023 ] 	Mean training loss: 0.2600.  Mean training acc: 92.20%.
[ Tue Jan 10 20:16:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:16:05 2023 ] Eval epoch: 39
[ Tue Jan 10 20:38:07 2023 ] 	Mean test loss of 796 batches: 0.5061179912934576.
[ Tue Jan 10 20:38:15 2023 ] 	Top1: 85.04%
[ Tue Jan 10 20:38:16 2023 ] 	Top5: 97.32%
[ Tue Jan 10 20:38:16 2023 ] Training epoch: 40
[ Tue Jan 10 21:16:56 2023 ] 	Mean training loss: 0.2387.  Mean training acc: 92.95%.
[ Tue Jan 10 21:17:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 21:17:05 2023 ] Eval epoch: 40
[ Tue Jan 10 21:38:49 2023 ] 	Mean test loss of 796 batches: 0.5350586939696691.
[ Tue Jan 10 21:38:50 2023 ] 	Top1: 84.31%
[ Tue Jan 10 21:38:51 2023 ] 	Top5: 97.21%
[ Tue Jan 10 21:38:51 2023 ] Training epoch: 41
[ Tue Jan 10 22:17:26 2023 ] 	Mean training loss: 0.2204.  Mean training acc: 93.50%.
[ Tue Jan 10 22:17:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 22:17:29 2023 ] Eval epoch: 41
[ Tue Jan 10 22:39:37 2023 ] 	Mean test loss of 796 batches: 0.5328763198977964.
[ Tue Jan 10 22:39:38 2023 ] 	Top1: 84.55%
[ Tue Jan 10 22:39:39 2023 ] 	Top5: 97.21%
[ Tue Jan 10 22:39:39 2023 ] Training epoch: 42
[ Tue Jan 10 23:17:23 2023 ] 	Mean training loss: 0.2110.  Mean training acc: 93.80%.
[ Tue Jan 10 23:17:24 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 23:17:26 2023 ] Eval epoch: 42
[ Tue Jan 10 23:39:19 2023 ] 	Mean test loss of 796 batches: 0.5410974408036575.
[ Tue Jan 10 23:39:21 2023 ] 	Top1: 84.32%
[ Tue Jan 10 23:39:22 2023 ] 	Top5: 97.24%
[ Tue Jan 10 23:39:22 2023 ] Training epoch: 43
[ Wed Jan 11 00:24:30 2023 ] 	Mean training loss: 0.2003.  Mean training acc: 94.11%.
[ Wed Jan 11 00:24:31 2023 ] 	Time consumption: [Data]00%, [Network]83%
[ Wed Jan 11 00:24:31 2023 ] Eval epoch: 43
[ Wed Jan 11 00:44:44 2023 ] 	Mean test loss of 796 batches: 0.5580571047708991.
[ Wed Jan 11 00:44:45 2023 ] 	Top1: 84.03%
[ Wed Jan 11 00:44:46 2023 ] 	Top5: 97.11%
[ Wed Jan 11 00:44:46 2023 ] Training epoch: 44
[ Wed Jan 11 01:20:42 2023 ] 	Mean training loss: 0.1952.  Mean training acc: 94.42%.
[ Wed Jan 11 01:20:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 01:20:44 2023 ] Eval epoch: 44
[ Wed Jan 11 01:41:02 2023 ] 	Mean test loss of 796 batches: 0.5520368315204603.
[ Wed Jan 11 01:41:03 2023 ] 	Top1: 84.19%
[ Wed Jan 11 01:41:03 2023 ] 	Top5: 97.14%
[ Wed Jan 11 01:41:03 2023 ] Training epoch: 45
[ Wed Jan 11 02:17:00 2023 ] 	Mean training loss: 0.1889.  Mean training acc: 94.53%.
[ Wed Jan 11 02:17:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 02:17:08 2023 ] Eval epoch: 45
[ Wed Jan 11 02:37:29 2023 ] 	Mean test loss of 796 batches: 0.5864932226232398.
[ Wed Jan 11 02:37:34 2023 ] 	Top1: 83.51%
[ Wed Jan 11 02:37:34 2023 ] 	Top5: 97.00%
[ Wed Jan 11 02:37:34 2023 ] Training epoch: 46
[ Wed Jan 11 03:14:16 2023 ] 	Mean training loss: 0.1831.  Mean training acc: 94.62%.
[ Wed Jan 11 03:14:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 03:14:17 2023 ] Eval epoch: 46
[ Wed Jan 11 03:35:59 2023 ] 	Mean test loss of 796 batches: 0.5742153991341367.
[ Wed Jan 11 03:36:00 2023 ] 	Top1: 84.00%
[ Wed Jan 11 03:36:00 2023 ] 	Top5: 97.02%
[ Wed Jan 11 03:36:01 2023 ] Training epoch: 47
[ Wed Jan 11 04:14:21 2023 ] 	Mean training loss: 0.1792.  Mean training acc: 94.82%.
[ Wed Jan 11 04:14:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:14:24 2023 ] Eval epoch: 47
[ Wed Jan 11 04:36:17 2023 ] 	Mean test loss of 796 batches: 0.5683742729787851.
[ Wed Jan 11 04:36:18 2023 ] 	Top1: 84.17%
[ Wed Jan 11 04:36:18 2023 ] 	Top5: 97.02%
[ Wed Jan 11 04:36:18 2023 ] Training epoch: 48
[ Wed Jan 11 05:15:10 2023 ] 	Mean training loss: 0.1794.  Mean training acc: 94.84%.
[ Wed Jan 11 05:15:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 05:15:11 2023 ] Eval epoch: 48
[ Wed Jan 11 05:36:57 2023 ] 	Mean test loss of 796 batches: 0.5671746595084068.
[ Wed Jan 11 05:37:00 2023 ] 	Top1: 84.23%
[ Wed Jan 11 05:37:01 2023 ] 	Top5: 97.09%
[ Wed Jan 11 05:37:01 2023 ] Training epoch: 49
[ Wed Jan 11 12:24:34 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:36:14 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:41:08 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:41:38 2023 ] using warm up, epoch: 5
[ Wed Jan 11 12:46:10 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:46:13 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:47:51 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 49, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:47:51 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:47:51 2023 ] Training epoch: 50
[ Wed Jan 11 12:48:41 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:48:44 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:49:02 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:49:02 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:49:02 2023 ] Training epoch: 49
[ Wed Jan 11 12:50:33 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:50:37 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:50:52 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:50:52 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:50:52 2023 ] Training epoch: 49
[ Wed Jan 11 13:16:42 2023 ] 	Mean training loss: 0.1737.  Mean training acc: 94.92%.
[ Wed Jan 11 13:16:43 2023 ] 	Time consumption: [Data]00%, [Network]90%
[ Wed Jan 11 13:16:43 2023 ] Eval epoch: 49
[ Wed Jan 11 13:36:32 2023 ] 	Mean test loss of 796 batches: 0.6181181672698439.
[ Wed Jan 11 13:36:33 2023 ] 	Top1: 83.39%
[ Wed Jan 11 13:36:34 2023 ] 	Top5: 96.68%
[ Wed Jan 11 13:36:36 2023 ] Training epoch: 50
[ Wed Jan 11 14:16:10 2023 ] 	Mean training loss: 0.1751.  Mean training acc: 94.88%.
[ Wed Jan 11 14:16:11 2023 ] 	Time consumption: [Data]01%, [Network]84%
[ Wed Jan 11 14:16:12 2023 ] Eval epoch: 50
[ Wed Jan 11 14:37:00 2023 ] 	Mean test loss of 796 batches: 0.6391387500673832.
[ Wed Jan 11 14:37:02 2023 ] 	Top1: 82.66%
[ Wed Jan 11 14:37:02 2023 ] 	Top5: 96.64%
[ Wed Jan 11 14:37:02 2023 ] Training epoch: 51
[ Wed Jan 11 15:16:33 2023 ] 	Mean training loss: 0.1798.  Mean training acc: 94.75%.
[ Wed Jan 11 15:16:34 2023 ] 	Time consumption: [Data]01%, [Network]86%
[ Wed Jan 11 15:16:34 2023 ] Eval epoch: 51
[ Wed Jan 11 15:38:00 2023 ] 	Mean test loss of 796 batches: 0.6211046703889891.
[ Wed Jan 11 15:38:02 2023 ] 	Top1: 82.85%
[ Wed Jan 11 15:38:02 2023 ] 	Top5: 96.60%
[ Wed Jan 11 15:38:03 2023 ] Training epoch: 52
[ Wed Jan 11 16:28:21 2023 ] 	Mean training loss: 0.1771.  Mean training acc: 94.89%.
[ Wed Jan 11 16:28:22 2023 ] 	Time consumption: [Data]00%, [Network]69%
[ Wed Jan 11 16:28:23 2023 ] Eval epoch: 52
[ Wed Jan 11 16:48:40 2023 ] 	Mean test loss of 796 batches: 0.6157425588755002.
[ Wed Jan 11 16:48:40 2023 ] 	Top1: 83.24%
[ Wed Jan 11 16:48:41 2023 ] 	Top5: 96.66%
[ Wed Jan 11 16:48:42 2023 ] Training epoch: 53
[ Wed Jan 11 17:21:09 2023 ] 	Mean training loss: 0.1816.  Mean training acc: 94.75%.
[ Wed Jan 11 17:21:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 17:21:10 2023 ] Eval epoch: 53
[ Wed Jan 11 17:35:15 2023 ] 	Mean test loss of 796 batches: 0.6604087305297355.
[ Wed Jan 11 17:35:16 2023 ] 	Top1: 82.51%
[ Wed Jan 11 17:35:16 2023 ] 	Top5: 96.24%
[ Wed Jan 11 17:35:17 2023 ] Training epoch: 54
[ Wed Jan 11 17:59:13 2023 ] 	Mean training loss: 0.1741.  Mean training acc: 94.92%.
[ Wed Jan 11 17:59:13 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Wed Jan 11 17:59:14 2023 ] Eval epoch: 54
[ Wed Jan 11 18:08:36 2023 ] 	Mean test loss of 796 batches: 0.6028564107749406.
[ Wed Jan 11 18:08:37 2023 ] 	Top1: 83.42%
[ Wed Jan 11 18:08:37 2023 ] 	Top5: 96.74%
[ Wed Jan 11 18:08:38 2023 ] Training epoch: 55
[ Wed Jan 11 18:34:30 2023 ] 	Mean training loss: 0.1730.  Mean training acc: 94.95%.
[ Wed Jan 11 18:34:31 2023 ] 	Time consumption: [Data]00%, [Network]90%
[ Wed Jan 11 18:34:32 2023 ] Eval epoch: 55
[ Wed Jan 11 18:45:56 2023 ] 	Mean test loss of 796 batches: 0.6509839486021867.
[ Wed Jan 11 18:45:57 2023 ] 	Top1: 82.37%
[ Wed Jan 11 18:45:57 2023 ] 	Top5: 96.62%
[ Wed Jan 11 18:45:57 2023 ] Training epoch: 56
[ Wed Jan 11 19:14:45 2023 ] 	Mean training loss: 0.1021.  Mean training acc: 97.48%.
[ Wed Jan 11 19:14:45 2023 ] 	Time consumption: [Data]00%, [Network]80%
[ Wed Jan 11 19:14:46 2023 ] Eval epoch: 56
[ Wed Jan 11 19:24:29 2023 ] 	Mean test loss of 796 batches: 0.5328608143105916.
[ Wed Jan 11 19:24:45 2023 ] 	Top1: 85.37%
[ Wed Jan 11 19:24:46 2023 ] 	Top5: 97.25%
[ Wed Jan 11 19:24:46 2023 ] Training epoch: 57
[ Wed Jan 11 19:50:28 2023 ] 	Mean training loss: 0.0764.  Mean training acc: 98.30%.
[ Wed Jan 11 19:50:29 2023 ] 	Time consumption: [Data]01%, [Network]86%
[ Wed Jan 11 19:50:29 2023 ] Eval epoch: 57
[ Wed Jan 11 20:01:13 2023 ] 	Mean test loss of 796 batches: 0.536161619449156.
[ Wed Jan 11 20:01:15 2023 ] 	Top1: 85.50%
[ Wed Jan 11 20:01:15 2023 ] 	Top5: 97.30%
[ Wed Jan 11 20:01:16 2023 ] Training epoch: 58
[ Wed Jan 11 20:29:54 2023 ] 	Mean training loss: 0.0644.  Mean training acc: 98.68%.
[ Wed Jan 11 20:29:55 2023 ] 	Time consumption: [Data]00%, [Network]82%
[ Wed Jan 11 20:29:56 2023 ] Eval epoch: 58
[ Wed Jan 11 20:40:59 2023 ] 	Mean test loss of 796 batches: 0.5347045123595838.
[ Wed Jan 11 20:41:00 2023 ] 	Top1: 85.53%
[ Wed Jan 11 20:41:01 2023 ] 	Top5: 97.29%
[ Wed Jan 11 20:41:01 2023 ] Training epoch: 59
[ Wed Jan 11 21:14:56 2023 ] 	Mean training loss: 0.0606.  Mean training acc: 98.76%.
[ Wed Jan 11 21:14:57 2023 ] 	Time consumption: [Data]00%, [Network]69%
[ Wed Jan 11 21:14:57 2023 ] Eval epoch: 59
[ Wed Jan 11 21:26:16 2023 ] 	Mean test loss of 796 batches: 0.5389243212467687.
[ Wed Jan 11 21:26:17 2023 ] 	Top1: 85.58%
[ Wed Jan 11 21:26:17 2023 ] 	Top5: 97.24%
[ Wed Jan 11 21:26:17 2023 ] Training epoch: 60
[ Wed Jan 11 21:51:22 2023 ] 	Mean training loss: 0.0551.  Mean training acc: 98.93%.
[ Wed Jan 11 21:51:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 21:51:22 2023 ] Eval epoch: 60
[ Wed Jan 11 22:02:19 2023 ] 	Mean test loss of 796 batches: 0.538259614392385.
[ Wed Jan 11 22:02:19 2023 ] 	Top1: 85.60%
[ Wed Jan 11 22:02:19 2023 ] 	Top5: 97.27%
[ Wed Jan 11 22:02:19 2023 ] Training epoch: 61
[ Wed Jan 11 22:25:21 2023 ] 	Mean training loss: 0.0517.  Mean training acc: 99.06%.
[ Wed Jan 11 22:25:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 22:25:21 2023 ] Eval epoch: 61
[ Wed Jan 11 22:35:47 2023 ] 	Mean test loss of 796 batches: 0.5436628072513221.
[ Wed Jan 11 22:35:48 2023 ] 	Top1: 85.63%
[ Wed Jan 11 22:35:48 2023 ] 	Top5: 97.25%
[ Wed Jan 11 22:35:48 2023 ] Training epoch: 62
[ Wed Jan 11 22:58:15 2023 ] 	Mean training loss: 0.0494.  Mean training acc: 99.12%.
[ Wed Jan 11 22:58:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 22:58:16 2023 ] Eval epoch: 62
[ Wed Jan 11 23:08:31 2023 ] 	Mean test loss of 796 batches: 0.5466563003629109.
[ Wed Jan 11 23:08:32 2023 ] 	Top1: 85.50%
[ Wed Jan 11 23:08:32 2023 ] 	Top5: 97.19%
[ Wed Jan 11 23:08:32 2023 ] Training epoch: 63
[ Wed Jan 11 23:31:15 2023 ] 	Mean training loss: 0.0475.  Mean training acc: 99.15%.
[ Wed Jan 11 23:31:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 23:31:15 2023 ] Eval epoch: 63
[ Wed Jan 11 23:41:27 2023 ] 	Mean test loss of 796 batches: 0.5536100744227668.
[ Wed Jan 11 23:41:27 2023 ] 	Top1: 85.42%
[ Wed Jan 11 23:41:28 2023 ] 	Top5: 97.21%
[ Wed Jan 11 23:41:28 2023 ] Training epoch: 64
[ Thu Jan 12 00:04:29 2023 ] 	Mean training loss: 0.0438.  Mean training acc: 99.29%.
[ Thu Jan 12 00:04:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 00:04:29 2023 ] Eval epoch: 64
[ Thu Jan 12 00:14:41 2023 ] 	Mean test loss of 796 batches: 0.5537914788284942.
[ Thu Jan 12 00:14:41 2023 ] 	Top1: 85.51%
[ Thu Jan 12 00:14:42 2023 ] 	Top5: 97.13%
[ Thu Jan 12 00:14:42 2023 ] Training epoch: 65
[ Thu Jan 12 00:37:18 2023 ] 	Mean training loss: 0.0433.  Mean training acc: 99.26%.
[ Thu Jan 12 00:37:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 00:37:18 2023 ] Eval epoch: 65
[ Thu Jan 12 00:47:24 2023 ] 	Mean test loss of 796 batches: 0.5510755018904412.
[ Thu Jan 12 00:47:24 2023 ] 	Top1: 85.58%
[ Thu Jan 12 00:47:24 2023 ] 	Top5: 97.21%
[ Thu Jan 12 00:57:29 2023 ] Best accuracy: 0.856261906164693
[ Thu Jan 12 00:57:29 2023 ] Epoch number: 61
[ Thu Jan 12 00:57:29 2023 ] Model name: work_dir/csub/ctrgcn_local_SHT_bone
[ Thu Jan 12 00:57:29 2023 ] Model total number of params: 1508876
[ Thu Jan 12 00:57:29 2023 ] Weight decay: 0.0004
[ Thu Jan 12 00:57:29 2023 ] Base LR: 0.1
[ Thu Jan 12 00:57:29 2023 ] Batch Size: 64
[ Thu Jan 12 00:57:29 2023 ] Test Batch Size: 64
[ Thu Jan 12 00:57:29 2023 ] seed: 1
