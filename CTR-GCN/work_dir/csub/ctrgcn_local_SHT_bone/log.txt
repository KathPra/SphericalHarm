[ Mon Jan  9 16:06:06 2023 ] using warm up, epoch: 5
[ Mon Jan  9 16:07:56 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan  9 16:07:56 2023 ] # Parameters: 1508876
[ Mon Jan  9 16:07:56 2023 ] Training epoch: 1
[ Mon Jan  9 16:26:07 2023 ] 	Mean training loss: 3.3925.  Mean training acc: 18.02%.
[ Mon Jan  9 16:26:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 16:26:08 2023 ] Eval epoch: 1
[ Mon Jan  9 16:38:42 2023 ] 	Mean test loss of 796 batches: 2.69046626947633.
[ Mon Jan  9 16:38:44 2023 ] 	Top1: 27.24%
[ Mon Jan  9 16:38:44 2023 ] 	Top5: 62.29%
[ Mon Jan  9 16:38:44 2023 ] Training epoch: 2
[ Mon Jan  9 17:06:37 2023 ] 	Mean training loss: 2.1020.  Mean training acc: 41.90%.
[ Mon Jan  9 17:06:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 17:06:39 2023 ] Eval epoch: 2
[ Mon Jan  9 17:21:12 2023 ] 	Mean test loss of 796 batches: 1.7399542408073367.
[ Mon Jan  9 17:21:13 2023 ] 	Top1: 49.98%
[ Mon Jan  9 17:21:13 2023 ] 	Top5: 82.43%
[ Mon Jan  9 17:21:14 2023 ] Training epoch: 3
[ Mon Jan  9 17:49:36 2023 ] 	Mean training loss: 1.5552.  Mean training acc: 55.42%.
[ Mon Jan  9 17:49:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 17:49:56 2023 ] Eval epoch: 3
[ Mon Jan  9 18:05:24 2023 ] 	Mean test loss of 796 batches: 1.5306492638797615.
[ Mon Jan  9 18:05:26 2023 ] 	Top1: 56.04%
[ Mon Jan  9 18:05:26 2023 ] 	Top5: 86.55%
[ Mon Jan  9 18:05:26 2023 ] Training epoch: 4
[ Mon Jan  9 18:33:38 2023 ] 	Mean training loss: 1.3291.  Mean training acc: 61.41%.
[ Mon Jan  9 18:33:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 18:33:41 2023 ] Eval epoch: 4
[ Mon Jan  9 18:48:46 2023 ] 	Mean test loss of 796 batches: 1.5991568891846355.
[ Mon Jan  9 18:48:48 2023 ] 	Top1: 55.33%
[ Mon Jan  9 18:48:48 2023 ] 	Top5: 85.75%
[ Mon Jan  9 18:48:49 2023 ] Training epoch: 5
[ Mon Jan  9 19:17:11 2023 ] 	Mean training loss: 1.2365.  Mean training acc: 63.67%.
[ Mon Jan  9 19:17:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 19:17:12 2023 ] Eval epoch: 5
[ Mon Jan  9 19:31:41 2023 ] 	Mean test loss of 796 batches: 1.4470458939746396.
[ Mon Jan  9 19:31:42 2023 ] 	Top1: 57.30%
[ Mon Jan  9 19:31:42 2023 ] 	Top5: 87.79%
[ Mon Jan  9 19:31:43 2023 ] Training epoch: 6
[ Mon Jan  9 20:00:35 2023 ] 	Mean training loss: 1.0993.  Mean training acc: 67.40%.
[ Mon Jan  9 20:00:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Mon Jan  9 20:00:37 2023 ] Eval epoch: 6
[ Mon Jan  9 20:15:03 2023 ] 	Mean test loss of 796 batches: 1.866064881035431.
[ Mon Jan  9 20:15:05 2023 ] 	Top1: 53.35%
[ Mon Jan  9 20:15:05 2023 ] 	Top5: 83.99%
[ Mon Jan  9 20:15:06 2023 ] Training epoch: 7
[ Mon Jan  9 20:43:42 2023 ] 	Mean training loss: 1.0280.  Mean training acc: 69.49%.
[ Mon Jan  9 20:43:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 20:43:44 2023 ] Eval epoch: 7
[ Mon Jan  9 20:58:02 2023 ] 	Mean test loss of 796 batches: 1.2014359175484983.
[ Mon Jan  9 20:58:06 2023 ] 	Top1: 64.85%
[ Mon Jan  9 20:58:06 2023 ] 	Top5: 91.54%
[ Mon Jan  9 20:58:07 2023 ] Training epoch: 8
[ Mon Jan  9 21:27:31 2023 ] 	Mean training loss: 0.9775.  Mean training acc: 70.89%.
[ Mon Jan  9 21:27:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 21:27:32 2023 ] Eval epoch: 8
[ Mon Jan  9 21:41:58 2023 ] 	Mean test loss of 796 batches: 1.177736516836001.
[ Mon Jan  9 21:42:00 2023 ] 	Top1: 65.22%
[ Mon Jan  9 21:42:00 2023 ] 	Top5: 91.42%
[ Mon Jan  9 21:42:00 2023 ] Training epoch: 9
[ Mon Jan  9 22:11:58 2023 ] 	Mean training loss: 0.9310.  Mean training acc: 72.29%.
[ Mon Jan  9 22:11:58 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 22:12:00 2023 ] Eval epoch: 9
[ Mon Jan  9 22:27:25 2023 ] 	Mean test loss of 796 batches: 1.2715531887870337.
[ Mon Jan  9 22:27:26 2023 ] 	Top1: 62.31%
[ Mon Jan  9 22:27:27 2023 ] 	Top5: 90.49%
[ Mon Jan  9 22:27:27 2023 ] Training epoch: 10
[ Mon Jan  9 22:56:34 2023 ] 	Mean training loss: 0.9047.  Mean training acc: 72.93%.
[ Mon Jan  9 22:56:34 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 22:56:35 2023 ] Eval epoch: 10
[ Mon Jan  9 23:11:47 2023 ] 	Mean test loss of 796 batches: 1.1364753645418877.
[ Mon Jan  9 23:11:50 2023 ] 	Top1: 67.37%
[ Mon Jan  9 23:11:51 2023 ] 	Top5: 92.01%
[ Mon Jan  9 23:11:51 2023 ] Training epoch: 11
[ Mon Jan  9 23:40:39 2023 ] 	Mean training loss: 0.8770.  Mean training acc: 73.68%.
[ Mon Jan  9 23:40:39 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 23:40:40 2023 ] Eval epoch: 11
[ Mon Jan  9 23:56:07 2023 ] 	Mean test loss of 796 batches: 1.1653004021725464.
[ Mon Jan  9 23:56:13 2023 ] 	Top1: 67.16%
[ Mon Jan  9 23:56:14 2023 ] 	Top5: 92.06%
[ Mon Jan  9 23:56:14 2023 ] Training epoch: 12
[ Tue Jan 10 00:24:37 2023 ] 	Mean training loss: 0.8557.  Mean training acc: 74.45%.
[ Tue Jan 10 00:24:37 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 00:24:38 2023 ] Eval epoch: 12
[ Tue Jan 10 00:40:08 2023 ] 	Mean test loss of 796 batches: 0.9932212089773399.
[ Tue Jan 10 00:40:09 2023 ] 	Top1: 69.65%
[ Tue Jan 10 00:40:10 2023 ] 	Top5: 93.75%
[ Tue Jan 10 00:40:10 2023 ] Training epoch: 13
[ Tue Jan 10 01:08:35 2023 ] 	Mean training loss: 0.8425.  Mean training acc: 74.83%.
[ Tue Jan 10 01:08:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 01:08:37 2023 ] Eval epoch: 13
[ Tue Jan 10 01:23:55 2023 ] 	Mean test loss of 796 batches: 1.1410113040676069.
[ Tue Jan 10 01:23:58 2023 ] 	Top1: 67.49%
[ Tue Jan 10 01:23:58 2023 ] 	Top5: 91.43%
[ Tue Jan 10 01:23:59 2023 ] Training epoch: 14
[ Tue Jan 10 01:52:16 2023 ] 	Mean training loss: 0.8287.  Mean training acc: 75.11%.
[ Tue Jan 10 01:52:18 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 01:52:19 2023 ] Eval epoch: 14
[ Tue Jan 10 02:07:25 2023 ] 	Mean test loss of 796 batches: 0.9684629084252233.
[ Tue Jan 10 02:07:27 2023 ] 	Top1: 71.31%
[ Tue Jan 10 02:07:27 2023 ] 	Top5: 93.46%
[ Tue Jan 10 02:07:28 2023 ] Training epoch: 15
[ Tue Jan 10 02:35:51 2023 ] 	Mean training loss: 0.8116.  Mean training acc: 75.62%.
[ Tue Jan 10 02:35:51 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 02:35:51 2023 ] Eval epoch: 15
[ Tue Jan 10 02:50:42 2023 ] 	Mean test loss of 796 batches: 1.0137138759071505.
[ Tue Jan 10 02:50:43 2023 ] 	Top1: 70.43%
[ Tue Jan 10 02:50:44 2023 ] 	Top5: 93.00%
[ Tue Jan 10 02:50:44 2023 ] Training epoch: 16
[ Tue Jan 10 03:19:22 2023 ] 	Mean training loss: 0.8038.  Mean training acc: 75.71%.
[ Tue Jan 10 03:19:24 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 03:19:25 2023 ] Eval epoch: 16
[ Tue Jan 10 03:34:23 2023 ] 	Mean test loss of 796 batches: 1.2234525309136166.
[ Tue Jan 10 03:34:23 2023 ] 	Top1: 64.22%
[ Tue Jan 10 03:34:24 2023 ] 	Top5: 91.01%
[ Tue Jan 10 03:34:24 2023 ] Training epoch: 17
[ Tue Jan 10 04:02:48 2023 ] 	Mean training loss: 0.7957.  Mean training acc: 76.29%.
[ Tue Jan 10 04:02:48 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 04:03:00 2023 ] Eval epoch: 17
[ Tue Jan 10 04:17:23 2023 ] 	Mean test loss of 796 batches: 1.1639360291274947.
[ Tue Jan 10 04:17:27 2023 ] 	Top1: 67.20%
[ Tue Jan 10 04:17:28 2023 ] 	Top5: 90.77%
[ Tue Jan 10 04:17:29 2023 ] Training epoch: 18
[ Tue Jan 10 04:45:54 2023 ] 	Mean training loss: 0.7853.  Mean training acc: 76.53%.
[ Tue Jan 10 04:45:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 04:45:55 2023 ] Eval epoch: 18
[ Tue Jan 10 05:00:50 2023 ] 	Mean test loss of 796 batches: 1.1768577078254379.
[ Tue Jan 10 05:00:56 2023 ] 	Top1: 66.13%
[ Tue Jan 10 05:00:56 2023 ] 	Top5: 91.27%
[ Tue Jan 10 05:00:57 2023 ] Training epoch: 19
[ Tue Jan 10 05:29:20 2023 ] 	Mean training loss: 0.7767.  Mean training acc: 76.82%.
[ Tue Jan 10 05:29:20 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 05:29:21 2023 ] Eval epoch: 19
[ Tue Jan 10 05:44:21 2023 ] 	Mean test loss of 796 batches: 1.062390650037545.
[ Tue Jan 10 05:44:22 2023 ] 	Top1: 69.36%
[ Tue Jan 10 05:44:22 2023 ] 	Top5: 92.28%
[ Tue Jan 10 05:44:23 2023 ] Training epoch: 20
[ Tue Jan 10 06:12:39 2023 ] 	Mean training loss: 0.7765.  Mean training acc: 76.42%.
[ Tue Jan 10 06:12:39 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 06:12:39 2023 ] Eval epoch: 20
[ Tue Jan 10 06:27:47 2023 ] 	Mean test loss of 796 batches: 1.0694457008011977.
[ Tue Jan 10 06:27:48 2023 ] 	Top1: 68.85%
[ Tue Jan 10 06:27:48 2023 ] 	Top5: 93.02%
[ Tue Jan 10 06:27:49 2023 ] Training epoch: 21
[ Tue Jan 10 06:56:07 2023 ] 	Mean training loss: 0.7641.  Mean training acc: 77.08%.
[ Tue Jan 10 06:56:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 06:56:08 2023 ] Eval epoch: 21
[ Tue Jan 10 07:11:27 2023 ] 	Mean test loss of 796 batches: 1.0686813261940251.
[ Tue Jan 10 07:11:29 2023 ] 	Top1: 68.27%
[ Tue Jan 10 07:11:29 2023 ] 	Top5: 93.00%
[ Tue Jan 10 07:11:29 2023 ] Training epoch: 22
[ Tue Jan 10 07:39:27 2023 ] 	Mean training loss: 0.7631.  Mean training acc: 76.97%.
[ Tue Jan 10 07:39:28 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 07:39:29 2023 ] Eval epoch: 22
[ Tue Jan 10 07:54:11 2023 ] 	Mean test loss of 796 batches: 0.9539009758912439.
[ Tue Jan 10 07:54:12 2023 ] 	Top1: 71.90%
[ Tue Jan 10 07:54:13 2023 ] 	Top5: 94.14%
[ Tue Jan 10 07:54:14 2023 ] Training epoch: 23
[ Tue Jan 10 08:22:35 2023 ] 	Mean training loss: 0.7680.  Mean training acc: 76.91%.
[ Tue Jan 10 08:22:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 08:22:36 2023 ] Eval epoch: 23
[ Tue Jan 10 08:37:19 2023 ] 	Mean test loss of 796 batches: 0.9478402618861678.
[ Tue Jan 10 08:37:33 2023 ] 	Top1: 72.01%
[ Tue Jan 10 08:37:33 2023 ] 	Top5: 93.70%
[ Tue Jan 10 08:37:34 2023 ] Training epoch: 24
[ Tue Jan 10 08:59:52 2023 ] 	Mean training loss: 0.7569.  Mean training acc: 77.10%.
[ Tue Jan 10 08:59:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 08:59:59 2023 ] Eval epoch: 24
[ Tue Jan 10 09:12:29 2023 ] 	Mean test loss of 796 batches: 1.0189750079608442.
[ Tue Jan 10 09:12:31 2023 ] 	Top1: 69.83%
[ Tue Jan 10 09:12:32 2023 ] 	Top5: 92.77%
[ Tue Jan 10 09:12:33 2023 ] Training epoch: 25
[ Tue Jan 10 09:34:10 2023 ] 	Mean training loss: 0.7529.  Mean training acc: 77.32%.
[ Tue Jan 10 09:34:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:34:12 2023 ] Eval epoch: 25
[ Tue Jan 10 09:48:05 2023 ] 	Mean test loss of 796 batches: 1.052597267843371.
[ Tue Jan 10 09:48:06 2023 ] 	Top1: 70.14%
[ Tue Jan 10 09:48:06 2023 ] 	Top5: 92.07%
[ Tue Jan 10 09:48:07 2023 ] Training epoch: 26
[ Tue Jan 10 10:10:04 2023 ] 	Mean training loss: 0.7516.  Mean training acc: 77.39%.
[ Tue Jan 10 10:10:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:10:07 2023 ] Eval epoch: 26
[ Tue Jan 10 10:23:55 2023 ] 	Mean test loss of 796 batches: 1.033688613705.
[ Tue Jan 10 10:23:56 2023 ] 	Top1: 69.86%
[ Tue Jan 10 10:23:56 2023 ] 	Top5: 92.95%
[ Tue Jan 10 10:23:57 2023 ] Training epoch: 27
[ Tue Jan 10 10:45:13 2023 ] 	Mean training loss: 0.7552.  Mean training acc: 77.26%.
[ Tue Jan 10 10:45:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:45:15 2023 ] Eval epoch: 27
[ Tue Jan 10 10:58:07 2023 ] 	Mean test loss of 796 batches: 1.0171469807924338.
[ Tue Jan 10 10:58:08 2023 ] 	Top1: 71.02%
[ Tue Jan 10 10:58:09 2023 ] 	Top5: 93.15%
[ Tue Jan 10 10:58:09 2023 ] Training epoch: 28
[ Tue Jan 10 11:20:09 2023 ] 	Mean training loss: 0.7494.  Mean training acc: 77.26%.
[ Tue Jan 10 11:20:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:20:11 2023 ] Eval epoch: 28
[ Tue Jan 10 11:32:15 2023 ] 	Mean test loss of 796 batches: 1.0822398020094963.
[ Tue Jan 10 11:32:16 2023 ] 	Top1: 69.64%
[ Tue Jan 10 11:32:16 2023 ] 	Top5: 92.11%
[ Tue Jan 10 11:32:17 2023 ] Training epoch: 29
[ Tue Jan 10 11:54:39 2023 ] 	Mean training loss: 0.7468.  Mean training acc: 77.63%.
[ Tue Jan 10 11:54:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:54:41 2023 ] Eval epoch: 29
[ Tue Jan 10 12:08:56 2023 ] 	Mean test loss of 796 batches: 0.9860386560909712.
[ Tue Jan 10 12:08:57 2023 ] 	Top1: 71.69%
[ Tue Jan 10 12:08:58 2023 ] 	Top5: 93.04%
[ Tue Jan 10 12:08:58 2023 ] Training epoch: 30
[ Tue Jan 10 12:31:30 2023 ] 	Mean training loss: 0.7415.  Mean training acc: 77.82%.
[ Tue Jan 10 12:31:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:31:32 2023 ] Eval epoch: 30
[ Tue Jan 10 12:45:57 2023 ] 	Mean test loss of 796 batches: 0.9384622734844984.
[ Tue Jan 10 12:45:59 2023 ] 	Top1: 71.70%
[ Tue Jan 10 12:45:59 2023 ] 	Top5: 94.02%
[ Tue Jan 10 12:46:00 2023 ] Training epoch: 31
[ Tue Jan 10 13:08:43 2023 ] 	Mean training loss: 0.7426.  Mean training acc: 77.77%.
[ Tue Jan 10 13:08:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:08:46 2023 ] Eval epoch: 31
[ Tue Jan 10 13:22:55 2023 ] 	Mean test loss of 796 batches: 1.00757201289262.
[ Tue Jan 10 13:22:56 2023 ] 	Top1: 71.09%
[ Tue Jan 10 13:22:56 2023 ] 	Top5: 92.90%
[ Tue Jan 10 13:22:57 2023 ] Training epoch: 32
[ Tue Jan 10 13:45:35 2023 ] 	Mean training loss: 0.7471.  Mean training acc: 77.35%.
[ Tue Jan 10 13:45:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:45:43 2023 ] Eval epoch: 32
[ Tue Jan 10 14:03:09 2023 ] 	Mean test loss of 796 batches: 1.0210210722894524.
[ Tue Jan 10 14:03:12 2023 ] 	Top1: 70.08%
[ Tue Jan 10 14:03:13 2023 ] 	Top5: 93.48%
[ Tue Jan 10 14:03:15 2023 ] Training epoch: 33
[ Tue Jan 10 14:37:25 2023 ] 	Mean training loss: 0.7343.  Mean training acc: 77.99%.
[ Tue Jan 10 14:37:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 14:38:07 2023 ] Eval epoch: 33
[ Tue Jan 10 14:56:21 2023 ] 	Mean test loss of 796 batches: 1.0128636823302537.
[ Tue Jan 10 14:56:23 2023 ] 	Top1: 70.00%
[ Tue Jan 10 14:56:23 2023 ] 	Top5: 93.01%
[ Tue Jan 10 14:56:25 2023 ] Training epoch: 34
[ Tue Jan 10 15:30:34 2023 ] 	Mean training loss: 0.7263.  Mean training acc: 78.22%.
[ Tue Jan 10 15:30:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:30:40 2023 ] Eval epoch: 34
[ Tue Jan 10 15:49:04 2023 ] 	Mean test loss of 796 batches: 1.0421736705018647.
[ Tue Jan 10 15:49:07 2023 ] 	Top1: 70.24%
[ Tue Jan 10 15:49:08 2023 ] 	Top5: 92.90%
[ Tue Jan 10 15:49:10 2023 ] Training epoch: 35
[ Tue Jan 10 16:23:26 2023 ] 	Mean training loss: 0.7308.  Mean training acc: 77.93%.
[ Tue Jan 10 16:23:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 16:23:29 2023 ] Eval epoch: 35
[ Tue Jan 10 16:42:10 2023 ] 	Mean test loss of 796 batches: 1.0978750004690496.
[ Tue Jan 10 16:42:14 2023 ] 	Top1: 67.74%
[ Tue Jan 10 16:42:15 2023 ] 	Top5: 92.59%
[ Tue Jan 10 16:42:16 2023 ] Training epoch: 36
[ Tue Jan 10 17:20:04 2023 ] 	Mean training loss: 0.4102.  Mean training acc: 87.78%.
[ Tue Jan 10 17:20:10 2023 ] 	Time consumption: [Data]00%, [Network]91%
[ Tue Jan 10 17:20:17 2023 ] Eval epoch: 36
[ Tue Jan 10 17:38:21 2023 ] 	Mean test loss of 796 batches: 0.5258984915144629.
[ Tue Jan 10 17:38:25 2023 ] 	Top1: 84.06%
[ Tue Jan 10 17:38:25 2023 ] 	Top5: 97.24%
[ Tue Jan 10 17:38:28 2023 ] Training epoch: 37
[ Tue Jan 10 18:15:27 2023 ] 	Mean training loss: 0.3177.  Mean training acc: 90.51%.
[ Tue Jan 10 18:15:28 2023 ] 	Time consumption: [Data]01%, [Network]95%
[ Tue Jan 10 18:15:30 2023 ] Eval epoch: 37
[ Tue Jan 10 18:36:43 2023 ] 	Mean test loss of 796 batches: 0.5201074658242527.
[ Tue Jan 10 18:36:47 2023 ] 	Top1: 84.37%
[ Tue Jan 10 18:36:47 2023 ] 	Top5: 97.28%
[ Tue Jan 10 18:36:48 2023 ] Training epoch: 38
[ Tue Jan 10 19:15:16 2023 ] 	Mean training loss: 0.2848.  Mean training acc: 91.33%.
[ Tue Jan 10 19:15:18 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 19:15:20 2023 ] Eval epoch: 38
[ Tue Jan 10 19:37:31 2023 ] 	Mean test loss of 796 batches: 0.502441572989501.
[ Tue Jan 10 19:37:32 2023 ] 	Top1: 84.99%
[ Tue Jan 10 19:37:33 2023 ] 	Top5: 97.52%
[ Tue Jan 10 19:37:34 2023 ] Training epoch: 39
[ Tue Jan 10 20:16:02 2023 ] 	Mean training loss: 0.2600.  Mean training acc: 92.20%.
[ Tue Jan 10 20:16:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:16:05 2023 ] Eval epoch: 39
[ Tue Jan 10 20:38:07 2023 ] 	Mean test loss of 796 batches: 0.5061179912934576.
[ Tue Jan 10 20:38:15 2023 ] 	Top1: 85.04%
[ Tue Jan 10 20:38:16 2023 ] 	Top5: 97.32%
[ Tue Jan 10 20:38:16 2023 ] Training epoch: 40
[ Tue Jan 10 21:16:56 2023 ] 	Mean training loss: 0.2387.  Mean training acc: 92.95%.
[ Tue Jan 10 21:17:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 21:17:05 2023 ] Eval epoch: 40
[ Tue Jan 10 21:38:49 2023 ] 	Mean test loss of 796 batches: 0.5350586939696691.
[ Tue Jan 10 21:38:50 2023 ] 	Top1: 84.31%
[ Tue Jan 10 21:38:51 2023 ] 	Top5: 97.21%
[ Tue Jan 10 21:38:51 2023 ] Training epoch: 41
[ Tue Jan 10 22:17:26 2023 ] 	Mean training loss: 0.2204.  Mean training acc: 93.50%.
[ Tue Jan 10 22:17:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 22:17:29 2023 ] Eval epoch: 41
[ Tue Jan 10 22:39:37 2023 ] 	Mean test loss of 796 batches: 0.5328763198977964.
[ Tue Jan 10 22:39:38 2023 ] 	Top1: 84.55%
[ Tue Jan 10 22:39:39 2023 ] 	Top5: 97.21%
[ Tue Jan 10 22:39:39 2023 ] Training epoch: 42
[ Tue Jan 10 23:17:23 2023 ] 	Mean training loss: 0.2110.  Mean training acc: 93.80%.
[ Tue Jan 10 23:17:24 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 23:17:26 2023 ] Eval epoch: 42
[ Tue Jan 10 23:39:19 2023 ] 	Mean test loss of 796 batches: 0.5410974408036575.
[ Tue Jan 10 23:39:21 2023 ] 	Top1: 84.32%
[ Tue Jan 10 23:39:22 2023 ] 	Top5: 97.24%
[ Tue Jan 10 23:39:22 2023 ] Training epoch: 43
[ Wed Jan 11 00:24:30 2023 ] 	Mean training loss: 0.2003.  Mean training acc: 94.11%.
[ Wed Jan 11 00:24:31 2023 ] 	Time consumption: [Data]00%, [Network]83%
[ Wed Jan 11 00:24:31 2023 ] Eval epoch: 43
[ Wed Jan 11 00:44:44 2023 ] 	Mean test loss of 796 batches: 0.5580571047708991.
[ Wed Jan 11 00:44:45 2023 ] 	Top1: 84.03%
[ Wed Jan 11 00:44:46 2023 ] 	Top5: 97.11%
[ Wed Jan 11 00:44:46 2023 ] Training epoch: 44
[ Wed Jan 11 01:20:42 2023 ] 	Mean training loss: 0.1952.  Mean training acc: 94.42%.
[ Wed Jan 11 01:20:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 01:20:44 2023 ] Eval epoch: 44
[ Wed Jan 11 01:41:02 2023 ] 	Mean test loss of 796 batches: 0.5520368315204603.
[ Wed Jan 11 01:41:03 2023 ] 	Top1: 84.19%
[ Wed Jan 11 01:41:03 2023 ] 	Top5: 97.14%
[ Wed Jan 11 01:41:03 2023 ] Training epoch: 45
[ Wed Jan 11 02:17:00 2023 ] 	Mean training loss: 0.1889.  Mean training acc: 94.53%.
[ Wed Jan 11 02:17:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 02:17:08 2023 ] Eval epoch: 45
[ Wed Jan 11 02:37:29 2023 ] 	Mean test loss of 796 batches: 0.5864932226232398.
[ Wed Jan 11 02:37:34 2023 ] 	Top1: 83.51%
[ Wed Jan 11 02:37:34 2023 ] 	Top5: 97.00%
[ Wed Jan 11 02:37:34 2023 ] Training epoch: 46
[ Wed Jan 11 03:14:16 2023 ] 	Mean training loss: 0.1831.  Mean training acc: 94.62%.
[ Wed Jan 11 03:14:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 03:14:17 2023 ] Eval epoch: 46
[ Wed Jan 11 03:35:59 2023 ] 	Mean test loss of 796 batches: 0.5742153991341367.
[ Wed Jan 11 03:36:00 2023 ] 	Top1: 84.00%
[ Wed Jan 11 03:36:00 2023 ] 	Top5: 97.02%
[ Wed Jan 11 03:36:01 2023 ] Training epoch: 47
[ Wed Jan 11 04:14:21 2023 ] 	Mean training loss: 0.1792.  Mean training acc: 94.82%.
[ Wed Jan 11 04:14:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:14:24 2023 ] Eval epoch: 47
[ Wed Jan 11 04:36:17 2023 ] 	Mean test loss of 796 batches: 0.5683742729787851.
[ Wed Jan 11 04:36:18 2023 ] 	Top1: 84.17%
[ Wed Jan 11 04:36:18 2023 ] 	Top5: 97.02%
[ Wed Jan 11 04:36:18 2023 ] Training epoch: 48
[ Wed Jan 11 05:15:10 2023 ] 	Mean training loss: 0.1794.  Mean training acc: 94.84%.
[ Wed Jan 11 05:15:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 05:15:11 2023 ] Eval epoch: 48
[ Wed Jan 11 05:36:57 2023 ] 	Mean test loss of 796 batches: 0.5671746595084068.
[ Wed Jan 11 05:37:00 2023 ] 	Top1: 84.23%
[ Wed Jan 11 05:37:01 2023 ] 	Top5: 97.09%
[ Wed Jan 11 05:37:01 2023 ] Training epoch: 49
[ Wed Jan 11 12:24:34 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:36:14 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:41:08 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:41:38 2023 ] using warm up, epoch: 5
[ Wed Jan 11 12:46:10 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:46:13 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:47:51 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 49, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:47:51 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:47:51 2023 ] Training epoch: 50
[ Wed Jan 11 12:48:41 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt.
[ Wed Jan 11 12:48:44 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:49:02 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:49:02 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:49:02 2023 ] Training epoch: 49
[ Wed Jan 11 12:50:33 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt.
[ Wed Jan 11 12:50:37 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:50:52 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT_bone/runs-48-47232.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:50:52 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:50:52 2023 ] Training epoch: 49
[ Wed Jan 11 13:16:42 2023 ] 	Mean training loss: 0.1737.  Mean training acc: 94.92%.
[ Wed Jan 11 13:16:43 2023 ] 	Time consumption: [Data]00%, [Network]90%
[ Wed Jan 11 13:16:43 2023 ] Eval epoch: 49
[ Wed Jan 11 13:36:32 2023 ] 	Mean test loss of 796 batches: 0.6181181672698439.
[ Wed Jan 11 13:36:33 2023 ] 	Top1: 83.39%
[ Wed Jan 11 13:36:34 2023 ] 	Top5: 96.68%
[ Wed Jan 11 13:36:36 2023 ] Training epoch: 50
[ Wed Jan 11 14:16:10 2023 ] 	Mean training loss: 0.1751.  Mean training acc: 94.88%.
[ Wed Jan 11 14:16:11 2023 ] 	Time consumption: [Data]01%, [Network]84%
[ Wed Jan 11 14:16:12 2023 ] Eval epoch: 50
[ Wed Jan 11 14:37:00 2023 ] 	Mean test loss of 796 batches: 0.6391387500673832.
[ Wed Jan 11 14:37:02 2023 ] 	Top1: 82.66%
[ Wed Jan 11 14:37:02 2023 ] 	Top5: 96.64%
[ Wed Jan 11 14:37:02 2023 ] Training epoch: 51
[ Wed Jan 11 15:16:33 2023 ] 	Mean training loss: 0.1798.  Mean training acc: 94.75%.
[ Wed Jan 11 15:16:34 2023 ] 	Time consumption: [Data]01%, [Network]86%
[ Wed Jan 11 15:16:34 2023 ] Eval epoch: 51
[ Wed Jan 11 15:38:00 2023 ] 	Mean test loss of 796 batches: 0.6211046703889891.
[ Wed Jan 11 15:38:02 2023 ] 	Top1: 82.85%
[ Wed Jan 11 15:38:02 2023 ] 	Top5: 96.60%
[ Wed Jan 11 15:38:03 2023 ] Training epoch: 52
[ Wed Jan 11 16:28:21 2023 ] 	Mean training loss: 0.1771.  Mean training acc: 94.89%.
[ Wed Jan 11 16:28:22 2023 ] 	Time consumption: [Data]00%, [Network]69%
[ Wed Jan 11 16:28:23 2023 ] Eval epoch: 52
[ Wed Jan 11 16:48:40 2023 ] 	Mean test loss of 796 batches: 0.6157425588755002.
[ Wed Jan 11 16:48:40 2023 ] 	Top1: 83.24%
[ Wed Jan 11 16:48:41 2023 ] 	Top5: 96.66%
[ Wed Jan 11 16:48:42 2023 ] Training epoch: 53
[ Wed Jan 11 17:21:09 2023 ] 	Mean training loss: 0.1816.  Mean training acc: 94.75%.
[ Wed Jan 11 17:21:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 17:21:10 2023 ] Eval epoch: 53
[ Wed Jan 11 17:35:15 2023 ] 	Mean test loss of 796 batches: 0.6604087305297355.
[ Wed Jan 11 17:35:16 2023 ] 	Top1: 82.51%
[ Wed Jan 11 17:35:16 2023 ] 	Top5: 96.24%
[ Wed Jan 11 17:35:17 2023 ] Training epoch: 54
[ Wed Jan 11 17:59:13 2023 ] 	Mean training loss: 0.1741.  Mean training acc: 94.92%.
[ Wed Jan 11 17:59:13 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Wed Jan 11 17:59:14 2023 ] Eval epoch: 54
[ Wed Jan 11 18:08:36 2023 ] 	Mean test loss of 796 batches: 0.6028564107749406.
[ Wed Jan 11 18:08:37 2023 ] 	Top1: 83.42%
[ Wed Jan 11 18:08:37 2023 ] 	Top5: 96.74%
[ Wed Jan 11 18:08:38 2023 ] Training epoch: 55
[ Wed Jan 11 18:34:30 2023 ] 	Mean training loss: 0.1730.  Mean training acc: 94.95%.
[ Wed Jan 11 18:34:31 2023 ] 	Time consumption: [Data]00%, [Network]90%
[ Wed Jan 11 18:34:32 2023 ] Eval epoch: 55
[ Wed Jan 11 18:45:56 2023 ] 	Mean test loss of 796 batches: 0.6509839486021867.
[ Wed Jan 11 18:45:57 2023 ] 	Top1: 82.37%
[ Wed Jan 11 18:45:57 2023 ] 	Top5: 96.62%
[ Wed Jan 11 18:45:57 2023 ] Training epoch: 56
[ Wed Jan 11 19:14:45 2023 ] 	Mean training loss: 0.1021.  Mean training acc: 97.48%.
[ Wed Jan 11 19:14:45 2023 ] 	Time consumption: [Data]00%, [Network]80%
[ Wed Jan 11 19:14:46 2023 ] Eval epoch: 56
[ Wed Jan 11 19:24:29 2023 ] 	Mean test loss of 796 batches: 0.5328608143105916.
[ Wed Jan 11 19:24:45 2023 ] 	Top1: 85.37%
[ Wed Jan 11 19:24:46 2023 ] 	Top5: 97.25%
[ Wed Jan 11 19:24:46 2023 ] Training epoch: 57
[ Wed Jan 11 19:50:28 2023 ] 	Mean training loss: 0.0764.  Mean training acc: 98.30%.
[ Wed Jan 11 19:50:29 2023 ] 	Time consumption: [Data]01%, [Network]86%
[ Wed Jan 11 19:50:29 2023 ] Eval epoch: 57
[ Wed Jan 11 20:01:13 2023 ] 	Mean test loss of 796 batches: 0.536161619449156.
[ Wed Jan 11 20:01:15 2023 ] 	Top1: 85.50%
[ Wed Jan 11 20:01:15 2023 ] 	Top5: 97.30%
[ Wed Jan 11 20:01:16 2023 ] Training epoch: 58
[ Wed Jan 11 20:29:54 2023 ] 	Mean training loss: 0.0644.  Mean training acc: 98.68%.
[ Wed Jan 11 20:29:55 2023 ] 	Time consumption: [Data]00%, [Network]82%
[ Wed Jan 11 20:29:56 2023 ] Eval epoch: 58
[ Wed Jan 11 20:40:59 2023 ] 	Mean test loss of 796 batches: 0.5347045123595838.
[ Wed Jan 11 20:41:00 2023 ] 	Top1: 85.53%
[ Wed Jan 11 20:41:01 2023 ] 	Top5: 97.29%
[ Wed Jan 11 20:41:01 2023 ] Training epoch: 59
[ Wed Jan 11 21:14:56 2023 ] 	Mean training loss: 0.0606.  Mean training acc: 98.76%.
[ Wed Jan 11 21:14:57 2023 ] 	Time consumption: [Data]00%, [Network]69%
[ Wed Jan 11 21:14:57 2023 ] Eval epoch: 59
[ Wed Jan 11 21:26:16 2023 ] 	Mean test loss of 796 batches: 0.5389243212467687.
[ Wed Jan 11 21:26:17 2023 ] 	Top1: 85.58%
[ Wed Jan 11 21:26:17 2023 ] 	Top5: 97.24%
[ Wed Jan 11 21:26:17 2023 ] Training epoch: 60
[ Wed Jan 11 21:51:22 2023 ] 	Mean training loss: 0.0551.  Mean training acc: 98.93%.
[ Wed Jan 11 21:51:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 21:51:22 2023 ] Eval epoch: 60
[ Wed Jan 11 22:02:19 2023 ] 	Mean test loss of 796 batches: 0.538259614392385.
[ Wed Jan 11 22:02:19 2023 ] 	Top1: 85.60%
[ Wed Jan 11 22:02:19 2023 ] 	Top5: 97.27%
[ Wed Jan 11 22:02:19 2023 ] Training epoch: 61
[ Wed Jan 11 22:25:21 2023 ] 	Mean training loss: 0.0517.  Mean training acc: 99.06%.
[ Wed Jan 11 22:25:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 22:25:21 2023 ] Eval epoch: 61
[ Wed Jan 11 22:35:47 2023 ] 	Mean test loss of 796 batches: 0.5436628072513221.
[ Wed Jan 11 22:35:48 2023 ] 	Top1: 85.63%
[ Wed Jan 11 22:35:48 2023 ] 	Top5: 97.25%
[ Wed Jan 11 22:35:48 2023 ] Training epoch: 62
[ Wed Jan 11 22:58:15 2023 ] 	Mean training loss: 0.0494.  Mean training acc: 99.12%.
[ Wed Jan 11 22:58:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 22:58:16 2023 ] Eval epoch: 62
[ Wed Jan 11 23:08:31 2023 ] 	Mean test loss of 796 batches: 0.5466563003629109.
[ Wed Jan 11 23:08:32 2023 ] 	Top1: 85.50%
[ Wed Jan 11 23:08:32 2023 ] 	Top5: 97.19%
[ Wed Jan 11 23:08:32 2023 ] Training epoch: 63
[ Wed Jan 11 23:31:15 2023 ] 	Mean training loss: 0.0475.  Mean training acc: 99.15%.
[ Wed Jan 11 23:31:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 23:31:15 2023 ] Eval epoch: 63
[ Wed Jan 11 23:41:27 2023 ] 	Mean test loss of 796 batches: 0.5536100744227668.
[ Wed Jan 11 23:41:27 2023 ] 	Top1: 85.42%
[ Wed Jan 11 23:41:28 2023 ] 	Top5: 97.21%
[ Wed Jan 11 23:41:28 2023 ] Training epoch: 64
[ Thu Jan 12 00:04:29 2023 ] 	Mean training loss: 0.0438.  Mean training acc: 99.29%.
[ Thu Jan 12 00:04:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 00:04:29 2023 ] Eval epoch: 64
[ Thu Jan 12 00:14:41 2023 ] 	Mean test loss of 796 batches: 0.5537914788284942.
[ Thu Jan 12 00:14:41 2023 ] 	Top1: 85.51%
[ Thu Jan 12 00:14:42 2023 ] 	Top5: 97.13%
[ Thu Jan 12 00:14:42 2023 ] Training epoch: 65
[ Thu Jan 12 00:37:18 2023 ] 	Mean training loss: 0.0433.  Mean training acc: 99.26%.
[ Thu Jan 12 00:37:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 00:37:18 2023 ] Eval epoch: 65
[ Thu Jan 12 00:47:24 2023 ] 	Mean test loss of 796 batches: 0.5510755018904412.
[ Thu Jan 12 00:47:24 2023 ] 	Top1: 85.58%
[ Thu Jan 12 00:47:24 2023 ] 	Top5: 97.21%
[ Thu Jan 12 00:57:29 2023 ] Best accuracy: 0.856261906164693
[ Thu Jan 12 00:57:29 2023 ] Epoch number: 61
[ Thu Jan 12 00:57:29 2023 ] Model name: work_dir/csub/ctrgcn_local_SHT_bone
[ Thu Jan 12 00:57:29 2023 ] Model total number of params: 1508876
[ Thu Jan 12 00:57:29 2023 ] Weight decay: 0.0004
[ Thu Jan 12 00:57:29 2023 ] Base LR: 0.1
[ Thu Jan 12 00:57:29 2023 ] Batch Size: 64
[ Thu Jan 12 00:57:29 2023 ] Test Batch Size: 64
[ Thu Jan 12 00:57:29 2023 ] seed: 1
[ Thu Feb  2 18:01:25 2023 ] using warm up, epoch: 5
[ Thu Feb  2 18:02:06 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Feb  2 18:02:06 2023 ] # Parameters: 1508876
[ Thu Feb  2 18:02:06 2023 ] Training epoch: 1
[ Thu Feb  2 18:11:14 2023 ] using warm up, epoch: 5
[ Thu Feb  2 18:11:30 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Feb  2 18:11:30 2023 ] # Parameters: 1508876
[ Thu Feb  2 18:11:30 2023 ] Training epoch: 1
[ Thu Feb  2 19:09:19 2023 ] 	Mean training loss: 3.3632.  Mean training acc: 18.54%.
[ Thu Feb  2 19:09:19 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Feb  2 19:09:19 2023 ] Eval epoch: 1
[ Thu Feb  2 22:38:50 2023 ] 	Mean test loss of 796 batches: 2.6154366101152333.
[ Thu Feb  2 22:38:50 2023 ] 	Top1: 28.54%
[ Thu Feb  2 22:38:50 2023 ] 	Top5: 65.04%
[ Thu Feb  2 22:38:50 2023 ] Training epoch: 2
[ Fri Feb  3 06:59:37 2023 ] 	Mean training loss: 2.0902.  Mean training acc: 42.48%.
[ Fri Feb  3 06:59:38 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Feb  3 06:59:38 2023 ] Eval epoch: 2
[ Fri Feb  3 07:54:23 2023 ] 	Mean test loss of 796 batches: 1.8205549254938587.
[ Fri Feb  3 07:54:29 2023 ] 	Top1: 47.89%
[ Fri Feb  3 07:54:29 2023 ] 	Top5: 82.05%
[ Fri Feb  3 07:54:30 2023 ] Training epoch: 3
[ Fri Feb  3 10:53:54 2023 ] 	Mean training loss: 1.5602.  Mean training acc: 55.34%.
[ Fri Feb  3 10:53:54 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Feb  3 10:53:54 2023 ] Eval epoch: 3
[ Fri Feb  3 13:09:38 2023 ] 	Mean test loss of 796 batches: 1.5749914091286348.
[ Fri Feb  3 13:09:40 2023 ] 	Top1: 54.25%
[ Fri Feb  3 13:09:40 2023 ] 	Top5: 86.31%
[ Fri Feb  3 13:09:40 2023 ] Training epoch: 4
[ Fri Feb  3 16:28:14 2023 ] 	Mean training loss: 1.3352.  Mean training acc: 61.02%.
[ Fri Feb  3 16:28:14 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Feb  3 16:28:14 2023 ] Eval epoch: 4
[ Fri Feb  3 19:03:29 2023 ] 	Mean test loss of 796 batches: 1.4226595330328198.
[ Fri Feb  3 19:03:29 2023 ] 	Top1: 58.37%
[ Fri Feb  3 19:03:29 2023 ] 	Top5: 88.00%
[ Fri Feb  3 19:03:29 2023 ] Training epoch: 5
[ Fri Feb  3 23:03:07 2023 ] 	Mean training loss: 1.2358.  Mean training acc: 63.69%.
[ Fri Feb  3 23:03:07 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Feb  3 23:03:07 2023 ] Eval epoch: 5
[ Sat Feb  4 01:51:59 2023 ] 	Mean test loss of 796 batches: 1.5790941071270699.
[ Sat Feb  4 01:51:59 2023 ] 	Top1: 54.71%
[ Sat Feb  4 01:51:59 2023 ] 	Top5: 85.56%
[ Sat Feb  4 01:51:59 2023 ] Training epoch: 6
[ Sat Feb  4 05:58:58 2023 ] 	Mean training loss: 1.0975.  Mean training acc: 67.70%.
[ Sat Feb  4 05:58:58 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 05:58:58 2023 ] Eval epoch: 6
[ Sat Feb  4 08:05:49 2023 ] 	Mean test loss of 796 batches: 1.3009330567403055.
[ Sat Feb  4 08:05:50 2023 ] 	Top1: 62.27%
[ Sat Feb  4 08:05:50 2023 ] 	Top5: 89.62%
[ Sat Feb  4 08:05:51 2023 ] Training epoch: 7
[ Sat Feb  4 11:06:14 2023 ] 	Mean training loss: 1.0180.  Mean training acc: 69.70%.
[ Sat Feb  4 11:06:14 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 11:06:14 2023 ] Eval epoch: 7
[ Sat Feb  4 12:58:03 2023 ] 	Mean test loss of 796 batches: 1.2877865760919436.
[ Sat Feb  4 12:58:03 2023 ] 	Top1: 63.61%
[ Sat Feb  4 12:58:04 2023 ] 	Top5: 90.16%
[ Sat Feb  4 12:58:04 2023 ] Training epoch: 8
[ Sat Feb  4 13:21:07 2023 ] 	Mean training loss: 0.9786.  Mean training acc: 70.83%.
[ Sat Feb  4 13:21:07 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 13:21:07 2023 ] Eval epoch: 8
[ Sat Feb  4 14:09:23 2023 ] 	Mean test loss of 796 batches: 1.1732600590017572.
[ Sat Feb  4 14:09:23 2023 ] 	Top1: 65.90%
[ Sat Feb  4 14:09:23 2023 ] 	Top5: 91.17%
[ Sat Feb  4 14:09:24 2023 ] Training epoch: 9
[ Sat Feb  4 17:38:45 2023 ] 	Mean training loss: 0.9303.  Mean training acc: 72.17%.
[ Sat Feb  4 17:38:45 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 17:38:45 2023 ] Eval epoch: 9
[ Sat Feb  4 20:09:59 2023 ] 	Mean test loss of 796 batches: 1.086846381613058.
[ Sat Feb  4 20:09:59 2023 ] 	Top1: 67.45%
[ Sat Feb  4 20:10:00 2023 ] 	Top5: 92.59%
[ Sat Feb  4 20:10:00 2023 ] Training epoch: 10
[ Sat Feb  4 23:38:27 2023 ] 	Mean training loss: 0.9081.  Mean training acc: 72.95%.
[ Sat Feb  4 23:38:27 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 23:38:27 2023 ] Eval epoch: 10
[ Sun Feb  5 01:52:05 2023 ] 	Mean test loss of 796 batches: 1.3355248153359447.
[ Sun Feb  5 01:52:05 2023 ] 	Top1: 63.31%
[ Sun Feb  5 01:52:06 2023 ] 	Top5: 89.40%
[ Sun Feb  5 01:52:06 2023 ] Training epoch: 11
[ Sun Feb  5 05:21:18 2023 ] 	Mean training loss: 0.8842.  Mean training acc: 73.46%.
[ Sun Feb  5 05:21:18 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 05:21:19 2023 ] Eval epoch: 11
[ Sun Feb  5 07:30:08 2023 ] 	Mean test loss of 796 batches: 1.139449420137022.
[ Sun Feb  5 07:30:09 2023 ] 	Top1: 66.61%
[ Sun Feb  5 07:30:09 2023 ] 	Top5: 91.92%
[ Sun Feb  5 07:30:09 2023 ] Training epoch: 12
[ Sun Feb  5 10:24:50 2023 ] 	Mean training loss: 0.8634.  Mean training acc: 74.11%.
[ Sun Feb  5 10:24:51 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 10:24:51 2023 ] Eval epoch: 12
[ Sun Feb  5 12:59:23 2023 ] 	Mean test loss of 796 batches: 1.3486807831193335.
[ Sun Feb  5 12:59:24 2023 ] 	Top1: 63.02%
[ Sun Feb  5 12:59:24 2023 ] 	Top5: 90.98%
[ Sun Feb  5 12:59:24 2023 ] Training epoch: 13
[ Sun Feb  5 14:20:52 2023 ] 	Mean training loss: 0.8536.  Mean training acc: 74.57%.
[ Sun Feb  5 14:20:52 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 14:20:52 2023 ] Eval epoch: 13
[ Sun Feb  5 14:59:49 2023 ] 	Mean test loss of 796 batches: 1.1588002599064429.
[ Sun Feb  5 14:59:49 2023 ] 	Top1: 67.10%
[ Sun Feb  5 14:59:49 2023 ] 	Top5: 91.84%
[ Sun Feb  5 14:59:50 2023 ] Training epoch: 14
[ Sun Feb  5 18:07:55 2023 ] 	Mean training loss: 0.8343.  Mean training acc: 74.95%.
[ Sun Feb  5 18:07:55 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 18:07:55 2023 ] Eval epoch: 14
[ Sun Feb  5 20:15:25 2023 ] 	Mean test loss of 796 batches: 1.0080651317409535.
[ Sun Feb  5 20:15:26 2023 ] 	Top1: 70.84%
[ Sun Feb  5 20:15:26 2023 ] 	Top5: 93.31%
[ Sun Feb  5 20:15:26 2023 ] Training epoch: 15
[ Sun Feb  5 21:49:09 2023 ] 	Mean training loss: 0.8244.  Mean training acc: 75.35%.
[ Sun Feb  5 21:49:09 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 21:49:09 2023 ] Eval epoch: 15
[ Sun Feb  5 22:15:14 2023 ] 	Mean test loss of 796 batches: 1.193298472269396.
[ Sun Feb  5 22:15:14 2023 ] 	Top1: 66.12%
[ Sun Feb  5 22:15:14 2023 ] 	Top5: 91.48%
[ Sun Feb  5 22:15:15 2023 ] Training epoch: 16
[ Sun Feb  5 23:45:21 2023 ] 	Mean training loss: 0.8093.  Mean training acc: 75.72%.
[ Sun Feb  5 23:45:21 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 23:45:22 2023 ] Eval epoch: 16
[ Mon Feb  6 01:06:56 2023 ] 	Mean test loss of 796 batches: 1.0862782691516468.
[ Mon Feb  6 01:06:56 2023 ] 	Top1: 68.17%
[ Mon Feb  6 01:06:57 2023 ] 	Top5: 92.51%
[ Mon Feb  6 01:06:57 2023 ] Training epoch: 17
[ Mon Feb  6 02:40:49 2023 ] 	Mean training loss: 0.8033.  Mean training acc: 75.87%.
[ Mon Feb  6 02:40:49 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 02:40:50 2023 ] Eval epoch: 17
[ Mon Feb  6 03:05:31 2023 ] 	Mean test loss of 796 batches: 1.0249248798094204.
[ Mon Feb  6 03:05:32 2023 ] 	Top1: 70.20%
[ Mon Feb  6 03:05:32 2023 ] 	Top5: 92.64%
[ Mon Feb  6 03:05:32 2023 ] Training epoch: 18
[ Mon Feb  6 04:36:43 2023 ] 	Mean training loss: 0.7940.  Mean training acc: 76.26%.
[ Mon Feb  6 04:36:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 04:36:43 2023 ] Eval epoch: 18
[ Mon Feb  6 06:00:46 2023 ] 	Mean test loss of 796 batches: 0.9920143840750258.
[ Mon Feb  6 06:00:46 2023 ] 	Top1: 71.46%
[ Mon Feb  6 06:00:47 2023 ] 	Top5: 93.64%
[ Mon Feb  6 06:00:47 2023 ] Training epoch: 19
[ Mon Feb  6 07:46:58 2023 ] 	Mean training loss: 0.7822.  Mean training acc: 76.70%.
[ Mon Feb  6 07:46:58 2023 ] 	Time consumption: [Data]00%, [Network]91%
[ Mon Feb  6 07:46:58 2023 ] Eval epoch: 19
[ Mon Feb  6 08:21:16 2023 ] 	Mean test loss of 796 batches: 1.2106656577044994.
[ Mon Feb  6 08:21:17 2023 ] 	Top1: 65.95%
[ Mon Feb  6 08:21:17 2023 ] 	Top5: 91.21%
[ Mon Feb  6 08:21:18 2023 ] Training epoch: 20
[ Mon Feb  6 09:38:34 2023 ] 	Mean training loss: 0.7837.  Mean training acc: 76.56%.
[ Mon Feb  6 09:38:34 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 09:38:34 2023 ] Eval epoch: 20
[ Mon Feb  6 10:55:29 2023 ] 	Mean test loss of 796 batches: 1.1194157774873714.
[ Mon Feb  6 10:55:29 2023 ] 	Top1: 68.72%
[ Mon Feb  6 10:55:29 2023 ] 	Top5: 92.92%
[ Mon Feb  6 10:55:30 2023 ] Training epoch: 21
[ Mon Feb  6 13:54:44 2023 ] 	Mean training loss: 0.7747.  Mean training acc: 76.68%.
[ Mon Feb  6 13:54:44 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 13:54:44 2023 ] Eval epoch: 21
[ Mon Feb  6 16:04:06 2023 ] 	Mean test loss of 796 batches: 1.0135441319127778.
[ Mon Feb  6 16:04:06 2023 ] 	Top1: 70.55%
[ Mon Feb  6 16:04:07 2023 ] 	Top5: 93.03%
[ Mon Feb  6 16:04:07 2023 ] Training epoch: 22
[ Mon Feb  6 19:36:02 2023 ] 	Mean training loss: 0.7679.  Mean training acc: 76.90%.
[ Mon Feb  6 19:36:02 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 19:36:02 2023 ] Eval epoch: 22
[ Mon Feb  6 21:53:03 2023 ] 	Mean test loss of 796 batches: 1.025862075163791.
[ Mon Feb  6 21:53:03 2023 ] 	Top1: 70.26%
[ Mon Feb  6 21:53:04 2023 ] 	Top5: 92.99%
[ Mon Feb  6 21:53:04 2023 ] Training epoch: 23
[ Tue Feb  7 01:19:53 2023 ] 	Mean training loss: 0.7678.  Mean training acc: 77.04%.
[ Tue Feb  7 01:19:53 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 01:19:53 2023 ] Eval epoch: 23
[ Tue Feb  7 03:34:04 2023 ] 	Mean test loss of 796 batches: 1.1778426678411325.
[ Tue Feb  7 03:34:05 2023 ] 	Top1: 66.55%
[ Tue Feb  7 03:34:05 2023 ] 	Top5: 91.11%
[ Tue Feb  7 03:34:05 2023 ] Training epoch: 24
[ Tue Feb  7 06:53:00 2023 ] 	Mean training loss: 0.7619.  Mean training acc: 77.19%.
[ Tue Feb  7 06:53:02 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 06:53:02 2023 ] Eval epoch: 24
[ Tue Feb  7 08:30:50 2023 ] 	Mean test loss of 796 batches: 0.9960981245016932.
[ Tue Feb  7 08:30:51 2023 ] 	Top1: 70.47%
[ Tue Feb  7 08:30:51 2023 ] 	Top5: 93.09%
[ Tue Feb  7 08:30:51 2023 ] Training epoch: 25
[ Tue Feb  7 11:18:10 2023 ] 	Mean training loss: 0.7563.  Mean training acc: 77.32%.
[ Tue Feb  7 11:18:10 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Feb  7 11:18:10 2023 ] Eval epoch: 25
[ Tue Feb  7 13:37:35 2023 ] 	Mean test loss of 796 batches: 1.0101563477111821.
[ Tue Feb  7 13:37:35 2023 ] 	Top1: 71.21%
[ Tue Feb  7 13:37:36 2023 ] 	Top5: 92.38%
[ Tue Feb  7 13:37:36 2023 ] Training epoch: 26
[ Tue Feb  7 16:56:16 2023 ] 	Mean training loss: 0.7543.  Mean training acc: 77.28%.
[ Tue Feb  7 16:56:16 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 16:56:16 2023 ] Eval epoch: 26
[ Tue Feb  7 19:06:37 2023 ] 	Mean test loss of 796 batches: 1.0389985025078807.
[ Tue Feb  7 19:06:37 2023 ] 	Top1: 69.39%
[ Tue Feb  7 19:06:38 2023 ] 	Top5: 92.87%
[ Tue Feb  7 19:06:38 2023 ] Training epoch: 27
[ Tue Feb  7 19:28:50 2023 ] 	Mean training loss: 0.7553.  Mean training acc: 77.44%.
[ Tue Feb  7 19:28:50 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 19:28:50 2023 ] Eval epoch: 27
[ Tue Feb  7 19:42:29 2023 ] 	Mean test loss of 796 batches: 1.0783805878992057.
[ Tue Feb  7 19:42:29 2023 ] 	Top1: 69.42%
[ Tue Feb  7 19:42:29 2023 ] 	Top5: 93.21%
[ Tue Feb  7 19:42:29 2023 ] Training epoch: 28
[ Tue Feb  7 20:48:23 2023 ] 	Mean training loss: 0.7544.  Mean training acc: 77.34%.
[ Tue Feb  7 20:48:23 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 20:48:23 2023 ] Eval epoch: 28
[ Tue Feb  7 22:56:57 2023 ] 	Mean test loss of 796 batches: 1.1016191736088325.
[ Tue Feb  7 22:56:58 2023 ] 	Top1: 68.14%
[ Tue Feb  7 22:56:58 2023 ] 	Top5: 92.15%
[ Tue Feb  7 22:56:58 2023 ] Training epoch: 29
[ Wed Feb  8 02:05:26 2023 ] 	Mean training loss: 0.7435.  Mean training acc: 77.57%.
[ Wed Feb  8 02:05:26 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 02:05:26 2023 ] Eval epoch: 29
[ Wed Feb  8 04:25:56 2023 ] 	Mean test loss of 796 batches: 0.9465618262713279.
[ Wed Feb  8 04:25:56 2023 ] 	Top1: 72.65%
[ Wed Feb  8 04:25:56 2023 ] 	Top5: 93.85%
[ Wed Feb  8 04:25:56 2023 ] Training epoch: 30
[ Wed Feb  8 07:25:42 2023 ] 	Mean training loss: 0.7434.  Mean training acc: 77.61%.
[ Wed Feb  8 07:25:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 07:25:43 2023 ] Eval epoch: 30
[ Wed Feb  8 08:49:31 2023 ] 	Mean test loss of 796 batches: 0.9156706180779179.
[ Wed Feb  8 08:49:31 2023 ] 	Top1: 73.05%
[ Wed Feb  8 08:49:32 2023 ] 	Top5: 93.74%
[ Wed Feb  8 08:49:32 2023 ] Training epoch: 31
[ Wed Feb  8 11:44:14 2023 ] 	Mean training loss: 0.7457.  Mean training acc: 77.53%.
[ Wed Feb  8 11:44:14 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 11:44:14 2023 ] Eval epoch: 31
[ Wed Feb  8 13:50:04 2023 ] 	Mean test loss of 796 batches: 0.9963566979496323.
[ Wed Feb  8 13:50:04 2023 ] 	Top1: 71.98%
[ Wed Feb  8 13:50:05 2023 ] 	Top5: 92.70%
[ Wed Feb  8 13:50:05 2023 ] Training epoch: 32
[ Tue Feb 14 19:43:14 2023 ] using warm up, epoch: 5
[ Tue Feb 14 19:43:38 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_bone', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Feb 14 19:43:38 2023 ] # Parameters: 1508876
[ Tue Feb 14 19:43:38 2023 ] Training epoch: 1
[ Tue Feb 14 20:01:34 2023 ] 	Mean training loss: 3.3903.  Mean training acc: 18.26%.
[ Tue Feb 14 20:01:34 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:01:34 2023 ] Eval epoch: 1
[ Tue Feb 14 20:11:26 2023 ] 	Mean test loss of 796 batches: 2.672199724607132.
[ Tue Feb 14 20:11:26 2023 ] 	Top1: 27.74%
[ Tue Feb 14 20:11:27 2023 ] 	Top5: 63.33%
[ Tue Feb 14 20:11:27 2023 ] Training epoch: 2
[ Tue Feb 14 20:29:20 2023 ] 	Mean training loss: 2.1050.  Mean training acc: 41.97%.
[ Tue Feb 14 20:29:20 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:29:20 2023 ] Eval epoch: 2
[ Tue Feb 14 20:39:12 2023 ] 	Mean test loss of 796 batches: 1.8443699130161324.
[ Tue Feb 14 20:39:12 2023 ] 	Top1: 47.89%
[ Tue Feb 14 20:39:13 2023 ] 	Top5: 81.84%
[ Tue Feb 14 20:39:13 2023 ] Training epoch: 3
[ Tue Feb 14 20:57:02 2023 ] 	Mean training loss: 1.5540.  Mean training acc: 55.21%.
[ Tue Feb 14 20:57:02 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:57:02 2023 ] Eval epoch: 3
[ Tue Feb 14 21:06:52 2023 ] 	Mean test loss of 796 batches: 1.6121189364386563.
[ Tue Feb 14 21:06:52 2023 ] 	Top1: 53.25%
[ Tue Feb 14 21:06:53 2023 ] 	Top5: 85.90%
[ Tue Feb 14 21:06:53 2023 ] Training epoch: 4
[ Tue Feb 14 21:24:44 2023 ] 	Mean training loss: 1.3209.  Mean training acc: 61.43%.
[ Tue Feb 14 21:24:44 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 21:24:44 2023 ] Eval epoch: 4
[ Tue Feb 14 21:34:36 2023 ] 	Mean test loss of 796 batches: 1.331425638953645.
[ Tue Feb 14 21:34:37 2023 ] 	Top1: 60.69%
[ Tue Feb 14 21:34:37 2023 ] 	Top5: 89.32%
[ Tue Feb 14 21:34:37 2023 ] Training epoch: 5
[ Tue Feb 14 21:52:28 2023 ] 	Mean training loss: 1.2229.  Mean training acc: 64.15%.
[ Tue Feb 14 21:52:28 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 21:52:28 2023 ] Eval epoch: 5
[ Tue Feb 14 22:02:20 2023 ] 	Mean test loss of 796 batches: 1.5431529610750063.
[ Tue Feb 14 22:02:20 2023 ] 	Top1: 55.48%
[ Tue Feb 14 22:02:20 2023 ] 	Top5: 86.73%
[ Tue Feb 14 22:02:21 2023 ] Training epoch: 6
[ Tue Feb 14 22:20:14 2023 ] 	Mean training loss: 1.1001.  Mean training acc: 67.61%.
[ Tue Feb 14 22:20:14 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 22:20:14 2023 ] Eval epoch: 6
[ Tue Feb 14 22:29:59 2023 ] 	Mean test loss of 796 batches: 1.27455041763471.
[ Tue Feb 14 22:29:59 2023 ] 	Top1: 62.20%
[ Tue Feb 14 22:29:59 2023 ] 	Top5: 89.69%
[ Tue Feb 14 22:29:59 2023 ] Training epoch: 7
[ Tue Feb 14 22:47:52 2023 ] 	Mean training loss: 1.0273.  Mean training acc: 69.35%.
[ Tue Feb 14 22:47:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 22:47:52 2023 ] Eval epoch: 7
[ Tue Feb 14 22:57:37 2023 ] 	Mean test loss of 796 batches: 1.2009539692545657.
[ Tue Feb 14 22:57:38 2023 ] 	Top1: 64.54%
[ Tue Feb 14 22:57:38 2023 ] 	Top5: 90.98%
[ Tue Feb 14 22:57:38 2023 ] Training epoch: 8
[ Tue Feb 14 23:15:28 2023 ] 	Mean training loss: 0.9914.  Mean training acc: 70.52%.
[ Tue Feb 14 23:15:28 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 23:15:28 2023 ] Eval epoch: 8
[ Tue Feb 14 23:25:15 2023 ] 	Mean test loss of 796 batches: 1.3059073221219244.
[ Tue Feb 14 23:25:16 2023 ] 	Top1: 62.35%
[ Tue Feb 14 23:25:16 2023 ] 	Top5: 90.09%
[ Tue Feb 14 23:25:16 2023 ] Training epoch: 9
[ Tue Feb 14 23:43:11 2023 ] 	Mean training loss: 0.9386.  Mean training acc: 72.14%.
[ Tue Feb 14 23:43:11 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 23:43:11 2023 ] Eval epoch: 9
[ Tue Feb 14 23:52:56 2023 ] 	Mean test loss of 796 batches: 1.1901305600177103.
[ Tue Feb 14 23:52:57 2023 ] 	Top1: 64.66%
[ Tue Feb 14 23:52:57 2023 ] 	Top5: 91.51%
[ Tue Feb 14 23:52:57 2023 ] Training epoch: 10
[ Wed Feb 15 00:10:48 2023 ] 	Mean training loss: 0.9158.  Mean training acc: 72.69%.
[ Wed Feb 15 00:10:48 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 00:10:48 2023 ] Eval epoch: 10
[ Wed Feb 15 00:20:28 2023 ] 	Mean test loss of 796 batches: 1.2690463415042839.
[ Wed Feb 15 00:20:28 2023 ] 	Top1: 62.36%
[ Wed Feb 15 00:20:28 2023 ] 	Top5: 90.20%
[ Wed Feb 15 00:20:28 2023 ] Training epoch: 11
[ Wed Feb 15 00:38:20 2023 ] 	Mean training loss: 0.8880.  Mean training acc: 73.45%.
[ Wed Feb 15 00:38:20 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 00:38:20 2023 ] Eval epoch: 11
[ Wed Feb 15 00:47:56 2023 ] 	Mean test loss of 796 batches: 1.0738821465840291.
[ Wed Feb 15 00:47:57 2023 ] 	Top1: 68.98%
[ Wed Feb 15 00:47:57 2023 ] 	Top5: 92.39%
[ Wed Feb 15 00:47:57 2023 ] Training epoch: 12
[ Wed Feb 15 01:05:50 2023 ] 	Mean training loss: 0.8663.  Mean training acc: 74.00%.
[ Wed Feb 15 01:05:50 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 01:05:50 2023 ] Eval epoch: 12
[ Wed Feb 15 01:15:25 2023 ] 	Mean test loss of 796 batches: 1.022237695603814.
[ Wed Feb 15 01:15:25 2023 ] 	Top1: 69.06%
[ Wed Feb 15 01:15:26 2023 ] 	Top5: 93.47%
[ Wed Feb 15 01:15:26 2023 ] Training epoch: 13
[ Wed Feb 15 01:33:15 2023 ] 	Mean training loss: 0.8566.  Mean training acc: 74.35%.
[ Wed Feb 15 01:33:15 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 01:33:15 2023 ] Eval epoch: 13
[ Wed Feb 15 01:42:48 2023 ] 	Mean test loss of 796 batches: 1.294998106120819.
[ Wed Feb 15 01:42:48 2023 ] 	Top1: 63.50%
[ Wed Feb 15 01:42:49 2023 ] 	Top5: 89.83%
[ Wed Feb 15 01:42:49 2023 ] Training epoch: 14
[ Wed Feb 15 02:00:39 2023 ] 	Mean training loss: 0.8438.  Mean training acc: 74.63%.
[ Wed Feb 15 02:00:39 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 02:00:39 2023 ] Eval epoch: 14
[ Wed Feb 15 02:10:06 2023 ] 	Mean test loss of 796 batches: 0.9748422026858857.
[ Wed Feb 15 02:10:06 2023 ] 	Top1: 71.08%
[ Wed Feb 15 02:10:07 2023 ] 	Top5: 93.59%
[ Wed Feb 15 02:10:07 2023 ] Training epoch: 15
[ Wed Feb 15 02:28:00 2023 ] 	Mean training loss: 0.8236.  Mean training acc: 75.29%.
[ Wed Feb 15 02:28:00 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 02:28:00 2023 ] Eval epoch: 15
[ Wed Feb 15 02:37:26 2023 ] 	Mean test loss of 796 batches: 0.9921986832840359.
[ Wed Feb 15 02:37:26 2023 ] 	Top1: 71.04%
[ Wed Feb 15 02:37:27 2023 ] 	Top5: 93.19%
[ Wed Feb 15 02:37:27 2023 ] Training epoch: 16
[ Wed Feb 15 02:55:19 2023 ] 	Mean training loss: 0.8224.  Mean training acc: 75.19%.
[ Wed Feb 15 02:55:19 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 02:55:19 2023 ] Eval epoch: 16
[ Wed Feb 15 03:04:43 2023 ] 	Mean test loss of 796 batches: 1.0549316027730553.
[ Wed Feb 15 03:04:43 2023 ] 	Top1: 68.17%
[ Wed Feb 15 03:04:44 2023 ] 	Top5: 92.77%
[ Wed Feb 15 03:04:44 2023 ] Training epoch: 17
[ Wed Feb 15 03:22:32 2023 ] 	Mean training loss: 0.8051.  Mean training acc: 75.85%.
[ Wed Feb 15 03:22:32 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 03:22:32 2023 ] Eval epoch: 17
[ Wed Feb 15 03:31:54 2023 ] 	Mean test loss of 796 batches: 1.0327065696368865.
[ Wed Feb 15 03:31:55 2023 ] 	Top1: 70.29%
[ Wed Feb 15 03:31:55 2023 ] 	Top5: 92.69%
[ Wed Feb 15 03:31:55 2023 ] Training epoch: 18
[ Wed Feb 15 03:49:43 2023 ] 	Mean training loss: 0.8009.  Mean training acc: 76.13%.
[ Wed Feb 15 03:49:43 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 03:49:43 2023 ] Eval epoch: 18
[ Wed Feb 15 03:59:05 2023 ] 	Mean test loss of 796 batches: 0.998595350014804.
[ Wed Feb 15 03:59:05 2023 ] 	Top1: 70.70%
[ Wed Feb 15 03:59:06 2023 ] 	Top5: 93.26%
[ Wed Feb 15 03:59:06 2023 ] Training epoch: 19
[ Wed Feb 15 04:16:59 2023 ] 	Mean training loss: 0.7926.  Mean training acc: 76.12%.
[ Wed Feb 15 04:16:59 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 04:16:59 2023 ] Eval epoch: 19
[ Wed Feb 15 04:26:20 2023 ] 	Mean test loss of 796 batches: 1.0832519087959174.
[ Wed Feb 15 04:26:21 2023 ] 	Top1: 68.41%
[ Wed Feb 15 04:26:21 2023 ] 	Top5: 92.04%
[ Wed Feb 15 04:26:21 2023 ] Training epoch: 20
[ Wed Feb 15 04:44:01 2023 ] 	Mean training loss: 0.7890.  Mean training acc: 76.34%.
[ Wed Feb 15 04:44:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 04:44:01 2023 ] Eval epoch: 20
[ Wed Feb 15 04:53:20 2023 ] 	Mean test loss of 796 batches: 1.2438190781965328.
[ Wed Feb 15 04:53:21 2023 ] 	Top1: 65.38%
[ Wed Feb 15 04:53:21 2023 ] 	Top5: 91.83%
[ Wed Feb 15 04:53:21 2023 ] Training epoch: 21
[ Wed Feb 15 05:11:14 2023 ] 	Mean training loss: 0.7780.  Mean training acc: 76.68%.
[ Wed Feb 15 05:11:14 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 05:11:14 2023 ] Eval epoch: 21
[ Wed Feb 15 05:20:33 2023 ] 	Mean test loss of 796 batches: 0.9934162614333569.
[ Wed Feb 15 05:20:33 2023 ] 	Top1: 71.23%
[ Wed Feb 15 05:20:34 2023 ] 	Top5: 93.43%
[ Wed Feb 15 05:20:34 2023 ] Training epoch: 22
[ Wed Feb 15 05:38:21 2023 ] 	Mean training loss: 0.7733.  Mean training acc: 76.62%.
[ Wed Feb 15 05:38:21 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 05:38:21 2023 ] Eval epoch: 22
[ Wed Feb 15 05:47:42 2023 ] 	Mean test loss of 796 batches: 1.1245114017072035.
[ Wed Feb 15 05:47:42 2023 ] 	Top1: 68.21%
[ Wed Feb 15 05:47:42 2023 ] 	Top5: 92.09%
[ Wed Feb 15 05:47:42 2023 ] Training epoch: 23
[ Wed Feb 15 06:05:35 2023 ] 	Mean training loss: 0.7669.  Mean training acc: 76.94%.
[ Wed Feb 15 06:05:35 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:05:35 2023 ] Eval epoch: 23
[ Wed Feb 15 06:14:38 2023 ] 	Mean test loss of 796 batches: 1.04602406005464.
[ Wed Feb 15 06:14:39 2023 ] 	Top1: 69.42%
[ Wed Feb 15 06:14:39 2023 ] 	Top5: 92.41%
[ Wed Feb 15 06:14:39 2023 ] Training epoch: 24
[ Wed Feb 15 06:32:11 2023 ] 	Mean training loss: 0.7750.  Mean training acc: 76.50%.
[ Wed Feb 15 06:32:11 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:32:11 2023 ] Eval epoch: 24
[ Wed Feb 15 06:41:22 2023 ] 	Mean test loss of 796 batches: 1.1076196912844576.
[ Wed Feb 15 06:41:22 2023 ] 	Top1: 67.86%
[ Wed Feb 15 06:41:23 2023 ] 	Top5: 91.80%
[ Wed Feb 15 06:41:23 2023 ] Training epoch: 25
[ Wed Feb 15 06:59:15 2023 ] 	Mean training loss: 0.7608.  Mean training acc: 77.03%.
[ Wed Feb 15 06:59:15 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:59:15 2023 ] Eval epoch: 25
[ Wed Feb 15 07:08:26 2023 ] 	Mean test loss of 796 batches: 0.9226135942130232.
[ Wed Feb 15 07:08:26 2023 ] 	Top1: 72.78%
[ Wed Feb 15 07:08:27 2023 ] 	Top5: 94.03%
[ Wed Feb 15 07:08:27 2023 ] Training epoch: 26
[ Wed Feb 15 07:26:15 2023 ] 	Mean training loss: 0.7531.  Mean training acc: 77.34%.
[ Wed Feb 15 07:26:15 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 07:26:15 2023 ] Eval epoch: 26
[ Wed Feb 15 07:35:15 2023 ] 	Mean test loss of 796 batches: 1.0764872966774146.
[ Wed Feb 15 07:35:15 2023 ] 	Top1: 68.29%
[ Wed Feb 15 07:35:15 2023 ] 	Top5: 92.91%
[ Wed Feb 15 07:35:15 2023 ] Training epoch: 27
[ Wed Feb 15 07:52:43 2023 ] 	Mean training loss: 0.7508.  Mean training acc: 77.30%.
[ Wed Feb 15 07:52:43 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 07:52:43 2023 ] Eval epoch: 27
[ Wed Feb 15 08:01:41 2023 ] 	Mean test loss of 796 batches: 1.1546718877314324.
[ Wed Feb 15 08:01:42 2023 ] 	Top1: 67.65%
[ Wed Feb 15 08:01:42 2023 ] 	Top5: 92.26%
[ Wed Feb 15 08:01:42 2023 ] Training epoch: 28
[ Wed Feb 15 08:19:08 2023 ] 	Mean training loss: 0.7583.  Mean training acc: 76.98%.
[ Wed Feb 15 08:19:08 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 08:19:08 2023 ] Eval epoch: 28
[ Wed Feb 15 08:28:07 2023 ] 	Mean test loss of 796 batches: 0.9851028018036679.
[ Wed Feb 15 08:28:08 2023 ] 	Top1: 71.29%
[ Wed Feb 15 08:28:08 2023 ] 	Top5: 92.74%
[ Wed Feb 15 08:28:08 2023 ] Training epoch: 29
[ Wed Feb 15 08:45:36 2023 ] 	Mean training loss: 0.7445.  Mean training acc: 77.54%.
[ Wed Feb 15 08:45:36 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 08:45:37 2023 ] Eval epoch: 29
[ Wed Feb 15 08:54:36 2023 ] 	Mean test loss of 796 batches: 0.9870943965474565.
[ Wed Feb 15 08:54:36 2023 ] 	Top1: 71.66%
[ Wed Feb 15 08:54:37 2023 ] 	Top5: 93.41%
[ Wed Feb 15 08:54:37 2023 ] Training epoch: 30
[ Wed Feb 15 09:12:26 2023 ] 	Mean training loss: 0.7481.  Mean training acc: 77.31%.
[ Wed Feb 15 09:12:26 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 09:12:26 2023 ] Eval epoch: 30
[ Wed Feb 15 09:21:25 2023 ] 	Mean test loss of 796 batches: 0.954375449474433.
[ Wed Feb 15 09:21:25 2023 ] 	Top1: 71.93%
[ Wed Feb 15 09:21:26 2023 ] 	Top5: 93.77%
[ Wed Feb 15 09:21:26 2023 ] Training epoch: 31
[ Wed Feb 15 09:38:56 2023 ] 	Mean training loss: 0.7452.  Mean training acc: 77.61%.
[ Wed Feb 15 09:38:56 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 09:38:56 2023 ] Eval epoch: 31
[ Wed Feb 15 09:47:55 2023 ] 	Mean test loss of 796 batches: 0.887455659895087.
[ Wed Feb 15 09:47:55 2023 ] 	Top1: 73.77%
[ Wed Feb 15 09:47:56 2023 ] 	Top5: 94.13%
[ Wed Feb 15 09:47:56 2023 ] Training epoch: 32
[ Wed Feb 15 10:05:43 2023 ] 	Mean training loss: 0.7462.  Mean training acc: 77.52%.
[ Wed Feb 15 10:05:43 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:05:44 2023 ] Eval epoch: 32
[ Wed Feb 15 10:14:43 2023 ] 	Mean test loss of 796 batches: 1.031729397836642.
[ Wed Feb 15 10:14:44 2023 ] 	Top1: 69.89%
[ Wed Feb 15 10:14:44 2023 ] 	Top5: 93.25%
[ Wed Feb 15 10:14:44 2023 ] Training epoch: 33
[ Wed Feb 15 10:32:32 2023 ] 	Mean training loss: 0.7408.  Mean training acc: 77.64%.
[ Wed Feb 15 10:32:32 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:32:32 2023 ] Eval epoch: 33
[ Wed Feb 15 10:41:30 2023 ] 	Mean test loss of 796 batches: 1.0486573249700681.
[ Wed Feb 15 10:41:31 2023 ] 	Top1: 69.23%
[ Wed Feb 15 10:41:31 2023 ] 	Top5: 92.70%
[ Wed Feb 15 10:41:31 2023 ] Training epoch: 34
[ Wed Feb 15 10:59:08 2023 ] 	Mean training loss: 0.7343.  Mean training acc: 77.89%.
[ Wed Feb 15 10:59:08 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:59:08 2023 ] Eval epoch: 34
[ Wed Feb 15 11:08:07 2023 ] 	Mean test loss of 796 batches: 0.9765568900872116.
[ Wed Feb 15 11:08:08 2023 ] 	Top1: 71.00%
[ Wed Feb 15 11:08:08 2023 ] 	Top5: 93.87%
[ Wed Feb 15 11:08:08 2023 ] Training epoch: 35
[ Wed Feb 15 11:25:56 2023 ] 	Mean training loss: 0.7385.  Mean training acc: 77.79%.
[ Wed Feb 15 11:25:56 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:25:56 2023 ] Eval epoch: 35
[ Wed Feb 15 11:34:55 2023 ] 	Mean test loss of 796 batches: 0.9955413010551701.
[ Wed Feb 15 11:34:56 2023 ] 	Top1: 70.38%
[ Wed Feb 15 11:34:56 2023 ] 	Top5: 93.88%
[ Wed Feb 15 11:34:56 2023 ] Training epoch: 36
[ Wed Feb 15 11:52:24 2023 ] 	Mean training loss: 0.4136.  Mean training acc: 87.64%.
[ Wed Feb 15 11:52:24 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:52:24 2023 ] Eval epoch: 36
[ Wed Feb 15 12:01:23 2023 ] 	Mean test loss of 796 batches: 0.5307972939525867.
[ Wed Feb 15 12:01:24 2023 ] 	Top1: 83.85%
[ Wed Feb 15 12:01:24 2023 ] 	Top5: 97.25%
[ Wed Feb 15 12:01:24 2023 ] Training epoch: 37
[ Wed Feb 15 12:19:17 2023 ] 	Mean training loss: 0.3230.  Mean training acc: 90.33%.
[ Wed Feb 15 12:19:17 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:19:17 2023 ] Eval epoch: 37
[ Wed Feb 15 12:28:17 2023 ] 	Mean test loss of 796 batches: 0.5269845714090607.
[ Wed Feb 15 12:28:17 2023 ] 	Top1: 84.05%
[ Wed Feb 15 12:28:17 2023 ] 	Top5: 97.28%
[ Wed Feb 15 12:28:17 2023 ] Training epoch: 38
[ Wed Feb 15 12:46:03 2023 ] 	Mean training loss: 0.2899.  Mean training acc: 91.21%.
[ Wed Feb 15 12:46:03 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:46:03 2023 ] Eval epoch: 38
[ Wed Feb 15 12:55:03 2023 ] 	Mean test loss of 796 batches: 0.5148076593183243.
[ Wed Feb 15 12:55:03 2023 ] 	Top1: 84.59%
[ Wed Feb 15 12:55:04 2023 ] 	Top5: 97.40%
[ Wed Feb 15 12:55:04 2023 ] Training epoch: 39
[ Wed Feb 15 13:12:57 2023 ] 	Mean training loss: 0.2624.  Mean training acc: 92.03%.
[ Wed Feb 15 13:12:57 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:12:58 2023 ] Eval epoch: 39
[ Wed Feb 15 13:21:56 2023 ] 	Mean test loss of 796 batches: 0.5191498822509194.
[ Wed Feb 15 13:21:56 2023 ] 	Top1: 84.46%
[ Wed Feb 15 13:21:56 2023 ] 	Top5: 97.41%
[ Wed Feb 15 13:21:56 2023 ] Training epoch: 40
[ Wed Feb 15 13:39:27 2023 ] 	Mean training loss: 0.2417.  Mean training acc: 92.84%.
[ Wed Feb 15 13:39:27 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:39:27 2023 ] Eval epoch: 40
[ Wed Feb 15 13:48:26 2023 ] 	Mean test loss of 796 batches: 0.5285479825729477.
[ Wed Feb 15 13:48:26 2023 ] 	Top1: 84.31%
[ Wed Feb 15 13:48:27 2023 ] 	Top5: 97.23%
[ Wed Feb 15 13:48:27 2023 ] Training epoch: 41
[ Wed Feb 15 14:05:55 2023 ] 	Mean training loss: 0.2268.  Mean training acc: 93.35%.
[ Wed Feb 15 14:05:55 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:05:55 2023 ] Eval epoch: 41
[ Wed Feb 15 14:14:54 2023 ] 	Mean test loss of 796 batches: 0.5229295657283097.
[ Wed Feb 15 14:14:55 2023 ] 	Top1: 84.67%
[ Wed Feb 15 14:14:55 2023 ] 	Top5: 97.29%
[ Wed Feb 15 14:14:55 2023 ] Training epoch: 42
[ Wed Feb 15 14:32:21 2023 ] 	Mean training loss: 0.2156.  Mean training acc: 93.60%.
[ Wed Feb 15 14:32:21 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:32:21 2023 ] Eval epoch: 42
[ Wed Feb 15 14:41:21 2023 ] 	Mean test loss of 796 batches: 0.5550174949569019.
[ Wed Feb 15 14:41:21 2023 ] 	Top1: 83.91%
[ Wed Feb 15 14:41:21 2023 ] 	Top5: 97.20%
[ Wed Feb 15 14:41:22 2023 ] Training epoch: 43
[ Wed Feb 15 14:58:46 2023 ] 	Mean training loss: 0.2029.  Mean training acc: 94.13%.
[ Wed Feb 15 14:58:46 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:58:46 2023 ] Eval epoch: 43
[ Wed Feb 15 15:07:44 2023 ] 	Mean test loss of 796 batches: 0.5670893576520322.
[ Wed Feb 15 15:07:45 2023 ] 	Top1: 83.62%
[ Wed Feb 15 15:07:45 2023 ] 	Top5: 97.07%
[ Wed Feb 15 15:07:45 2023 ] Training epoch: 44
[ Wed Feb 15 15:25:21 2023 ] 	Mean training loss: 0.1976.  Mean training acc: 94.24%.
[ Wed Feb 15 15:25:21 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:25:21 2023 ] Eval epoch: 44
[ Wed Feb 15 15:34:20 2023 ] 	Mean test loss of 796 batches: 0.5462865722997479.
[ Wed Feb 15 15:34:21 2023 ] 	Top1: 84.26%
[ Wed Feb 15 15:34:21 2023 ] 	Top5: 97.25%
[ Wed Feb 15 15:34:21 2023 ] Training epoch: 45
[ Wed Feb 15 15:51:51 2023 ] 	Mean training loss: 0.1904.  Mean training acc: 94.43%.
[ Wed Feb 15 15:51:51 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:51:51 2023 ] Eval epoch: 45
[ Wed Feb 15 16:00:51 2023 ] 	Mean test loss of 796 batches: 0.5600833998684158.
[ Wed Feb 15 16:00:52 2023 ] 	Top1: 84.13%
[ Wed Feb 15 16:00:52 2023 ] 	Top5: 96.99%
[ Wed Feb 15 16:00:52 2023 ] Training epoch: 46
