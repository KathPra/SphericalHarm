[ Wed Nov  9 10:27:14 2022 ] using warm up, epoch: 5
[ Wed Nov  9 10:29:48 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHTg_bone_BL', 'model_saved_name': 'work_dir/ntu120/csub/local_SHTg_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Nov  9 10:29:48 2022 ] # Parameters: 2141090
[ Wed Nov  9 10:29:48 2022 ] Training epoch: 1
[ Wed Nov  9 10:39:26 2022 ] 	Mean training loss: 3.4713.  Mean training acc: 16.53%.
[ Wed Nov  9 10:39:26 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 10:39:26 2022 ] Eval epoch: 1
[ Wed Nov  9 10:44:02 2022 ] 	Mean test loss of 796 batches: 2.9610654172585837.
[ Wed Nov  9 10:44:03 2022 ] 	Top1: 21.35%
[ Wed Nov  9 10:44:04 2022 ] 	Top5: 52.92%
[ Wed Nov  9 10:44:05 2022 ] Training epoch: 2
[ Wed Nov  9 10:53:31 2022 ] 	Mean training loss: 2.2759.  Mean training acc: 38.23%.
[ Wed Nov  9 10:53:31 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 10:53:31 2022 ] Eval epoch: 2
[ Wed Nov  9 10:58:09 2022 ] 	Mean test loss of 796 batches: 2.2134713764166714.
[ Wed Nov  9 10:58:10 2022 ] 	Top1: 39.37%
[ Wed Nov  9 10:58:12 2022 ] 	Top5: 74.57%
[ Wed Nov  9 10:58:12 2022 ] Training epoch: 3
[ Wed Nov  9 11:07:39 2022 ] 	Mean training loss: 1.7170.  Mean training acc: 50.99%.
[ Wed Nov  9 11:07:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:07:39 2022 ] Eval epoch: 3
[ Wed Nov  9 11:12:06 2022 ] 	Mean test loss of 796 batches: 2.305763412061049.
[ Wed Nov  9 11:12:08 2022 ] 	Top1: 39.05%
[ Wed Nov  9 11:12:09 2022 ] 	Top5: 76.22%
[ Wed Nov  9 11:12:09 2022 ] Training epoch: 4
[ Wed Nov  9 11:21:29 2022 ] 	Mean training loss: 1.4734.  Mean training acc: 57.28%.
[ Wed Nov  9 11:21:29 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:21:29 2022 ] Eval epoch: 4
[ Wed Nov  9 11:26:02 2022 ] 	Mean test loss of 796 batches: 1.7672714260804594.
[ Wed Nov  9 11:26:03 2022 ] 	Top1: 51.48%
[ Wed Nov  9 11:26:04 2022 ] 	Top5: 82.93%
[ Wed Nov  9 11:26:05 2022 ] Training epoch: 5
[ Wed Nov  9 11:35:18 2022 ] 	Mean training loss: 1.3224.  Mean training acc: 61.35%.
[ Wed Nov  9 11:35:18 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:35:18 2022 ] Eval epoch: 5
[ Wed Nov  9 11:39:53 2022 ] 	Mean test loss of 796 batches: 1.5633974678851852.
[ Wed Nov  9 11:39:54 2022 ] 	Top1: 55.05%
[ Wed Nov  9 11:39:54 2022 ] 	Top5: 86.20%
[ Wed Nov  9 11:39:55 2022 ] Training epoch: 6
[ Wed Nov  9 11:49:09 2022 ] 	Mean training loss: 1.1661.  Mean training acc: 65.80%.
[ Wed Nov  9 11:49:09 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:49:09 2022 ] Eval epoch: 6
[ Wed Nov  9 11:53:42 2022 ] 	Mean test loss of 796 batches: 1.2375709158391808.
[ Wed Nov  9 11:53:43 2022 ] 	Top1: 63.29%
[ Wed Nov  9 11:53:44 2022 ] 	Top5: 90.93%
[ Wed Nov  9 11:53:44 2022 ] Training epoch: 7
[ Wed Nov  9 12:02:51 2022 ] 	Mean training loss: 1.0867.  Mean training acc: 67.98%.
[ Wed Nov  9 12:02:51 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:02:51 2022 ] Eval epoch: 7
[ Wed Nov  9 12:07:18 2022 ] 	Mean test loss of 796 batches: 1.3266781511618264.
[ Wed Nov  9 12:07:20 2022 ] 	Top1: 60.47%
[ Wed Nov  9 12:07:21 2022 ] 	Top5: 90.24%
[ Wed Nov  9 12:07:21 2022 ] Training epoch: 8
[ Wed Nov  9 12:16:39 2022 ] 	Mean training loss: 1.0264.  Mean training acc: 69.66%.
[ Wed Nov  9 12:16:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:16:39 2022 ] Eval epoch: 8
[ Wed Nov  9 12:21:11 2022 ] 	Mean test loss of 796 batches: 1.1928049709329653.
[ Wed Nov  9 12:21:12 2022 ] 	Top1: 64.91%
[ Wed Nov  9 12:21:13 2022 ] 	Top5: 90.85%
[ Wed Nov  9 12:21:13 2022 ] Training epoch: 9
[ Wed Nov  9 12:30:29 2022 ] 	Mean training loss: 0.9858.  Mean training acc: 70.60%.
[ Wed Nov  9 12:30:29 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:30:29 2022 ] Eval epoch: 9
[ Wed Nov  9 12:35:02 2022 ] 	Mean test loss of 796 batches: 1.1834447828669046.
[ Wed Nov  9 12:35:03 2022 ] 	Top1: 65.58%
[ Wed Nov  9 12:35:05 2022 ] 	Top5: 90.73%
[ Wed Nov  9 12:35:05 2022 ] Training epoch: 10
[ Wed Nov  9 12:44:16 2022 ] 	Mean training loss: 0.9574.  Mean training acc: 71.51%.
[ Wed Nov  9 12:44:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:44:16 2022 ] Eval epoch: 10
[ Wed Nov  9 12:48:38 2022 ] 	Mean test loss of 796 batches: 1.230976102452482.
[ Wed Nov  9 12:48:39 2022 ] 	Top1: 64.36%
[ Wed Nov  9 12:48:40 2022 ] 	Top5: 91.02%
[ Wed Nov  9 12:48:40 2022 ] Training epoch: 11
[ Wed Nov  9 12:57:55 2022 ] 	Mean training loss: 0.9327.  Mean training acc: 72.04%.
[ Wed Nov  9 12:57:55 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:57:55 2022 ] Eval epoch: 11
[ Wed Nov  9 13:02:32 2022 ] 	Mean test loss of 796 batches: 1.1395524259113787.
[ Wed Nov  9 13:02:33 2022 ] 	Top1: 66.21%
[ Wed Nov  9 13:02:34 2022 ] 	Top5: 91.35%
[ Wed Nov  9 13:02:34 2022 ] Training epoch: 12
[ Wed Nov  9 13:11:39 2022 ] 	Mean training loss: 0.9114.  Mean training acc: 72.91%.
[ Wed Nov  9 13:11:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:11:39 2022 ] Eval epoch: 12
[ Wed Nov  9 13:16:10 2022 ] 	Mean test loss of 796 batches: 1.1361244801600374.
[ Wed Nov  9 13:16:11 2022 ] 	Top1: 66.35%
[ Wed Nov  9 13:16:13 2022 ] 	Top5: 91.90%
[ Wed Nov  9 13:16:13 2022 ] Training epoch: 13
[ Wed Nov  9 13:25:27 2022 ] 	Mean training loss: 0.8808.  Mean training acc: 73.64%.
[ Wed Nov  9 13:25:27 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:25:27 2022 ] Eval epoch: 13
[ Wed Nov  9 13:30:09 2022 ] 	Mean test loss of 796 batches: 1.216088928357141.
[ Wed Nov  9 13:30:11 2022 ] 	Top1: 65.47%
[ Wed Nov  9 13:30:12 2022 ] 	Top5: 91.00%
[ Wed Nov  9 13:30:12 2022 ] Training epoch: 14
[ Wed Nov  9 13:39:18 2022 ] 	Mean training loss: 0.8727.  Mean training acc: 73.96%.
[ Wed Nov  9 13:39:18 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:39:18 2022 ] Eval epoch: 14
[ Wed Nov  9 13:43:53 2022 ] 	Mean test loss of 796 batches: 1.158270927791919.
[ Wed Nov  9 13:43:54 2022 ] 	Top1: 67.06%
[ Wed Nov  9 13:43:56 2022 ] 	Top5: 92.30%
[ Wed Nov  9 13:43:56 2022 ] Training epoch: 15
[ Wed Nov  9 13:52:59 2022 ] 	Mean training loss: 0.8664.  Mean training acc: 74.26%.
[ Wed Nov  9 13:52:59 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:52:59 2022 ] Eval epoch: 15
[ Wed Nov  9 13:57:34 2022 ] 	Mean test loss of 796 batches: 1.0725868985281517.
[ Wed Nov  9 13:57:35 2022 ] 	Top1: 68.56%
[ Wed Nov  9 13:57:37 2022 ] 	Top5: 92.78%
[ Wed Nov  9 13:57:37 2022 ] Training epoch: 16
[ Wed Nov  9 14:06:45 2022 ] 	Mean training loss: 0.8463.  Mean training acc: 74.58%.
[ Wed Nov  9 14:06:45 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:06:45 2022 ] Eval epoch: 16
[ Wed Nov  9 14:11:16 2022 ] 	Mean test loss of 796 batches: 1.0733177892152388.
[ Wed Nov  9 14:11:17 2022 ] 	Top1: 68.68%
[ Wed Nov  9 14:11:18 2022 ] 	Top5: 92.63%
[ Wed Nov  9 14:11:19 2022 ] Training epoch: 17
[ Wed Nov  9 14:20:24 2022 ] 	Mean training loss: 0.8355.  Mean training acc: 74.94%.
[ Wed Nov  9 14:20:24 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:20:24 2022 ] Eval epoch: 17
[ Wed Nov  9 14:25:01 2022 ] 	Mean test loss of 796 batches: 1.3017915789056662.
[ Wed Nov  9 14:25:03 2022 ] 	Top1: 64.20%
[ Wed Nov  9 14:25:04 2022 ] 	Top5: 89.31%
[ Wed Nov  9 14:25:04 2022 ] Training epoch: 18
[ Wed Nov  9 14:34:11 2022 ] 	Mean training loss: 0.8324.  Mean training acc: 75.30%.
[ Wed Nov  9 14:34:11 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:34:11 2022 ] Eval epoch: 18
[ Wed Nov  9 14:38:51 2022 ] 	Mean test loss of 796 batches: 1.127905133419001.
[ Wed Nov  9 14:38:53 2022 ] 	Top1: 67.86%
[ Wed Nov  9 14:38:53 2022 ] 	Top5: 90.94%
[ Wed Nov  9 14:38:54 2022 ] Training epoch: 19
[ Wed Nov  9 14:47:55 2022 ] 	Mean training loss: 0.8182.  Mean training acc: 75.49%.
[ Wed Nov  9 14:47:55 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:47:55 2022 ] Eval epoch: 19
[ Wed Nov  9 14:52:30 2022 ] 	Mean test loss of 796 batches: 1.1961867173562697.
[ Wed Nov  9 14:52:31 2022 ] 	Top1: 65.36%
[ Wed Nov  9 14:52:33 2022 ] 	Top5: 91.66%
[ Wed Nov  9 14:52:33 2022 ] Training epoch: 20
[ Wed Nov  9 15:01:40 2022 ] 	Mean training loss: 0.8016.  Mean training acc: 76.15%.
[ Wed Nov  9 15:01:40 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 15:01:40 2022 ] Eval epoch: 20
[ Wed Nov  9 15:06:08 2022 ] 	Mean test loss of 796 batches: 1.0437528979239152.
[ Wed Nov  9 15:06:10 2022 ] 	Top1: 69.43%
[ Wed Nov  9 15:06:12 2022 ] 	Top5: 92.46%
[ Wed Nov  9 15:06:12 2022 ] Training epoch: 21
[ Wed Nov  9 15:15:16 2022 ] 	Mean training loss: 0.8020.  Mean training acc: 75.93%.
[ Wed Nov  9 15:15:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 15:15:16 2022 ] Eval epoch: 21
[ Tue Jan  3 16:52:56 2023 ] Load weights from work_dir/csub/local_SHTg_bone_BL/runs-20-19680.pt.
[ Tue Jan  3 16:53:03 2023 ] using warm up, epoch: 5
[ Tue Jan  3 16:53:17 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHTg_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHTg_bone_BL/runs', 'config': 'work_dir/csub/local_SHTg_bone_BL/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': False, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': False, 'window_size': 64}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/csub/local_SHTg_bone_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 16:53:17 2023 ] # Parameters: 2141090
[ Tue Jan  3 16:53:17 2023 ] Training epoch: 21
[ Tue Jan  3 17:02:30 2023 ] 	Mean training loss: 0.8019.  Mean training acc: 76.05%.
[ Tue Jan  3 17:02:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:02:30 2023 ] Eval epoch: 21
[ Tue Jan  3 17:05:30 2023 ] 	Mean test loss of 796 batches: 1.1970780480222487.
[ Tue Jan  3 17:05:31 2023 ] 	Top1: 66.34%
[ Tue Jan  3 17:05:31 2023 ] 	Top5: 91.03%
[ Tue Jan  3 17:05:31 2023 ] Training epoch: 22
[ Tue Jan  3 17:14:48 2023 ] 	Mean training loss: 0.7940.  Mean training acc: 76.34%.
[ Tue Jan  3 17:14:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:14:48 2023 ] Eval epoch: 22
[ Tue Jan  3 17:17:44 2023 ] 	Mean test loss of 796 batches: 1.0517906934846586.
[ Tue Jan  3 17:17:44 2023 ] 	Top1: 69.19%
[ Tue Jan  3 17:17:45 2023 ] 	Top5: 92.95%
[ Tue Jan  3 17:17:45 2023 ] Training epoch: 23
[ Tue Jan  3 17:27:16 2023 ] 	Mean training loss: 0.7831.  Mean training acc: 76.48%.
[ Tue Jan  3 17:27:16 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:27:16 2023 ] Eval epoch: 23
[ Tue Jan  3 17:30:27 2023 ] 	Mean test loss of 796 batches: 1.0667441580163775.
[ Tue Jan  3 17:30:27 2023 ] 	Top1: 68.79%
[ Tue Jan  3 17:30:28 2023 ] 	Top5: 92.98%
[ Tue Jan  3 17:30:28 2023 ] Training epoch: 24
[ Tue Jan  3 17:40:03 2023 ] 	Mean training loss: 0.7837.  Mean training acc: 76.70%.
[ Tue Jan  3 17:40:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:40:03 2023 ] Eval epoch: 24
[ Tue Jan  3 17:43:18 2023 ] 	Mean test loss of 796 batches: 1.0300247663603954.
[ Tue Jan  3 17:43:19 2023 ] 	Top1: 69.65%
[ Tue Jan  3 17:43:20 2023 ] 	Top5: 93.18%
[ Tue Jan  3 17:43:20 2023 ] Training epoch: 25
[ Tue Jan  3 17:52:47 2023 ] 	Mean training loss: 0.7816.  Mean training acc: 76.63%.
[ Tue Jan  3 17:52:47 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 17:52:47 2023 ] Eval epoch: 25
[ Tue Jan  3 17:56:11 2023 ] 	Mean test loss of 796 batches: 0.9991627461347149.
[ Tue Jan  3 17:56:12 2023 ] 	Top1: 70.09%
[ Tue Jan  3 17:56:13 2023 ] 	Top5: 93.22%
[ Tue Jan  3 17:56:13 2023 ] Training epoch: 26
[ Tue Jan  3 18:05:24 2023 ] 	Mean training loss: 0.7730.  Mean training acc: 76.90%.
[ Tue Jan  3 18:05:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:05:24 2023 ] Eval epoch: 26
[ Tue Jan  3 18:09:01 2023 ] 	Mean test loss of 796 batches: 1.000316319678297.
[ Tue Jan  3 18:09:01 2023 ] 	Top1: 70.52%
[ Tue Jan  3 18:09:02 2023 ] 	Top5: 93.34%
[ Tue Jan  3 18:09:02 2023 ] Training epoch: 27
[ Tue Jan  3 18:18:03 2023 ] 	Mean training loss: 0.7680.  Mean training acc: 77.10%.
[ Tue Jan  3 18:18:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:18:03 2023 ] Eval epoch: 27
[ Tue Jan  3 18:21:43 2023 ] 	Mean test loss of 796 batches: 0.9994821442880822.
[ Tue Jan  3 18:21:43 2023 ] 	Top1: 70.78%
[ Tue Jan  3 18:21:44 2023 ] 	Top5: 93.25%
[ Tue Jan  3 18:21:44 2023 ] Training epoch: 28
[ Tue Jan  3 18:30:34 2023 ] 	Mean training loss: 0.7584.  Mean training acc: 77.25%.
[ Tue Jan  3 18:30:34 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:30:34 2023 ] Eval epoch: 28
[ Tue Jan  3 18:34:17 2023 ] 	Mean test loss of 796 batches: 1.0690017429054084.
[ Tue Jan  3 18:34:17 2023 ] 	Top1: 69.37%
[ Tue Jan  3 18:34:18 2023 ] 	Top5: 92.62%
[ Tue Jan  3 18:34:18 2023 ] Training epoch: 29
[ Tue Jan  3 18:43:05 2023 ] 	Mean training loss: 0.7597.  Mean training acc: 77.15%.
[ Tue Jan  3 18:43:05 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:43:05 2023 ] Eval epoch: 29
[ Tue Jan  3 18:46:53 2023 ] 	Mean test loss of 796 batches: 1.1319770511221048.
[ Tue Jan  3 18:46:53 2023 ] 	Top1: 68.08%
[ Tue Jan  3 18:46:54 2023 ] 	Top5: 91.65%
[ Tue Jan  3 18:46:54 2023 ] Training epoch: 30
[ Tue Jan  3 18:55:52 2023 ] 	Mean training loss: 0.7558.  Mean training acc: 77.24%.
[ Tue Jan  3 18:55:52 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:55:52 2023 ] Eval epoch: 30
[ Tue Jan  3 18:59:44 2023 ] 	Mean test loss of 796 batches: 1.0136296075193127.
[ Tue Jan  3 18:59:44 2023 ] 	Top1: 71.36%
[ Tue Jan  3 18:59:45 2023 ] 	Top5: 92.80%
[ Tue Jan  3 18:59:45 2023 ] Training epoch: 31
[ Tue Jan  3 19:08:37 2023 ] 	Mean training loss: 0.7593.  Mean training acc: 77.30%.
[ Tue Jan  3 19:08:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:08:37 2023 ] Eval epoch: 31
[ Tue Jan  3 19:12:24 2023 ] 	Mean test loss of 796 batches: 1.1182804039525027.
[ Tue Jan  3 19:12:24 2023 ] 	Top1: 68.72%
[ Tue Jan  3 19:12:25 2023 ] 	Top5: 91.78%
[ Tue Jan  3 19:12:25 2023 ] Training epoch: 32
[ Tue Jan  3 19:21:11 2023 ] 	Mean training loss: 0.7505.  Mean training acc: 77.56%.
[ Tue Jan  3 19:21:11 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:21:11 2023 ] Eval epoch: 32
[ Tue Jan  3 19:24:54 2023 ] 	Mean test loss of 796 batches: 1.0480592144868481.
[ Tue Jan  3 19:24:55 2023 ] 	Top1: 69.61%
[ Tue Jan  3 19:24:55 2023 ] 	Top5: 93.14%
[ Tue Jan  3 19:24:55 2023 ] Training epoch: 33
[ Tue Jan  3 19:33:37 2023 ] 	Mean training loss: 0.7427.  Mean training acc: 77.84%.
[ Tue Jan  3 19:33:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:33:37 2023 ] Eval epoch: 33
[ Tue Jan  3 19:37:24 2023 ] 	Mean test loss of 796 batches: 1.0406883855785556.
[ Tue Jan  3 19:37:24 2023 ] 	Top1: 70.17%
[ Tue Jan  3 19:37:25 2023 ] 	Top5: 92.81%
[ Tue Jan  3 19:37:25 2023 ] Training epoch: 34
[ Tue Jan  3 19:46:19 2023 ] 	Mean training loss: 0.7454.  Mean training acc: 77.67%.
[ Tue Jan  3 19:46:19 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:46:20 2023 ] Eval epoch: 34
[ Tue Jan  3 19:50:03 2023 ] 	Mean test loss of 796 batches: 1.1685751394261068.
[ Tue Jan  3 19:50:03 2023 ] 	Top1: 67.35%
[ Tue Jan  3 19:50:04 2023 ] 	Top5: 90.93%
[ Tue Jan  3 19:50:04 2023 ] Training epoch: 35
[ Tue Jan  3 19:58:49 2023 ] 	Mean training loss: 0.7489.  Mean training acc: 77.57%.
[ Tue Jan  3 19:58:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:58:51 2023 ] Eval epoch: 35
[ Tue Jan  3 20:02:31 2023 ] 	Mean test loss of 796 batches: 1.0222135121798395.
[ Tue Jan  3 20:02:31 2023 ] 	Top1: 70.98%
[ Tue Jan  3 20:02:32 2023 ] 	Top5: 93.48%
[ Tue Jan  3 20:02:32 2023 ] Training epoch: 36
[ Tue Jan  3 20:11:33 2023 ] 	Mean training loss: 0.4062.  Mean training acc: 88.04%.
[ Tue Jan  3 20:11:33 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:11:34 2023 ] Eval epoch: 36
[ Tue Jan  3 20:15:13 2023 ] 	Mean test loss of 796 batches: 0.5505591631778072.
[ Tue Jan  3 20:15:14 2023 ] 	Top1: 83.12%
[ Tue Jan  3 20:15:14 2023 ] 	Top5: 97.08%
[ Tue Jan  3 20:15:14 2023 ] Training epoch: 37
[ Tue Jan  3 20:24:14 2023 ] 	Mean training loss: 0.3201.  Mean training acc: 90.48%.
[ Tue Jan  3 20:24:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:24:15 2023 ] Eval epoch: 37
[ Tue Jan  3 20:27:54 2023 ] 	Mean test loss of 796 batches: 0.5479950981317603.
[ Tue Jan  3 20:27:55 2023 ] 	Top1: 83.38%
[ Tue Jan  3 20:27:56 2023 ] 	Top5: 97.03%
[ Tue Jan  3 20:27:56 2023 ] Training epoch: 38
[ Tue Jan  3 20:37:02 2023 ] 	Mean training loss: 0.2819.  Mean training acc: 91.68%.
[ Tue Jan  3 20:37:02 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:37:02 2023 ] Eval epoch: 38
[ Tue Jan  3 20:40:42 2023 ] 	Mean test loss of 796 batches: 0.5414868775923648.
[ Tue Jan  3 20:40:43 2023 ] 	Top1: 83.69%
[ Tue Jan  3 20:40:43 2023 ] 	Top5: 97.20%
[ Tue Jan  3 20:40:43 2023 ] Training epoch: 39
[ Tue Jan  3 20:49:59 2023 ] 	Mean training loss: 0.2518.  Mean training acc: 92.69%.
[ Tue Jan  3 20:49:59 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:49:59 2023 ] Eval epoch: 39
[ Tue Jan  3 20:53:36 2023 ] 	Mean test loss of 796 batches: 0.5487369884685356.
[ Tue Jan  3 20:53:37 2023 ] 	Top1: 83.81%
[ Tue Jan  3 20:53:37 2023 ] 	Top5: 97.10%
[ Tue Jan  3 20:53:38 2023 ] Training epoch: 40
[ Tue Jan  3 21:02:45 2023 ] 	Mean training loss: 0.2345.  Mean training acc: 93.19%.
[ Tue Jan  3 21:02:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:02:46 2023 ] Eval epoch: 40
[ Tue Jan  3 21:06:23 2023 ] 	Mean test loss of 796 batches: 0.5441941731052482.
[ Tue Jan  3 21:06:23 2023 ] 	Top1: 83.79%
[ Tue Jan  3 21:06:24 2023 ] 	Top5: 97.10%
[ Tue Jan  3 21:06:24 2023 ] Training epoch: 41
[ Tue Jan  3 21:15:19 2023 ] 	Mean training loss: 0.2154.  Mean training acc: 93.80%.
[ Tue Jan  3 21:15:19 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:15:20 2023 ] Eval epoch: 41
[ Tue Jan  3 21:18:59 2023 ] 	Mean test loss of 796 batches: 0.5679431456847855.
[ Tue Jan  3 21:18:59 2023 ] 	Top1: 83.41%
[ Tue Jan  3 21:19:00 2023 ] 	Top5: 97.01%
[ Tue Jan  3 21:19:00 2023 ] Training epoch: 42
[ Tue Jan  3 21:27:41 2023 ] 	Mean training loss: 0.1974.  Mean training acc: 94.42%.
[ Tue Jan  3 21:27:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:27:42 2023 ] Eval epoch: 42
[ Tue Jan  3 21:31:32 2023 ] 	Mean test loss of 796 batches: 0.5773991528598956.
[ Tue Jan  3 21:31:33 2023 ] 	Top1: 83.17%
[ Tue Jan  3 21:31:34 2023 ] 	Top5: 96.85%
[ Tue Jan  3 21:31:34 2023 ] Training epoch: 43
[ Tue Jan  3 21:40:18 2023 ] 	Mean training loss: 0.1871.  Mean training acc: 94.81%.
[ Tue Jan  3 21:40:18 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:40:18 2023 ] Eval epoch: 43
[ Tue Jan  3 21:44:11 2023 ] 	Mean test loss of 796 batches: 0.5915972023228904.
[ Tue Jan  3 21:44:12 2023 ] 	Top1: 82.97%
[ Tue Jan  3 21:44:12 2023 ] 	Top5: 96.88%
[ Tue Jan  3 21:44:12 2023 ] Training epoch: 44
[ Tue Jan  3 21:53:04 2023 ] 	Mean training loss: 0.1735.  Mean training acc: 95.23%.
[ Tue Jan  3 21:53:04 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:53:04 2023 ] Eval epoch: 44
[ Tue Jan  3 21:56:51 2023 ] 	Mean test loss of 796 batches: 0.6352448582593071.
[ Tue Jan  3 21:56:52 2023 ] 	Top1: 82.25%
[ Tue Jan  3 21:56:52 2023 ] 	Top5: 96.39%
[ Tue Jan  3 21:56:53 2023 ] Training epoch: 45
[ Tue Jan  3 22:05:43 2023 ] 	Mean training loss: 0.1689.  Mean training acc: 95.40%.
[ Tue Jan  3 22:05:43 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:05:43 2023 ] Eval epoch: 45
[ Tue Jan  3 22:09:26 2023 ] 	Mean test loss of 796 batches: 0.6224721578328903.
[ Tue Jan  3 22:09:26 2023 ] 	Top1: 82.40%
[ Tue Jan  3 22:09:27 2023 ] 	Top5: 96.63%
[ Tue Jan  3 22:09:27 2023 ] Training epoch: 46
[ Tue Jan  3 22:18:14 2023 ] 	Mean training loss: 0.1621.  Mean training acc: 95.55%.
[ Tue Jan  3 22:18:14 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:18:15 2023 ] Eval epoch: 46
[ Tue Jan  3 22:21:56 2023 ] 	Mean test loss of 796 batches: 0.6176833117090578.
[ Tue Jan  3 22:21:56 2023 ] 	Top1: 82.63%
[ Tue Jan  3 22:21:57 2023 ] 	Top5: 96.58%
[ Tue Jan  3 22:21:57 2023 ] Training epoch: 47
[ Tue Jan  3 22:30:57 2023 ] 	Mean training loss: 0.1589.  Mean training acc: 95.69%.
[ Tue Jan  3 22:30:57 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:30:57 2023 ] Eval epoch: 47
[ Tue Jan  3 22:34:38 2023 ] 	Mean test loss of 796 batches: 0.6189652713455597.
[ Tue Jan  3 22:34:39 2023 ] 	Top1: 82.39%
[ Tue Jan  3 22:34:39 2023 ] 	Top5: 96.61%
[ Tue Jan  3 22:34:40 2023 ] Training epoch: 48
[ Tue Jan  3 22:43:35 2023 ] 	Mean training loss: 0.1450.  Mean training acc: 96.21%.
[ Tue Jan  3 22:43:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:43:35 2023 ] Eval epoch: 48
[ Tue Jan  3 22:47:17 2023 ] 	Mean test loss of 796 batches: 0.6684137866949317.
[ Tue Jan  3 22:47:18 2023 ] 	Top1: 81.81%
[ Tue Jan  3 22:47:18 2023 ] 	Top5: 96.19%
[ Tue Jan  3 22:47:18 2023 ] Training epoch: 49
[ Tue Jan  3 22:56:22 2023 ] 	Mean training loss: 0.1481.  Mean training acc: 96.04%.
[ Tue Jan  3 22:56:22 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:56:23 2023 ] Eval epoch: 49
[ Tue Jan  3 23:00:02 2023 ] 	Mean test loss of 796 batches: 0.6594147843931188.
[ Tue Jan  3 23:00:03 2023 ] 	Top1: 81.86%
[ Tue Jan  3 23:00:04 2023 ] 	Top5: 96.25%
[ Tue Jan  3 23:00:04 2023 ] Training epoch: 50
[ Tue Jan  3 23:09:25 2023 ] 	Mean training loss: 0.1454.  Mean training acc: 96.23%.
[ Tue Jan  3 23:09:25 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:09:25 2023 ] Eval epoch: 50
[ Tue Jan  3 23:13:09 2023 ] 	Mean test loss of 796 batches: 0.6755909211465612.
[ Tue Jan  3 23:13:10 2023 ] 	Top1: 81.69%
[ Tue Jan  3 23:13:11 2023 ] 	Top5: 96.10%
[ Tue Jan  3 23:13:11 2023 ] Training epoch: 51
[ Tue Jan  3 23:22:34 2023 ] 	Mean training loss: 0.1484.  Mean training acc: 96.05%.
[ Tue Jan  3 23:22:34 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:22:34 2023 ] Eval epoch: 51
[ Tue Jan  3 23:26:16 2023 ] 	Mean test loss of 796 batches: 0.6514747621276271.
[ Tue Jan  3 23:26:17 2023 ] 	Top1: 81.98%
[ Tue Jan  3 23:26:18 2023 ] 	Top5: 96.37%
[ Tue Jan  3 23:26:18 2023 ] Training epoch: 52
[ Tue Jan  3 23:35:47 2023 ] 	Mean training loss: 0.1493.  Mean training acc: 95.97%.
[ Tue Jan  3 23:35:47 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:35:48 2023 ] Eval epoch: 52
[ Tue Jan  3 23:39:10 2023 ] 	Mean test loss of 796 batches: 0.6682246365776313.
[ Tue Jan  3 23:39:11 2023 ] 	Top1: 81.70%
[ Tue Jan  3 23:39:11 2023 ] 	Top5: 96.34%
[ Tue Jan  3 23:39:11 2023 ] Training epoch: 53
[ Tue Jan  3 23:48:44 2023 ] 	Mean training loss: 0.1478.  Mean training acc: 96.08%.
[ Tue Jan  3 23:48:44 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:48:44 2023 ] Eval epoch: 53
[ Tue Jan  3 23:52:07 2023 ] 	Mean test loss of 796 batches: 0.6696698822118529.
[ Tue Jan  3 23:52:08 2023 ] 	Top1: 81.70%
[ Tue Jan  3 23:52:08 2023 ] 	Top5: 96.13%
[ Tue Jan  3 23:52:09 2023 ] Training epoch: 54
[ Wed Jan  4 00:01:27 2023 ] 	Mean training loss: 0.1537.  Mean training acc: 95.84%.
[ Wed Jan  4 00:01:27 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:01:27 2023 ] Eval epoch: 54
[ Wed Jan  4 00:04:48 2023 ] 	Mean test loss of 796 batches: 0.6913987007085702.
[ Wed Jan  4 00:04:49 2023 ] 	Top1: 81.20%
[ Wed Jan  4 00:04:49 2023 ] 	Top5: 95.81%
[ Wed Jan  4 00:04:49 2023 ] Training epoch: 55
[ Wed Jan  4 00:14:22 2023 ] 	Mean training loss: 0.1459.  Mean training acc: 96.17%.
[ Wed Jan  4 00:14:22 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:14:22 2023 ] Eval epoch: 55
[ Wed Jan  4 00:17:44 2023 ] 	Mean test loss of 796 batches: 0.704833040584871.
[ Wed Jan  4 00:17:45 2023 ] 	Top1: 81.21%
[ Wed Jan  4 00:17:45 2023 ] 	Top5: 95.87%
[ Wed Jan  4 00:17:45 2023 ] Training epoch: 56
[ Wed Jan  4 00:27:24 2023 ] 	Mean training loss: 0.0782.  Mean training acc: 98.41%.
[ Wed Jan  4 00:27:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:27:24 2023 ] Eval epoch: 56
[ Wed Jan  4 00:30:48 2023 ] 	Mean test loss of 796 batches: 0.5942189816207667.
[ Wed Jan  4 00:30:48 2023 ] 	Top1: 83.85%
[ Wed Jan  4 00:30:49 2023 ] 	Top5: 96.66%
[ Wed Jan  4 00:30:49 2023 ] Training epoch: 57
[ Wed Jan  4 00:40:22 2023 ] 	Mean training loss: 0.0555.  Mean training acc: 99.08%.
[ Wed Jan  4 00:40:22 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:40:22 2023 ] Eval epoch: 57
[ Wed Jan  4 00:43:48 2023 ] 	Mean test loss of 796 batches: 0.5968074305965823.
[ Wed Jan  4 00:43:49 2023 ] 	Top1: 83.89%
[ Wed Jan  4 00:43:49 2023 ] 	Top5: 96.62%
[ Wed Jan  4 00:43:49 2023 ] Training epoch: 58
[ Wed Jan  4 00:53:14 2023 ] 	Mean training loss: 0.0484.  Mean training acc: 99.28%.
[ Wed Jan  4 00:53:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:53:15 2023 ] Eval epoch: 58
[ Wed Jan  4 00:56:42 2023 ] 	Mean test loss of 796 batches: 0.6042218591278447.
[ Wed Jan  4 00:56:43 2023 ] 	Top1: 83.72%
[ Wed Jan  4 00:56:43 2023 ] 	Top5: 96.61%
[ Wed Jan  4 00:56:44 2023 ] Training epoch: 59
[ Wed Jan  4 01:05:51 2023 ] 	Mean training loss: 0.0444.  Mean training acc: 99.30%.
[ Wed Jan  4 01:05:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:05:51 2023 ] Eval epoch: 59
[ Wed Jan  4 01:09:26 2023 ] 	Mean test loss of 796 batches: 0.5985555136716695.
[ Wed Jan  4 01:09:27 2023 ] 	Top1: 84.03%
[ Wed Jan  4 01:09:27 2023 ] 	Top5: 96.70%
[ Wed Jan  4 01:09:27 2023 ] Training epoch: 60
[ Wed Jan  4 01:18:37 2023 ] 	Mean training loss: 0.0407.  Mean training acc: 99.43%.
[ Wed Jan  4 01:18:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:18:37 2023 ] Eval epoch: 60
[ Wed Jan  4 01:22:22 2023 ] 	Mean test loss of 796 batches: 0.5949053135162322.
[ Wed Jan  4 01:22:23 2023 ] 	Top1: 84.13%
[ Wed Jan  4 01:22:23 2023 ] 	Top5: 96.69%
[ Wed Jan  4 01:22:23 2023 ] Training epoch: 61
[ Wed Jan  4 01:31:28 2023 ] 	Mean training loss: 0.0399.  Mean training acc: 99.44%.
[ Wed Jan  4 01:31:28 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:31:28 2023 ] Eval epoch: 61
[ Wed Jan  4 01:35:09 2023 ] 	Mean test loss of 796 batches: 0.5943155902339585.
[ Wed Jan  4 01:35:10 2023 ] 	Top1: 84.19%
[ Wed Jan  4 01:35:10 2023 ] 	Top5: 96.70%
[ Wed Jan  4 01:35:10 2023 ] Training epoch: 62
[ Wed Jan  4 01:44:00 2023 ] 	Mean training loss: 0.0372.  Mean training acc: 99.51%.
[ Wed Jan  4 01:44:00 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:44:00 2023 ] Eval epoch: 62
[ Wed Jan  4 01:47:39 2023 ] 	Mean test loss of 796 batches: 0.6011701225392033.
[ Wed Jan  4 01:47:40 2023 ] 	Top1: 84.03%
[ Wed Jan  4 01:47:40 2023 ] 	Top5: 96.58%
[ Wed Jan  4 01:47:40 2023 ] Training epoch: 63
[ Wed Jan  4 01:56:26 2023 ] 	Mean training loss: 0.0362.  Mean training acc: 99.54%.
[ Wed Jan  4 01:56:26 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:56:26 2023 ] Eval epoch: 63
[ Wed Jan  4 02:00:10 2023 ] 	Mean test loss of 796 batches: 0.5956803751201486.
[ Wed Jan  4 02:00:10 2023 ] 	Top1: 84.13%
[ Wed Jan  4 02:00:11 2023 ] 	Top5: 96.68%
[ Wed Jan  4 02:00:11 2023 ] Training epoch: 64
[ Wed Jan  4 02:08:52 2023 ] 	Mean training loss: 0.0325.  Mean training acc: 99.58%.
[ Wed Jan  4 02:08:52 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:08:52 2023 ] Eval epoch: 64
[ Wed Jan  4 02:12:39 2023 ] 	Mean test loss of 796 batches: 0.6039478906322664.
[ Wed Jan  4 02:12:40 2023 ] 	Top1: 84.00%
[ Wed Jan  4 02:12:40 2023 ] 	Top5: 96.67%
[ Wed Jan  4 02:12:40 2023 ] Training epoch: 65
[ Wed Jan  4 02:21:24 2023 ] 	Mean training loss: 0.0332.  Mean training acc: 99.57%.
[ Wed Jan  4 02:21:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:21:24 2023 ] Eval epoch: 65
[ Wed Jan  4 02:25:11 2023 ] 	Mean test loss of 796 batches: 0.5997615091118905.
[ Wed Jan  4 02:25:12 2023 ] 	Top1: 84.11%
[ Wed Jan  4 02:25:12 2023 ] 	Top5: 96.59%
[ Wed Jan  4 02:28:48 2023 ] Best accuracy: 0.8422396354995189
[ Wed Jan  4 02:28:48 2023 ] Epoch number: 61
[ Wed Jan  4 02:28:48 2023 ] Model name: work_dir/csub/local_SHTg_bone_BL
[ Wed Jan  4 02:28:48 2023 ] Model total number of params: 2141090
[ Wed Jan  4 02:28:48 2023 ] Weight decay: 0.0004
[ Wed Jan  4 02:28:48 2023 ] Base LR: 0.1
[ Wed Jan  4 02:28:48 2023 ] Batch Size: 64
[ Wed Jan  4 02:28:48 2023 ] Test Batch Size: 64
[ Wed Jan  4 02:28:48 2023 ] seed: 1
[ Fri Jan 13 18:26:15 2023 ] Load weights from work_dir/csub/local_SHT_bone_BL/runs-20-19680.pt.
[ Fri Jan 13 18:26:19 2023 ] using warm up, epoch: 0
[ Fri Jan 13 18:26:33 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/local_SHT_bone_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Fri Jan 13 18:26:33 2023 ] # Parameters: 2141090
[ Fri Jan 13 18:26:33 2023 ] Training epoch: 21
[ Fri Jan 13 18:32:52 2023 ] 	Mean training loss: 0.7988.  Mean training acc: 76.15%.
[ Fri Jan 13 18:32:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:32:52 2023 ] Eval epoch: 21
[ Fri Jan 13 18:35:55 2023 ] 	Mean test loss of 796 batches: 1.3026626439924216.
[ Fri Jan 13 18:35:55 2023 ] 	Top1: 64.26%
[ Fri Jan 13 18:35:56 2023 ] 	Top5: 90.08%
[ Fri Jan 13 18:35:56 2023 ] Training epoch: 22
[ Fri Jan 13 18:44:03 2023 ] 	Mean training loss: 0.7988.  Mean training acc: 76.08%.
[ Fri Jan 13 18:44:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:44:03 2023 ] Eval epoch: 22
[ Fri Jan 13 18:47:11 2023 ] 	Mean test loss of 796 batches: 1.0980823089429481.
[ Fri Jan 13 18:47:12 2023 ] 	Top1: 68.60%
[ Fri Jan 13 18:47:12 2023 ] 	Top5: 92.10%
[ Fri Jan 13 18:47:12 2023 ] Training epoch: 23
[ Fri Jan 13 18:54:34 2023 ] 	Mean training loss: 0.7810.  Mean training acc: 76.69%.
[ Fri Jan 13 18:54:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:54:34 2023 ] Eval epoch: 23
[ Fri Jan 13 18:57:26 2023 ] 	Mean test loss of 796 batches: 1.1283799145913602.
[ Fri Jan 13 18:57:26 2023 ] 	Top1: 67.10%
[ Fri Jan 13 18:57:27 2023 ] 	Top5: 92.44%
[ Fri Jan 13 18:57:27 2023 ] Training epoch: 24
[ Fri Jan 13 19:05:05 2023 ] 	Mean training loss: 0.7836.  Mean training acc: 76.56%.
[ Fri Jan 13 19:05:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:05:05 2023 ] Eval epoch: 24
[ Fri Jan 13 19:08:06 2023 ] 	Mean test loss of 796 batches: 1.0994822852425838.
[ Fri Jan 13 19:08:07 2023 ] 	Top1: 68.20%
[ Fri Jan 13 19:08:07 2023 ] 	Top5: 91.82%
[ Fri Jan 13 19:08:07 2023 ] Training epoch: 25
[ Fri Jan 13 19:16:22 2023 ] 	Mean training loss: 0.7751.  Mean training acc: 76.77%.
[ Fri Jan 13 19:16:22 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:16:22 2023 ] Eval epoch: 25
[ Fri Jan 13 19:19:25 2023 ] 	Mean test loss of 796 batches: 1.0754600867030009.
[ Fri Jan 13 19:19:25 2023 ] 	Top1: 68.49%
[ Fri Jan 13 19:19:26 2023 ] 	Top5: 92.43%
[ Fri Jan 13 19:19:26 2023 ] Training epoch: 26
[ Fri Jan 13 19:26:52 2023 ] 	Mean training loss: 0.7698.  Mean training acc: 77.01%.
[ Fri Jan 13 19:26:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:26:52 2023 ] Eval epoch: 26
[ Fri Jan 13 19:29:43 2023 ] 	Mean test loss of 796 batches: 1.0515991723417637.
[ Fri Jan 13 19:29:44 2023 ] 	Top1: 69.51%
[ Fri Jan 13 19:29:44 2023 ] 	Top5: 93.02%
[ Fri Jan 13 19:29:44 2023 ] Training epoch: 27
[ Fri Jan 13 19:37:30 2023 ] 	Mean training loss: 0.7645.  Mean training acc: 77.34%.
[ Fri Jan 13 19:37:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:37:30 2023 ] Eval epoch: 27
[ Fri Jan 13 19:40:31 2023 ] 	Mean test loss of 796 batches: 1.2460462919731237.
[ Fri Jan 13 19:40:31 2023 ] 	Top1: 64.03%
[ Fri Jan 13 19:40:32 2023 ] 	Top5: 90.95%
[ Fri Jan 13 19:40:32 2023 ] Training epoch: 28
[ Fri Jan 13 19:48:41 2023 ] 	Mean training loss: 0.7612.  Mean training acc: 77.15%.
[ Fri Jan 13 19:48:41 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:48:41 2023 ] Eval epoch: 28
[ Fri Jan 13 19:51:44 2023 ] 	Mean test loss of 796 batches: 1.044006018857261.
[ Fri Jan 13 19:51:44 2023 ] 	Top1: 70.01%
[ Fri Jan 13 19:51:45 2023 ] 	Top5: 92.73%
[ Fri Jan 13 19:51:45 2023 ] Training epoch: 29
[ Fri Jan 13 19:59:09 2023 ] 	Mean training loss: 0.7528.  Mean training acc: 77.50%.
[ Fri Jan 13 19:59:09 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:59:09 2023 ] Eval epoch: 29
[ Fri Jan 13 20:01:59 2023 ] 	Mean test loss of 796 batches: 1.0130929831583895.
[ Fri Jan 13 20:01:59 2023 ] 	Top1: 70.51%
[ Fri Jan 13 20:02:00 2023 ] 	Top5: 93.28%
[ Fri Jan 13 20:02:00 2023 ] Training epoch: 30
[ Fri Jan 13 20:09:45 2023 ] 	Mean training loss: 0.7547.  Mean training acc: 77.36%.
[ Fri Jan 13 20:09:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:09:45 2023 ] Eval epoch: 30
[ Fri Jan 13 20:12:48 2023 ] 	Mean test loss of 796 batches: 0.9899048743086245.
[ Fri Jan 13 20:12:48 2023 ] 	Top1: 71.93%
[ Fri Jan 13 20:12:49 2023 ] 	Top5: 93.11%
[ Fri Jan 13 20:12:49 2023 ] Training epoch: 31
[ Fri Jan 13 20:20:57 2023 ] 	Mean training loss: 0.7601.  Mean training acc: 77.17%.
[ Fri Jan 13 20:20:57 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:20:57 2023 ] Eval epoch: 31
[ Fri Jan 13 20:23:58 2023 ] 	Mean test loss of 796 batches: 1.213955810883237.
[ Fri Jan 13 20:23:58 2023 ] 	Top1: 66.71%
[ Fri Jan 13 20:23:59 2023 ] 	Top5: 91.23%
[ Fri Jan 13 20:23:59 2023 ] Training epoch: 32
[ Fri Jan 13 20:31:19 2023 ] 	Mean training loss: 0.7499.  Mean training acc: 77.67%.
[ Fri Jan 13 20:31:19 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:31:19 2023 ] Eval epoch: 32
[ Fri Jan 13 20:34:11 2023 ] 	Mean test loss of 796 batches: 1.4015082861460633.
[ Fri Jan 13 20:34:12 2023 ] 	Top1: 64.37%
[ Fri Jan 13 20:34:12 2023 ] 	Top5: 88.49%
[ Fri Jan 13 20:34:12 2023 ] Training epoch: 33
[ Fri Jan 13 20:42:11 2023 ] 	Mean training loss: 0.7404.  Mean training acc: 77.84%.
[ Fri Jan 13 20:42:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:42:11 2023 ] Eval epoch: 33
[ Fri Jan 13 20:45:13 2023 ] 	Mean test loss of 796 batches: 1.1263836576186832.
[ Fri Jan 13 20:45:13 2023 ] 	Top1: 68.18%
[ Fri Jan 13 20:45:14 2023 ] 	Top5: 91.58%
[ Fri Jan 13 20:45:14 2023 ] Training epoch: 34
[ Fri Jan 13 20:53:30 2023 ] 	Mean training loss: 0.7440.  Mean training acc: 77.88%.
[ Fri Jan 13 20:53:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:53:31 2023 ] Eval epoch: 34
[ Fri Jan 13 20:56:24 2023 ] 	Mean test loss of 796 batches: 1.345127407480125.
[ Fri Jan 13 20:56:25 2023 ] 	Top1: 62.95%
[ Fri Jan 13 20:56:25 2023 ] 	Top5: 90.27%
[ Fri Jan 13 20:56:25 2023 ] Training epoch: 35
[ Fri Jan 13 21:03:48 2023 ] 	Mean training loss: 0.7474.  Mean training acc: 77.62%.
[ Fri Jan 13 21:03:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:03:48 2023 ] Eval epoch: 35
[ Fri Jan 13 21:06:37 2023 ] 	Mean test loss of 796 batches: 1.0103975969867491.
[ Fri Jan 13 21:06:37 2023 ] 	Top1: 70.49%
[ Fri Jan 13 21:06:38 2023 ] 	Top5: 93.46%
[ Fri Jan 13 21:06:38 2023 ] Training epoch: 36
[ Fri Jan 13 21:14:44 2023 ] 	Mean training loss: 0.4050.  Mean training acc: 88.02%.
[ Fri Jan 13 21:14:44 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:14:44 2023 ] Eval epoch: 36
[ Fri Jan 13 21:17:48 2023 ] 	Mean test loss of 796 batches: 0.5525536552333652.
[ Fri Jan 13 21:17:49 2023 ] 	Top1: 83.12%
[ Fri Jan 13 21:17:49 2023 ] 	Top5: 97.01%
[ Fri Jan 13 21:17:49 2023 ] Training epoch: 37
[ Fri Jan 13 21:25:55 2023 ] 	Mean training loss: 0.3190.  Mean training acc: 90.52%.
[ Fri Jan 13 21:25:55 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:25:55 2023 ] Eval epoch: 37
[ Fri Jan 13 21:28:47 2023 ] 	Mean test loss of 796 batches: 0.5510428002169684.
[ Fri Jan 13 21:28:48 2023 ] 	Top1: 83.38%
[ Fri Jan 13 21:28:48 2023 ] 	Top5: 97.03%
[ Fri Jan 13 21:28:48 2023 ] Training epoch: 38
[ Fri Jan 13 21:36:01 2023 ] 	Mean training loss: 0.2820.  Mean training acc: 91.52%.
[ Fri Jan 13 21:36:01 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:36:01 2023 ] Eval epoch: 38
[ Fri Jan 13 21:38:54 2023 ] 	Mean test loss of 796 batches: 0.5503581074445542.
[ Fri Jan 13 21:38:54 2023 ] 	Top1: 83.72%
[ Fri Jan 13 21:38:55 2023 ] 	Top5: 97.06%
[ Fri Jan 13 21:38:55 2023 ] Training epoch: 39
[ Fri Jan 13 21:47:04 2023 ] 	Mean training loss: 0.2536.  Mean training acc: 92.49%.
[ Fri Jan 13 21:47:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:47:04 2023 ] Eval epoch: 39
[ Fri Jan 13 21:50:07 2023 ] 	Mean test loss of 796 batches: 0.5488252934892124.
[ Fri Jan 13 21:50:08 2023 ] 	Top1: 83.74%
[ Fri Jan 13 21:50:08 2023 ] 	Top5: 97.05%
[ Fri Jan 13 21:50:08 2023 ] Training epoch: 40
[ Fri Jan 13 21:58:11 2023 ] 	Mean training loss: 0.2353.  Mean training acc: 93.21%.
[ Fri Jan 13 21:58:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:58:11 2023 ] Eval epoch: 40
[ Fri Jan 13 22:00:59 2023 ] 	Mean test loss of 796 batches: 0.5472120592960311.
[ Fri Jan 13 22:00:59 2023 ] 	Top1: 83.84%
[ Fri Jan 13 22:01:00 2023 ] 	Top5: 97.04%
[ Fri Jan 13 22:01:00 2023 ] Training epoch: 41
[ Fri Jan 13 22:08:21 2023 ] 	Mean training loss: 0.2136.  Mean training acc: 93.90%.
[ Fri Jan 13 22:08:21 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:08:21 2023 ] Eval epoch: 41
[ Fri Jan 13 22:11:20 2023 ] 	Mean test loss of 796 batches: 0.575199195722015.
[ Fri Jan 13 22:11:21 2023 ] 	Top1: 83.35%
[ Fri Jan 13 22:11:21 2023 ] 	Top5: 96.83%
[ Fri Jan 13 22:11:21 2023 ] Training epoch: 42
[ Fri Jan 13 22:19:34 2023 ] 	Mean training loss: 0.1954.  Mean training acc: 94.46%.
[ Fri Jan 13 22:19:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:19:34 2023 ] Eval epoch: 42
[ Fri Jan 13 22:22:35 2023 ] 	Mean test loss of 796 batches: 0.5769451697118319.
[ Fri Jan 13 22:22:36 2023 ] 	Top1: 83.35%
[ Fri Jan 13 22:22:36 2023 ] 	Top5: 96.92%
[ Fri Jan 13 22:22:36 2023 ] Training epoch: 43
[ Fri Jan 13 22:30:26 2023 ] 	Mean training loss: 0.1866.  Mean training acc: 94.84%.
[ Fri Jan 13 22:30:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:30:27 2023 ] Eval epoch: 43
[ Fri Jan 13 22:33:18 2023 ] 	Mean test loss of 796 batches: 0.5779535623931855.
[ Fri Jan 13 22:33:18 2023 ] 	Top1: 83.26%
[ Fri Jan 13 22:33:19 2023 ] 	Top5: 96.84%
[ Fri Jan 13 22:33:19 2023 ] Training epoch: 44
[ Fri Jan 13 22:40:38 2023 ] 	Mean training loss: 0.1747.  Mean training acc: 95.14%.
[ Fri Jan 13 22:40:38 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:40:38 2023 ] Eval epoch: 44
[ Fri Jan 13 22:43:39 2023 ] 	Mean test loss of 796 batches: 0.6371992094133367.
[ Fri Jan 13 22:43:40 2023 ] 	Top1: 82.07%
[ Fri Jan 13 22:43:40 2023 ] 	Top5: 96.30%
[ Fri Jan 13 22:43:40 2023 ] Training epoch: 45
[ Fri Jan 13 22:51:58 2023 ] 	Mean training loss: 0.1656.  Mean training acc: 95.47%.
[ Fri Jan 13 22:51:58 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:51:58 2023 ] Eval epoch: 45
[ Fri Jan 13 22:54:59 2023 ] 	Mean test loss of 796 batches: 0.6194841961034728.
[ Fri Jan 13 22:55:00 2023 ] 	Top1: 82.74%
[ Fri Jan 13 22:55:00 2023 ] 	Top5: 96.45%
[ Fri Jan 13 22:55:00 2023 ] Training epoch: 46
[ Fri Jan 13 23:02:44 2023 ] 	Mean training loss: 0.1626.  Mean training acc: 95.59%.
[ Fri Jan 13 23:02:44 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:02:44 2023 ] Eval epoch: 46
[ Fri Jan 13 23:05:35 2023 ] 	Mean test loss of 796 batches: 0.6213225349596697.
[ Fri Jan 13 23:05:35 2023 ] 	Top1: 82.56%
[ Fri Jan 13 23:05:36 2023 ] 	Top5: 96.51%
[ Fri Jan 13 23:05:36 2023 ] Training epoch: 47
[ Fri Jan 13 23:13:02 2023 ] 	Mean training loss: 0.1543.  Mean training acc: 95.94%.
[ Fri Jan 13 23:13:02 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:13:02 2023 ] Eval epoch: 47
[ Fri Jan 13 23:16:03 2023 ] 	Mean test loss of 796 batches: 0.6590575798597168.
[ Fri Jan 13 23:16:04 2023 ] 	Top1: 81.88%
[ Fri Jan 13 23:16:04 2023 ] 	Top5: 96.21%
[ Fri Jan 13 23:16:05 2023 ] Training epoch: 48
[ Fri Jan 13 23:24:27 2023 ] 	Mean training loss: 0.1483.  Mean training acc: 95.96%.
[ Fri Jan 13 23:24:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:24:27 2023 ] Eval epoch: 48
[ Fri Jan 13 23:27:29 2023 ] 	Mean test loss of 796 batches: 0.6836627504727499.
[ Fri Jan 13 23:27:29 2023 ] 	Top1: 81.40%
[ Fri Jan 13 23:27:30 2023 ] 	Top5: 96.21%
[ Fri Jan 13 23:27:30 2023 ] Training epoch: 49
[ Fri Jan 13 23:35:05 2023 ] 	Mean training loss: 0.1475.  Mean training acc: 96.11%.
[ Fri Jan 13 23:35:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:35:05 2023 ] Eval epoch: 49
[ Fri Jan 13 23:37:55 2023 ] 	Mean test loss of 796 batches: 0.6479647298760001.
[ Fri Jan 13 23:37:55 2023 ] 	Top1: 82.25%
[ Fri Jan 13 23:37:56 2023 ] 	Top5: 96.33%
[ Fri Jan 13 23:37:56 2023 ] Training epoch: 50
[ Fri Jan 13 23:45:32 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.07%.
[ Fri Jan 13 23:45:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:45:32 2023 ] Eval epoch: 50
[ Fri Jan 13 23:48:34 2023 ] 	Mean test loss of 796 batches: 0.6746224209329291.
[ Fri Jan 13 23:48:35 2023 ] 	Top1: 81.68%
[ Fri Jan 13 23:48:35 2023 ] 	Top5: 96.04%
[ Fri Jan 13 23:48:35 2023 ] Training epoch: 51
[ Fri Jan 13 23:56:45 2023 ] 	Mean training loss: 0.1484.  Mean training acc: 96.08%.
[ Fri Jan 13 23:56:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:56:45 2023 ] Eval epoch: 51
[ Fri Jan 13 23:59:48 2023 ] 	Mean test loss of 796 batches: 0.6799373661528281.
[ Fri Jan 13 23:59:48 2023 ] 	Top1: 81.41%
[ Fri Jan 13 23:59:49 2023 ] 	Top5: 96.08%
[ Fri Jan 13 23:59:49 2023 ] Training epoch: 52
[ Sat Jan 14 00:07:15 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.07%.
[ Sat Jan 14 00:07:15 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:07:15 2023 ] Eval epoch: 52
[ Sat Jan 14 00:10:03 2023 ] 	Mean test loss of 796 batches: 0.677835013736133.
[ Sat Jan 14 00:10:04 2023 ] 	Top1: 81.31%
[ Sat Jan 14 00:10:04 2023 ] 	Top5: 96.00%
[ Sat Jan 14 00:10:04 2023 ] Training epoch: 53
[ Sat Jan 14 00:17:53 2023 ] 	Mean training loss: 0.1467.  Mean training acc: 96.10%.
[ Sat Jan 14 00:17:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:17:53 2023 ] Eval epoch: 53
[ Sat Jan 14 00:20:55 2023 ] 	Mean test loss of 796 batches: 0.6757578826860418.
[ Sat Jan 14 00:20:56 2023 ] 	Top1: 81.61%
[ Sat Jan 14 00:20:56 2023 ] 	Top5: 95.90%
[ Sat Jan 14 00:20:56 2023 ] Training epoch: 54
[ Sat Jan 14 00:29:14 2023 ] 	Mean training loss: 0.1529.  Mean training acc: 95.89%.
[ Sat Jan 14 00:29:14 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:29:14 2023 ] Eval epoch: 54
[ Sat Jan 14 00:32:09 2023 ] 	Mean test loss of 796 batches: 0.7494552339890495.
[ Sat Jan 14 00:32:09 2023 ] 	Top1: 79.95%
[ Sat Jan 14 00:32:10 2023 ] 	Top5: 95.50%
[ Sat Jan 14 00:32:10 2023 ] Training epoch: 55
[ Sat Jan 14 00:39:34 2023 ] 	Mean training loss: 0.1459.  Mean training acc: 96.10%.
[ Sat Jan 14 00:39:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:39:34 2023 ] Eval epoch: 55
[ Sat Jan 14 00:42:25 2023 ] 	Mean test loss of 796 batches: 0.7303930070232506.
[ Sat Jan 14 00:42:26 2023 ] 	Top1: 80.55%
[ Sat Jan 14 00:42:26 2023 ] 	Top5: 95.78%
[ Sat Jan 14 00:42:26 2023 ] Training epoch: 56
[ Sat Jan 14 00:50:28 2023 ] 	Mean training loss: 0.0777.  Mean training acc: 98.39%.
[ Sat Jan 14 00:50:28 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:50:28 2023 ] Eval epoch: 56
[ Sat Jan 14 00:53:30 2023 ] 	Mean test loss of 796 batches: 0.6064712685631148.
[ Sat Jan 14 00:53:31 2023 ] 	Top1: 83.61%
[ Sat Jan 14 00:53:31 2023 ] 	Top5: 96.57%
[ Sat Jan 14 00:53:31 2023 ] Training epoch: 57
[ Sat Jan 14 01:01:53 2023 ] 	Mean training loss: 0.0556.  Mean training acc: 99.02%.
[ Sat Jan 14 01:01:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 01:01:53 2023 ] Eval epoch: 57
[ Sat Jan 14 01:04:36 2023 ] 	Mean test loss of 796 batches: 0.6062962535076105.
[ Sat Jan 14 01:04:37 2023 ] 	Top1: 83.59%
[ Sat Jan 14 01:04:37 2023 ] 	Top5: 96.62%
[ Sat Jan 14 01:04:37 2023 ] Training epoch: 58
[ Sat Jan 14 01:12:07 2023 ] 	Mean training loss: 0.0485.  Mean training acc: 99.27%.
[ Sat Jan 14 01:12:07 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 01:12:07 2023 ] Eval epoch: 58
[ Sat Jan 14 01:15:01 2023 ] 	Mean test loss of 796 batches: 0.613047160844707.
[ Sat Jan 14 01:15:02 2023 ] 	Top1: 83.54%
[ Sat Jan 14 01:15:02 2023 ] 	Top5: 96.55%
[ Sat Jan 14 01:15:02 2023 ] Training epoch: 59
[ Sat Jan 14 01:23:35 2023 ] 	Mean training loss: 0.0437.  Mean training acc: 99.34%.
[ Sat Jan 14 01:23:35 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 14 01:23:35 2023 ] Eval epoch: 59
[ Sat Jan 14 01:26:29 2023 ] 	Mean test loss of 796 batches: 0.6091794386206559.
[ Sat Jan 14 01:26:30 2023 ] 	Top1: 83.75%
[ Sat Jan 14 01:26:30 2023 ] 	Top5: 96.59%
[ Sat Jan 14 01:26:30 2023 ] Training epoch: 60
[ Sat Jan 14 01:34:30 2023 ] 	Mean training loss: 0.0411.  Mean training acc: 99.40%.
[ Sat Jan 14 01:34:30 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:34:30 2023 ] Eval epoch: 60
[ Sat Jan 14 01:37:09 2023 ] 	Mean test loss of 796 batches: 0.6106256188253811.
[ Sat Jan 14 01:37:09 2023 ] 	Top1: 83.79%
[ Sat Jan 14 01:37:10 2023 ] 	Top5: 96.56%
[ Sat Jan 14 01:37:10 2023 ] Training epoch: 61
[ Sat Jan 14 01:45:50 2023 ] 	Mean training loss: 0.0387.  Mean training acc: 99.47%.
[ Sat Jan 14 01:45:50 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:45:50 2023 ] Eval epoch: 61
[ Sat Jan 14 01:48:45 2023 ] 	Mean test loss of 796 batches: 0.6029228599713975.
[ Sat Jan 14 01:48:45 2023 ] 	Top1: 83.93%
[ Sat Jan 14 01:48:46 2023 ] 	Top5: 96.61%
[ Sat Jan 14 01:48:46 2023 ] Training epoch: 62
[ Sat Jan 14 01:56:55 2023 ] 	Mean training loss: 0.0370.  Mean training acc: 99.49%.
[ Sat Jan 14 01:56:55 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:56:55 2023 ] Eval epoch: 62
[ Sat Jan 14 01:59:33 2023 ] 	Mean test loss of 796 batches: 0.61229905169738.
[ Sat Jan 14 01:59:33 2023 ] 	Top1: 83.78%
[ Sat Jan 14 01:59:34 2023 ] 	Top5: 96.58%
[ Sat Jan 14 01:59:34 2023 ] Training epoch: 63
[ Sat Jan 14 02:07:23 2023 ] 	Mean training loss: 0.0349.  Mean training acc: 99.60%.
[ Sat Jan 14 02:07:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:07:23 2023 ] Eval epoch: 63
[ Sat Jan 14 02:10:01 2023 ] 	Mean test loss of 796 batches: 0.6097899006689014.
[ Sat Jan 14 02:10:01 2023 ] 	Top1: 83.90%
[ Sat Jan 14 02:10:01 2023 ] 	Top5: 96.65%
[ Sat Jan 14 02:10:01 2023 ] Training epoch: 64
[ Sat Jan 14 02:17:26 2023 ] 	Mean training loss: 0.0333.  Mean training acc: 99.63%.
[ Sat Jan 14 02:17:26 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:17:26 2023 ] Eval epoch: 64
[ Sat Jan 14 02:19:50 2023 ] 	Mean test loss of 796 batches: 0.6107523184569188.
[ Sat Jan 14 02:19:50 2023 ] 	Top1: 83.83%
[ Sat Jan 14 02:19:50 2023 ] 	Top5: 96.64%
[ Sat Jan 14 02:19:50 2023 ] Training epoch: 65
[ Sat Jan 14 02:26:58 2023 ] 	Mean training loss: 0.0324.  Mean training acc: 99.62%.
[ Sat Jan 14 02:26:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:26:58 2023 ] Eval epoch: 65
[ Sat Jan 14 02:29:24 2023 ] 	Mean test loss of 796 batches: 0.6128224502668609.
[ Sat Jan 14 02:29:25 2023 ] 	Top1: 83.76%
[ Sat Jan 14 02:29:25 2023 ] 	Top5: 96.55%
[ Sat Jan 14 02:31:52 2023 ] Best accuracy: 0.8393723364559398
[ Sat Jan 14 02:31:52 2023 ] Epoch number: 1
[ Sat Jan 14 02:31:52 2023 ] Model name: work_dir/csub/local_SHT_bone_BL
[ Sat Jan 14 02:31:52 2023 ] Model total number of params: 2141090
[ Sat Jan 14 02:31:52 2023 ] Weight decay: 0.0004
[ Sat Jan 14 02:31:52 2023 ] Base LR: 0.1
[ Sat Jan 14 02:31:52 2023 ] Batch Size: 64
[ Sat Jan 14 02:31:52 2023 ] Test Batch Size: 64
[ Sat Jan 14 02:31:52 2023 ] seed: 1
[ Tue Jan 17 13:18:36 2023 ] Load weights from work_dir/csub/local_SHT_bone_BL/runs-61-40651.pt.
[ Tue Jan 17 13:18:38 2023 ] using warm up, epoch: 5
[ Wed Jan 25 16:06:41 2023 ] using warm up, epoch: 5
[ Wed Jan 25 16:07:40 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jan 25 16:07:40 2023 ] # Parameters: 2141090
[ Wed Jan 25 16:07:40 2023 ] Training epoch: 1
[ Wed Jan 25 16:12:08 2023 ] 	Mean training loss: 3.4621.  Mean training acc: 16.69%.
[ Wed Jan 25 16:12:08 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:12:08 2023 ] Eval epoch: 1
[ Wed Jan 25 16:13:46 2023 ] 	Mean test loss of 796 batches: 3.0389448314455887.
[ Wed Jan 25 16:13:46 2023 ] 	Top1: 20.87%
[ Wed Jan 25 16:13:47 2023 ] 	Top5: 51.78%
[ Wed Jan 25 16:13:47 2023 ] Training epoch: 2
[ Wed Jan 25 16:18:13 2023 ] 	Mean training loss: 2.2768.  Mean training acc: 38.18%.
[ Wed Jan 25 16:18:13 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:18:13 2023 ] Eval epoch: 2
[ Wed Jan 25 16:19:51 2023 ] 	Mean test loss of 796 batches: 2.3543555141992902.
[ Wed Jan 25 16:19:51 2023 ] 	Top1: 35.79%
[ Wed Jan 25 16:19:51 2023 ] 	Top5: 71.36%
[ Wed Jan 25 16:19:51 2023 ] Training epoch: 3
[ Wed Jan 25 16:24:18 2023 ] 	Mean training loss: 1.7338.  Mean training acc: 50.70%.
[ Wed Jan 25 16:24:18 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:24:18 2023 ] Eval epoch: 3
[ Wed Jan 25 16:25:56 2023 ] 	Mean test loss of 796 batches: 1.8316426042036795.
[ Wed Jan 25 16:25:56 2023 ] 	Top1: 47.00%
[ Wed Jan 25 16:25:57 2023 ] 	Top5: 82.52%
[ Wed Jan 25 16:25:57 2023 ] Training epoch: 4
[ Wed Jan 25 16:30:43 2023 ] 	Mean training loss: 1.4790.  Mean training acc: 57.26%.
[ Wed Jan 25 16:30:43 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:30:43 2023 ] Eval epoch: 4
[ Wed Jan 25 16:32:28 2023 ] 	Mean test loss of 796 batches: 1.6020085219312552.
[ Wed Jan 25 16:32:28 2023 ] 	Top1: 53.99%
[ Wed Jan 25 16:32:29 2023 ] 	Top5: 85.46%
[ Wed Jan 25 16:32:29 2023 ] Training epoch: 5
[ Wed Jan 25 16:37:19 2023 ] 	Mean training loss: 1.3270.  Mean training acc: 61.29%.
[ Wed Jan 25 16:37:19 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:37:19 2023 ] Eval epoch: 5
[ Wed Jan 25 16:39:06 2023 ] 	Mean test loss of 796 batches: 1.6772196217248188.
[ Wed Jan 25 16:39:06 2023 ] 	Top1: 53.14%
[ Wed Jan 25 16:39:07 2023 ] 	Top5: 84.33%
[ Wed Jan 25 16:39:07 2023 ] Training epoch: 6
[ Wed Jan 25 16:43:57 2023 ] 	Mean training loss: 1.1792.  Mean training acc: 65.31%.
[ Wed Jan 25 16:43:57 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:43:57 2023 ] Eval epoch: 6
[ Wed Jan 25 16:45:43 2023 ] 	Mean test loss of 796 batches: 1.3531344326297243.
[ Wed Jan 25 16:45:44 2023 ] 	Top1: 60.51%
[ Wed Jan 25 16:45:44 2023 ] 	Top5: 89.63%
[ Wed Jan 25 16:45:44 2023 ] Training epoch: 7
[ Wed Jan 25 16:50:35 2023 ] 	Mean training loss: 1.0915.  Mean training acc: 67.66%.
[ Wed Jan 25 16:50:35 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 25 16:50:35 2023 ] Eval epoch: 7
[ Wed Jan 25 16:52:24 2023 ] 	Mean test loss of 796 batches: 1.4581146899928998.
[ Wed Jan 25 16:52:25 2023 ] 	Top1: 59.09%
[ Wed Jan 25 16:52:25 2023 ] 	Top5: 88.23%
[ Wed Jan 25 16:52:25 2023 ] Training epoch: 8
[ Wed Jan 25 16:59:37 2023 ] 	Mean training loss: 1.0341.  Mean training acc: 69.40%.
[ Wed Jan 25 16:59:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 16:59:37 2023 ] Eval epoch: 8
[ Wed Jan 25 17:02:06 2023 ] 	Mean test loss of 796 batches: 1.3735890929498265.
[ Wed Jan 25 17:02:06 2023 ] 	Top1: 60.60%
[ Wed Jan 25 17:02:07 2023 ] 	Top5: 88.97%
[ Wed Jan 25 17:02:07 2023 ] Training epoch: 9
[ Wed Jan 25 17:10:05 2023 ] 	Mean training loss: 0.9916.  Mean training acc: 70.53%.
[ Wed Jan 25 17:10:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 17:10:05 2023 ] Eval epoch: 9
[ Wed Jan 25 17:12:32 2023 ] 	Mean test loss of 796 batches: 1.3535317172806467.
[ Wed Jan 25 17:12:33 2023 ] 	Top1: 60.84%
[ Wed Jan 25 17:12:33 2023 ] 	Top5: 88.99%
[ Wed Jan 25 17:12:33 2023 ] Training epoch: 10
[ Wed Jan 25 17:20:33 2023 ] 	Mean training loss: 0.9606.  Mean training acc: 71.39%.
[ Wed Jan 25 17:20:33 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 17:20:33 2023 ] Eval epoch: 10
[ Wed Jan 25 17:23:03 2023 ] 	Mean test loss of 796 batches: 1.0648967475447821.
[ Wed Jan 25 17:23:03 2023 ] 	Top1: 69.21%
[ Wed Jan 25 17:23:04 2023 ] 	Top5: 92.53%
[ Wed Jan 25 17:23:04 2023 ] Training epoch: 11
[ Wed Jan 25 17:31:05 2023 ] 	Mean training loss: 0.9337.  Mean training acc: 72.16%.
[ Wed Jan 25 17:31:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 17:31:05 2023 ] Eval epoch: 11
[ Wed Jan 25 17:33:34 2023 ] 	Mean test loss of 796 batches: 1.181959480009786.
[ Wed Jan 25 17:33:35 2023 ] 	Top1: 65.16%
[ Wed Jan 25 17:33:35 2023 ] 	Top5: 91.54%
[ Wed Jan 25 17:33:35 2023 ] Training epoch: 12
[ Wed Jan 25 17:41:36 2023 ] 	Mean training loss: 0.9147.  Mean training acc: 72.80%.
[ Wed Jan 25 17:41:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 17:41:36 2023 ] Eval epoch: 12
[ Wed Jan 25 17:44:06 2023 ] 	Mean test loss of 796 batches: 1.1067298251255673.
[ Wed Jan 25 17:44:06 2023 ] 	Top1: 66.92%
[ Wed Jan 25 17:44:07 2023 ] 	Top5: 92.35%
[ Wed Jan 25 17:44:07 2023 ] Training epoch: 13
[ Wed Jan 25 17:52:07 2023 ] 	Mean training loss: 0.8851.  Mean training acc: 73.56%.
[ Wed Jan 25 17:52:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 17:52:07 2023 ] Eval epoch: 13
[ Wed Jan 25 17:54:36 2023 ] 	Mean test loss of 796 batches: 1.160423575820935.
[ Wed Jan 25 17:54:37 2023 ] 	Top1: 67.57%
[ Wed Jan 25 17:54:37 2023 ] 	Top5: 91.79%
[ Wed Jan 25 17:54:37 2023 ] Training epoch: 14
[ Wed Jan 25 18:02:41 2023 ] 	Mean training loss: 0.8745.  Mean training acc: 73.85%.
[ Wed Jan 25 18:02:41 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:02:41 2023 ] Eval epoch: 14
[ Wed Jan 25 18:05:17 2023 ] 	Mean test loss of 796 batches: 1.1968634761682706.
[ Wed Jan 25 18:05:17 2023 ] 	Top1: 65.70%
[ Wed Jan 25 18:05:17 2023 ] 	Top5: 91.76%
[ Wed Jan 25 18:05:18 2023 ] Training epoch: 15
[ Wed Jan 25 18:13:36 2023 ] 	Mean training loss: 0.8652.  Mean training acc: 74.32%.
[ Wed Jan 25 18:13:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:13:37 2023 ] Eval epoch: 15
[ Wed Jan 25 18:16:10 2023 ] 	Mean test loss of 796 batches: 1.2022370651139687.
[ Wed Jan 25 18:16:11 2023 ] 	Top1: 65.58%
[ Wed Jan 25 18:16:11 2023 ] 	Top5: 91.82%
[ Wed Jan 25 18:16:11 2023 ] Training epoch: 16
[ Wed Jan 25 18:24:32 2023 ] 	Mean training loss: 0.8512.  Mean training acc: 74.60%.
[ Wed Jan 25 18:24:32 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:24:32 2023 ] Eval epoch: 16
[ Wed Jan 25 18:27:06 2023 ] 	Mean test loss of 796 batches: 1.0917034939156105.
[ Wed Jan 25 18:27:07 2023 ] 	Top1: 67.76%
[ Wed Jan 25 18:27:07 2023 ] 	Top5: 92.41%
[ Wed Jan 25 18:27:07 2023 ] Training epoch: 17
[ Wed Jan 25 18:35:27 2023 ] 	Mean training loss: 0.8430.  Mean training acc: 74.81%.
[ Wed Jan 25 18:35:27 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:35:28 2023 ] Eval epoch: 17
[ Wed Jan 25 18:38:03 2023 ] 	Mean test loss of 796 batches: 1.3030651285495591.
[ Wed Jan 25 18:38:03 2023 ] 	Top1: 64.19%
[ Wed Jan 25 18:38:04 2023 ] 	Top5: 90.71%
[ Wed Jan 25 18:38:04 2023 ] Training epoch: 18
[ Wed Jan 25 18:46:22 2023 ] 	Mean training loss: 0.8293.  Mean training acc: 75.26%.
[ Wed Jan 25 18:46:22 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:46:22 2023 ] Eval epoch: 18
[ Wed Jan 25 18:48:55 2023 ] 	Mean test loss of 796 batches: 1.149493555477516.
[ Wed Jan 25 18:48:56 2023 ] 	Top1: 67.70%
[ Wed Jan 25 18:48:56 2023 ] 	Top5: 91.44%
[ Wed Jan 25 18:48:56 2023 ] Training epoch: 19
[ Wed Jan 25 18:57:15 2023 ] 	Mean training loss: 0.8151.  Mean training acc: 75.47%.
[ Wed Jan 25 18:57:15 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 18:57:15 2023 ] Eval epoch: 19
[ Wed Jan 25 18:59:50 2023 ] 	Mean test loss of 796 batches: 1.2257306922844906.
[ Wed Jan 25 18:59:51 2023 ] 	Top1: 65.26%
[ Wed Jan 25 18:59:51 2023 ] 	Top5: 91.40%
[ Wed Jan 25 18:59:51 2023 ] Training epoch: 20
[ Wed Jan 25 19:08:12 2023 ] 	Mean training loss: 0.8076.  Mean training acc: 75.94%.
[ Wed Jan 25 19:08:12 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 19:08:12 2023 ] Eval epoch: 20
[ Wed Jan 25 19:10:48 2023 ] 	Mean test loss of 796 batches: 1.371625041954182.
[ Wed Jan 25 19:10:48 2023 ] 	Top1: 63.38%
[ Wed Jan 25 19:10:49 2023 ] 	Top5: 88.43%
[ Wed Jan 25 19:10:49 2023 ] Training epoch: 21
[ Wed Jan 25 19:19:05 2023 ] 	Mean training loss: 0.7953.  Mean training acc: 76.14%.
[ Wed Jan 25 19:19:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 19:19:05 2023 ] Eval epoch: 21
[ Wed Jan 25 19:21:40 2023 ] 	Mean test loss of 796 batches: 1.1640388343352168.
[ Wed Jan 25 19:21:41 2023 ] 	Top1: 66.85%
[ Wed Jan 25 19:21:41 2023 ] 	Top5: 90.88%
[ Wed Jan 25 19:21:41 2023 ] Training epoch: 22
[ Wed Jan 25 19:30:01 2023 ] 	Mean training loss: 0.7898.  Mean training acc: 76.41%.
[ Wed Jan 25 19:30:01 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 19:30:01 2023 ] Eval epoch: 22
[ Wed Jan 25 19:32:34 2023 ] 	Mean test loss of 796 batches: 1.1171563802352502.
[ Wed Jan 25 19:32:34 2023 ] 	Top1: 67.95%
[ Wed Jan 25 19:32:34 2023 ] 	Top5: 91.98%
[ Wed Jan 25 19:32:34 2023 ] Training epoch: 23
[ Wed Jan 25 19:40:51 2023 ] 	Mean training loss: 0.7894.  Mean training acc: 76.42%.
[ Wed Jan 25 19:40:51 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 19:40:51 2023 ] Eval epoch: 23
[ Wed Jan 25 19:43:25 2023 ] 	Mean test loss of 796 batches: 1.2168122412421596.
[ Wed Jan 25 19:43:25 2023 ] 	Top1: 65.66%
[ Wed Jan 25 19:43:26 2023 ] 	Top5: 90.64%
[ Wed Jan 25 19:43:26 2023 ] Training epoch: 24
[ Wed Jan 25 19:51:40 2023 ] 	Mean training loss: 0.7811.  Mean training acc: 76.75%.
[ Wed Jan 25 19:51:40 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 19:51:40 2023 ] Eval epoch: 24
[ Wed Jan 25 19:54:13 2023 ] 	Mean test loss of 796 batches: 1.4149668282599905.
[ Wed Jan 25 19:54:13 2023 ] 	Top1: 61.76%
[ Wed Jan 25 19:54:14 2023 ] 	Top5: 89.34%
[ Wed Jan 25 19:54:14 2023 ] Training epoch: 25
[ Wed Jan 25 20:02:28 2023 ] 	Mean training loss: 0.7780.  Mean training acc: 76.67%.
[ Wed Jan 25 20:02:28 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:02:28 2023 ] Eval epoch: 25
[ Wed Jan 25 20:05:00 2023 ] 	Mean test loss of 796 batches: 1.051749524047327.
[ Wed Jan 25 20:05:01 2023 ] 	Top1: 69.16%
[ Wed Jan 25 20:05:01 2023 ] 	Top5: 92.79%
[ Wed Jan 25 20:05:01 2023 ] Training epoch: 26
[ Wed Jan 25 20:13:17 2023 ] 	Mean training loss: 0.7723.  Mean training acc: 76.76%.
[ Wed Jan 25 20:13:17 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:13:17 2023 ] Eval epoch: 26
[ Wed Jan 25 20:15:49 2023 ] 	Mean test loss of 796 batches: 1.0468958085356046.
[ Wed Jan 25 20:15:49 2023 ] 	Top1: 70.08%
[ Wed Jan 25 20:15:50 2023 ] 	Top5: 92.76%
[ Wed Jan 25 20:15:50 2023 ] Training epoch: 27
[ Wed Jan 25 20:24:05 2023 ] 	Mean training loss: 0.7706.  Mean training acc: 77.04%.
[ Wed Jan 25 20:24:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:24:05 2023 ] Eval epoch: 27
[ Wed Jan 25 20:26:38 2023 ] 	Mean test loss of 796 batches: 1.294176002805257.
[ Wed Jan 25 20:26:38 2023 ] 	Top1: 64.08%
[ Wed Jan 25 20:26:38 2023 ] 	Top5: 90.50%
[ Wed Jan 25 20:26:38 2023 ] Training epoch: 28
[ Wed Jan 25 20:34:54 2023 ] 	Mean training loss: 0.7536.  Mean training acc: 77.36%.
[ Wed Jan 25 20:34:54 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:34:54 2023 ] Eval epoch: 28
[ Wed Jan 25 20:37:26 2023 ] 	Mean test loss of 796 batches: 1.186568498948411.
[ Wed Jan 25 20:37:26 2023 ] 	Top1: 67.87%
[ Wed Jan 25 20:37:26 2023 ] 	Top5: 91.87%
[ Wed Jan 25 20:37:26 2023 ] Training epoch: 29
[ Wed Jan 25 20:45:43 2023 ] 	Mean training loss: 0.7576.  Mean training acc: 77.42%.
[ Wed Jan 25 20:45:43 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:45:43 2023 ] Eval epoch: 29
[ Wed Jan 25 20:48:15 2023 ] 	Mean test loss of 796 batches: 1.206957798694546.
[ Wed Jan 25 20:48:16 2023 ] 	Top1: 65.65%
[ Wed Jan 25 20:48:16 2023 ] 	Top5: 91.00%
[ Wed Jan 25 20:48:16 2023 ] Training epoch: 30
[ Wed Jan 25 20:56:31 2023 ] 	Mean training loss: 0.7545.  Mean training acc: 77.41%.
[ Wed Jan 25 20:56:31 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 20:56:31 2023 ] Eval epoch: 30
[ Wed Jan 25 20:59:05 2023 ] 	Mean test loss of 796 batches: 0.952713115243756.
[ Wed Jan 25 20:59:05 2023 ] 	Top1: 71.58%
[ Wed Jan 25 20:59:05 2023 ] 	Top5: 93.76%
[ Wed Jan 25 20:59:05 2023 ] Training epoch: 31
[ Wed Jan 25 21:07:23 2023 ] 	Mean training loss: 0.7457.  Mean training acc: 77.67%.
[ Wed Jan 25 21:07:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 21:07:23 2023 ] Eval epoch: 31
[ Wed Jan 25 21:09:56 2023 ] 	Mean test loss of 796 batches: 1.1004148234224798.
[ Wed Jan 25 21:09:56 2023 ] 	Top1: 69.13%
[ Wed Jan 25 21:09:57 2023 ] 	Top5: 92.49%
[ Wed Jan 25 21:09:57 2023 ] Training epoch: 32
[ Wed Jan 25 21:18:13 2023 ] 	Mean training loss: 0.7521.  Mean training acc: 77.42%.
[ Wed Jan 25 21:18:13 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 21:18:13 2023 ] Eval epoch: 32
[ Wed Jan 25 21:20:46 2023 ] 	Mean test loss of 796 batches: 1.1444238030056857.
[ Wed Jan 25 21:20:47 2023 ] 	Top1: 67.16%
[ Wed Jan 25 21:20:47 2023 ] 	Top5: 92.02%
[ Wed Jan 25 21:20:47 2023 ] Training epoch: 33
[ Wed Jan 25 21:29:03 2023 ] 	Mean training loss: 0.7446.  Mean training acc: 77.87%.
[ Wed Jan 25 21:29:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 21:29:03 2023 ] Eval epoch: 33
[ Wed Jan 25 21:31:37 2023 ] 	Mean test loss of 796 batches: 1.0232698718207565.
[ Wed Jan 25 21:31:37 2023 ] 	Top1: 70.52%
[ Wed Jan 25 21:31:37 2023 ] 	Top5: 92.80%
[ Wed Jan 25 21:31:37 2023 ] Training epoch: 34
[ Wed Jan 25 21:39:54 2023 ] 	Mean training loss: 0.7483.  Mean training acc: 77.39%.
[ Wed Jan 25 21:39:54 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 21:39:54 2023 ] Eval epoch: 34
[ Wed Jan 25 21:42:28 2023 ] 	Mean test loss of 796 batches: 1.0311125974783946.
[ Wed Jan 25 21:42:28 2023 ] 	Top1: 69.95%
[ Wed Jan 25 21:42:29 2023 ] 	Top5: 92.55%
[ Wed Jan 25 21:42:29 2023 ] Training epoch: 35
[ Wed Jan 25 21:50:45 2023 ] 	Mean training loss: 0.7378.  Mean training acc: 77.94%.
[ Wed Jan 25 21:50:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 21:50:45 2023 ] Eval epoch: 35
[ Wed Jan 25 21:53:18 2023 ] 	Mean test loss of 796 batches: 1.121053206710959.
[ Wed Jan 25 21:53:18 2023 ] 	Top1: 67.87%
[ Wed Jan 25 21:53:18 2023 ] 	Top5: 92.00%
[ Wed Jan 25 21:53:18 2023 ] Training epoch: 36
[ Wed Jan 25 22:01:34 2023 ] 	Mean training loss: 0.4069.  Mean training acc: 87.97%.
[ Wed Jan 25 22:01:34 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:01:34 2023 ] Eval epoch: 36
[ Wed Jan 25 22:04:09 2023 ] 	Mean test loss of 796 batches: 0.5625052109978457.
[ Wed Jan 25 22:04:09 2023 ] 	Top1: 83.00%
[ Wed Jan 25 22:04:10 2023 ] 	Top5: 96.95%
[ Wed Jan 25 22:04:10 2023 ] Training epoch: 37
[ Wed Jan 25 22:12:43 2023 ] 	Mean training loss: 0.3139.  Mean training acc: 90.58%.
[ Wed Jan 25 22:12:43 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:12:43 2023 ] Eval epoch: 37
[ Wed Jan 25 22:15:20 2023 ] 	Mean test loss of 796 batches: 0.5478291762009937.
[ Wed Jan 25 22:15:21 2023 ] 	Top1: 83.38%
[ Wed Jan 25 22:15:21 2023 ] 	Top5: 97.13%
[ Wed Jan 25 22:15:21 2023 ] Training epoch: 38
[ Wed Jan 25 22:24:00 2023 ] 	Mean training loss: 0.2821.  Mean training acc: 91.60%.
[ Wed Jan 25 22:24:00 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:24:00 2023 ] Eval epoch: 38
[ Wed Jan 25 22:26:41 2023 ] 	Mean test loss of 796 batches: 0.5466720082577149.
[ Wed Jan 25 22:26:41 2023 ] 	Top1: 83.44%
[ Wed Jan 25 22:26:41 2023 ] 	Top5: 97.14%
[ Wed Jan 25 22:26:41 2023 ] Training epoch: 39
[ Wed Jan 25 22:35:17 2023 ] 	Mean training loss: 0.2517.  Mean training acc: 92.57%.
[ Wed Jan 25 22:35:17 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:35:17 2023 ] Eval epoch: 39
[ Wed Jan 25 22:37:58 2023 ] 	Mean test loss of 796 batches: 0.5592825441579123.
[ Wed Jan 25 22:37:58 2023 ] 	Top1: 83.23%
[ Wed Jan 25 22:37:58 2023 ] 	Top5: 97.06%
[ Wed Jan 25 22:37:58 2023 ] Training epoch: 40
[ Wed Jan 25 22:46:38 2023 ] 	Mean training loss: 0.2285.  Mean training acc: 93.48%.
[ Wed Jan 25 22:46:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:46:38 2023 ] Eval epoch: 40
[ Wed Jan 25 22:49:16 2023 ] 	Mean test loss of 796 batches: 0.5581358928121065.
[ Wed Jan 25 22:49:16 2023 ] 	Top1: 83.42%
[ Wed Jan 25 22:49:17 2023 ] 	Top5: 96.98%
[ Wed Jan 25 22:49:17 2023 ] Training epoch: 41
[ Wed Jan 25 22:57:56 2023 ] 	Mean training loss: 0.2146.  Mean training acc: 93.83%.
[ Wed Jan 25 22:57:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 22:57:56 2023 ] Eval epoch: 41
[ Wed Jan 25 23:00:37 2023 ] 	Mean test loss of 796 batches: 0.5648931589904218.
[ Wed Jan 25 23:00:37 2023 ] 	Top1: 83.46%
[ Wed Jan 25 23:00:38 2023 ] 	Top5: 96.86%
[ Wed Jan 25 23:00:38 2023 ] Training epoch: 42
[ Wed Jan 25 23:09:20 2023 ] 	Mean training loss: 0.1972.  Mean training acc: 94.46%.
[ Wed Jan 25 23:09:20 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 23:09:20 2023 ] Eval epoch: 42
[ Wed Jan 25 23:11:56 2023 ] 	Mean test loss of 796 batches: 0.5775530338568154.
[ Wed Jan 25 23:11:56 2023 ] 	Top1: 83.26%
[ Wed Jan 25 23:11:56 2023 ] 	Top5: 96.86%
[ Wed Jan 25 23:11:56 2023 ] Training epoch: 43
[ Wed Jan 25 23:20:35 2023 ] 	Mean training loss: 0.1838.  Mean training acc: 94.90%.
[ Wed Jan 25 23:20:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 23:20:35 2023 ] Eval epoch: 43
[ Wed Jan 25 23:23:18 2023 ] 	Mean test loss of 796 batches: 0.599652765580832.
[ Wed Jan 25 23:23:18 2023 ] 	Top1: 82.83%
[ Wed Jan 25 23:23:18 2023 ] 	Top5: 96.69%
[ Wed Jan 25 23:23:18 2023 ] Training epoch: 44
[ Wed Jan 25 23:31:59 2023 ] 	Mean training loss: 0.1712.  Mean training acc: 95.32%.
[ Wed Jan 25 23:31:59 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 23:31:59 2023 ] Eval epoch: 44
[ Wed Jan 25 23:34:37 2023 ] 	Mean test loss of 796 batches: 0.6001545623805954.
[ Wed Jan 25 23:34:37 2023 ] 	Top1: 83.08%
[ Wed Jan 25 23:34:38 2023 ] 	Top5: 96.70%
[ Wed Jan 25 23:34:38 2023 ] Training epoch: 45
[ Wed Jan 25 23:43:20 2023 ] 	Mean training loss: 0.1658.  Mean training acc: 95.47%.
[ Wed Jan 25 23:43:20 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 23:43:20 2023 ] Eval epoch: 45
[ Wed Jan 25 23:46:00 2023 ] 	Mean test loss of 796 batches: 0.6263572739802263.
[ Wed Jan 25 23:46:01 2023 ] 	Top1: 82.21%
[ Wed Jan 25 23:46:01 2023 ] 	Top5: 96.51%
[ Wed Jan 25 23:46:01 2023 ] Training epoch: 46
[ Wed Jan 25 23:54:38 2023 ] 	Mean training loss: 0.1594.  Mean training acc: 95.65%.
[ Wed Jan 25 23:54:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 25 23:54:38 2023 ] Eval epoch: 46
[ Wed Jan 25 23:57:19 2023 ] 	Mean test loss of 796 batches: 0.6378908498802377.
[ Wed Jan 25 23:57:19 2023 ] 	Top1: 82.08%
[ Wed Jan 25 23:57:20 2023 ] 	Top5: 96.33%
[ Wed Jan 25 23:57:20 2023 ] Training epoch: 47
[ Thu Jan 26 00:05:58 2023 ] 	Mean training loss: 0.1536.  Mean training acc: 95.98%.
[ Thu Jan 26 00:05:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 00:05:58 2023 ] Eval epoch: 47
[ Thu Jan 26 00:08:37 2023 ] 	Mean test loss of 796 batches: 0.6183780454117899.
[ Thu Jan 26 00:08:38 2023 ] 	Top1: 82.76%
[ Thu Jan 26 00:08:38 2023 ] 	Top5: 96.50%
[ Thu Jan 26 00:08:38 2023 ] Training epoch: 48
[ Thu Jan 26 00:17:06 2023 ] 	Mean training loss: 0.1485.  Mean training acc: 96.10%.
[ Thu Jan 26 00:17:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 00:17:07 2023 ] Eval epoch: 48
[ Thu Jan 26 00:19:44 2023 ] 	Mean test loss of 796 batches: 0.6616355603251924.
[ Thu Jan 26 00:19:45 2023 ] 	Top1: 81.66%
[ Thu Jan 26 00:19:45 2023 ] 	Top5: 96.20%
[ Thu Jan 26 00:19:45 2023 ] Training epoch: 49
[ Thu Jan 26 00:28:23 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.13%.
[ Thu Jan 26 00:28:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 00:28:23 2023 ] Eval epoch: 49
[ Thu Jan 26 00:31:00 2023 ] 	Mean test loss of 796 batches: 0.6640914808584368.
[ Thu Jan 26 00:31:01 2023 ] 	Top1: 81.87%
[ Thu Jan 26 00:31:01 2023 ] 	Top5: 96.29%
[ Thu Jan 26 00:31:01 2023 ] Training epoch: 50
[ Thu Jan 26 00:39:37 2023 ] 	Mean training loss: 0.1458.  Mean training acc: 96.11%.
[ Thu Jan 26 00:39:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 00:39:37 2023 ] Eval epoch: 50
[ Thu Jan 26 00:42:16 2023 ] 	Mean test loss of 796 batches: 0.6618064904501241.
[ Thu Jan 26 00:42:16 2023 ] 	Top1: 82.22%
[ Thu Jan 26 00:42:16 2023 ] 	Top5: 96.25%
[ Thu Jan 26 00:42:16 2023 ] Training epoch: 51
[ Thu Jan 26 00:50:53 2023 ] 	Mean training loss: 0.1454.  Mean training acc: 96.14%.
[ Thu Jan 26 00:50:53 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 00:50:53 2023 ] Eval epoch: 51
[ Thu Jan 26 00:53:31 2023 ] 	Mean test loss of 796 batches: 0.7732500670449668.
[ Thu Jan 26 00:53:31 2023 ] 	Top1: 79.27%
[ Thu Jan 26 00:53:31 2023 ] 	Top5: 94.90%
[ Thu Jan 26 00:53:31 2023 ] Training epoch: 52
[ Thu Jan 26 01:02:10 2023 ] 	Mean training loss: 0.1446.  Mean training acc: 96.16%.
[ Thu Jan 26 01:02:10 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:02:10 2023 ] Eval epoch: 52
[ Thu Jan 26 01:04:49 2023 ] 	Mean test loss of 796 batches: 0.6751555896097392.
[ Thu Jan 26 01:04:49 2023 ] 	Top1: 81.41%
[ Thu Jan 26 01:04:50 2023 ] 	Top5: 96.09%
[ Thu Jan 26 01:04:50 2023 ] Training epoch: 53
[ Thu Jan 26 01:12:59 2023 ] 	Mean training loss: 0.1463.  Mean training acc: 96.14%.
[ Thu Jan 26 01:12:59 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:12:59 2023 ] Eval epoch: 53
[ Thu Jan 26 01:15:27 2023 ] 	Mean test loss of 796 batches: 0.7188130744157275.
[ Thu Jan 26 01:15:28 2023 ] 	Top1: 80.85%
[ Thu Jan 26 01:15:28 2023 ] 	Top5: 95.75%
[ Thu Jan 26 01:15:28 2023 ] Training epoch: 54
[ Thu Jan 26 01:23:24 2023 ] 	Mean training loss: 0.1460.  Mean training acc: 96.17%.
[ Thu Jan 26 01:23:24 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:23:24 2023 ] Eval epoch: 54
[ Thu Jan 26 01:25:53 2023 ] 	Mean test loss of 796 batches: 0.6866678628022197.
[ Thu Jan 26 01:25:53 2023 ] 	Top1: 81.07%
[ Thu Jan 26 01:25:54 2023 ] 	Top5: 96.13%
[ Thu Jan 26 01:25:54 2023 ] Training epoch: 55
[ Thu Jan 26 01:33:47 2023 ] 	Mean training loss: 0.1433.  Mean training acc: 96.22%.
[ Thu Jan 26 01:33:47 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:33:47 2023 ] Eval epoch: 55
[ Thu Jan 26 01:36:14 2023 ] 	Mean test loss of 796 batches: 0.6650750864503072.
[ Thu Jan 26 01:36:15 2023 ] 	Top1: 81.81%
[ Thu Jan 26 01:36:15 2023 ] 	Top5: 96.17%
[ Thu Jan 26 01:36:15 2023 ] Training epoch: 56
[ Thu Jan 26 01:44:09 2023 ] 	Mean training loss: 0.0786.  Mean training acc: 98.39%.
[ Thu Jan 26 01:44:09 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:44:09 2023 ] Eval epoch: 56
[ Thu Jan 26 01:46:39 2023 ] 	Mean test loss of 796 batches: 0.5855109420974725.
[ Thu Jan 26 01:46:39 2023 ] 	Top1: 84.11%
[ Thu Jan 26 01:46:40 2023 ] 	Top5: 96.73%
[ Thu Jan 26 01:46:40 2023 ] Training epoch: 57
[ Thu Jan 26 01:54:37 2023 ] 	Mean training loss: 0.0568.  Mean training acc: 99.02%.
[ Thu Jan 26 01:54:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 01:54:37 2023 ] Eval epoch: 57
[ Thu Jan 26 01:57:06 2023 ] 	Mean test loss of 796 batches: 0.582394056663329.
[ Thu Jan 26 01:57:07 2023 ] 	Top1: 84.28%
[ Thu Jan 26 01:57:07 2023 ] 	Top5: 96.79%
[ Thu Jan 26 01:57:07 2023 ] Training epoch: 58
[ Thu Jan 26 02:05:03 2023 ] 	Mean training loss: 0.0485.  Mean training acc: 99.24%.
[ Thu Jan 26 02:05:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:05:03 2023 ] Eval epoch: 58
[ Thu Jan 26 02:07:33 2023 ] 	Mean test loss of 796 batches: 0.5917735319706289.
[ Thu Jan 26 02:07:33 2023 ] 	Top1: 84.19%
[ Thu Jan 26 02:07:34 2023 ] 	Top5: 96.68%
[ Thu Jan 26 02:07:34 2023 ] Training epoch: 59
[ Thu Jan 26 02:15:29 2023 ] 	Mean training loss: 0.0433.  Mean training acc: 99.40%.
[ Thu Jan 26 02:15:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:15:29 2023 ] Eval epoch: 59
[ Thu Jan 26 02:17:58 2023 ] 	Mean test loss of 796 batches: 0.5893565793685502.
[ Thu Jan 26 02:17:59 2023 ] 	Top1: 84.28%
[ Thu Jan 26 02:17:59 2023 ] 	Top5: 96.76%
[ Thu Jan 26 02:17:59 2023 ] Training epoch: 60
[ Thu Jan 26 02:25:55 2023 ] 	Mean training loss: 0.0403.  Mean training acc: 99.48%.
[ Thu Jan 26 02:25:55 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:25:55 2023 ] Eval epoch: 60
[ Thu Jan 26 02:28:25 2023 ] 	Mean test loss of 796 batches: 0.5892927675185042.
[ Thu Jan 26 02:28:25 2023 ] 	Top1: 84.39%
[ Thu Jan 26 02:28:25 2023 ] 	Top5: 96.76%
[ Thu Jan 26 02:28:25 2023 ] Training epoch: 61
[ Thu Jan 26 02:36:21 2023 ] 	Mean training loss: 0.0387.  Mean training acc: 99.50%.
[ Thu Jan 26 02:36:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:36:21 2023 ] Eval epoch: 61
[ Thu Jan 26 02:38:50 2023 ] 	Mean test loss of 796 batches: 0.5865686151419004.
[ Thu Jan 26 02:38:50 2023 ] 	Top1: 84.40%
[ Thu Jan 26 02:38:51 2023 ] 	Top5: 96.72%
[ Thu Jan 26 02:38:51 2023 ] Training epoch: 62
[ Thu Jan 26 02:46:47 2023 ] 	Mean training loss: 0.0372.  Mean training acc: 99.55%.
[ Thu Jan 26 02:46:47 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:46:47 2023 ] Eval epoch: 62
[ Thu Jan 26 02:49:16 2023 ] 	Mean test loss of 796 batches: 0.5964858324814531.
[ Thu Jan 26 02:49:16 2023 ] 	Top1: 84.16%
[ Thu Jan 26 02:49:17 2023 ] 	Top5: 96.68%
[ Thu Jan 26 02:49:17 2023 ] Training epoch: 63
[ Thu Jan 26 02:57:13 2023 ] 	Mean training loss: 0.0345.  Mean training acc: 99.58%.
[ Thu Jan 26 02:57:13 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 02:57:13 2023 ] Eval epoch: 63
[ Thu Jan 26 02:59:41 2023 ] 	Mean test loss of 796 batches: 0.5893360460457865.
[ Thu Jan 26 02:59:42 2023 ] 	Top1: 84.28%
[ Thu Jan 26 02:59:42 2023 ] 	Top5: 96.73%
[ Thu Jan 26 02:59:42 2023 ] Training epoch: 64
[ Thu Jan 26 03:07:38 2023 ] 	Mean training loss: 0.0333.  Mean training acc: 99.62%.
[ Thu Jan 26 03:07:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 03:07:38 2023 ] Eval epoch: 64
[ Thu Jan 26 03:10:06 2023 ] 	Mean test loss of 796 batches: 0.5891450071782248.
[ Thu Jan 26 03:10:06 2023 ] 	Top1: 84.42%
[ Thu Jan 26 03:10:07 2023 ] 	Top5: 96.78%
[ Thu Jan 26 03:10:07 2023 ] Training epoch: 65
[ Thu Jan 26 03:18:02 2023 ] 	Mean training loss: 0.0332.  Mean training acc: 99.61%.
[ Thu Jan 26 03:18:02 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 03:18:02 2023 ] Eval epoch: 65
[ Thu Jan 26 03:20:31 2023 ] 	Mean test loss of 796 batches: 0.5869877605076561.
[ Thu Jan 26 03:20:31 2023 ] 	Top1: 84.44%
[ Thu Jan 26 03:20:32 2023 ] 	Top5: 96.79%
[ Thu Jan 26 03:23:04 2023 ] Best accuracy: 0.8443999292994756
[ Thu Jan 26 03:23:04 2023 ] Epoch number: 65
[ Thu Jan 26 03:23:04 2023 ] Model name: work_dir/csub/local_SHT_bone_BL
[ Thu Jan 26 03:23:04 2023 ] Model total number of params: 2141090
[ Thu Jan 26 03:23:04 2023 ] Weight decay: 0.0004
[ Thu Jan 26 03:23:04 2023 ] Base LR: 0.1
[ Thu Jan 26 03:23:04 2023 ] Batch Size: 64
[ Thu Jan 26 03:23:04 2023 ] Test Batch Size: 64
[ Thu Jan 26 03:23:04 2023 ] seed: 1
[ Thu Jan 26 22:13:36 2023 ] using warm up, epoch: 5
[ Thu Jan 26 22:13:53 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Jan 26 22:13:53 2023 ] # Parameters: 2141090
[ Thu Jan 26 22:13:53 2023 ] Training epoch: 1
[ Thu Jan 26 22:23:03 2023 ] 	Mean training loss: 3.4621.  Mean training acc: 16.69%.
[ Thu Jan 26 22:23:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 22:23:03 2023 ] Eval epoch: 1
[ Thu Jan 26 22:25:59 2023 ] 	Mean test loss of 796 batches: 3.0389448314455887.
[ Thu Jan 26 22:25:59 2023 ] 	Top1: 20.87%
[ Thu Jan 26 22:26:00 2023 ] 	Top5: 51.78%
[ Thu Jan 26 22:26:00 2023 ] Training epoch: 2
[ Thu Jan 26 22:27:19 2023 ] using warm up, epoch: 5
[ Thu Jan 26 22:27:36 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Jan 26 22:27:36 2023 ] # Parameters: 2141090
[ Thu Jan 26 22:27:36 2023 ] Training epoch: 1
[ Thu Jan 26 22:37:39 2023 ] 	Mean training loss: 3.4621.  Mean training acc: 16.69%.
[ Thu Jan 26 22:37:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 22:37:39 2023 ] Eval epoch: 1
[ Thu Jan 26 22:40:40 2023 ] 	Mean test loss of 796 batches: 3.0389448314455887.
[ Thu Jan 26 22:40:41 2023 ] 	Top1: 20.87%
[ Thu Jan 26 22:40:41 2023 ] 	Top5: 51.78%
[ Thu Jan 26 22:40:41 2023 ] Training epoch: 2
[ Thu Jan 26 22:49:48 2023 ] 	Mean training loss: 2.2768.  Mean training acc: 38.18%.
[ Thu Jan 26 22:49:48 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 22:49:48 2023 ] Eval epoch: 2
[ Thu Jan 26 22:52:47 2023 ] 	Mean test loss of 796 batches: 2.3543555141992902.
[ Thu Jan 26 22:52:48 2023 ] 	Top1: 35.79%
[ Thu Jan 26 22:52:48 2023 ] 	Top5: 71.36%
[ Thu Jan 26 22:52:48 2023 ] Training epoch: 3
[ Thu Jan 26 23:02:52 2023 ] 	Mean training loss: 1.7338.  Mean training acc: 50.70%.
[ Thu Jan 26 23:02:52 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 23:02:52 2023 ] Eval epoch: 3
[ Thu Jan 26 23:05:53 2023 ] 	Mean test loss of 796 batches: 1.8316426042036795.
[ Thu Jan 26 23:05:53 2023 ] 	Top1: 47.00%
[ Thu Jan 26 23:05:54 2023 ] 	Top5: 82.52%
[ Thu Jan 26 23:05:54 2023 ] Training epoch: 4
[ Thu Jan 26 23:15:06 2023 ] 	Mean training loss: 1.4790.  Mean training acc: 57.26%.
[ Thu Jan 26 23:15:06 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 23:15:06 2023 ] Eval epoch: 4
[ Thu Jan 26 23:18:02 2023 ] 	Mean test loss of 796 batches: 1.6020085219312552.
[ Thu Jan 26 23:18:02 2023 ] 	Top1: 53.99%
[ Thu Jan 26 23:18:03 2023 ] 	Top5: 85.46%
[ Thu Jan 26 23:18:03 2023 ] Training epoch: 5
[ Thu Jan 26 23:28:05 2023 ] 	Mean training loss: 1.3270.  Mean training acc: 61.29%.
[ Thu Jan 26 23:28:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 23:28:05 2023 ] Eval epoch: 5
[ Thu Jan 26 23:31:06 2023 ] 	Mean test loss of 796 batches: 1.6772196217248188.
[ Thu Jan 26 23:31:07 2023 ] 	Top1: 53.14%
[ Thu Jan 26 23:31:07 2023 ] 	Top5: 84.33%
[ Thu Jan 26 23:31:07 2023 ] Training epoch: 6
[ Thu Jan 26 23:40:21 2023 ] 	Mean training loss: 1.1792.  Mean training acc: 65.31%.
[ Thu Jan 26 23:40:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 23:40:21 2023 ] Eval epoch: 6
[ Thu Jan 26 23:43:15 2023 ] 	Mean test loss of 796 batches: 1.3531344326297243.
[ Thu Jan 26 23:43:15 2023 ] 	Top1: 60.51%
[ Thu Jan 26 23:43:16 2023 ] 	Top5: 89.63%
[ Thu Jan 26 23:43:16 2023 ] Training epoch: 7
[ Thu Jan 26 23:53:17 2023 ] 	Mean training loss: 1.0915.  Mean training acc: 67.66%.
[ Thu Jan 26 23:53:17 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jan 26 23:53:17 2023 ] Eval epoch: 7
[ Thu Jan 26 23:56:18 2023 ] 	Mean test loss of 796 batches: 1.4581146899928998.
[ Thu Jan 26 23:56:18 2023 ] 	Top1: 59.09%
[ Thu Jan 26 23:56:18 2023 ] 	Top5: 88.23%
[ Thu Jan 26 23:56:18 2023 ] Training epoch: 8
[ Fri Jan 27 00:05:39 2023 ] 	Mean training loss: 1.0341.  Mean training acc: 69.40%.
[ Fri Jan 27 00:05:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 00:05:39 2023 ] Eval epoch: 8
[ Fri Jan 27 00:08:13 2023 ] 	Mean test loss of 796 batches: 1.3735890929498265.
[ Fri Jan 27 00:08:14 2023 ] 	Top1: 60.60%
[ Fri Jan 27 00:08:14 2023 ] 	Top5: 88.97%
[ Fri Jan 27 00:08:14 2023 ] Training epoch: 9
[ Fri Jan 27 00:18:13 2023 ] 	Mean training loss: 0.9916.  Mean training acc: 70.53%.
[ Fri Jan 27 00:18:13 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 00:18:13 2023 ] Eval epoch: 9
[ Fri Jan 27 00:21:16 2023 ] 	Mean test loss of 796 batches: 1.3535317172806467.
[ Fri Jan 27 00:21:16 2023 ] 	Top1: 60.84%
[ Fri Jan 27 00:21:16 2023 ] 	Top5: 88.99%
[ Fri Jan 27 00:21:16 2023 ] Training epoch: 10
[ Fri Jan 27 00:30:45 2023 ] 	Mean training loss: 0.9606.  Mean training acc: 71.39%.
[ Fri Jan 27 00:30:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 00:30:45 2023 ] Eval epoch: 10
[ Fri Jan 27 00:33:34 2023 ] 	Mean test loss of 796 batches: 1.0648967475447821.
[ Fri Jan 27 00:33:34 2023 ] 	Top1: 69.21%
[ Fri Jan 27 00:33:35 2023 ] 	Top5: 92.53%
[ Fri Jan 27 00:33:35 2023 ] Training epoch: 11
[ Fri Jan 27 00:43:30 2023 ] 	Mean training loss: 0.9337.  Mean training acc: 72.16%.
[ Fri Jan 27 00:43:30 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 00:43:30 2023 ] Eval epoch: 11
[ Fri Jan 27 00:46:33 2023 ] 	Mean test loss of 796 batches: 1.181959480009786.
[ Fri Jan 27 00:46:34 2023 ] 	Top1: 65.16%
[ Fri Jan 27 00:46:34 2023 ] 	Top5: 91.54%
[ Fri Jan 27 00:46:34 2023 ] Training epoch: 12
[ Fri Jan 27 00:56:07 2023 ] 	Mean training loss: 0.9147.  Mean training acc: 72.80%.
[ Fri Jan 27 00:56:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 00:56:07 2023 ] Eval epoch: 12
[ Fri Jan 27 00:58:55 2023 ] 	Mean test loss of 796 batches: 1.1067298251255673.
[ Fri Jan 27 00:58:56 2023 ] 	Top1: 66.92%
[ Fri Jan 27 00:58:56 2023 ] 	Top5: 92.35%
[ Fri Jan 27 00:58:56 2023 ] Training epoch: 13
[ Fri Jan 27 01:08:48 2023 ] 	Mean training loss: 0.8851.  Mean training acc: 73.56%.
[ Fri Jan 27 01:08:48 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 01:08:48 2023 ] Eval epoch: 13
[ Fri Jan 27 01:11:51 2023 ] 	Mean test loss of 796 batches: 1.160423575820935.
[ Fri Jan 27 01:11:51 2023 ] 	Top1: 67.57%
[ Fri Jan 27 01:11:52 2023 ] 	Top5: 91.79%
[ Fri Jan 27 01:11:52 2023 ] Training epoch: 14
[ Fri Jan 27 01:21:31 2023 ] 	Mean training loss: 0.8745.  Mean training acc: 73.85%.
[ Fri Jan 27 01:21:31 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 01:21:31 2023 ] Eval epoch: 14
[ Fri Jan 27 01:24:21 2023 ] 	Mean test loss of 796 batches: 1.1968634761682706.
[ Fri Jan 27 01:24:22 2023 ] 	Top1: 65.70%
[ Fri Jan 27 01:24:22 2023 ] 	Top5: 91.76%
[ Fri Jan 27 01:24:22 2023 ] Training epoch: 15
[ Fri Jan 27 01:34:07 2023 ] 	Mean training loss: 0.8652.  Mean training acc: 74.32%.
[ Fri Jan 27 01:34:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 01:34:07 2023 ] Eval epoch: 15
[ Fri Jan 27 01:37:10 2023 ] 	Mean test loss of 796 batches: 1.2022370651139687.
[ Fri Jan 27 01:37:10 2023 ] 	Top1: 65.58%
[ Fri Jan 27 01:37:11 2023 ] 	Top5: 91.82%
[ Fri Jan 27 01:37:11 2023 ] Training epoch: 16
[ Fri Jan 27 01:46:56 2023 ] 	Mean training loss: 0.8512.  Mean training acc: 74.60%.
[ Fri Jan 27 01:46:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 01:46:56 2023 ] Eval epoch: 16
[ Fri Jan 27 01:49:45 2023 ] 	Mean test loss of 796 batches: 1.0917034939156105.
[ Fri Jan 27 01:49:45 2023 ] 	Top1: 67.76%
[ Fri Jan 27 01:49:46 2023 ] 	Top5: 92.41%
[ Fri Jan 27 01:49:46 2023 ] Training epoch: 17
[ Fri Jan 27 01:59:05 2023 ] 	Mean training loss: 0.8430.  Mean training acc: 74.81%.
[ Fri Jan 27 01:59:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 01:59:05 2023 ] Eval epoch: 17
[ Fri Jan 27 02:02:09 2023 ] 	Mean test loss of 796 batches: 1.3030651285495591.
[ Fri Jan 27 02:02:09 2023 ] 	Top1: 64.19%
[ Fri Jan 27 02:02:10 2023 ] 	Top5: 90.71%
[ Fri Jan 27 02:02:10 2023 ] Training epoch: 18
[ Fri Jan 27 02:12:02 2023 ] 	Mean training loss: 0.8293.  Mean training acc: 75.26%.
[ Fri Jan 27 02:12:02 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 02:12:02 2023 ] Eval epoch: 18
[ Fri Jan 27 02:14:53 2023 ] 	Mean test loss of 796 batches: 1.149493555477516.
[ Fri Jan 27 02:14:54 2023 ] 	Top1: 67.70%
[ Fri Jan 27 02:14:54 2023 ] 	Top5: 91.44%
[ Fri Jan 27 02:14:54 2023 ] Training epoch: 19
[ Fri Jan 27 02:24:23 2023 ] 	Mean training loss: 0.8151.  Mean training acc: 75.47%.
[ Fri Jan 27 02:24:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 02:24:23 2023 ] Eval epoch: 19
[ Fri Jan 27 02:27:26 2023 ] 	Mean test loss of 796 batches: 1.2257306922844906.
[ Fri Jan 27 02:27:27 2023 ] 	Top1: 65.26%
[ Fri Jan 27 02:27:27 2023 ] 	Top5: 91.40%
[ Fri Jan 27 02:27:28 2023 ] Training epoch: 20
[ Fri Jan 27 02:37:25 2023 ] 	Mean training loss: 0.8076.  Mean training acc: 75.94%.
[ Fri Jan 27 02:37:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 02:37:25 2023 ] Eval epoch: 20
[ Fri Jan 27 02:40:14 2023 ] 	Mean test loss of 796 batches: 1.371625041954182.
[ Fri Jan 27 02:40:15 2023 ] 	Top1: 63.38%
[ Fri Jan 27 02:40:15 2023 ] 	Top5: 88.43%
[ Fri Jan 27 02:40:15 2023 ] Training epoch: 21
[ Fri Jan 27 02:49:18 2023 ] 	Mean training loss: 0.7953.  Mean training acc: 76.14%.
[ Fri Jan 27 02:49:18 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 02:49:18 2023 ] Eval epoch: 21
[ Fri Jan 27 02:52:05 2023 ] 	Mean test loss of 796 batches: 1.1640388343352168.
[ Fri Jan 27 02:52:05 2023 ] 	Top1: 66.85%
[ Fri Jan 27 02:52:05 2023 ] 	Top5: 90.88%
[ Fri Jan 27 02:52:05 2023 ] Training epoch: 22
[ Fri Jan 27 03:00:32 2023 ] 	Mean training loss: 0.7898.  Mean training acc: 76.41%.
[ Fri Jan 27 03:00:32 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:00:32 2023 ] Eval epoch: 22
[ Fri Jan 27 03:03:06 2023 ] 	Mean test loss of 796 batches: 1.1171563802352502.
[ Fri Jan 27 03:03:07 2023 ] 	Top1: 67.95%
[ Fri Jan 27 03:03:07 2023 ] 	Top5: 91.98%
[ Fri Jan 27 03:03:07 2023 ] Training epoch: 23
[ Fri Jan 27 03:11:20 2023 ] 	Mean training loss: 0.7894.  Mean training acc: 76.42%.
[ Fri Jan 27 03:11:20 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:11:20 2023 ] Eval epoch: 23
[ Fri Jan 27 03:13:56 2023 ] 	Mean test loss of 796 batches: 1.2168122412421596.
[ Fri Jan 27 03:13:57 2023 ] 	Top1: 65.66%
[ Fri Jan 27 03:13:57 2023 ] 	Top5: 90.64%
[ Fri Jan 27 03:13:57 2023 ] Training epoch: 24
[ Fri Jan 27 03:22:11 2023 ] 	Mean training loss: 0.7811.  Mean training acc: 76.75%.
[ Fri Jan 27 03:22:11 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:22:11 2023 ] Eval epoch: 24
[ Fri Jan 27 03:24:47 2023 ] 	Mean test loss of 796 batches: 1.4149668282599905.
[ Fri Jan 27 03:24:48 2023 ] 	Top1: 61.76%
[ Fri Jan 27 03:24:48 2023 ] 	Top5: 89.34%
[ Fri Jan 27 03:24:48 2023 ] Training epoch: 25
[ Fri Jan 27 03:32:59 2023 ] 	Mean training loss: 0.7780.  Mean training acc: 76.67%.
[ Fri Jan 27 03:32:59 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:33:00 2023 ] Eval epoch: 25
[ Fri Jan 27 03:35:32 2023 ] 	Mean test loss of 796 batches: 1.051749524047327.
[ Fri Jan 27 03:35:32 2023 ] 	Top1: 69.16%
[ Fri Jan 27 03:35:33 2023 ] 	Top5: 92.79%
[ Fri Jan 27 03:35:33 2023 ] Training epoch: 26
[ Fri Jan 27 03:43:46 2023 ] 	Mean training loss: 0.7723.  Mean training acc: 76.76%.
[ Fri Jan 27 03:43:46 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:43:46 2023 ] Eval epoch: 26
[ Fri Jan 27 03:46:20 2023 ] 	Mean test loss of 796 batches: 1.0468958085356046.
[ Fri Jan 27 03:46:20 2023 ] 	Top1: 70.08%
[ Fri Jan 27 03:46:21 2023 ] 	Top5: 92.76%
[ Fri Jan 27 03:46:21 2023 ] Training epoch: 27
[ Fri Jan 27 03:54:33 2023 ] 	Mean training loss: 0.7706.  Mean training acc: 77.04%.
[ Fri Jan 27 03:54:33 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 03:54:33 2023 ] Eval epoch: 27
[ Fri Jan 27 03:57:07 2023 ] 	Mean test loss of 796 batches: 1.294176002805257.
[ Fri Jan 27 03:57:07 2023 ] 	Top1: 64.08%
[ Fri Jan 27 03:57:07 2023 ] 	Top5: 90.50%
[ Fri Jan 27 03:57:07 2023 ] Training epoch: 28
[ Fri Jan 27 04:04:58 2023 ] 	Mean training loss: 0.7536.  Mean training acc: 77.36%.
[ Fri Jan 27 04:04:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:04:58 2023 ] Eval epoch: 28
[ Fri Jan 27 04:07:25 2023 ] 	Mean test loss of 796 batches: 1.186568498948411.
[ Fri Jan 27 04:07:25 2023 ] 	Top1: 67.87%
[ Fri Jan 27 04:07:26 2023 ] 	Top5: 91.87%
[ Fri Jan 27 04:07:26 2023 ] Training epoch: 29
[ Fri Jan 27 04:15:29 2023 ] 	Mean training loss: 0.7576.  Mean training acc: 77.42%.
[ Fri Jan 27 04:15:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:15:29 2023 ] Eval epoch: 29
[ Fri Jan 27 04:18:04 2023 ] 	Mean test loss of 796 batches: 1.206957798694546.
[ Fri Jan 27 04:18:04 2023 ] 	Top1: 65.65%
[ Fri Jan 27 04:18:04 2023 ] 	Top5: 91.00%
[ Fri Jan 27 04:18:05 2023 ] Training epoch: 30
[ Fri Jan 27 04:25:53 2023 ] 	Mean training loss: 0.7545.  Mean training acc: 77.41%.
[ Fri Jan 27 04:25:53 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:25:53 2023 ] Eval epoch: 30
[ Fri Jan 27 04:28:27 2023 ] 	Mean test loss of 796 batches: 0.952713115243756.
[ Fri Jan 27 04:28:27 2023 ] 	Top1: 71.58%
[ Fri Jan 27 04:28:28 2023 ] 	Top5: 93.76%
[ Fri Jan 27 04:28:28 2023 ] Training epoch: 31
[ Fri Jan 27 04:36:38 2023 ] 	Mean training loss: 0.7457.  Mean training acc: 77.67%.
[ Fri Jan 27 04:36:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:36:38 2023 ] Eval epoch: 31
[ Fri Jan 27 04:39:12 2023 ] 	Mean test loss of 796 batches: 1.1004148234224798.
[ Fri Jan 27 04:39:12 2023 ] 	Top1: 69.13%
[ Fri Jan 27 04:39:12 2023 ] 	Top5: 92.49%
[ Fri Jan 27 04:39:13 2023 ] Training epoch: 32
[ Fri Jan 27 04:47:25 2023 ] 	Mean training loss: 0.7521.  Mean training acc: 77.42%.
[ Fri Jan 27 04:47:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:47:25 2023 ] Eval epoch: 32
[ Fri Jan 27 04:49:58 2023 ] 	Mean test loss of 796 batches: 1.1444238030056857.
[ Fri Jan 27 04:49:59 2023 ] 	Top1: 67.16%
[ Fri Jan 27 04:49:59 2023 ] 	Top5: 92.02%
[ Fri Jan 27 04:49:59 2023 ] Training epoch: 33
[ Fri Jan 27 04:58:13 2023 ] 	Mean training loss: 0.7446.  Mean training acc: 77.87%.
[ Fri Jan 27 04:58:13 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 04:58:13 2023 ] Eval epoch: 33
[ Fri Jan 27 05:00:46 2023 ] 	Mean test loss of 796 batches: 1.0232698718207565.
[ Fri Jan 27 05:00:47 2023 ] 	Top1: 70.52%
[ Fri Jan 27 05:00:47 2023 ] 	Top5: 92.80%
[ Fri Jan 27 05:00:47 2023 ] Training epoch: 34
[ Fri Jan 27 05:09:01 2023 ] 	Mean training loss: 0.7483.  Mean training acc: 77.39%.
[ Fri Jan 27 05:09:01 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 05:09:01 2023 ] Eval epoch: 34
[ Fri Jan 27 05:11:35 2023 ] 	Mean test loss of 796 batches: 1.0311125974783946.
[ Fri Jan 27 05:11:35 2023 ] 	Top1: 69.95%
[ Fri Jan 27 05:11:36 2023 ] 	Top5: 92.55%
[ Fri Jan 27 05:11:36 2023 ] Training epoch: 35
[ Fri Jan 27 05:19:26 2023 ] 	Mean training loss: 0.7378.  Mean training acc: 77.94%.
[ Fri Jan 27 05:19:26 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 05:19:26 2023 ] Eval epoch: 35
[ Fri Jan 27 05:21:59 2023 ] 	Mean test loss of 796 batches: 1.121053206710959.
[ Fri Jan 27 05:21:59 2023 ] 	Top1: 67.87%
[ Fri Jan 27 05:22:00 2023 ] 	Top5: 92.00%
[ Fri Jan 27 05:22:00 2023 ] Training epoch: 36
[ Fri Jan 27 05:30:11 2023 ] 	Mean training loss: 0.4069.  Mean training acc: 87.97%.
[ Fri Jan 27 05:30:11 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 05:30:11 2023 ] Eval epoch: 36
[ Fri Jan 27 05:32:46 2023 ] 	Mean test loss of 796 batches: 0.5625052109978457.
[ Fri Jan 27 05:32:46 2023 ] 	Top1: 83.00%
[ Fri Jan 27 05:32:47 2023 ] 	Top5: 96.95%
[ Fri Jan 27 05:32:47 2023 ] Training epoch: 37
[ Fri Jan 27 05:40:58 2023 ] 	Mean training loss: 0.3139.  Mean training acc: 90.58%.
[ Fri Jan 27 05:40:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 05:40:58 2023 ] Eval epoch: 37
[ Fri Jan 27 05:43:32 2023 ] 	Mean test loss of 796 batches: 0.5478291762009937.
[ Fri Jan 27 05:43:33 2023 ] 	Top1: 83.38%
[ Fri Jan 27 05:43:33 2023 ] 	Top5: 97.13%
[ Fri Jan 27 05:43:33 2023 ] Training epoch: 38
[ Fri Jan 27 05:51:46 2023 ] 	Mean training loss: 0.2821.  Mean training acc: 91.60%.
[ Fri Jan 27 05:51:46 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 05:51:46 2023 ] Eval epoch: 38
[ Fri Jan 27 05:54:20 2023 ] 	Mean test loss of 796 batches: 0.5466720082577149.
[ Fri Jan 27 05:54:20 2023 ] 	Top1: 83.44%
[ Fri Jan 27 05:54:21 2023 ] 	Top5: 97.14%
[ Fri Jan 27 05:54:21 2023 ] Training epoch: 39
[ Fri Jan 27 06:02:36 2023 ] 	Mean training loss: 0.2517.  Mean training acc: 92.57%.
[ Fri Jan 27 06:02:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 06:02:36 2023 ] Eval epoch: 39
[ Fri Jan 27 06:05:10 2023 ] 	Mean test loss of 796 batches: 0.5592825441579123.
[ Fri Jan 27 06:05:10 2023 ] 	Top1: 83.23%
[ Fri Jan 27 06:05:10 2023 ] 	Top5: 97.06%
[ Fri Jan 27 06:05:10 2023 ] Training epoch: 40
[ Fri Jan 27 06:13:21 2023 ] 	Mean training loss: 0.2285.  Mean training acc: 93.48%.
[ Fri Jan 27 06:13:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 06:13:21 2023 ] Eval epoch: 40
[ Fri Jan 27 06:15:54 2023 ] 	Mean test loss of 796 batches: 0.5581358928121065.
[ Fri Jan 27 06:15:54 2023 ] 	Top1: 83.42%
[ Fri Jan 27 06:15:55 2023 ] 	Top5: 96.98%
[ Fri Jan 27 06:15:55 2023 ] Training epoch: 41
[ Fri Jan 27 06:24:07 2023 ] 	Mean training loss: 0.2146.  Mean training acc: 93.83%.
[ Fri Jan 27 06:24:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 06:24:07 2023 ] Eval epoch: 41
[ Fri Jan 27 06:26:41 2023 ] 	Mean test loss of 796 batches: 0.5648931589904218.
[ Fri Jan 27 06:26:44 2023 ] 	Top1: 83.46%
[ Fri Jan 27 06:26:44 2023 ] 	Top5: 96.86%
[ Fri Jan 27 06:26:46 2023 ] Training epoch: 42
[ Fri Jan 27 06:34:23 2023 ] 	Mean training loss: 0.1972.  Mean training acc: 94.46%.
[ Fri Jan 27 06:34:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 06:34:24 2023 ] Eval epoch: 42
[ Fri Jan 27 06:36:56 2023 ] 	Mean test loss of 796 batches: 0.5775530338568154.
[ Fri Jan 27 06:36:56 2023 ] 	Top1: 83.26%
[ Fri Jan 27 06:36:57 2023 ] 	Top5: 96.86%
[ Fri Jan 27 06:36:57 2023 ] Training epoch: 43
[ Fri Jan 27 06:45:11 2023 ] 	Mean training loss: 0.1838.  Mean training acc: 94.90%.
[ Fri Jan 27 06:45:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 06:45:22 2023 ] Eval epoch: 43
[ Fri Jan 27 06:47:57 2023 ] 	Mean test loss of 796 batches: 0.599652765580832.
[ Fri Jan 27 06:47:57 2023 ] 	Top1: 82.83%
[ Fri Jan 27 06:47:57 2023 ] 	Top5: 96.69%
[ Fri Jan 27 06:47:58 2023 ] Training epoch: 44
[ Fri Jan 27 07:03:13 2023 ] 	Mean training loss: 0.1712.  Mean training acc: 95.32%.
[ Fri Jan 27 07:03:13 2023 ] 	Time consumption: [Data]01%, [Network]50%
[ Fri Jan 27 07:06:58 2023 ] Eval epoch: 44
[ Fri Jan 27 07:09:35 2023 ] 	Mean test loss of 796 batches: 0.6001545623805954.
[ Fri Jan 27 07:09:38 2023 ] 	Top1: 83.08%
[ Fri Jan 27 07:09:38 2023 ] 	Top5: 96.70%
[ Fri Jan 27 07:09:39 2023 ] Training epoch: 45
[ Fri Jan 27 07:17:46 2023 ] 	Mean training loss: 0.1658.  Mean training acc: 95.47%.
[ Fri Jan 27 07:17:51 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Fri Jan 27 07:17:51 2023 ] Eval epoch: 45
[ Fri Jan 27 07:20:19 2023 ] 	Mean test loss of 796 batches: 0.6263572739802263.
[ Fri Jan 27 07:20:26 2023 ] 	Top1: 82.21%
[ Fri Jan 27 07:20:26 2023 ] 	Top5: 96.51%
[ Fri Jan 27 07:20:27 2023 ] Training epoch: 46
[ Fri Jan 27 07:28:35 2023 ] 	Mean training loss: 0.1594.  Mean training acc: 95.65%.
[ Fri Jan 27 07:28:40 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 07:28:40 2023 ] Eval epoch: 46
[ Fri Jan 27 07:31:08 2023 ] 	Mean test loss of 796 batches: 0.6378908498802377.
[ Fri Jan 27 07:31:08 2023 ] 	Top1: 82.08%
[ Fri Jan 27 07:31:09 2023 ] 	Top5: 96.33%
[ Fri Jan 27 07:31:17 2023 ] Training epoch: 47
[ Fri Jan 27 07:39:33 2023 ] 	Mean training loss: 0.1536.  Mean training acc: 95.98%.
[ Fri Jan 27 07:39:33 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Fri Jan 27 07:39:33 2023 ] Eval epoch: 47
[ Fri Jan 27 07:42:01 2023 ] 	Mean test loss of 796 batches: 0.6183780454117899.
[ Fri Jan 27 07:42:02 2023 ] 	Top1: 82.76%
[ Fri Jan 27 07:42:02 2023 ] 	Top5: 96.50%
[ Fri Jan 27 07:42:16 2023 ] Training epoch: 48
[ Fri Jan 27 07:49:32 2023 ] 	Mean training loss: 0.1485.  Mean training acc: 96.10%.
[ Fri Jan 27 07:49:32 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 07:49:32 2023 ] Eval epoch: 48
[ Fri Jan 27 07:52:10 2023 ] 	Mean test loss of 796 batches: 0.6616355603251924.
[ Fri Jan 27 07:52:10 2023 ] 	Top1: 81.66%
[ Fri Jan 27 07:52:11 2023 ] 	Top5: 96.20%
[ Fri Jan 27 07:52:11 2023 ] Training epoch: 49
[ Fri Jan 27 08:00:22 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.13%.
[ Fri Jan 27 08:00:22 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 08:00:22 2023 ] Eval epoch: 49
[ Fri Jan 27 08:02:54 2023 ] 	Mean test loss of 796 batches: 0.6640914808584368.
[ Fri Jan 27 08:02:54 2023 ] 	Top1: 81.87%
[ Fri Jan 27 08:02:55 2023 ] 	Top5: 96.29%
[ Fri Jan 27 08:02:55 2023 ] Training epoch: 50
[ Fri Jan 27 08:11:05 2023 ] 	Mean training loss: 0.1458.  Mean training acc: 96.11%.
[ Fri Jan 27 08:11:05 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 08:11:05 2023 ] Eval epoch: 50
[ Fri Jan 27 08:13:35 2023 ] 	Mean test loss of 796 batches: 0.6618064904501241.
[ Fri Jan 27 08:13:35 2023 ] 	Top1: 82.22%
[ Fri Jan 27 08:13:35 2023 ] 	Top5: 96.25%
[ Fri Jan 27 08:13:39 2023 ] Training epoch: 51
[ Fri Jan 27 08:21:46 2023 ] 	Mean training loss: 0.1454.  Mean training acc: 96.14%.
[ Fri Jan 27 08:21:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 27 08:21:57 2023 ] Eval epoch: 51
[ Fri Jan 27 08:24:32 2023 ] 	Mean test loss of 796 batches: 0.7732500670449668.
[ Fri Jan 27 08:24:32 2023 ] 	Top1: 79.27%
[ Fri Jan 27 08:24:33 2023 ] 	Top5: 94.90%
[ Fri Jan 27 08:24:38 2023 ] Training epoch: 52
[ Fri Jan 27 08:32:38 2023 ] 	Mean training loss: 0.1446.  Mean training acc: 96.16%.
[ Fri Jan 27 08:32:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 08:32:45 2023 ] Eval epoch: 52
[ Fri Jan 27 08:35:20 2023 ] 	Mean test loss of 796 batches: 0.6751555896097392.
[ Fri Jan 27 08:35:20 2023 ] 	Top1: 81.41%
[ Fri Jan 27 08:35:20 2023 ] 	Top5: 96.09%
[ Fri Jan 27 08:35:21 2023 ] Training epoch: 53
[ Fri Jan 27 08:43:04 2023 ] 	Mean training loss: 0.1463.  Mean training acc: 96.14%.
[ Fri Jan 27 08:43:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 08:43:26 2023 ] Eval epoch: 53
[ Fri Jan 27 08:45:55 2023 ] 	Mean test loss of 796 batches: 0.7188130744157275.
[ Fri Jan 27 08:45:56 2023 ] 	Top1: 80.85%
[ Fri Jan 27 08:45:56 2023 ] 	Top5: 95.75%
[ Fri Jan 27 08:46:46 2023 ] Training epoch: 54
[ Fri Jan 27 08:54:05 2023 ] 	Mean training loss: 0.1460.  Mean training acc: 96.17%.
[ Fri Jan 27 08:54:14 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jan 27 08:54:25 2023 ] Eval epoch: 54
[ Fri Jan 27 08:57:01 2023 ] 	Mean test loss of 796 batches: 0.6866678628022197.
[ Fri Jan 27 08:57:05 2023 ] 	Top1: 81.07%
[ Fri Jan 27 08:57:05 2023 ] 	Top5: 96.13%
[ Fri Jan 27 08:57:05 2023 ] Training epoch: 55
[ Fri Jan 27 09:05:07 2023 ] 	Mean training loss: 0.1433.  Mean training acc: 96.22%.
[ Fri Jan 27 09:05:07 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 09:05:07 2023 ] Eval epoch: 55
[ Fri Jan 27 09:07:42 2023 ] 	Mean test loss of 796 batches: 0.6650750864503072.
[ Fri Jan 27 09:07:43 2023 ] 	Top1: 81.81%
[ Fri Jan 27 09:07:43 2023 ] 	Top5: 96.17%
[ Fri Jan 27 09:07:44 2023 ] Training epoch: 56
[ Fri Jan 27 09:15:55 2023 ] 	Mean training loss: 0.0786.  Mean training acc: 98.39%.
[ Fri Jan 27 09:15:55 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 27 09:15:55 2023 ] Eval epoch: 56
[ Fri Jan 27 09:18:31 2023 ] 	Mean test loss of 796 batches: 0.5855109420974725.
[ Fri Jan 27 09:18:31 2023 ] 	Top1: 84.11%
[ Fri Jan 27 09:18:32 2023 ] 	Top5: 96.73%
[ Fri Jan 27 09:18:32 2023 ] Training epoch: 57
[ Fri Jan 27 09:26:44 2023 ] 	Mean training loss: 0.0568.  Mean training acc: 99.02%.
[ Fri Jan 27 09:26:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 09:26:45 2023 ] Eval epoch: 57
[ Fri Jan 27 09:29:17 2023 ] 	Mean test loss of 796 batches: 0.582394056663329.
[ Fri Jan 27 09:29:17 2023 ] 	Top1: 84.28%
[ Fri Jan 27 09:29:18 2023 ] 	Top5: 96.79%
[ Fri Jan 27 09:29:18 2023 ] Training epoch: 58
[ Fri Jan 27 09:37:29 2023 ] 	Mean training loss: 0.0485.  Mean training acc: 99.24%.
[ Fri Jan 27 09:37:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 09:37:29 2023 ] Eval epoch: 58
[ Fri Jan 27 09:40:03 2023 ] 	Mean test loss of 796 batches: 0.5917735319706289.
[ Fri Jan 27 09:40:04 2023 ] 	Top1: 84.19%
[ Fri Jan 27 09:40:04 2023 ] 	Top5: 96.68%
[ Fri Jan 27 09:40:04 2023 ] Training epoch: 59
[ Fri Jan 27 09:48:16 2023 ] 	Mean training loss: 0.0433.  Mean training acc: 99.40%.
[ Fri Jan 27 09:48:16 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 09:48:16 2023 ] Eval epoch: 59
[ Fri Jan 27 09:50:52 2023 ] 	Mean test loss of 796 batches: 0.5893565793685502.
[ Fri Jan 27 09:50:52 2023 ] 	Top1: 84.28%
[ Fri Jan 27 09:50:53 2023 ] 	Top5: 96.76%
[ Fri Jan 27 09:50:53 2023 ] Training epoch: 60
[ Fri Jan 27 09:59:03 2023 ] 	Mean training loss: 0.0403.  Mean training acc: 99.48%.
[ Fri Jan 27 09:59:06 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 27 09:59:06 2023 ] Eval epoch: 60
[ Fri Jan 27 10:01:41 2023 ] 	Mean test loss of 796 batches: 0.5892927675185042.
[ Fri Jan 27 10:01:43 2023 ] 	Top1: 84.39%
[ Fri Jan 27 10:01:43 2023 ] 	Top5: 96.76%
[ Fri Jan 27 10:01:44 2023 ] Training epoch: 61
[ Fri Jan 27 10:09:45 2023 ] 	Mean training loss: 0.0387.  Mean training acc: 99.50%.
[ Fri Jan 27 10:09:45 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jan 27 10:09:46 2023 ] Eval epoch: 61
[ Fri Jan 27 10:12:21 2023 ] 	Mean test loss of 796 batches: 0.5865686151419004.
[ Fri Jan 27 10:12:22 2023 ] 	Top1: 84.40%
[ Fri Jan 27 10:12:22 2023 ] 	Top5: 96.72%
[ Fri Jan 27 10:12:26 2023 ] Training epoch: 62
[ Fri Jan 27 10:20:15 2023 ] 	Mean training loss: 0.0372.  Mean training acc: 99.55%.
[ Fri Jan 27 10:20:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 10:20:26 2023 ] Eval epoch: 62
[ Fri Jan 27 10:22:58 2023 ] 	Mean test loss of 796 batches: 0.5964858324814531.
[ Fri Jan 27 10:22:58 2023 ] 	Top1: 84.16%
[ Fri Jan 27 10:22:59 2023 ] 	Top5: 96.68%
[ Fri Jan 27 10:23:01 2023 ] Training epoch: 63
[ Fri Jan 27 10:31:46 2023 ] 	Mean training loss: 0.0345.  Mean training acc: 99.58%.
[ Fri Jan 27 10:31:46 2023 ] 	Time consumption: [Data]01%, [Network]90%
[ Fri Jan 27 10:31:46 2023 ] Eval epoch: 63
[ Fri Jan 27 10:34:19 2023 ] 	Mean test loss of 796 batches: 0.5893360460457865.
[ Fri Jan 27 10:34:20 2023 ] 	Top1: 84.28%
[ Fri Jan 27 10:34:20 2023 ] 	Top5: 96.73%
[ Fri Jan 27 10:34:20 2023 ] Training epoch: 64
[ Fri Jan 27 10:42:35 2023 ] 	Mean training loss: 0.0333.  Mean training acc: 99.62%.
[ Fri Jan 27 10:42:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 10:42:35 2023 ] Eval epoch: 64
[ Fri Jan 27 10:45:08 2023 ] 	Mean test loss of 796 batches: 0.5891450071782248.
[ Fri Jan 27 10:45:08 2023 ] 	Top1: 84.42%
[ Fri Jan 27 10:45:08 2023 ] 	Top5: 96.78%
[ Fri Jan 27 10:45:08 2023 ] Training epoch: 65
[ Fri Jan 27 10:52:53 2023 ] 	Mean training loss: 0.0332.  Mean training acc: 99.61%.
[ Fri Jan 27 10:52:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Fri Jan 27 10:53:00 2023 ] Eval epoch: 65
[ Fri Jan 27 10:55:27 2023 ] 	Mean test loss of 796 batches: 0.5869877605076561.
[ Fri Jan 27 10:55:28 2023 ] 	Top1: 84.44%
[ Fri Jan 27 10:55:29 2023 ] 	Top5: 96.79%
[ Fri Jan 27 10:58:00 2023 ] Best accuracy: 0.8443999292994756
[ Fri Jan 27 10:58:00 2023 ] Epoch number: 65
[ Fri Jan 27 10:58:00 2023 ] Model name: work_dir/csub/local_SHT_bone_BL
[ Fri Jan 27 10:58:00 2023 ] Model total number of params: 2141090
[ Fri Jan 27 10:58:00 2023 ] Weight decay: 0.0004
[ Fri Jan 27 10:58:00 2023 ] Base LR: 0.1
[ Fri Jan 27 10:58:00 2023 ] Batch Size: 64
[ Fri Jan 27 10:58:00 2023 ] Test Batch Size: 64
[ Fri Jan 27 10:58:00 2023 ] seed: 1
