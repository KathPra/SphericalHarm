[ Wed Nov  9 10:27:14 2022 ] using warm up, epoch: 5
[ Wed Nov  9 10:29:48 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHTg_bone_BL', 'model_saved_name': 'work_dir/ntu120/csub/local_SHTg_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Nov  9 10:29:48 2022 ] # Parameters: 2141090
[ Wed Nov  9 10:29:48 2022 ] Training epoch: 1
[ Wed Nov  9 10:39:26 2022 ] 	Mean training loss: 3.4713.  Mean training acc: 16.53%.
[ Wed Nov  9 10:39:26 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 10:39:26 2022 ] Eval epoch: 1
[ Wed Nov  9 10:44:02 2022 ] 	Mean test loss of 796 batches: 2.9610654172585837.
[ Wed Nov  9 10:44:03 2022 ] 	Top1: 21.35%
[ Wed Nov  9 10:44:04 2022 ] 	Top5: 52.92%
[ Wed Nov  9 10:44:05 2022 ] Training epoch: 2
[ Wed Nov  9 10:53:31 2022 ] 	Mean training loss: 2.2759.  Mean training acc: 38.23%.
[ Wed Nov  9 10:53:31 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 10:53:31 2022 ] Eval epoch: 2
[ Wed Nov  9 10:58:09 2022 ] 	Mean test loss of 796 batches: 2.2134713764166714.
[ Wed Nov  9 10:58:10 2022 ] 	Top1: 39.37%
[ Wed Nov  9 10:58:12 2022 ] 	Top5: 74.57%
[ Wed Nov  9 10:58:12 2022 ] Training epoch: 3
[ Wed Nov  9 11:07:39 2022 ] 	Mean training loss: 1.7170.  Mean training acc: 50.99%.
[ Wed Nov  9 11:07:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:07:39 2022 ] Eval epoch: 3
[ Wed Nov  9 11:12:06 2022 ] 	Mean test loss of 796 batches: 2.305763412061049.
[ Wed Nov  9 11:12:08 2022 ] 	Top1: 39.05%
[ Wed Nov  9 11:12:09 2022 ] 	Top5: 76.22%
[ Wed Nov  9 11:12:09 2022 ] Training epoch: 4
[ Wed Nov  9 11:21:29 2022 ] 	Mean training loss: 1.4734.  Mean training acc: 57.28%.
[ Wed Nov  9 11:21:29 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:21:29 2022 ] Eval epoch: 4
[ Wed Nov  9 11:26:02 2022 ] 	Mean test loss of 796 batches: 1.7672714260804594.
[ Wed Nov  9 11:26:03 2022 ] 	Top1: 51.48%
[ Wed Nov  9 11:26:04 2022 ] 	Top5: 82.93%
[ Wed Nov  9 11:26:05 2022 ] Training epoch: 5
[ Wed Nov  9 11:35:18 2022 ] 	Mean training loss: 1.3224.  Mean training acc: 61.35%.
[ Wed Nov  9 11:35:18 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:35:18 2022 ] Eval epoch: 5
[ Wed Nov  9 11:39:53 2022 ] 	Mean test loss of 796 batches: 1.5633974678851852.
[ Wed Nov  9 11:39:54 2022 ] 	Top1: 55.05%
[ Wed Nov  9 11:39:54 2022 ] 	Top5: 86.20%
[ Wed Nov  9 11:39:55 2022 ] Training epoch: 6
[ Wed Nov  9 11:49:09 2022 ] 	Mean training loss: 1.1661.  Mean training acc: 65.80%.
[ Wed Nov  9 11:49:09 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 11:49:09 2022 ] Eval epoch: 6
[ Wed Nov  9 11:53:42 2022 ] 	Mean test loss of 796 batches: 1.2375709158391808.
[ Wed Nov  9 11:53:43 2022 ] 	Top1: 63.29%
[ Wed Nov  9 11:53:44 2022 ] 	Top5: 90.93%
[ Wed Nov  9 11:53:44 2022 ] Training epoch: 7
[ Wed Nov  9 12:02:51 2022 ] 	Mean training loss: 1.0867.  Mean training acc: 67.98%.
[ Wed Nov  9 12:02:51 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:02:51 2022 ] Eval epoch: 7
[ Wed Nov  9 12:07:18 2022 ] 	Mean test loss of 796 batches: 1.3266781511618264.
[ Wed Nov  9 12:07:20 2022 ] 	Top1: 60.47%
[ Wed Nov  9 12:07:21 2022 ] 	Top5: 90.24%
[ Wed Nov  9 12:07:21 2022 ] Training epoch: 8
[ Wed Nov  9 12:16:39 2022 ] 	Mean training loss: 1.0264.  Mean training acc: 69.66%.
[ Wed Nov  9 12:16:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:16:39 2022 ] Eval epoch: 8
[ Wed Nov  9 12:21:11 2022 ] 	Mean test loss of 796 batches: 1.1928049709329653.
[ Wed Nov  9 12:21:12 2022 ] 	Top1: 64.91%
[ Wed Nov  9 12:21:13 2022 ] 	Top5: 90.85%
[ Wed Nov  9 12:21:13 2022 ] Training epoch: 9
[ Wed Nov  9 12:30:29 2022 ] 	Mean training loss: 0.9858.  Mean training acc: 70.60%.
[ Wed Nov  9 12:30:29 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:30:29 2022 ] Eval epoch: 9
[ Wed Nov  9 12:35:02 2022 ] 	Mean test loss of 796 batches: 1.1834447828669046.
[ Wed Nov  9 12:35:03 2022 ] 	Top1: 65.58%
[ Wed Nov  9 12:35:05 2022 ] 	Top5: 90.73%
[ Wed Nov  9 12:35:05 2022 ] Training epoch: 10
[ Wed Nov  9 12:44:16 2022 ] 	Mean training loss: 0.9574.  Mean training acc: 71.51%.
[ Wed Nov  9 12:44:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:44:16 2022 ] Eval epoch: 10
[ Wed Nov  9 12:48:38 2022 ] 	Mean test loss of 796 batches: 1.230976102452482.
[ Wed Nov  9 12:48:39 2022 ] 	Top1: 64.36%
[ Wed Nov  9 12:48:40 2022 ] 	Top5: 91.02%
[ Wed Nov  9 12:48:40 2022 ] Training epoch: 11
[ Wed Nov  9 12:57:55 2022 ] 	Mean training loss: 0.9327.  Mean training acc: 72.04%.
[ Wed Nov  9 12:57:55 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 12:57:55 2022 ] Eval epoch: 11
[ Wed Nov  9 13:02:32 2022 ] 	Mean test loss of 796 batches: 1.1395524259113787.
[ Wed Nov  9 13:02:33 2022 ] 	Top1: 66.21%
[ Wed Nov  9 13:02:34 2022 ] 	Top5: 91.35%
[ Wed Nov  9 13:02:34 2022 ] Training epoch: 12
[ Wed Nov  9 13:11:39 2022 ] 	Mean training loss: 0.9114.  Mean training acc: 72.91%.
[ Wed Nov  9 13:11:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:11:39 2022 ] Eval epoch: 12
[ Wed Nov  9 13:16:10 2022 ] 	Mean test loss of 796 batches: 1.1361244801600374.
[ Wed Nov  9 13:16:11 2022 ] 	Top1: 66.35%
[ Wed Nov  9 13:16:13 2022 ] 	Top5: 91.90%
[ Wed Nov  9 13:16:13 2022 ] Training epoch: 13
[ Wed Nov  9 13:25:27 2022 ] 	Mean training loss: 0.8808.  Mean training acc: 73.64%.
[ Wed Nov  9 13:25:27 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:25:27 2022 ] Eval epoch: 13
[ Wed Nov  9 13:30:09 2022 ] 	Mean test loss of 796 batches: 1.216088928357141.
[ Wed Nov  9 13:30:11 2022 ] 	Top1: 65.47%
[ Wed Nov  9 13:30:12 2022 ] 	Top5: 91.00%
[ Wed Nov  9 13:30:12 2022 ] Training epoch: 14
[ Wed Nov  9 13:39:18 2022 ] 	Mean training loss: 0.8727.  Mean training acc: 73.96%.
[ Wed Nov  9 13:39:18 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:39:18 2022 ] Eval epoch: 14
[ Wed Nov  9 13:43:53 2022 ] 	Mean test loss of 796 batches: 1.158270927791919.
[ Wed Nov  9 13:43:54 2022 ] 	Top1: 67.06%
[ Wed Nov  9 13:43:56 2022 ] 	Top5: 92.30%
[ Wed Nov  9 13:43:56 2022 ] Training epoch: 15
[ Wed Nov  9 13:52:59 2022 ] 	Mean training loss: 0.8664.  Mean training acc: 74.26%.
[ Wed Nov  9 13:52:59 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 13:52:59 2022 ] Eval epoch: 15
[ Wed Nov  9 13:57:34 2022 ] 	Mean test loss of 796 batches: 1.0725868985281517.
[ Wed Nov  9 13:57:35 2022 ] 	Top1: 68.56%
[ Wed Nov  9 13:57:37 2022 ] 	Top5: 92.78%
[ Wed Nov  9 13:57:37 2022 ] Training epoch: 16
[ Wed Nov  9 14:06:45 2022 ] 	Mean training loss: 0.8463.  Mean training acc: 74.58%.
[ Wed Nov  9 14:06:45 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:06:45 2022 ] Eval epoch: 16
[ Wed Nov  9 14:11:16 2022 ] 	Mean test loss of 796 batches: 1.0733177892152388.
[ Wed Nov  9 14:11:17 2022 ] 	Top1: 68.68%
[ Wed Nov  9 14:11:18 2022 ] 	Top5: 92.63%
[ Wed Nov  9 14:11:19 2022 ] Training epoch: 17
[ Wed Nov  9 14:20:24 2022 ] 	Mean training loss: 0.8355.  Mean training acc: 74.94%.
[ Wed Nov  9 14:20:24 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:20:24 2022 ] Eval epoch: 17
[ Wed Nov  9 14:25:01 2022 ] 	Mean test loss of 796 batches: 1.3017915789056662.
[ Wed Nov  9 14:25:03 2022 ] 	Top1: 64.20%
[ Wed Nov  9 14:25:04 2022 ] 	Top5: 89.31%
[ Wed Nov  9 14:25:04 2022 ] Training epoch: 18
[ Wed Nov  9 14:34:11 2022 ] 	Mean training loss: 0.8324.  Mean training acc: 75.30%.
[ Wed Nov  9 14:34:11 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:34:11 2022 ] Eval epoch: 18
[ Wed Nov  9 14:38:51 2022 ] 	Mean test loss of 796 batches: 1.127905133419001.
[ Wed Nov  9 14:38:53 2022 ] 	Top1: 67.86%
[ Wed Nov  9 14:38:53 2022 ] 	Top5: 90.94%
[ Wed Nov  9 14:38:54 2022 ] Training epoch: 19
[ Wed Nov  9 14:47:55 2022 ] 	Mean training loss: 0.8182.  Mean training acc: 75.49%.
[ Wed Nov  9 14:47:55 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 14:47:55 2022 ] Eval epoch: 19
[ Wed Nov  9 14:52:30 2022 ] 	Mean test loss of 796 batches: 1.1961867173562697.
[ Wed Nov  9 14:52:31 2022 ] 	Top1: 65.36%
[ Wed Nov  9 14:52:33 2022 ] 	Top5: 91.66%
[ Wed Nov  9 14:52:33 2022 ] Training epoch: 20
[ Wed Nov  9 15:01:40 2022 ] 	Mean training loss: 0.8016.  Mean training acc: 76.15%.
[ Wed Nov  9 15:01:40 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 15:01:40 2022 ] Eval epoch: 20
[ Wed Nov  9 15:06:08 2022 ] 	Mean test loss of 796 batches: 1.0437528979239152.
[ Wed Nov  9 15:06:10 2022 ] 	Top1: 69.43%
[ Wed Nov  9 15:06:12 2022 ] 	Top5: 92.46%
[ Wed Nov  9 15:06:12 2022 ] Training epoch: 21
[ Wed Nov  9 15:15:16 2022 ] 	Mean training loss: 0.8020.  Mean training acc: 75.93%.
[ Wed Nov  9 15:15:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Nov  9 15:15:16 2022 ] Eval epoch: 21
[ Tue Jan  3 16:52:56 2023 ] Load weights from work_dir/csub/local_SHTg_bone_BL/runs-20-19680.pt.
[ Tue Jan  3 16:53:03 2023 ] using warm up, epoch: 5
[ Tue Jan  3 16:53:17 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHTg_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHTg_bone_BL/runs', 'config': 'work_dir/csub/local_SHTg_bone_BL/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': False, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSub.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': False, 'window_size': 64}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/csub/local_SHTg_bone_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 16:53:17 2023 ] # Parameters: 2141090
[ Tue Jan  3 16:53:17 2023 ] Training epoch: 21
[ Tue Jan  3 17:02:30 2023 ] 	Mean training loss: 0.8019.  Mean training acc: 76.05%.
[ Tue Jan  3 17:02:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:02:30 2023 ] Eval epoch: 21
[ Tue Jan  3 17:05:30 2023 ] 	Mean test loss of 796 batches: 1.1970780480222487.
[ Tue Jan  3 17:05:31 2023 ] 	Top1: 66.34%
[ Tue Jan  3 17:05:31 2023 ] 	Top5: 91.03%
[ Tue Jan  3 17:05:31 2023 ] Training epoch: 22
[ Tue Jan  3 17:14:48 2023 ] 	Mean training loss: 0.7940.  Mean training acc: 76.34%.
[ Tue Jan  3 17:14:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:14:48 2023 ] Eval epoch: 22
[ Tue Jan  3 17:17:44 2023 ] 	Mean test loss of 796 batches: 1.0517906934846586.
[ Tue Jan  3 17:17:44 2023 ] 	Top1: 69.19%
[ Tue Jan  3 17:17:45 2023 ] 	Top5: 92.95%
[ Tue Jan  3 17:17:45 2023 ] Training epoch: 23
[ Tue Jan  3 17:27:16 2023 ] 	Mean training loss: 0.7831.  Mean training acc: 76.48%.
[ Tue Jan  3 17:27:16 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:27:16 2023 ] Eval epoch: 23
[ Tue Jan  3 17:30:27 2023 ] 	Mean test loss of 796 batches: 1.0667441580163775.
[ Tue Jan  3 17:30:27 2023 ] 	Top1: 68.79%
[ Tue Jan  3 17:30:28 2023 ] 	Top5: 92.98%
[ Tue Jan  3 17:30:28 2023 ] Training epoch: 24
[ Tue Jan  3 17:40:03 2023 ] 	Mean training loss: 0.7837.  Mean training acc: 76.70%.
[ Tue Jan  3 17:40:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:40:03 2023 ] Eval epoch: 24
[ Tue Jan  3 17:43:18 2023 ] 	Mean test loss of 796 batches: 1.0300247663603954.
[ Tue Jan  3 17:43:19 2023 ] 	Top1: 69.65%
[ Tue Jan  3 17:43:20 2023 ] 	Top5: 93.18%
[ Tue Jan  3 17:43:20 2023 ] Training epoch: 25
[ Tue Jan  3 17:52:47 2023 ] 	Mean training loss: 0.7816.  Mean training acc: 76.63%.
[ Tue Jan  3 17:52:47 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 17:52:47 2023 ] Eval epoch: 25
[ Tue Jan  3 17:56:11 2023 ] 	Mean test loss of 796 batches: 0.9991627461347149.
[ Tue Jan  3 17:56:12 2023 ] 	Top1: 70.09%
[ Tue Jan  3 17:56:13 2023 ] 	Top5: 93.22%
[ Tue Jan  3 17:56:13 2023 ] Training epoch: 26
[ Tue Jan  3 18:05:24 2023 ] 	Mean training loss: 0.7730.  Mean training acc: 76.90%.
[ Tue Jan  3 18:05:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:05:24 2023 ] Eval epoch: 26
[ Tue Jan  3 18:09:01 2023 ] 	Mean test loss of 796 batches: 1.000316319678297.
[ Tue Jan  3 18:09:01 2023 ] 	Top1: 70.52%
[ Tue Jan  3 18:09:02 2023 ] 	Top5: 93.34%
[ Tue Jan  3 18:09:02 2023 ] Training epoch: 27
[ Tue Jan  3 18:18:03 2023 ] 	Mean training loss: 0.7680.  Mean training acc: 77.10%.
[ Tue Jan  3 18:18:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:18:03 2023 ] Eval epoch: 27
[ Tue Jan  3 18:21:43 2023 ] 	Mean test loss of 796 batches: 0.9994821442880822.
[ Tue Jan  3 18:21:43 2023 ] 	Top1: 70.78%
[ Tue Jan  3 18:21:44 2023 ] 	Top5: 93.25%
[ Tue Jan  3 18:21:44 2023 ] Training epoch: 28
[ Tue Jan  3 18:30:34 2023 ] 	Mean training loss: 0.7584.  Mean training acc: 77.25%.
[ Tue Jan  3 18:30:34 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:30:34 2023 ] Eval epoch: 28
[ Tue Jan  3 18:34:17 2023 ] 	Mean test loss of 796 batches: 1.0690017429054084.
[ Tue Jan  3 18:34:17 2023 ] 	Top1: 69.37%
[ Tue Jan  3 18:34:18 2023 ] 	Top5: 92.62%
[ Tue Jan  3 18:34:18 2023 ] Training epoch: 29
[ Tue Jan  3 18:43:05 2023 ] 	Mean training loss: 0.7597.  Mean training acc: 77.15%.
[ Tue Jan  3 18:43:05 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:43:05 2023 ] Eval epoch: 29
[ Tue Jan  3 18:46:53 2023 ] 	Mean test loss of 796 batches: 1.1319770511221048.
[ Tue Jan  3 18:46:53 2023 ] 	Top1: 68.08%
[ Tue Jan  3 18:46:54 2023 ] 	Top5: 91.65%
[ Tue Jan  3 18:46:54 2023 ] Training epoch: 30
[ Tue Jan  3 18:55:52 2023 ] 	Mean training loss: 0.7558.  Mean training acc: 77.24%.
[ Tue Jan  3 18:55:52 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 18:55:52 2023 ] Eval epoch: 30
[ Tue Jan  3 18:59:44 2023 ] 	Mean test loss of 796 batches: 1.0136296075193127.
[ Tue Jan  3 18:59:44 2023 ] 	Top1: 71.36%
[ Tue Jan  3 18:59:45 2023 ] 	Top5: 92.80%
[ Tue Jan  3 18:59:45 2023 ] Training epoch: 31
[ Tue Jan  3 19:08:37 2023 ] 	Mean training loss: 0.7593.  Mean training acc: 77.30%.
[ Tue Jan  3 19:08:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:08:37 2023 ] Eval epoch: 31
[ Tue Jan  3 19:12:24 2023 ] 	Mean test loss of 796 batches: 1.1182804039525027.
[ Tue Jan  3 19:12:24 2023 ] 	Top1: 68.72%
[ Tue Jan  3 19:12:25 2023 ] 	Top5: 91.78%
[ Tue Jan  3 19:12:25 2023 ] Training epoch: 32
[ Tue Jan  3 19:21:11 2023 ] 	Mean training loss: 0.7505.  Mean training acc: 77.56%.
[ Tue Jan  3 19:21:11 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:21:11 2023 ] Eval epoch: 32
[ Tue Jan  3 19:24:54 2023 ] 	Mean test loss of 796 batches: 1.0480592144868481.
[ Tue Jan  3 19:24:55 2023 ] 	Top1: 69.61%
[ Tue Jan  3 19:24:55 2023 ] 	Top5: 93.14%
[ Tue Jan  3 19:24:55 2023 ] Training epoch: 33
[ Tue Jan  3 19:33:37 2023 ] 	Mean training loss: 0.7427.  Mean training acc: 77.84%.
[ Tue Jan  3 19:33:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:33:37 2023 ] Eval epoch: 33
[ Tue Jan  3 19:37:24 2023 ] 	Mean test loss of 796 batches: 1.0406883855785556.
[ Tue Jan  3 19:37:24 2023 ] 	Top1: 70.17%
[ Tue Jan  3 19:37:25 2023 ] 	Top5: 92.81%
[ Tue Jan  3 19:37:25 2023 ] Training epoch: 34
[ Tue Jan  3 19:46:19 2023 ] 	Mean training loss: 0.7454.  Mean training acc: 77.67%.
[ Tue Jan  3 19:46:19 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:46:20 2023 ] Eval epoch: 34
[ Tue Jan  3 19:50:03 2023 ] 	Mean test loss of 796 batches: 1.1685751394261068.
[ Tue Jan  3 19:50:03 2023 ] 	Top1: 67.35%
[ Tue Jan  3 19:50:04 2023 ] 	Top5: 90.93%
[ Tue Jan  3 19:50:04 2023 ] Training epoch: 35
[ Tue Jan  3 19:58:49 2023 ] 	Mean training loss: 0.7489.  Mean training acc: 77.57%.
[ Tue Jan  3 19:58:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:58:51 2023 ] Eval epoch: 35
[ Tue Jan  3 20:02:31 2023 ] 	Mean test loss of 796 batches: 1.0222135121798395.
[ Tue Jan  3 20:02:31 2023 ] 	Top1: 70.98%
[ Tue Jan  3 20:02:32 2023 ] 	Top5: 93.48%
[ Tue Jan  3 20:02:32 2023 ] Training epoch: 36
[ Tue Jan  3 20:11:33 2023 ] 	Mean training loss: 0.4062.  Mean training acc: 88.04%.
[ Tue Jan  3 20:11:33 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:11:34 2023 ] Eval epoch: 36
[ Tue Jan  3 20:15:13 2023 ] 	Mean test loss of 796 batches: 0.5505591631778072.
[ Tue Jan  3 20:15:14 2023 ] 	Top1: 83.12%
[ Tue Jan  3 20:15:14 2023 ] 	Top5: 97.08%
[ Tue Jan  3 20:15:14 2023 ] Training epoch: 37
[ Tue Jan  3 20:24:14 2023 ] 	Mean training loss: 0.3201.  Mean training acc: 90.48%.
[ Tue Jan  3 20:24:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:24:15 2023 ] Eval epoch: 37
[ Tue Jan  3 20:27:54 2023 ] 	Mean test loss of 796 batches: 0.5479950981317603.
[ Tue Jan  3 20:27:55 2023 ] 	Top1: 83.38%
[ Tue Jan  3 20:27:56 2023 ] 	Top5: 97.03%
[ Tue Jan  3 20:27:56 2023 ] Training epoch: 38
[ Tue Jan  3 20:37:02 2023 ] 	Mean training loss: 0.2819.  Mean training acc: 91.68%.
[ Tue Jan  3 20:37:02 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:37:02 2023 ] Eval epoch: 38
[ Tue Jan  3 20:40:42 2023 ] 	Mean test loss of 796 batches: 0.5414868775923648.
[ Tue Jan  3 20:40:43 2023 ] 	Top1: 83.69%
[ Tue Jan  3 20:40:43 2023 ] 	Top5: 97.20%
[ Tue Jan  3 20:40:43 2023 ] Training epoch: 39
[ Tue Jan  3 20:49:59 2023 ] 	Mean training loss: 0.2518.  Mean training acc: 92.69%.
[ Tue Jan  3 20:49:59 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:49:59 2023 ] Eval epoch: 39
[ Tue Jan  3 20:53:36 2023 ] 	Mean test loss of 796 batches: 0.5487369884685356.
[ Tue Jan  3 20:53:37 2023 ] 	Top1: 83.81%
[ Tue Jan  3 20:53:37 2023 ] 	Top5: 97.10%
[ Tue Jan  3 20:53:38 2023 ] Training epoch: 40
[ Tue Jan  3 21:02:45 2023 ] 	Mean training loss: 0.2345.  Mean training acc: 93.19%.
[ Tue Jan  3 21:02:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:02:46 2023 ] Eval epoch: 40
[ Tue Jan  3 21:06:23 2023 ] 	Mean test loss of 796 batches: 0.5441941731052482.
[ Tue Jan  3 21:06:23 2023 ] 	Top1: 83.79%
[ Tue Jan  3 21:06:24 2023 ] 	Top5: 97.10%
[ Tue Jan  3 21:06:24 2023 ] Training epoch: 41
[ Tue Jan  3 21:15:19 2023 ] 	Mean training loss: 0.2154.  Mean training acc: 93.80%.
[ Tue Jan  3 21:15:19 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:15:20 2023 ] Eval epoch: 41
[ Tue Jan  3 21:18:59 2023 ] 	Mean test loss of 796 batches: 0.5679431456847855.
[ Tue Jan  3 21:18:59 2023 ] 	Top1: 83.41%
[ Tue Jan  3 21:19:00 2023 ] 	Top5: 97.01%
[ Tue Jan  3 21:19:00 2023 ] Training epoch: 42
[ Tue Jan  3 21:27:41 2023 ] 	Mean training loss: 0.1974.  Mean training acc: 94.42%.
[ Tue Jan  3 21:27:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:27:42 2023 ] Eval epoch: 42
[ Tue Jan  3 21:31:32 2023 ] 	Mean test loss of 796 batches: 0.5773991528598956.
[ Tue Jan  3 21:31:33 2023 ] 	Top1: 83.17%
[ Tue Jan  3 21:31:34 2023 ] 	Top5: 96.85%
[ Tue Jan  3 21:31:34 2023 ] Training epoch: 43
[ Tue Jan  3 21:40:18 2023 ] 	Mean training loss: 0.1871.  Mean training acc: 94.81%.
[ Tue Jan  3 21:40:18 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:40:18 2023 ] Eval epoch: 43
[ Tue Jan  3 21:44:11 2023 ] 	Mean test loss of 796 batches: 0.5915972023228904.
[ Tue Jan  3 21:44:12 2023 ] 	Top1: 82.97%
[ Tue Jan  3 21:44:12 2023 ] 	Top5: 96.88%
[ Tue Jan  3 21:44:12 2023 ] Training epoch: 44
[ Tue Jan  3 21:53:04 2023 ] 	Mean training loss: 0.1735.  Mean training acc: 95.23%.
[ Tue Jan  3 21:53:04 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:53:04 2023 ] Eval epoch: 44
[ Tue Jan  3 21:56:51 2023 ] 	Mean test loss of 796 batches: 0.6352448582593071.
[ Tue Jan  3 21:56:52 2023 ] 	Top1: 82.25%
[ Tue Jan  3 21:56:52 2023 ] 	Top5: 96.39%
[ Tue Jan  3 21:56:53 2023 ] Training epoch: 45
[ Tue Jan  3 22:05:43 2023 ] 	Mean training loss: 0.1689.  Mean training acc: 95.40%.
[ Tue Jan  3 22:05:43 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:05:43 2023 ] Eval epoch: 45
[ Tue Jan  3 22:09:26 2023 ] 	Mean test loss of 796 batches: 0.6224721578328903.
[ Tue Jan  3 22:09:26 2023 ] 	Top1: 82.40%
[ Tue Jan  3 22:09:27 2023 ] 	Top5: 96.63%
[ Tue Jan  3 22:09:27 2023 ] Training epoch: 46
[ Tue Jan  3 22:18:14 2023 ] 	Mean training loss: 0.1621.  Mean training acc: 95.55%.
[ Tue Jan  3 22:18:14 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:18:15 2023 ] Eval epoch: 46
[ Tue Jan  3 22:21:56 2023 ] 	Mean test loss of 796 batches: 0.6176833117090578.
[ Tue Jan  3 22:21:56 2023 ] 	Top1: 82.63%
[ Tue Jan  3 22:21:57 2023 ] 	Top5: 96.58%
[ Tue Jan  3 22:21:57 2023 ] Training epoch: 47
[ Tue Jan  3 22:30:57 2023 ] 	Mean training loss: 0.1589.  Mean training acc: 95.69%.
[ Tue Jan  3 22:30:57 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:30:57 2023 ] Eval epoch: 47
[ Tue Jan  3 22:34:38 2023 ] 	Mean test loss of 796 batches: 0.6189652713455597.
[ Tue Jan  3 22:34:39 2023 ] 	Top1: 82.39%
[ Tue Jan  3 22:34:39 2023 ] 	Top5: 96.61%
[ Tue Jan  3 22:34:40 2023 ] Training epoch: 48
[ Tue Jan  3 22:43:35 2023 ] 	Mean training loss: 0.1450.  Mean training acc: 96.21%.
[ Tue Jan  3 22:43:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:43:35 2023 ] Eval epoch: 48
[ Tue Jan  3 22:47:17 2023 ] 	Mean test loss of 796 batches: 0.6684137866949317.
[ Tue Jan  3 22:47:18 2023 ] 	Top1: 81.81%
[ Tue Jan  3 22:47:18 2023 ] 	Top5: 96.19%
[ Tue Jan  3 22:47:18 2023 ] Training epoch: 49
[ Tue Jan  3 22:56:22 2023 ] 	Mean training loss: 0.1481.  Mean training acc: 96.04%.
[ Tue Jan  3 22:56:22 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:56:23 2023 ] Eval epoch: 49
[ Tue Jan  3 23:00:02 2023 ] 	Mean test loss of 796 batches: 0.6594147843931188.
[ Tue Jan  3 23:00:03 2023 ] 	Top1: 81.86%
[ Tue Jan  3 23:00:04 2023 ] 	Top5: 96.25%
[ Tue Jan  3 23:00:04 2023 ] Training epoch: 50
[ Tue Jan  3 23:09:25 2023 ] 	Mean training loss: 0.1454.  Mean training acc: 96.23%.
[ Tue Jan  3 23:09:25 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:09:25 2023 ] Eval epoch: 50
[ Tue Jan  3 23:13:09 2023 ] 	Mean test loss of 796 batches: 0.6755909211465612.
[ Tue Jan  3 23:13:10 2023 ] 	Top1: 81.69%
[ Tue Jan  3 23:13:11 2023 ] 	Top5: 96.10%
[ Tue Jan  3 23:13:11 2023 ] Training epoch: 51
[ Tue Jan  3 23:22:34 2023 ] 	Mean training loss: 0.1484.  Mean training acc: 96.05%.
[ Tue Jan  3 23:22:34 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:22:34 2023 ] Eval epoch: 51
[ Tue Jan  3 23:26:16 2023 ] 	Mean test loss of 796 batches: 0.6514747621276271.
[ Tue Jan  3 23:26:17 2023 ] 	Top1: 81.98%
[ Tue Jan  3 23:26:18 2023 ] 	Top5: 96.37%
[ Tue Jan  3 23:26:18 2023 ] Training epoch: 52
[ Tue Jan  3 23:35:47 2023 ] 	Mean training loss: 0.1493.  Mean training acc: 95.97%.
[ Tue Jan  3 23:35:47 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:35:48 2023 ] Eval epoch: 52
[ Tue Jan  3 23:39:10 2023 ] 	Mean test loss of 796 batches: 0.6682246365776313.
[ Tue Jan  3 23:39:11 2023 ] 	Top1: 81.70%
[ Tue Jan  3 23:39:11 2023 ] 	Top5: 96.34%
[ Tue Jan  3 23:39:11 2023 ] Training epoch: 53
[ Tue Jan  3 23:48:44 2023 ] 	Mean training loss: 0.1478.  Mean training acc: 96.08%.
[ Tue Jan  3 23:48:44 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:48:44 2023 ] Eval epoch: 53
[ Tue Jan  3 23:52:07 2023 ] 	Mean test loss of 796 batches: 0.6696698822118529.
[ Tue Jan  3 23:52:08 2023 ] 	Top1: 81.70%
[ Tue Jan  3 23:52:08 2023 ] 	Top5: 96.13%
[ Tue Jan  3 23:52:09 2023 ] Training epoch: 54
[ Wed Jan  4 00:01:27 2023 ] 	Mean training loss: 0.1537.  Mean training acc: 95.84%.
[ Wed Jan  4 00:01:27 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:01:27 2023 ] Eval epoch: 54
[ Wed Jan  4 00:04:48 2023 ] 	Mean test loss of 796 batches: 0.6913987007085702.
[ Wed Jan  4 00:04:49 2023 ] 	Top1: 81.20%
[ Wed Jan  4 00:04:49 2023 ] 	Top5: 95.81%
[ Wed Jan  4 00:04:49 2023 ] Training epoch: 55
[ Wed Jan  4 00:14:22 2023 ] 	Mean training loss: 0.1459.  Mean training acc: 96.17%.
[ Wed Jan  4 00:14:22 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:14:22 2023 ] Eval epoch: 55
[ Wed Jan  4 00:17:44 2023 ] 	Mean test loss of 796 batches: 0.704833040584871.
[ Wed Jan  4 00:17:45 2023 ] 	Top1: 81.21%
[ Wed Jan  4 00:17:45 2023 ] 	Top5: 95.87%
[ Wed Jan  4 00:17:45 2023 ] Training epoch: 56
[ Wed Jan  4 00:27:24 2023 ] 	Mean training loss: 0.0782.  Mean training acc: 98.41%.
[ Wed Jan  4 00:27:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:27:24 2023 ] Eval epoch: 56
[ Wed Jan  4 00:30:48 2023 ] 	Mean test loss of 796 batches: 0.5942189816207667.
[ Wed Jan  4 00:30:48 2023 ] 	Top1: 83.85%
[ Wed Jan  4 00:30:49 2023 ] 	Top5: 96.66%
[ Wed Jan  4 00:30:49 2023 ] Training epoch: 57
[ Wed Jan  4 00:40:22 2023 ] 	Mean training loss: 0.0555.  Mean training acc: 99.08%.
[ Wed Jan  4 00:40:22 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:40:22 2023 ] Eval epoch: 57
[ Wed Jan  4 00:43:48 2023 ] 	Mean test loss of 796 batches: 0.5968074305965823.
[ Wed Jan  4 00:43:49 2023 ] 	Top1: 83.89%
[ Wed Jan  4 00:43:49 2023 ] 	Top5: 96.62%
[ Wed Jan  4 00:43:49 2023 ] Training epoch: 58
[ Wed Jan  4 00:53:14 2023 ] 	Mean training loss: 0.0484.  Mean training acc: 99.28%.
[ Wed Jan  4 00:53:15 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:53:15 2023 ] Eval epoch: 58
[ Wed Jan  4 00:56:42 2023 ] 	Mean test loss of 796 batches: 0.6042218591278447.
[ Wed Jan  4 00:56:43 2023 ] 	Top1: 83.72%
[ Wed Jan  4 00:56:43 2023 ] 	Top5: 96.61%
[ Wed Jan  4 00:56:44 2023 ] Training epoch: 59
[ Wed Jan  4 01:05:51 2023 ] 	Mean training loss: 0.0444.  Mean training acc: 99.30%.
[ Wed Jan  4 01:05:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:05:51 2023 ] Eval epoch: 59
[ Wed Jan  4 01:09:26 2023 ] 	Mean test loss of 796 batches: 0.5985555136716695.
[ Wed Jan  4 01:09:27 2023 ] 	Top1: 84.03%
[ Wed Jan  4 01:09:27 2023 ] 	Top5: 96.70%
[ Wed Jan  4 01:09:27 2023 ] Training epoch: 60
[ Wed Jan  4 01:18:37 2023 ] 	Mean training loss: 0.0407.  Mean training acc: 99.43%.
[ Wed Jan  4 01:18:37 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:18:37 2023 ] Eval epoch: 60
[ Wed Jan  4 01:22:22 2023 ] 	Mean test loss of 796 batches: 0.5949053135162322.
[ Wed Jan  4 01:22:23 2023 ] 	Top1: 84.13%
[ Wed Jan  4 01:22:23 2023 ] 	Top5: 96.69%
[ Wed Jan  4 01:22:23 2023 ] Training epoch: 61
[ Wed Jan  4 01:31:28 2023 ] 	Mean training loss: 0.0399.  Mean training acc: 99.44%.
[ Wed Jan  4 01:31:28 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:31:28 2023 ] Eval epoch: 61
[ Wed Jan  4 01:35:09 2023 ] 	Mean test loss of 796 batches: 0.5943155902339585.
[ Wed Jan  4 01:35:10 2023 ] 	Top1: 84.19%
[ Wed Jan  4 01:35:10 2023 ] 	Top5: 96.70%
[ Wed Jan  4 01:35:10 2023 ] Training epoch: 62
[ Wed Jan  4 01:44:00 2023 ] 	Mean training loss: 0.0372.  Mean training acc: 99.51%.
[ Wed Jan  4 01:44:00 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:44:00 2023 ] Eval epoch: 62
[ Wed Jan  4 01:47:39 2023 ] 	Mean test loss of 796 batches: 0.6011701225392033.
[ Wed Jan  4 01:47:40 2023 ] 	Top1: 84.03%
[ Wed Jan  4 01:47:40 2023 ] 	Top5: 96.58%
[ Wed Jan  4 01:47:40 2023 ] Training epoch: 63
[ Wed Jan  4 01:56:26 2023 ] 	Mean training loss: 0.0362.  Mean training acc: 99.54%.
[ Wed Jan  4 01:56:26 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:56:26 2023 ] Eval epoch: 63
[ Wed Jan  4 02:00:10 2023 ] 	Mean test loss of 796 batches: 0.5956803751201486.
[ Wed Jan  4 02:00:10 2023 ] 	Top1: 84.13%
[ Wed Jan  4 02:00:11 2023 ] 	Top5: 96.68%
[ Wed Jan  4 02:00:11 2023 ] Training epoch: 64
[ Wed Jan  4 02:08:52 2023 ] 	Mean training loss: 0.0325.  Mean training acc: 99.58%.
[ Wed Jan  4 02:08:52 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:08:52 2023 ] Eval epoch: 64
[ Wed Jan  4 02:12:39 2023 ] 	Mean test loss of 796 batches: 0.6039478906322664.
[ Wed Jan  4 02:12:40 2023 ] 	Top1: 84.00%
[ Wed Jan  4 02:12:40 2023 ] 	Top5: 96.67%
[ Wed Jan  4 02:12:40 2023 ] Training epoch: 65
[ Wed Jan  4 02:21:24 2023 ] 	Mean training loss: 0.0332.  Mean training acc: 99.57%.
[ Wed Jan  4 02:21:24 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:21:24 2023 ] Eval epoch: 65
[ Wed Jan  4 02:25:11 2023 ] 	Mean test loss of 796 batches: 0.5997615091118905.
[ Wed Jan  4 02:25:12 2023 ] 	Top1: 84.11%
[ Wed Jan  4 02:25:12 2023 ] 	Top5: 96.59%
[ Wed Jan  4 02:28:48 2023 ] Best accuracy: 0.8422396354995189
[ Wed Jan  4 02:28:48 2023 ] Epoch number: 61
[ Wed Jan  4 02:28:48 2023 ] Model name: work_dir/csub/local_SHTg_bone_BL
[ Wed Jan  4 02:28:48 2023 ] Model total number of params: 2141090
[ Wed Jan  4 02:28:48 2023 ] Weight decay: 0.0004
[ Wed Jan  4 02:28:48 2023 ] Base LR: 0.1
[ Wed Jan  4 02:28:48 2023 ] Batch Size: 64
[ Wed Jan  4 02:28:48 2023 ] Test Batch Size: 64
[ Wed Jan  4 02:28:48 2023 ] seed: 1
[ Fri Jan 13 18:26:15 2023 ] Load weights from work_dir/csub/local_SHT_bone_BL/runs-20-19680.pt.
[ Fri Jan 13 18:26:19 2023 ] using warm up, epoch: 0
[ Fri Jan 13 18:26:33 2023 ] Parameters:
{'work_dir': 'work_dir/csub/local_SHT_bone_BL', 'model_saved_name': 'work_dir/csub/local_SHT_bone_BL/runs', 'config': 'config/nturgbd120-cross-subject/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/local_SHT_bone_BL/runs-20-19680.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 20, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Fri Jan 13 18:26:33 2023 ] # Parameters: 2141090
[ Fri Jan 13 18:26:33 2023 ] Training epoch: 21
[ Fri Jan 13 18:32:52 2023 ] 	Mean training loss: 0.7988.  Mean training acc: 76.15%.
[ Fri Jan 13 18:32:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:32:52 2023 ] Eval epoch: 21
[ Fri Jan 13 18:35:55 2023 ] 	Mean test loss of 796 batches: 1.3026626439924216.
[ Fri Jan 13 18:35:55 2023 ] 	Top1: 64.26%
[ Fri Jan 13 18:35:56 2023 ] 	Top5: 90.08%
[ Fri Jan 13 18:35:56 2023 ] Training epoch: 22
[ Fri Jan 13 18:44:03 2023 ] 	Mean training loss: 0.7988.  Mean training acc: 76.08%.
[ Fri Jan 13 18:44:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:44:03 2023 ] Eval epoch: 22
[ Fri Jan 13 18:47:11 2023 ] 	Mean test loss of 796 batches: 1.0980823089429481.
[ Fri Jan 13 18:47:12 2023 ] 	Top1: 68.60%
[ Fri Jan 13 18:47:12 2023 ] 	Top5: 92.10%
[ Fri Jan 13 18:47:12 2023 ] Training epoch: 23
[ Fri Jan 13 18:54:34 2023 ] 	Mean training loss: 0.7810.  Mean training acc: 76.69%.
[ Fri Jan 13 18:54:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 18:54:34 2023 ] Eval epoch: 23
[ Fri Jan 13 18:57:26 2023 ] 	Mean test loss of 796 batches: 1.1283799145913602.
[ Fri Jan 13 18:57:26 2023 ] 	Top1: 67.10%
[ Fri Jan 13 18:57:27 2023 ] 	Top5: 92.44%
[ Fri Jan 13 18:57:27 2023 ] Training epoch: 24
[ Fri Jan 13 19:05:05 2023 ] 	Mean training loss: 0.7836.  Mean training acc: 76.56%.
[ Fri Jan 13 19:05:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:05:05 2023 ] Eval epoch: 24
[ Fri Jan 13 19:08:06 2023 ] 	Mean test loss of 796 batches: 1.0994822852425838.
[ Fri Jan 13 19:08:07 2023 ] 	Top1: 68.20%
[ Fri Jan 13 19:08:07 2023 ] 	Top5: 91.82%
[ Fri Jan 13 19:08:07 2023 ] Training epoch: 25
[ Fri Jan 13 19:16:22 2023 ] 	Mean training loss: 0.7751.  Mean training acc: 76.77%.
[ Fri Jan 13 19:16:22 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:16:22 2023 ] Eval epoch: 25
[ Fri Jan 13 19:19:25 2023 ] 	Mean test loss of 796 batches: 1.0754600867030009.
[ Fri Jan 13 19:19:25 2023 ] 	Top1: 68.49%
[ Fri Jan 13 19:19:26 2023 ] 	Top5: 92.43%
[ Fri Jan 13 19:19:26 2023 ] Training epoch: 26
[ Fri Jan 13 19:26:52 2023 ] 	Mean training loss: 0.7698.  Mean training acc: 77.01%.
[ Fri Jan 13 19:26:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:26:52 2023 ] Eval epoch: 26
[ Fri Jan 13 19:29:43 2023 ] 	Mean test loss of 796 batches: 1.0515991723417637.
[ Fri Jan 13 19:29:44 2023 ] 	Top1: 69.51%
[ Fri Jan 13 19:29:44 2023 ] 	Top5: 93.02%
[ Fri Jan 13 19:29:44 2023 ] Training epoch: 27
[ Fri Jan 13 19:37:30 2023 ] 	Mean training loss: 0.7645.  Mean training acc: 77.34%.
[ Fri Jan 13 19:37:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:37:30 2023 ] Eval epoch: 27
[ Fri Jan 13 19:40:31 2023 ] 	Mean test loss of 796 batches: 1.2460462919731237.
[ Fri Jan 13 19:40:31 2023 ] 	Top1: 64.03%
[ Fri Jan 13 19:40:32 2023 ] 	Top5: 90.95%
[ Fri Jan 13 19:40:32 2023 ] Training epoch: 28
[ Fri Jan 13 19:48:41 2023 ] 	Mean training loss: 0.7612.  Mean training acc: 77.15%.
[ Fri Jan 13 19:48:41 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:48:41 2023 ] Eval epoch: 28
[ Fri Jan 13 19:51:44 2023 ] 	Mean test loss of 796 batches: 1.044006018857261.
[ Fri Jan 13 19:51:44 2023 ] 	Top1: 70.01%
[ Fri Jan 13 19:51:45 2023 ] 	Top5: 92.73%
[ Fri Jan 13 19:51:45 2023 ] Training epoch: 29
[ Fri Jan 13 19:59:09 2023 ] 	Mean training loss: 0.7528.  Mean training acc: 77.50%.
[ Fri Jan 13 19:59:09 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 19:59:09 2023 ] Eval epoch: 29
[ Fri Jan 13 20:01:59 2023 ] 	Mean test loss of 796 batches: 1.0130929831583895.
[ Fri Jan 13 20:01:59 2023 ] 	Top1: 70.51%
[ Fri Jan 13 20:02:00 2023 ] 	Top5: 93.28%
[ Fri Jan 13 20:02:00 2023 ] Training epoch: 30
[ Fri Jan 13 20:09:45 2023 ] 	Mean training loss: 0.7547.  Mean training acc: 77.36%.
[ Fri Jan 13 20:09:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:09:45 2023 ] Eval epoch: 30
[ Fri Jan 13 20:12:48 2023 ] 	Mean test loss of 796 batches: 0.9899048743086245.
[ Fri Jan 13 20:12:48 2023 ] 	Top1: 71.93%
[ Fri Jan 13 20:12:49 2023 ] 	Top5: 93.11%
[ Fri Jan 13 20:12:49 2023 ] Training epoch: 31
[ Fri Jan 13 20:20:57 2023 ] 	Mean training loss: 0.7601.  Mean training acc: 77.17%.
[ Fri Jan 13 20:20:57 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:20:57 2023 ] Eval epoch: 31
[ Fri Jan 13 20:23:58 2023 ] 	Mean test loss of 796 batches: 1.213955810883237.
[ Fri Jan 13 20:23:58 2023 ] 	Top1: 66.71%
[ Fri Jan 13 20:23:59 2023 ] 	Top5: 91.23%
[ Fri Jan 13 20:23:59 2023 ] Training epoch: 32
[ Fri Jan 13 20:31:19 2023 ] 	Mean training loss: 0.7499.  Mean training acc: 77.67%.
[ Fri Jan 13 20:31:19 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:31:19 2023 ] Eval epoch: 32
[ Fri Jan 13 20:34:11 2023 ] 	Mean test loss of 796 batches: 1.4015082861460633.
[ Fri Jan 13 20:34:12 2023 ] 	Top1: 64.37%
[ Fri Jan 13 20:34:12 2023 ] 	Top5: 88.49%
[ Fri Jan 13 20:34:12 2023 ] Training epoch: 33
[ Fri Jan 13 20:42:11 2023 ] 	Mean training loss: 0.7404.  Mean training acc: 77.84%.
[ Fri Jan 13 20:42:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:42:11 2023 ] Eval epoch: 33
[ Fri Jan 13 20:45:13 2023 ] 	Mean test loss of 796 batches: 1.1263836576186832.
[ Fri Jan 13 20:45:13 2023 ] 	Top1: 68.18%
[ Fri Jan 13 20:45:14 2023 ] 	Top5: 91.58%
[ Fri Jan 13 20:45:14 2023 ] Training epoch: 34
[ Fri Jan 13 20:53:30 2023 ] 	Mean training loss: 0.7440.  Mean training acc: 77.88%.
[ Fri Jan 13 20:53:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 20:53:31 2023 ] Eval epoch: 34
[ Fri Jan 13 20:56:24 2023 ] 	Mean test loss of 796 batches: 1.345127407480125.
[ Fri Jan 13 20:56:25 2023 ] 	Top1: 62.95%
[ Fri Jan 13 20:56:25 2023 ] 	Top5: 90.27%
[ Fri Jan 13 20:56:25 2023 ] Training epoch: 35
[ Fri Jan 13 21:03:48 2023 ] 	Mean training loss: 0.7474.  Mean training acc: 77.62%.
[ Fri Jan 13 21:03:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:03:48 2023 ] Eval epoch: 35
[ Fri Jan 13 21:06:37 2023 ] 	Mean test loss of 796 batches: 1.0103975969867491.
[ Fri Jan 13 21:06:37 2023 ] 	Top1: 70.49%
[ Fri Jan 13 21:06:38 2023 ] 	Top5: 93.46%
[ Fri Jan 13 21:06:38 2023 ] Training epoch: 36
[ Fri Jan 13 21:14:44 2023 ] 	Mean training loss: 0.4050.  Mean training acc: 88.02%.
[ Fri Jan 13 21:14:44 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:14:44 2023 ] Eval epoch: 36
[ Fri Jan 13 21:17:48 2023 ] 	Mean test loss of 796 batches: 0.5525536552333652.
[ Fri Jan 13 21:17:49 2023 ] 	Top1: 83.12%
[ Fri Jan 13 21:17:49 2023 ] 	Top5: 97.01%
[ Fri Jan 13 21:17:49 2023 ] Training epoch: 37
[ Fri Jan 13 21:25:55 2023 ] 	Mean training loss: 0.3190.  Mean training acc: 90.52%.
[ Fri Jan 13 21:25:55 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:25:55 2023 ] Eval epoch: 37
[ Fri Jan 13 21:28:47 2023 ] 	Mean test loss of 796 batches: 0.5510428002169684.
[ Fri Jan 13 21:28:48 2023 ] 	Top1: 83.38%
[ Fri Jan 13 21:28:48 2023 ] 	Top5: 97.03%
[ Fri Jan 13 21:28:48 2023 ] Training epoch: 38
[ Fri Jan 13 21:36:01 2023 ] 	Mean training loss: 0.2820.  Mean training acc: 91.52%.
[ Fri Jan 13 21:36:01 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:36:01 2023 ] Eval epoch: 38
[ Fri Jan 13 21:38:54 2023 ] 	Mean test loss of 796 batches: 0.5503581074445542.
[ Fri Jan 13 21:38:54 2023 ] 	Top1: 83.72%
[ Fri Jan 13 21:38:55 2023 ] 	Top5: 97.06%
[ Fri Jan 13 21:38:55 2023 ] Training epoch: 39
[ Fri Jan 13 21:47:04 2023 ] 	Mean training loss: 0.2536.  Mean training acc: 92.49%.
[ Fri Jan 13 21:47:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:47:04 2023 ] Eval epoch: 39
[ Fri Jan 13 21:50:07 2023 ] 	Mean test loss of 796 batches: 0.5488252934892124.
[ Fri Jan 13 21:50:08 2023 ] 	Top1: 83.74%
[ Fri Jan 13 21:50:08 2023 ] 	Top5: 97.05%
[ Fri Jan 13 21:50:08 2023 ] Training epoch: 40
[ Fri Jan 13 21:58:11 2023 ] 	Mean training loss: 0.2353.  Mean training acc: 93.21%.
[ Fri Jan 13 21:58:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 21:58:11 2023 ] Eval epoch: 40
[ Fri Jan 13 22:00:59 2023 ] 	Mean test loss of 796 batches: 0.5472120592960311.
[ Fri Jan 13 22:00:59 2023 ] 	Top1: 83.84%
[ Fri Jan 13 22:01:00 2023 ] 	Top5: 97.04%
[ Fri Jan 13 22:01:00 2023 ] Training epoch: 41
[ Fri Jan 13 22:08:21 2023 ] 	Mean training loss: 0.2136.  Mean training acc: 93.90%.
[ Fri Jan 13 22:08:21 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:08:21 2023 ] Eval epoch: 41
[ Fri Jan 13 22:11:20 2023 ] 	Mean test loss of 796 batches: 0.575199195722015.
[ Fri Jan 13 22:11:21 2023 ] 	Top1: 83.35%
[ Fri Jan 13 22:11:21 2023 ] 	Top5: 96.83%
[ Fri Jan 13 22:11:21 2023 ] Training epoch: 42
[ Fri Jan 13 22:19:34 2023 ] 	Mean training loss: 0.1954.  Mean training acc: 94.46%.
[ Fri Jan 13 22:19:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:19:34 2023 ] Eval epoch: 42
[ Fri Jan 13 22:22:35 2023 ] 	Mean test loss of 796 batches: 0.5769451697118319.
[ Fri Jan 13 22:22:36 2023 ] 	Top1: 83.35%
[ Fri Jan 13 22:22:36 2023 ] 	Top5: 96.92%
[ Fri Jan 13 22:22:36 2023 ] Training epoch: 43
[ Fri Jan 13 22:30:26 2023 ] 	Mean training loss: 0.1866.  Mean training acc: 94.84%.
[ Fri Jan 13 22:30:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:30:27 2023 ] Eval epoch: 43
[ Fri Jan 13 22:33:18 2023 ] 	Mean test loss of 796 batches: 0.5779535623931855.
[ Fri Jan 13 22:33:18 2023 ] 	Top1: 83.26%
[ Fri Jan 13 22:33:19 2023 ] 	Top5: 96.84%
[ Fri Jan 13 22:33:19 2023 ] Training epoch: 44
[ Fri Jan 13 22:40:38 2023 ] 	Mean training loss: 0.1747.  Mean training acc: 95.14%.
[ Fri Jan 13 22:40:38 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:40:38 2023 ] Eval epoch: 44
[ Fri Jan 13 22:43:39 2023 ] 	Mean test loss of 796 batches: 0.6371992094133367.
[ Fri Jan 13 22:43:40 2023 ] 	Top1: 82.07%
[ Fri Jan 13 22:43:40 2023 ] 	Top5: 96.30%
[ Fri Jan 13 22:43:40 2023 ] Training epoch: 45
[ Fri Jan 13 22:51:58 2023 ] 	Mean training loss: 0.1656.  Mean training acc: 95.47%.
[ Fri Jan 13 22:51:58 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 22:51:58 2023 ] Eval epoch: 45
[ Fri Jan 13 22:54:59 2023 ] 	Mean test loss of 796 batches: 0.6194841961034728.
[ Fri Jan 13 22:55:00 2023 ] 	Top1: 82.74%
[ Fri Jan 13 22:55:00 2023 ] 	Top5: 96.45%
[ Fri Jan 13 22:55:00 2023 ] Training epoch: 46
[ Fri Jan 13 23:02:44 2023 ] 	Mean training loss: 0.1626.  Mean training acc: 95.59%.
[ Fri Jan 13 23:02:44 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:02:44 2023 ] Eval epoch: 46
[ Fri Jan 13 23:05:35 2023 ] 	Mean test loss of 796 batches: 0.6213225349596697.
[ Fri Jan 13 23:05:35 2023 ] 	Top1: 82.56%
[ Fri Jan 13 23:05:36 2023 ] 	Top5: 96.51%
[ Fri Jan 13 23:05:36 2023 ] Training epoch: 47
[ Fri Jan 13 23:13:02 2023 ] 	Mean training loss: 0.1543.  Mean training acc: 95.94%.
[ Fri Jan 13 23:13:02 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:13:02 2023 ] Eval epoch: 47
[ Fri Jan 13 23:16:03 2023 ] 	Mean test loss of 796 batches: 0.6590575798597168.
[ Fri Jan 13 23:16:04 2023 ] 	Top1: 81.88%
[ Fri Jan 13 23:16:04 2023 ] 	Top5: 96.21%
[ Fri Jan 13 23:16:05 2023 ] Training epoch: 48
[ Fri Jan 13 23:24:27 2023 ] 	Mean training loss: 0.1483.  Mean training acc: 95.96%.
[ Fri Jan 13 23:24:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:24:27 2023 ] Eval epoch: 48
[ Fri Jan 13 23:27:29 2023 ] 	Mean test loss of 796 batches: 0.6836627504727499.
[ Fri Jan 13 23:27:29 2023 ] 	Top1: 81.40%
[ Fri Jan 13 23:27:30 2023 ] 	Top5: 96.21%
[ Fri Jan 13 23:27:30 2023 ] Training epoch: 49
[ Fri Jan 13 23:35:05 2023 ] 	Mean training loss: 0.1475.  Mean training acc: 96.11%.
[ Fri Jan 13 23:35:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:35:05 2023 ] Eval epoch: 49
[ Fri Jan 13 23:37:55 2023 ] 	Mean test loss of 796 batches: 0.6479647298760001.
[ Fri Jan 13 23:37:55 2023 ] 	Top1: 82.25%
[ Fri Jan 13 23:37:56 2023 ] 	Top5: 96.33%
[ Fri Jan 13 23:37:56 2023 ] Training epoch: 50
[ Fri Jan 13 23:45:32 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.07%.
[ Fri Jan 13 23:45:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:45:32 2023 ] Eval epoch: 50
[ Fri Jan 13 23:48:34 2023 ] 	Mean test loss of 796 batches: 0.6746224209329291.
[ Fri Jan 13 23:48:35 2023 ] 	Top1: 81.68%
[ Fri Jan 13 23:48:35 2023 ] 	Top5: 96.04%
[ Fri Jan 13 23:48:35 2023 ] Training epoch: 51
[ Fri Jan 13 23:56:45 2023 ] 	Mean training loss: 0.1484.  Mean training acc: 96.08%.
[ Fri Jan 13 23:56:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jan 13 23:56:45 2023 ] Eval epoch: 51
[ Fri Jan 13 23:59:48 2023 ] 	Mean test loss of 796 batches: 0.6799373661528281.
[ Fri Jan 13 23:59:48 2023 ] 	Top1: 81.41%
[ Fri Jan 13 23:59:49 2023 ] 	Top5: 96.08%
[ Fri Jan 13 23:59:49 2023 ] Training epoch: 52
[ Sat Jan 14 00:07:15 2023 ] 	Mean training loss: 0.1476.  Mean training acc: 96.07%.
[ Sat Jan 14 00:07:15 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:07:15 2023 ] Eval epoch: 52
[ Sat Jan 14 00:10:03 2023 ] 	Mean test loss of 796 batches: 0.677835013736133.
[ Sat Jan 14 00:10:04 2023 ] 	Top1: 81.31%
[ Sat Jan 14 00:10:04 2023 ] 	Top5: 96.00%
[ Sat Jan 14 00:10:04 2023 ] Training epoch: 53
[ Sat Jan 14 00:17:53 2023 ] 	Mean training loss: 0.1467.  Mean training acc: 96.10%.
[ Sat Jan 14 00:17:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:17:53 2023 ] Eval epoch: 53
[ Sat Jan 14 00:20:55 2023 ] 	Mean test loss of 796 batches: 0.6757578826860418.
[ Sat Jan 14 00:20:56 2023 ] 	Top1: 81.61%
[ Sat Jan 14 00:20:56 2023 ] 	Top5: 95.90%
[ Sat Jan 14 00:20:56 2023 ] Training epoch: 54
[ Sat Jan 14 00:29:14 2023 ] 	Mean training loss: 0.1529.  Mean training acc: 95.89%.
[ Sat Jan 14 00:29:14 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:29:14 2023 ] Eval epoch: 54
[ Sat Jan 14 00:32:09 2023 ] 	Mean test loss of 796 batches: 0.7494552339890495.
[ Sat Jan 14 00:32:09 2023 ] 	Top1: 79.95%
[ Sat Jan 14 00:32:10 2023 ] 	Top5: 95.50%
[ Sat Jan 14 00:32:10 2023 ] Training epoch: 55
[ Sat Jan 14 00:39:34 2023 ] 	Mean training loss: 0.1459.  Mean training acc: 96.10%.
[ Sat Jan 14 00:39:34 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:39:34 2023 ] Eval epoch: 55
[ Sat Jan 14 00:42:25 2023 ] 	Mean test loss of 796 batches: 0.7303930070232506.
[ Sat Jan 14 00:42:26 2023 ] 	Top1: 80.55%
[ Sat Jan 14 00:42:26 2023 ] 	Top5: 95.78%
[ Sat Jan 14 00:42:26 2023 ] Training epoch: 56
[ Sat Jan 14 00:50:28 2023 ] 	Mean training loss: 0.0777.  Mean training acc: 98.39%.
[ Sat Jan 14 00:50:28 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 00:50:28 2023 ] Eval epoch: 56
[ Sat Jan 14 00:53:30 2023 ] 	Mean test loss of 796 batches: 0.6064712685631148.
[ Sat Jan 14 00:53:31 2023 ] 	Top1: 83.61%
[ Sat Jan 14 00:53:31 2023 ] 	Top5: 96.57%
[ Sat Jan 14 00:53:31 2023 ] Training epoch: 57
[ Sat Jan 14 01:01:53 2023 ] 	Mean training loss: 0.0556.  Mean training acc: 99.02%.
[ Sat Jan 14 01:01:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 01:01:53 2023 ] Eval epoch: 57
[ Sat Jan 14 01:04:36 2023 ] 	Mean test loss of 796 batches: 0.6062962535076105.
[ Sat Jan 14 01:04:37 2023 ] 	Top1: 83.59%
[ Sat Jan 14 01:04:37 2023 ] 	Top5: 96.62%
[ Sat Jan 14 01:04:37 2023 ] Training epoch: 58
[ Sat Jan 14 01:12:07 2023 ] 	Mean training loss: 0.0485.  Mean training acc: 99.27%.
[ Sat Jan 14 01:12:07 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Sat Jan 14 01:12:07 2023 ] Eval epoch: 58
[ Sat Jan 14 01:15:01 2023 ] 	Mean test loss of 796 batches: 0.613047160844707.
[ Sat Jan 14 01:15:02 2023 ] 	Top1: 83.54%
[ Sat Jan 14 01:15:02 2023 ] 	Top5: 96.55%
[ Sat Jan 14 01:15:02 2023 ] Training epoch: 59
[ Sat Jan 14 01:23:35 2023 ] 	Mean training loss: 0.0437.  Mean training acc: 99.34%.
[ Sat Jan 14 01:23:35 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 14 01:23:35 2023 ] Eval epoch: 59
[ Sat Jan 14 01:26:29 2023 ] 	Mean test loss of 796 batches: 0.6091794386206559.
[ Sat Jan 14 01:26:30 2023 ] 	Top1: 83.75%
[ Sat Jan 14 01:26:30 2023 ] 	Top5: 96.59%
[ Sat Jan 14 01:26:30 2023 ] Training epoch: 60
[ Sat Jan 14 01:34:30 2023 ] 	Mean training loss: 0.0411.  Mean training acc: 99.40%.
[ Sat Jan 14 01:34:30 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:34:30 2023 ] Eval epoch: 60
[ Sat Jan 14 01:37:09 2023 ] 	Mean test loss of 796 batches: 0.6106256188253811.
[ Sat Jan 14 01:37:09 2023 ] 	Top1: 83.79%
[ Sat Jan 14 01:37:10 2023 ] 	Top5: 96.56%
[ Sat Jan 14 01:37:10 2023 ] Training epoch: 61
[ Sat Jan 14 01:45:50 2023 ] 	Mean training loss: 0.0387.  Mean training acc: 99.47%.
[ Sat Jan 14 01:45:50 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:45:50 2023 ] Eval epoch: 61
[ Sat Jan 14 01:48:45 2023 ] 	Mean test loss of 796 batches: 0.6029228599713975.
[ Sat Jan 14 01:48:45 2023 ] 	Top1: 83.93%
[ Sat Jan 14 01:48:46 2023 ] 	Top5: 96.61%
[ Sat Jan 14 01:48:46 2023 ] Training epoch: 62
[ Sat Jan 14 01:56:55 2023 ] 	Mean training loss: 0.0370.  Mean training acc: 99.49%.
[ Sat Jan 14 01:56:55 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 01:56:55 2023 ] Eval epoch: 62
[ Sat Jan 14 01:59:33 2023 ] 	Mean test loss of 796 batches: 0.61229905169738.
[ Sat Jan 14 01:59:33 2023 ] 	Top1: 83.78%
[ Sat Jan 14 01:59:34 2023 ] 	Top5: 96.58%
[ Sat Jan 14 01:59:34 2023 ] Training epoch: 63
[ Sat Jan 14 02:07:23 2023 ] 	Mean training loss: 0.0349.  Mean training acc: 99.60%.
[ Sat Jan 14 02:07:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:07:23 2023 ] Eval epoch: 63
[ Sat Jan 14 02:10:01 2023 ] 	Mean test loss of 796 batches: 0.6097899006689014.
[ Sat Jan 14 02:10:01 2023 ] 	Top1: 83.90%
[ Sat Jan 14 02:10:01 2023 ] 	Top5: 96.65%
[ Sat Jan 14 02:10:01 2023 ] Training epoch: 64
[ Sat Jan 14 02:17:26 2023 ] 	Mean training loss: 0.0333.  Mean training acc: 99.63%.
[ Sat Jan 14 02:17:26 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:17:26 2023 ] Eval epoch: 64
[ Sat Jan 14 02:19:50 2023 ] 	Mean test loss of 796 batches: 0.6107523184569188.
[ Sat Jan 14 02:19:50 2023 ] 	Top1: 83.83%
[ Sat Jan 14 02:19:50 2023 ] 	Top5: 96.64%
[ Sat Jan 14 02:19:50 2023 ] Training epoch: 65
[ Sat Jan 14 02:26:58 2023 ] 	Mean training loss: 0.0324.  Mean training acc: 99.62%.
[ Sat Jan 14 02:26:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Sat Jan 14 02:26:58 2023 ] Eval epoch: 65
[ Sat Jan 14 02:29:24 2023 ] 	Mean test loss of 796 batches: 0.6128224502668609.
[ Sat Jan 14 02:29:25 2023 ] 	Top1: 83.76%
[ Sat Jan 14 02:29:25 2023 ] 	Top5: 96.55%
[ Sat Jan 14 02:31:52 2023 ] Best accuracy: 0.8393723364559398
[ Sat Jan 14 02:31:52 2023 ] Epoch number: 1
[ Sat Jan 14 02:31:52 2023 ] Model name: work_dir/csub/local_SHT_bone_BL
[ Sat Jan 14 02:31:52 2023 ] Model total number of params: 2141090
[ Sat Jan 14 02:31:52 2023 ] Weight decay: 0.0004
[ Sat Jan 14 02:31:52 2023 ] Base LR: 0.1
[ Sat Jan 14 02:31:52 2023 ] Batch Size: 64
[ Sat Jan 14 02:31:52 2023 ] Test Batch Size: 64
[ Sat Jan 14 02:31:52 2023 ] seed: 1
[ Tue Jan 17 13:18:36 2023 ] Load weights from work_dir/csub/local_SHT_bone_BL/runs-61-40651.pt.
[ Tue Jan 17 13:18:38 2023 ] using warm up, epoch: 5
