[ Mon Jan  9 16:25:17 2023 ] using warm up, epoch: 5
[ Mon Jan  9 16:25:37 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan  9 16:25:37 2023 ] # Parameters: 1508876
[ Mon Jan  9 16:25:37 2023 ] Training epoch: 1
[ Mon Jan  9 16:52:45 2023 ] 	Mean training loss: 3.2406.  Mean training acc: 21.70%.
[ Mon Jan  9 16:52:51 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 16:52:51 2023 ] Eval epoch: 1
[ Mon Jan  9 17:07:02 2023 ] 	Mean test loss of 796 batches: 2.4929111691276034.
[ Mon Jan  9 17:07:09 2023 ] 	Top1: 32.54%
[ Mon Jan  9 17:07:10 2023 ] 	Top5: 65.85%
[ Mon Jan  9 17:07:10 2023 ] Training epoch: 2
[ Mon Jan  9 17:37:08 2023 ] 	Mean training loss: 2.0611.  Mean training acc: 43.48%.
[ Mon Jan  9 17:37:08 2023 ] 	Time consumption: [Data]00%, [Network]92%
[ Mon Jan  9 17:37:10 2023 ] Eval epoch: 2
[ Mon Jan  9 17:51:12 2023 ] 	Mean test loss of 796 batches: 1.8234373685253324.
[ Mon Jan  9 17:51:12 2023 ] 	Top1: 47.32%
[ Mon Jan  9 17:51:13 2023 ] 	Top5: 80.80%
[ Mon Jan  9 17:51:13 2023 ] Training epoch: 3
[ Mon Jan  9 18:19:29 2023 ] 	Mean training loss: 1.6345.  Mean training acc: 53.83%.
[ Mon Jan  9 18:19:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 18:19:30 2023 ] Eval epoch: 3
[ Mon Jan  9 18:33:38 2023 ] 	Mean test loss of 796 batches: 1.6133702833898103.
[ Mon Jan  9 18:33:39 2023 ] 	Top1: 53.18%
[ Mon Jan  9 18:33:40 2023 ] 	Top5: 84.54%
[ Mon Jan  9 18:33:41 2023 ] Training epoch: 4
[ Mon Jan  9 19:01:36 2023 ] 	Mean training loss: 1.4292.  Mean training acc: 58.93%.
[ Mon Jan  9 19:01:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 19:01:38 2023 ] Eval epoch: 4
[ Mon Jan  9 19:16:00 2023 ] 	Mean test loss of 796 batches: 1.6106949671728528.
[ Mon Jan  9 19:16:00 2023 ] 	Top1: 53.44%
[ Mon Jan  9 19:16:01 2023 ] 	Top5: 85.27%
[ Mon Jan  9 19:16:01 2023 ] Training epoch: 5
[ Mon Jan  9 19:44:32 2023 ] 	Mean training loss: 1.3245.  Mean training acc: 61.80%.
[ Mon Jan  9 19:44:32 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Mon Jan  9 19:44:34 2023 ] Eval epoch: 5
[ Mon Jan  9 19:58:54 2023 ] 	Mean test loss of 796 batches: 1.5299769123295444.
[ Mon Jan  9 19:58:55 2023 ] 	Top1: 55.22%
[ Mon Jan  9 19:58:55 2023 ] 	Top5: 85.95%
[ Mon Jan  9 19:58:56 2023 ] Training epoch: 6
[ Mon Jan  9 20:26:54 2023 ] 	Mean training loss: 1.2062.  Mean training acc: 64.91%.
[ Mon Jan  9 20:26:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 20:26:56 2023 ] Eval epoch: 6
[ Mon Jan  9 20:41:09 2023 ] 	Mean test loss of 796 batches: 1.3838979112143492.
[ Mon Jan  9 20:41:10 2023 ] 	Top1: 59.58%
[ Mon Jan  9 20:41:10 2023 ] 	Top5: 88.34%
[ Mon Jan  9 20:41:10 2023 ] Training epoch: 7
[ Mon Jan  9 21:08:56 2023 ] 	Mean training loss: 1.1384.  Mean training acc: 66.61%.
[ Mon Jan  9 21:08:56 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 21:08:56 2023 ] Eval epoch: 7
[ Mon Jan  9 21:24:56 2023 ] 	Mean test loss of 796 batches: 1.5422232389150552.
[ Mon Jan  9 21:24:57 2023 ] 	Top1: 57.88%
[ Mon Jan  9 21:24:57 2023 ] 	Top5: 84.88%
[ Mon Jan  9 21:24:58 2023 ] Training epoch: 8
[ Mon Jan  9 21:55:50 2023 ] 	Mean training loss: 1.0970.  Mean training acc: 67.75%.
[ Mon Jan  9 21:55:51 2023 ] 	Time consumption: [Data]01%, [Network]94%
[ Mon Jan  9 21:55:53 2023 ] Eval epoch: 8
[ Mon Jan  9 22:11:13 2023 ] 	Mean test loss of 796 batches: 1.3786807195026072.
[ Mon Jan  9 22:11:14 2023 ] 	Top1: 60.36%
[ Mon Jan  9 22:11:14 2023 ] 	Top5: 88.93%
[ Mon Jan  9 22:11:15 2023 ] Training epoch: 9
[ Mon Jan  9 22:40:39 2023 ] 	Mean training loss: 1.0649.  Mean training acc: 68.78%.
[ Mon Jan  9 22:40:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 22:40:40 2023 ] Eval epoch: 9
[ Mon Jan  9 22:57:09 2023 ] 	Mean test loss of 796 batches: 1.4598510226412633.
[ Mon Jan  9 22:57:10 2023 ] 	Top1: 58.27%
[ Mon Jan  9 22:57:11 2023 ] 	Top5: 86.31%
[ Mon Jan  9 22:57:11 2023 ] Training epoch: 10
[ Mon Jan  9 23:27:07 2023 ] 	Mean training loss: 1.0502.  Mean training acc: 68.82%.
[ Mon Jan  9 23:27:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 23:27:12 2023 ] Eval epoch: 10
[ Mon Jan  9 23:43:12 2023 ] 	Mean test loss of 796 batches: 1.2896476929361498.
[ Mon Jan  9 23:43:12 2023 ] 	Top1: 61.80%
[ Mon Jan  9 23:43:13 2023 ] 	Top5: 89.22%
[ Mon Jan  9 23:43:13 2023 ] Training epoch: 11
[ Tue Jan 10 00:12:55 2023 ] 	Mean training loss: 1.0214.  Mean training acc: 69.87%.
[ Tue Jan 10 00:12:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 00:12:57 2023 ] Eval epoch: 11
[ Tue Jan 10 00:28:46 2023 ] 	Mean test loss of 796 batches: 1.295218774009889.
[ Tue Jan 10 00:28:47 2023 ] 	Top1: 61.88%
[ Tue Jan 10 00:28:48 2023 ] 	Top5: 89.41%
[ Tue Jan 10 00:28:48 2023 ] Training epoch: 12
[ Tue Jan 10 00:58:49 2023 ] 	Mean training loss: 0.9958.  Mean training acc: 70.48%.
[ Tue Jan 10 00:58:50 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 00:58:51 2023 ] Eval epoch: 12
[ Tue Jan 10 01:14:34 2023 ] 	Mean test loss of 796 batches: 1.3349575508928777.
[ Tue Jan 10 01:14:35 2023 ] 	Top1: 61.60%
[ Tue Jan 10 01:14:35 2023 ] 	Top5: 89.62%
[ Tue Jan 10 01:14:47 2023 ] Training epoch: 13
[ Tue Jan 10 01:44:45 2023 ] 	Mean training loss: 0.9907.  Mean training acc: 70.74%.
[ Tue Jan 10 01:44:46 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 01:44:46 2023 ] Eval epoch: 13
[ Tue Jan 10 02:00:27 2023 ] 	Mean test loss of 796 batches: 1.307420723926482.
[ Tue Jan 10 02:00:27 2023 ] 	Top1: 61.06%
[ Tue Jan 10 02:00:28 2023 ] 	Top5: 88.87%
[ Tue Jan 10 02:00:28 2023 ] Training epoch: 14
[ Tue Jan 10 02:30:30 2023 ] 	Mean training loss: 0.9733.  Mean training acc: 71.12%.
[ Tue Jan 10 02:30:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 02:30:42 2023 ] Eval epoch: 14
[ Tue Jan 10 02:46:22 2023 ] 	Mean test loss of 796 batches: 1.1962086658307056.
[ Tue Jan 10 02:46:23 2023 ] 	Top1: 64.69%
[ Tue Jan 10 02:46:23 2023 ] 	Top5: 90.10%
[ Tue Jan 10 02:46:23 2023 ] Training epoch: 15
[ Tue Jan 10 03:16:03 2023 ] 	Mean training loss: 0.9495.  Mean training acc: 71.82%.
[ Tue Jan 10 03:16:08 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 03:16:09 2023 ] Eval epoch: 15
[ Tue Jan 10 03:31:49 2023 ] 	Mean test loss of 796 batches: 1.3407679046668.
[ Tue Jan 10 03:31:50 2023 ] 	Top1: 62.36%
[ Tue Jan 10 03:31:50 2023 ] 	Top5: 88.97%
[ Tue Jan 10 03:31:51 2023 ] Training epoch: 16
[ Tue Jan 10 04:01:27 2023 ] 	Mean training loss: 0.9532.  Mean training acc: 71.81%.
[ Tue Jan 10 04:01:28 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 04:01:28 2023 ] Eval epoch: 16
[ Tue Jan 10 04:16:43 2023 ] 	Mean test loss of 796 batches: 1.5018116110683086.
[ Tue Jan 10 04:16:51 2023 ] 	Top1: 56.82%
[ Tue Jan 10 04:16:52 2023 ] 	Top5: 86.83%
[ Tue Jan 10 04:16:52 2023 ] Training epoch: 17
[ Tue Jan 10 04:45:59 2023 ] 	Mean training loss: 0.9396.  Mean training acc: 71.97%.
[ Tue Jan 10 04:46:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 04:46:03 2023 ] Eval epoch: 17
[ Tue Jan 10 05:01:46 2023 ] 	Mean test loss of 796 batches: 1.3355650830658237.
[ Tue Jan 10 05:01:47 2023 ] 	Top1: 62.09%
[ Tue Jan 10 05:01:48 2023 ] 	Top5: 88.08%
[ Tue Jan 10 05:01:48 2023 ] Training epoch: 18
[ Tue Jan 10 05:30:55 2023 ] 	Mean training loss: 0.9259.  Mean training acc: 72.36%.
[ Tue Jan 10 05:31:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 05:31:03 2023 ] Eval epoch: 18
[ Tue Jan 10 05:46:53 2023 ] 	Mean test loss of 796 batches: 1.3133303090256063.
[ Tue Jan 10 05:47:03 2023 ] 	Top1: 61.09%
[ Tue Jan 10 05:47:04 2023 ] 	Top5: 89.38%
[ Tue Jan 10 05:47:04 2023 ] Training epoch: 19
[ Tue Jan 10 06:16:06 2023 ] 	Mean training loss: 0.9169.  Mean training acc: 72.57%.
[ Tue Jan 10 06:16:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 06:16:06 2023 ] Eval epoch: 19
[ Tue Jan 10 06:31:55 2023 ] 	Mean test loss of 796 batches: 1.202571506326522.
[ Tue Jan 10 06:31:56 2023 ] 	Top1: 65.22%
[ Tue Jan 10 06:31:57 2023 ] 	Top5: 90.76%
[ Tue Jan 10 06:31:57 2023 ] Training epoch: 20
[ Tue Jan 10 07:00:57 2023 ] 	Mean training loss: 0.9162.  Mean training acc: 72.57%.
[ Tue Jan 10 07:01:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 07:01:03 2023 ] Eval epoch: 20
[ Tue Jan 10 07:16:50 2023 ] 	Mean test loss of 796 batches: 1.2344171091090494.
[ Tue Jan 10 07:16:55 2023 ] 	Top1: 64.45%
[ Tue Jan 10 07:16:55 2023 ] 	Top5: 90.04%
[ Tue Jan 10 07:16:56 2023 ] Training epoch: 21
[ Tue Jan 10 07:45:53 2023 ] 	Mean training loss: 0.9096.  Mean training acc: 72.96%.
[ Tue Jan 10 07:45:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 07:45:54 2023 ] Eval epoch: 21
[ Tue Jan 10 08:01:37 2023 ] 	Mean test loss of 796 batches: 1.1676814342338835.
[ Tue Jan 10 08:01:45 2023 ] 	Top1: 65.78%
[ Tue Jan 10 08:01:46 2023 ] 	Top5: 91.25%
[ Tue Jan 10 08:01:47 2023 ] Training epoch: 22
[ Tue Jan 10 08:23:58 2023 ] 	Mean training loss: 0.9019.  Mean training acc: 73.19%.
[ Tue Jan 10 08:24:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 08:24:15 2023 ] Eval epoch: 22
[ Tue Jan 10 08:38:20 2023 ] 	Mean test loss of 796 batches: 1.2839589908194902.
[ Tue Jan 10 08:38:29 2023 ] 	Top1: 62.29%
[ Tue Jan 10 08:38:29 2023 ] 	Top5: 89.18%
[ Tue Jan 10 08:38:30 2023 ] Training epoch: 23
[ Tue Jan 10 09:00:45 2023 ] 	Mean training loss: 0.8899.  Mean training acc: 73.53%.
[ Tue Jan 10 09:00:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:00:49 2023 ] Eval epoch: 23
[ Tue Jan 10 09:14:27 2023 ] 	Mean test loss of 796 batches: 1.2891893202635512.
[ Tue Jan 10 09:14:30 2023 ] 	Top1: 63.22%
[ Tue Jan 10 09:14:30 2023 ] 	Top5: 88.79%
[ Tue Jan 10 09:14:32 2023 ] Training epoch: 24
[ Tue Jan 10 09:35:58 2023 ] 	Mean training loss: 0.8925.  Mean training acc: 73.45%.
[ Tue Jan 10 09:36:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:36:06 2023 ] Eval epoch: 24
[ Tue Jan 10 09:48:46 2023 ] 	Mean test loss of 796 batches: 1.1201173063723286.
[ Tue Jan 10 09:48:47 2023 ] 	Top1: 66.79%
[ Tue Jan 10 09:48:48 2023 ] 	Top5: 91.25%
[ Tue Jan 10 09:48:48 2023 ] Training epoch: 25
[ Tue Jan 10 10:09:08 2023 ] 	Mean training loss: 0.8779.  Mean training acc: 73.96%.
[ Tue Jan 10 10:09:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:09:10 2023 ] Eval epoch: 25
[ Tue Jan 10 10:21:31 2023 ] 	Mean test loss of 796 batches: 1.1884111450545152.
[ Tue Jan 10 10:21:32 2023 ] 	Top1: 65.63%
[ Tue Jan 10 10:21:33 2023 ] 	Top5: 90.50%
[ Tue Jan 10 10:21:34 2023 ] Training epoch: 26
[ Tue Jan 10 10:42:47 2023 ] 	Mean training loss: 0.8852.  Mean training acc: 73.69%.
[ Tue Jan 10 10:42:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 10:42:48 2023 ] Eval epoch: 26
[ Tue Jan 10 10:56:39 2023 ] 	Mean test loss of 796 batches: 1.2160163747156085.
[ Tue Jan 10 10:56:40 2023 ] 	Top1: 65.24%
[ Tue Jan 10 10:56:40 2023 ] 	Top5: 91.08%
[ Tue Jan 10 10:56:41 2023 ] Training epoch: 27
[ Tue Jan 10 11:17:53 2023 ] 	Mean training loss: 0.8850.  Mean training acc: 73.64%.
[ Tue Jan 10 11:17:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:17:55 2023 ] Eval epoch: 27
[ Tue Jan 10 11:29:48 2023 ] 	Mean test loss of 796 batches: 1.2719190182847593.
[ Tue Jan 10 11:29:49 2023 ] 	Top1: 63.11%
[ Tue Jan 10 11:29:50 2023 ] 	Top5: 89.64%
[ Tue Jan 10 11:29:50 2023 ] Training epoch: 28
[ Tue Jan 10 11:49:46 2023 ] 	Mean training loss: 0.8789.  Mean training acc: 73.94%.
[ Tue Jan 10 11:49:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:49:48 2023 ] Eval epoch: 28
[ Tue Jan 10 12:02:23 2023 ] 	Mean test loss of 796 batches: 1.2838128934328878.
[ Tue Jan 10 12:02:24 2023 ] 	Top1: 63.08%
[ Tue Jan 10 12:02:24 2023 ] 	Top5: 89.24%
[ Tue Jan 10 12:02:25 2023 ] Training epoch: 29
[ Tue Jan 10 12:23:11 2023 ] 	Mean training loss: 0.8672.  Mean training acc: 74.04%.
[ Tue Jan 10 12:23:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:23:14 2023 ] Eval epoch: 29
[ Tue Jan 10 12:36:11 2023 ] 	Mean test loss of 796 batches: 1.2508204649740726.
[ Tue Jan 10 12:36:12 2023 ] 	Top1: 65.08%
[ Tue Jan 10 12:36:13 2023 ] 	Top5: 90.51%
[ Tue Jan 10 12:36:13 2023 ] Training epoch: 30
[ Tue Jan 10 12:57:09 2023 ] 	Mean training loss: 0.8682.  Mean training acc: 73.97%.
[ Tue Jan 10 12:57:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:57:13 2023 ] Eval epoch: 30
[ Tue Jan 10 13:09:30 2023 ] 	Mean test loss of 796 batches: 1.2099626871134768.
[ Tue Jan 10 13:09:32 2023 ] 	Top1: 64.99%
[ Tue Jan 10 13:09:32 2023 ] 	Top5: 89.94%
[ Tue Jan 10 13:09:33 2023 ] Training epoch: 31
[ Tue Jan 10 13:30:27 2023 ] 	Mean training loss: 0.8601.  Mean training acc: 74.34%.
[ Tue Jan 10 13:30:27 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:30:29 2023 ] Eval epoch: 31
[ Tue Jan 10 13:42:37 2023 ] 	Mean test loss of 796 batches: 1.1470364310109435.
[ Tue Jan 10 13:42:40 2023 ] 	Top1: 65.93%
[ Tue Jan 10 13:42:40 2023 ] 	Top5: 91.05%
[ Tue Jan 10 13:42:43 2023 ] Training epoch: 32
[ Tue Jan 10 14:04:51 2023 ] 	Mean training loss: 0.8692.  Mean training acc: 73.96%.
[ Tue Jan 10 14:04:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 14:05:00 2023 ] Eval epoch: 32
[ Tue Jan 10 14:17:58 2023 ] 	Mean test loss of 796 batches: 1.3390556275844574.
[ Tue Jan 10 14:18:02 2023 ] 	Top1: 64.02%
[ Tue Jan 10 14:18:02 2023 ] 	Top5: 90.59%
[ Tue Jan 10 14:18:06 2023 ] Training epoch: 33
[ Tue Jan 10 14:40:52 2023 ] 	Mean training loss: 0.8583.  Mean training acc: 74.40%.
[ Tue Jan 10 14:40:54 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 14:40:57 2023 ] Eval epoch: 33
[ Tue Jan 10 14:54:33 2023 ] 	Mean test loss of 796 batches: 1.21633633862638.
[ Tue Jan 10 14:54:36 2023 ] 	Top1: 65.17%
[ Tue Jan 10 14:54:36 2023 ] 	Top5: 91.58%
[ Tue Jan 10 14:54:39 2023 ] Training epoch: 34
[ Tue Jan 10 15:16:43 2023 ] 	Mean training loss: 0.8529.  Mean training acc: 74.54%.
[ Tue Jan 10 15:16:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:16:48 2023 ] Eval epoch: 34
[ Tue Jan 10 15:30:11 2023 ] 	Mean test loss of 796 batches: 1.2619433041718138.
[ Tue Jan 10 15:30:13 2023 ] 	Top1: 63.28%
[ Tue Jan 10 15:30:14 2023 ] 	Top5: 90.00%
[ Tue Jan 10 15:30:16 2023 ] Training epoch: 35
[ Tue Jan 10 15:52:37 2023 ] 	Mean training loss: 0.8481.  Mean training acc: 74.69%.
[ Tue Jan 10 15:52:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:52:43 2023 ] Eval epoch: 35
[ Tue Jan 10 16:06:20 2023 ] 	Mean test loss of 796 batches: 1.1383560737922562.
[ Tue Jan 10 16:06:23 2023 ] 	Top1: 66.39%
[ Tue Jan 10 16:06:23 2023 ] 	Top5: 91.41%
[ Tue Jan 10 16:06:25 2023 ] Training epoch: 36
[ Tue Jan 10 16:28:38 2023 ] 	Mean training loss: 0.5250.  Mean training acc: 84.36%.
[ Tue Jan 10 16:28:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 16:28:41 2023 ] Eval epoch: 36
[ Tue Jan 10 16:42:54 2023 ] 	Mean test loss of 796 batches: 0.6879428229177716.
[ Tue Jan 10 16:42:57 2023 ] 	Top1: 78.88%
[ Tue Jan 10 16:42:57 2023 ] 	Top5: 95.86%
[ Tue Jan 10 16:43:00 2023 ] Training epoch: 37
[ Tue Jan 10 17:09:10 2023 ] 	Mean training loss: 0.4300.  Mean training acc: 87.00%.
[ Tue Jan 10 17:09:15 2023 ] 	Time consumption: [Data]01%, [Network]85%
[ Tue Jan 10 17:09:21 2023 ] Eval epoch: 37
[ Tue Jan 10 17:23:24 2023 ] 	Mean test loss of 796 batches: 0.7001251970703278.
[ Tue Jan 10 17:23:29 2023 ] 	Top1: 78.54%
[ Tue Jan 10 17:23:29 2023 ] 	Top5: 95.82%
[ Tue Jan 10 17:23:33 2023 ] Training epoch: 38
[ Tue Jan 10 17:46:28 2023 ] 	Mean training loss: 0.3956.  Mean training acc: 87.94%.
[ Tue Jan 10 17:46:32 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 17:46:37 2023 ] Eval epoch: 38
[ Tue Jan 10 18:00:25 2023 ] 	Mean test loss of 796 batches: 0.6743740406374087.
[ Tue Jan 10 18:00:31 2023 ] 	Top1: 79.43%
[ Tue Jan 10 18:00:31 2023 ] 	Top5: 96.09%
[ Tue Jan 10 18:00:34 2023 ] Training epoch: 39
[ Tue Jan 10 18:31:50 2023 ] 	Mean training loss: 0.3670.  Mean training acc: 88.92%.
[ Tue Jan 10 18:31:56 2023 ] 	Time consumption: [Data]01%, [Network]89%
[ Tue Jan 10 18:31:59 2023 ] Eval epoch: 39
[ Tue Jan 10 18:50:25 2023 ] 	Mean test loss of 796 batches: 0.6824278253968337.
[ Tue Jan 10 18:50:27 2023 ] 	Top1: 79.32%
[ Tue Jan 10 18:50:27 2023 ] 	Top5: 96.06%
[ Tue Jan 10 18:50:28 2023 ] Training epoch: 40
[ Tue Jan 10 19:18:44 2023 ] 	Mean training loss: 0.3456.  Mean training acc: 89.60%.
[ Tue Jan 10 19:18:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 19:18:49 2023 ] Eval epoch: 40
[ Tue Jan 10 19:37:49 2023 ] 	Mean test loss of 796 batches: 0.6619537939696606.
[ Tue Jan 10 19:37:51 2023 ] 	Top1: 80.00%
[ Tue Jan 10 19:37:51 2023 ] 	Top5: 96.16%
[ Tue Jan 10 19:37:52 2023 ] Training epoch: 41
[ Tue Jan 10 20:06:13 2023 ] 	Mean training loss: 0.3284.  Mean training acc: 90.15%.
[ Tue Jan 10 20:06:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:06:17 2023 ] Eval epoch: 41
[ Tue Jan 10 20:24:55 2023 ] 	Mean test loss of 796 batches: 0.6945621592072236.
[ Tue Jan 10 20:24:56 2023 ] 	Top1: 79.00%
[ Tue Jan 10 20:24:56 2023 ] 	Top5: 95.93%
[ Tue Jan 10 20:24:57 2023 ] Training epoch: 42
[ Tue Jan 10 20:53:37 2023 ] 	Mean training loss: 0.3128.  Mean training acc: 90.67%.
[ Tue Jan 10 20:53:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:53:47 2023 ] Eval epoch: 42
[ Tue Jan 10 21:11:57 2023 ] 	Mean test loss of 796 batches: 0.6844486510334302.
[ Tue Jan 10 21:11:58 2023 ] 	Top1: 79.75%
[ Tue Jan 10 21:11:59 2023 ] 	Top5: 96.10%
[ Tue Jan 10 21:12:00 2023 ] Training epoch: 43
[ Tue Jan 10 21:40:52 2023 ] 	Mean training loss: 0.3033.  Mean training acc: 90.94%.
[ Tue Jan 10 21:40:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 21:40:53 2023 ] Eval epoch: 43
[ Tue Jan 10 21:58:38 2023 ] 	Mean test loss of 796 batches: 0.6985491099650386.
[ Tue Jan 10 21:58:39 2023 ] 	Top1: 79.58%
[ Tue Jan 10 21:58:40 2023 ] 	Top5: 95.99%
[ Tue Jan 10 21:58:41 2023 ] Training epoch: 44
[ Tue Jan 10 22:27:31 2023 ] 	Mean training loss: 0.2945.  Mean training acc: 91.26%.
[ Tue Jan 10 22:27:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 22:27:33 2023 ] Eval epoch: 44
[ Tue Jan 10 22:45:40 2023 ] 	Mean test loss of 796 batches: 0.710781656907656.
[ Tue Jan 10 22:45:42 2023 ] 	Top1: 79.50%
[ Tue Jan 10 22:45:43 2023 ] 	Top5: 95.82%
[ Tue Jan 10 22:45:43 2023 ] Training epoch: 45
[ Tue Jan 10 23:14:00 2023 ] 	Mean training loss: 0.2860.  Mean training acc: 91.49%.
[ Tue Jan 10 23:14:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 23:14:03 2023 ] Eval epoch: 45
[ Tue Jan 10 23:31:56 2023 ] 	Mean test loss of 796 batches: 0.7416379058443422.
[ Tue Jan 10 23:31:58 2023 ] 	Top1: 78.73%
[ Tue Jan 10 23:31:59 2023 ] 	Top5: 95.78%
[ Tue Jan 10 23:31:59 2023 ] Training epoch: 46
[ Wed Jan 11 00:06:48 2023 ] 	Mean training loss: 0.2785.  Mean training acc: 91.73%.
[ Wed Jan 11 00:06:49 2023 ] 	Time consumption: [Data]01%, [Network]78%
[ Wed Jan 11 00:06:50 2023 ] Eval epoch: 46
[ Wed Jan 11 00:24:10 2023 ] 	Mean test loss of 796 batches: 0.7832711959473002.
[ Wed Jan 11 00:24:11 2023 ] 	Top1: 77.72%
[ Wed Jan 11 00:24:11 2023 ] 	Top5: 95.24%
[ Wed Jan 11 00:24:11 2023 ] Training epoch: 47
[ Wed Jan 11 00:55:17 2023 ] 	Mean training loss: 0.2739.  Mean training acc: 91.87%.
[ Wed Jan 11 00:55:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 00:55:18 2023 ] Eval epoch: 47
[ Wed Jan 11 01:14:40 2023 ] 	Mean test loss of 796 batches: 0.7400126739512736.
[ Wed Jan 11 01:14:40 2023 ] 	Top1: 79.20%
[ Wed Jan 11 01:14:41 2023 ] 	Top5: 95.70%
[ Wed Jan 11 01:14:42 2023 ] Training epoch: 48
[ Wed Jan 11 01:45:31 2023 ] 	Mean training loss: 0.2752.  Mean training acc: 91.84%.
[ Wed Jan 11 01:45:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 01:45:47 2023 ] Eval epoch: 48
[ Wed Jan 11 02:05:11 2023 ] 	Mean test loss of 796 batches: 0.7786480277851598.
[ Wed Jan 11 02:05:13 2023 ] 	Top1: 77.97%
[ Wed Jan 11 02:05:13 2023 ] 	Top5: 95.54%
[ Wed Jan 11 02:05:14 2023 ] Training epoch: 49
[ Wed Jan 11 02:36:17 2023 ] 	Mean training loss: 0.2693.  Mean training acc: 91.94%.
[ Wed Jan 11 02:36:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 02:36:18 2023 ] Eval epoch: 49
[ Wed Jan 11 02:56:01 2023 ] 	Mean test loss of 796 batches: 0.7980343201408284.
[ Wed Jan 11 02:56:01 2023 ] 	Top1: 78.10%
[ Wed Jan 11 02:56:02 2023 ] 	Top5: 95.35%
[ Wed Jan 11 02:56:02 2023 ] Training epoch: 50
[ Wed Jan 11 03:24:54 2023 ] 	Mean training loss: 0.2675.  Mean training acc: 92.07%.
[ Wed Jan 11 03:24:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 03:24:55 2023 ] Eval epoch: 50
[ Wed Jan 11 03:43:07 2023 ] 	Mean test loss of 796 batches: 0.8343540121749717.
[ Wed Jan 11 03:43:08 2023 ] 	Top1: 76.64%
[ Wed Jan 11 03:43:09 2023 ] 	Top5: 94.71%
[ Wed Jan 11 03:43:09 2023 ] Training epoch: 51
[ Wed Jan 11 04:11:50 2023 ] 	Mean training loss: 0.2635.  Mean training acc: 92.10%.
[ Wed Jan 11 04:11:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:11:52 2023 ] Eval epoch: 51
[ Wed Jan 11 04:29:56 2023 ] 	Mean test loss of 796 batches: 0.7878755170608586.
[ Wed Jan 11 04:29:57 2023 ] 	Top1: 78.25%
[ Wed Jan 11 04:29:58 2023 ] 	Top5: 95.44%
[ Wed Jan 11 04:29:58 2023 ] Training epoch: 52
[ Wed Jan 11 04:58:35 2023 ] 	Mean training loss: 0.2625.  Mean training acc: 92.20%.
[ Wed Jan 11 04:58:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:58:45 2023 ] Eval epoch: 52
[ Wed Jan 11 05:16:21 2023 ] 	Mean test loss of 796 batches: 0.7603467513980279.
[ Wed Jan 11 05:16:22 2023 ] 	Top1: 78.81%
[ Wed Jan 11 05:16:23 2023 ] 	Top5: 95.79%
[ Wed Jan 11 05:16:23 2023 ] Training epoch: 53
[ Wed Jan 11 05:45:25 2023 ] 	Mean training loss: 0.2577.  Mean training acc: 92.35%.
[ Wed Jan 11 05:45:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 05:45:36 2023 ] Eval epoch: 53
[ Wed Jan 11 12:54:16 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-52-51168.pt.
[ Wed Jan 11 12:54:20 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:54:32 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-52-51168.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 52, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:54:32 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:54:32 2023 ] Training epoch: 53
[ Wed Jan 11 12:55:45 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-52-51168.pt.
[ Wed Jan 11 12:55:48 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:56:07 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-52-51168.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 52, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:56:07 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:56:07 2023 ] Training epoch: 53
[ Wed Jan 11 12:57:14 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT_vel/runs-52-51168.pt.
[ Wed Jan 11 12:57:17 2023 ] using warm up, epoch: 0
[ Wed Jan 11 12:57:30 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT_vel/runs-52-51168.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 52, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 12:57:30 2023 ] # Parameters: 1508876
[ Wed Jan 11 12:57:30 2023 ] Training epoch: 53
[ Wed Jan 11 13:23:25 2023 ] 	Mean training loss: 0.2553.  Mean training acc: 92.43%.
[ Wed Jan 11 13:23:29 2023 ] 	Time consumption: [Data]01%, [Network]93%
[ Wed Jan 11 13:23:29 2023 ] Eval epoch: 53
[ Wed Jan 11 13:42:04 2023 ] 	Mean test loss of 796 batches: 0.8283984925429425.
[ Wed Jan 11 13:42:06 2023 ] 	Top1: 76.98%
[ Wed Jan 11 13:42:07 2023 ] 	Top5: 94.91%
[ Wed Jan 11 13:42:07 2023 ] Training epoch: 54
[ Wed Jan 11 14:15:22 2023 ] 	Mean training loss: 0.2545.  Mean training acc: 92.40%.
[ Wed Jan 11 14:15:23 2023 ] 	Time consumption: [Data]01%, [Network]82%
[ Wed Jan 11 14:15:24 2023 ] Eval epoch: 54
[ Wed Jan 11 14:33:32 2023 ] 	Mean test loss of 796 batches: 0.7779730688499745.
[ Wed Jan 11 14:33:33 2023 ] 	Top1: 78.05%
[ Wed Jan 11 14:33:34 2023 ] 	Top5: 95.40%
[ Wed Jan 11 14:33:34 2023 ] Training epoch: 55
[ Wed Jan 11 15:05:30 2023 ] 	Mean training loss: 0.2566.  Mean training acc: 92.35%.
[ Wed Jan 11 15:05:32 2023 ] 	Time consumption: [Data]01%, [Network]90%
[ Wed Jan 11 15:05:32 2023 ] Eval epoch: 55
[ Wed Jan 11 15:23:09 2023 ] 	Mean test loss of 796 batches: 0.7910337637567041.
[ Wed Jan 11 15:23:10 2023 ] 	Top1: 78.29%
[ Wed Jan 11 15:23:11 2023 ] 	Top5: 95.52%
[ Wed Jan 11 15:23:11 2023 ] Training epoch: 56
[ Wed Jan 11 16:15:50 2023 ] 	Mean training loss: 0.1651.  Mean training acc: 95.62%.
[ Wed Jan 11 16:15:51 2023 ] 	Time consumption: [Data]00%, [Network]72%
[ Wed Jan 11 16:15:52 2023 ] Eval epoch: 56
[ Wed Jan 11 16:38:13 2023 ] 	Mean test loss of 796 batches: 0.688963210491005.
[ Wed Jan 11 16:38:14 2023 ] 	Top1: 80.65%
[ Wed Jan 11 16:38:15 2023 ] 	Top5: 96.17%
[ Wed Jan 11 16:38:15 2023 ] Training epoch: 57
[ Wed Jan 11 17:15:04 2023 ] 	Mean training loss: 0.1304.  Mean training acc: 96.68%.
[ Wed Jan 11 17:15:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 17:15:05 2023 ] Eval epoch: 57
[ Wed Jan 11 17:31:42 2023 ] 	Mean test loss of 796 batches: 0.690496848596625.
[ Wed Jan 11 17:31:43 2023 ] 	Top1: 81.03%
[ Wed Jan 11 17:31:43 2023 ] 	Top5: 96.28%
[ Wed Jan 11 17:31:43 2023 ] Training epoch: 58
[ Wed Jan 11 17:49:08 2023 ] 	Mean training loss: 0.1161.  Mean training acc: 97.19%.
[ Wed Jan 11 17:49:09 2023 ] 	Time consumption: [Data]01%, [Network]96%
[ Wed Jan 11 17:49:09 2023 ] Eval epoch: 58
[ Wed Jan 11 17:58:27 2023 ] 	Mean test loss of 796 batches: 0.7069359991100416.
[ Wed Jan 11 17:58:27 2023 ] 	Top1: 80.89%
[ Wed Jan 11 17:58:28 2023 ] 	Top5: 96.14%
[ Wed Jan 11 17:58:28 2023 ] Training epoch: 59
[ Wed Jan 11 18:19:19 2023 ] 	Mean training loss: 0.1084.  Mean training acc: 97.37%.
[ Wed Jan 11 18:19:21 2023 ] 	Time consumption: [Data]00%, [Network]78%
[ Wed Jan 11 18:19:22 2023 ] Eval epoch: 59
[ Wed Jan 11 18:28:50 2023 ] 	Mean test loss of 796 batches: 0.7078243346332606.
[ Wed Jan 11 18:28:51 2023 ] 	Top1: 80.88%
[ Wed Jan 11 18:28:51 2023 ] 	Top5: 96.04%
[ Wed Jan 11 18:28:51 2023 ] Training epoch: 60
[ Wed Jan 11 18:45:25 2023 ] 	Mean training loss: 0.1036.  Mean training acc: 97.55%.
[ Wed Jan 11 18:45:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 18:45:26 2023 ] Eval epoch: 60
[ Wed Jan 11 18:54:22 2023 ] 	Mean test loss of 796 batches: 0.7023924742006327.
[ Wed Jan 11 18:54:23 2023 ] 	Top1: 81.18%
[ Wed Jan 11 18:54:23 2023 ] 	Top5: 96.20%
[ Wed Jan 11 18:54:23 2023 ] Training epoch: 61
[ Wed Jan 11 19:14:02 2023 ] 	Mean training loss: 0.0983.  Mean training acc: 97.78%.
[ Wed Jan 11 19:14:03 2023 ] 	Time consumption: [Data]00%, [Network]77%
[ Wed Jan 11 19:14:05 2023 ] Eval epoch: 61
[ Wed Jan 11 19:22:32 2023 ] 	Mean test loss of 796 batches: 0.7040598307123136.
[ Wed Jan 11 19:24:45 2023 ] 	Top1: 81.08%
[ Wed Jan 11 19:24:45 2023 ] 	Top5: 96.16%
[ Wed Jan 11 19:24:46 2023 ] Training epoch: 62
[ Wed Jan 11 19:40:51 2023 ] 	Mean training loss: 0.0932.  Mean training acc: 97.91%.
[ Wed Jan 11 19:40:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 19:40:51 2023 ] Eval epoch: 62
[ Wed Jan 11 19:48:54 2023 ] 	Mean test loss of 796 batches: 0.7019273231938556.
[ Wed Jan 11 19:48:55 2023 ] 	Top1: 81.19%
[ Wed Jan 11 19:48:55 2023 ] 	Top5: 96.18%
[ Wed Jan 11 19:48:56 2023 ] Training epoch: 63
[ Wed Jan 11 20:05:37 2023 ] 	Mean training loss: 0.0909.  Mean training acc: 97.98%.
[ Wed Jan 11 20:05:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 20:05:39 2023 ] Eval epoch: 63
[ Wed Jan 11 20:14:31 2023 ] 	Mean test loss of 796 batches: 0.7242197007614763.
[ Wed Jan 11 20:14:32 2023 ] 	Top1: 80.52%
[ Wed Jan 11 20:14:33 2023 ] 	Top5: 95.98%
[ Wed Jan 11 20:14:33 2023 ] Training epoch: 64
[ Wed Jan 11 20:33:19 2023 ] 	Mean training loss: 0.0874.  Mean training acc: 97.98%.
[ Wed Jan 11 20:33:19 2023 ] 	Time consumption: [Data]01%, [Network]87%
[ Wed Jan 11 20:33:19 2023 ] Eval epoch: 64
[ Wed Jan 11 20:42:17 2023 ] 	Mean test loss of 796 batches: 0.7249965124936709.
[ Wed Jan 11 20:42:18 2023 ] 	Top1: 80.64%
[ Wed Jan 11 20:42:19 2023 ] 	Top5: 95.95%
[ Wed Jan 11 20:42:19 2023 ] Training epoch: 65
[ Wed Jan 11 21:09:49 2023 ] 	Mean training loss: 0.0866.  Mean training acc: 98.05%.
[ Wed Jan 11 21:09:49 2023 ] 	Time consumption: [Data]00%, [Network]62%
[ Wed Jan 11 21:09:49 2023 ] Eval epoch: 65
[ Wed Jan 11 21:18:17 2023 ] 	Mean test loss of 796 batches: 0.721000709837705.
[ Wed Jan 11 21:18:17 2023 ] 	Top1: 81.11%
[ Wed Jan 11 21:18:18 2023 ] 	Top5: 95.95%
[ Wed Jan 11 21:27:31 2023 ] Best accuracy: 0.8118580490583083
[ Wed Jan 11 21:27:32 2023 ] Epoch number: 62
[ Wed Jan 11 21:27:32 2023 ] Model name: work_dir/csub/ctrgcn_local_SHT_vel
[ Wed Jan 11 21:27:32 2023 ] Model total number of params: 1508876
[ Wed Jan 11 21:27:32 2023 ] Weight decay: 0.0004
[ Wed Jan 11 21:27:32 2023 ] Base LR: 0.1
[ Wed Jan 11 21:27:32 2023 ] Batch Size: 64
[ Wed Jan 11 21:27:32 2023 ] Test Batch Size: 64
[ Wed Jan 11 21:27:32 2023 ] seed: 1
[ Fri Feb  3 15:25:10 2023 ] using warm up, epoch: 5
[ Fri Feb  3 15:27:08 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Fri Feb  3 15:27:08 2023 ] # Parameters: 1508876
[ Fri Feb  3 15:27:08 2023 ] Training epoch: 1
[ Fri Feb  3 19:16:43 2023 ] 	Mean training loss: 3.2577.  Mean training acc: 21.61%.
[ Fri Feb  3 19:16:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Feb  3 19:16:43 2023 ] Eval epoch: 1
[ Fri Feb  3 22:12:05 2023 ] 	Mean test loss of 796 batches: 2.5176191872088753.
[ Fri Feb  3 22:12:06 2023 ] 	Top1: 33.02%
[ Fri Feb  3 22:12:06 2023 ] 	Top5: 65.00%
[ Fri Feb  3 22:12:06 2023 ] Training epoch: 2
[ Sat Feb  4 02:20:55 2023 ] 	Mean training loss: 2.0684.  Mean training acc: 43.23%.
[ Sat Feb  4 02:20:55 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 02:20:55 2023 ] Eval epoch: 2
[ Sat Feb  4 05:29:51 2023 ] 	Mean test loss of 796 batches: 1.8404457676201011.
[ Sat Feb  4 05:29:51 2023 ] 	Top1: 47.61%
[ Sat Feb  4 05:29:52 2023 ] 	Top5: 79.60%
[ Sat Feb  4 05:29:52 2023 ] Training epoch: 3
[ Sat Feb  4 09:00:35 2023 ] 	Mean training loss: 1.6204.  Mean training acc: 54.09%.
[ Sat Feb  4 09:00:38 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 09:00:39 2023 ] Eval epoch: 3
[ Sat Feb  4 11:34:59 2023 ] 	Mean test loss of 796 batches: 1.757516563238211.
[ Sat Feb  4 11:35:00 2023 ] 	Top1: 50.15%
[ Sat Feb  4 11:35:00 2023 ] 	Top5: 81.38%
[ Sat Feb  4 11:35:00 2023 ] Training epoch: 4
[ Sat Feb  4 13:11:47 2023 ] 	Mean training loss: 1.4327.  Mean training acc: 58.86%.
[ Sat Feb  4 13:11:47 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 13:11:47 2023 ] Eval epoch: 4
[ Sat Feb  4 13:26:01 2023 ] 	Mean test loss of 796 batches: 1.6795383768914334.
[ Sat Feb  4 13:26:01 2023 ] 	Top1: 53.99%
[ Sat Feb  4 13:26:02 2023 ] 	Top5: 83.23%
[ Sat Feb  4 13:26:02 2023 ] Training epoch: 5
[ Sat Feb  4 16:58:25 2023 ] 	Mean training loss: 1.3301.  Mean training acc: 61.59%.
[ Sat Feb  4 16:58:25 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 16:58:25 2023 ] Eval epoch: 5
[ Sat Feb  4 19:44:01 2023 ] 	Mean test loss of 796 batches: 1.7378019576695696.
[ Sat Feb  4 19:44:02 2023 ] 	Top1: 50.22%
[ Sat Feb  4 19:44:02 2023 ] 	Top5: 82.31%
[ Sat Feb  4 19:44:02 2023 ] Training epoch: 6
[ Sat Feb  4 23:00:06 2023 ] 	Mean training loss: 1.2118.  Mean training acc: 64.68%.
[ Sat Feb  4 23:00:06 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Feb  4 23:00:06 2023 ] Eval epoch: 6
[ Sun Feb  5 01:46:27 2023 ] 	Mean test loss of 796 batches: 1.356488110881355.
[ Sun Feb  5 01:46:28 2023 ] 	Top1: 60.20%
[ Sun Feb  5 01:46:28 2023 ] 	Top5: 88.26%
[ Sun Feb  5 01:46:28 2023 ] Training epoch: 7
[ Sun Feb  5 06:02:22 2023 ] 	Mean training loss: 1.1357.  Mean training acc: 66.76%.
[ Sun Feb  5 06:02:23 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 06:02:23 2023 ] Eval epoch: 7
[ Sun Feb  5 08:29:59 2023 ] 	Mean test loss of 796 batches: 1.6072239079068054.
[ Sun Feb  5 08:29:59 2023 ] 	Top1: 54.10%
[ Sun Feb  5 08:30:00 2023 ] 	Top5: 84.38%
[ Sun Feb  5 08:30:00 2023 ] Training epoch: 8
[ Sun Feb  5 12:22:05 2023 ] 	Mean training loss: 1.0918.  Mean training acc: 67.86%.
[ Sun Feb  5 12:22:05 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 12:22:05 2023 ] Eval epoch: 8
[ Sun Feb  5 12:39:51 2023 ] 	Mean test loss of 796 batches: 1.4638248413950954.
[ Sun Feb  5 12:39:51 2023 ] 	Top1: 59.14%
[ Sun Feb  5 12:39:52 2023 ] 	Top5: 86.60%
[ Sun Feb  5 12:39:52 2023 ] Training epoch: 9
[ Sun Feb  5 14:53:37 2023 ] 	Mean training loss: 1.0631.  Mean training acc: 68.76%.
[ Sun Feb  5 14:53:37 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 14:53:37 2023 ] Eval epoch: 9
[ Sun Feb  5 17:03:44 2023 ] 	Mean test loss of 796 batches: 1.6130913722904483.
[ Sun Feb  5 17:03:44 2023 ] 	Top1: 55.18%
[ Sun Feb  5 17:03:45 2023 ] 	Top5: 84.04%
[ Sun Feb  5 17:03:45 2023 ] Training epoch: 10
[ Sun Feb  5 20:34:21 2023 ] 	Mean training loss: 1.0307.  Mean training acc: 69.46%.
[ Sun Feb  5 20:34:21 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 20:34:22 2023 ] Eval epoch: 10
[ Sun Feb  5 21:33:38 2023 ] 	Mean test loss of 796 batches: 1.363441512737442.
[ Sun Feb  5 21:33:38 2023 ] 	Top1: 60.59%
[ Sun Feb  5 21:33:39 2023 ] 	Top5: 89.13%
[ Sun Feb  5 21:33:39 2023 ] Training epoch: 11
[ Sun Feb  5 23:46:52 2023 ] 	Mean training loss: 1.0057.  Mean training acc: 70.32%.
[ Sun Feb  5 23:46:52 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Feb  5 23:46:52 2023 ] Eval epoch: 11
[ Mon Feb  6 01:04:57 2023 ] 	Mean test loss of 796 batches: 1.236356791239887.
[ Mon Feb  6 01:04:57 2023 ] 	Top1: 64.04%
[ Mon Feb  6 01:04:58 2023 ] 	Top5: 90.37%
[ Mon Feb  6 01:04:58 2023 ] Training epoch: 12
[ Mon Feb  6 01:28:51 2023 ] 	Mean training loss: 0.9988.  Mean training acc: 70.40%.
[ Mon Feb  6 01:28:51 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 01:28:51 2023 ] Eval epoch: 12
[ Mon Feb  6 01:43:21 2023 ] 	Mean test loss of 796 batches: 1.4536944378410752.
[ Mon Feb  6 01:43:22 2023 ] 	Top1: 58.43%
[ Mon Feb  6 01:43:22 2023 ] 	Top5: 87.42%
[ Mon Feb  6 01:43:22 2023 ] Training epoch: 13
[ Mon Feb  6 02:06:59 2023 ] 	Mean training loss: 0.9929.  Mean training acc: 70.63%.
[ Mon Feb  6 02:06:59 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 02:06:59 2023 ] Eval epoch: 13
[ Mon Feb  6 02:29:39 2023 ] 	Mean test loss of 796 batches: 1.5188284346356464.
[ Mon Feb  6 02:29:39 2023 ] 	Top1: 58.69%
[ Mon Feb  6 02:29:40 2023 ] 	Top5: 85.82%
[ Mon Feb  6 02:29:40 2023 ] Training epoch: 14
[ Mon Feb  6 09:54:39 2023 ] 	Mean training loss: 0.9742.  Mean training acc: 71.08%.
[ Mon Feb  6 09:54:40 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Feb  6 09:54:41 2023 ] Eval epoch: 14
[ Mon Feb  6 13:59:59 2023 ] 	Mean test loss of 796 batches: 1.2448058620319893.
[ Mon Feb  6 14:00:00 2023 ] 	Top1: 64.30%
[ Mon Feb  6 14:00:00 2023 ] 	Top5: 89.66%
[ Mon Feb  6 14:00:01 2023 ] Training epoch: 15
[ Mon Feb  6 16:58:31 2023 ] 	Mean training loss: 0.9539.  Mean training acc: 71.72%.
[ Mon Feb  6 16:58:31 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 16:58:31 2023 ] Eval epoch: 15
[ Mon Feb  6 17:18:44 2023 ] 	Mean test loss of 796 batches: 1.2723778249255975.
[ Mon Feb  6 17:18:45 2023 ] 	Top1: 63.90%
[ Mon Feb  6 17:18:45 2023 ] 	Top5: 90.00%
[ Mon Feb  6 17:18:45 2023 ] Training epoch: 16
[ Mon Feb  6 17:41:59 2023 ] 	Mean training loss: 0.9417.  Mean training acc: 72.02%.
[ Mon Feb  6 17:41:59 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 17:41:59 2023 ] Eval epoch: 16
[ Mon Feb  6 17:56:29 2023 ] 	Mean test loss of 796 batches: 1.6532197278648166.
[ Mon Feb  6 17:56:30 2023 ] 	Top1: 53.65%
[ Mon Feb  6 17:56:30 2023 ] 	Top5: 84.13%
[ Mon Feb  6 17:56:30 2023 ] Training epoch: 17
[ Mon Feb  6 21:39:58 2023 ] 	Mean training loss: 0.9323.  Mean training acc: 72.21%.
[ Mon Feb  6 21:39:58 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Feb  6 21:39:58 2023 ] Eval epoch: 17
[ Tue Feb  7 00:43:55 2023 ] 	Mean test loss of 796 batches: 1.2939520885596922.
[ Tue Feb  7 00:43:56 2023 ] 	Top1: 62.90%
[ Tue Feb  7 00:43:56 2023 ] 	Top5: 89.46%
[ Tue Feb  7 00:43:56 2023 ] Training epoch: 18
[ Tue Feb  7 05:19:29 2023 ] 	Mean training loss: 0.9303.  Mean training acc: 72.29%.
[ Tue Feb  7 05:19:29 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 05:19:29 2023 ] Eval epoch: 18
[ Tue Feb  7 07:45:07 2023 ] 	Mean test loss of 796 batches: 1.2463611496153788.
[ Tue Feb  7 07:45:08 2023 ] 	Top1: 63.18%
[ Tue Feb  7 07:45:09 2023 ] 	Top5: 91.01%
[ Tue Feb  7 07:45:09 2023 ] Training epoch: 19
[ Tue Feb  7 11:19:28 2023 ] 	Mean training loss: 0.9173.  Mean training acc: 72.67%.
[ Tue Feb  7 11:19:30 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 11:19:31 2023 ] Eval epoch: 19
[ Tue Feb  7 13:08:22 2023 ] 	Mean test loss of 796 batches: 1.4714855705972891.
[ Tue Feb  7 13:08:23 2023 ] 	Top1: 60.57%
[ Tue Feb  7 13:08:23 2023 ] 	Top5: 88.44%
[ Tue Feb  7 13:08:24 2023 ] Training epoch: 20
[ Tue Feb  7 14:18:11 2023 ] 	Mean training loss: 0.9173.  Mean training acc: 72.40%.
[ Tue Feb  7 14:18:11 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 14:18:11 2023 ] Eval epoch: 20
[ Tue Feb  7 14:32:42 2023 ] 	Mean test loss of 796 batches: 1.3547490129443869.
[ Tue Feb  7 14:32:42 2023 ] 	Top1: 60.18%
[ Tue Feb  7 14:32:42 2023 ] 	Top5: 88.74%
[ Tue Feb  7 14:32:42 2023 ] Training epoch: 21
[ Tue Feb  7 18:17:50 2023 ] 	Mean training loss: 0.8993.  Mean training acc: 73.20%.
[ Tue Feb  7 18:17:50 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Feb  7 18:17:50 2023 ] Eval epoch: 21
[ Tue Feb  7 21:05:37 2023 ] 	Mean test loss of 796 batches: 1.2779940472326088.
[ Tue Feb  7 21:05:38 2023 ] 	Top1: 62.46%
[ Tue Feb  7 21:05:38 2023 ] 	Top5: 90.18%
[ Tue Feb  7 21:05:38 2023 ] Training epoch: 22
[ Wed Feb  8 01:05:20 2023 ] 	Mean training loss: 0.9003.  Mean training acc: 73.25%.
[ Wed Feb  8 01:05:20 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 01:05:20 2023 ] Eval epoch: 22
[ Wed Feb  8 04:01:44 2023 ] 	Mean test loss of 796 batches: 1.2446357513866833.
[ Wed Feb  8 04:01:44 2023 ] 	Top1: 63.80%
[ Wed Feb  8 04:01:44 2023 ] 	Top5: 89.01%
[ Wed Feb  8 04:01:45 2023 ] Training epoch: 23
[ Wed Feb  8 07:45:40 2023 ] 	Mean training loss: 0.8877.  Mean training acc: 73.65%.
[ Wed Feb  8 07:45:41 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 07:45:41 2023 ] Eval epoch: 23
[ Wed Feb  8 09:55:42 2023 ] 	Mean test loss of 796 batches: 1.370450785411662.
[ Wed Feb  8 09:55:43 2023 ] 	Top1: 62.78%
[ Wed Feb  8 09:55:43 2023 ] 	Top5: 89.08%
[ Wed Feb  8 09:55:46 2023 ] Training epoch: 24
[ Wed Feb  8 13:35:00 2023 ] 	Mean training loss: 0.8874.  Mean training acc: 73.76%.
[ Wed Feb  8 13:35:00 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  8 13:35:00 2023 ] Eval epoch: 24
[ Wed Feb 15 09:44:09 2023 ] using warm up, epoch: 5
[ Wed Feb 15 09:44:24 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT_vel', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Feb 15 09:44:24 2023 ] # Parameters: 1508876
[ Wed Feb 15 09:44:24 2023 ] Training epoch: 1
[ Wed Feb 15 10:01:58 2023 ] 	Mean training loss: 3.2738.  Mean training acc: 21.27%.
[ Wed Feb 15 10:01:58 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:01:58 2023 ] Eval epoch: 1
[ Wed Feb 15 10:11:48 2023 ] 	Mean test loss of 796 batches: 2.5030366204791332.
[ Wed Feb 15 10:11:48 2023 ] 	Top1: 32.43%
[ Wed Feb 15 10:11:48 2023 ] 	Top5: 65.45%
[ Wed Feb 15 10:11:49 2023 ] Training epoch: 2
[ Wed Feb 15 10:29:23 2023 ] 	Mean training loss: 2.0592.  Mean training acc: 43.41%.
[ Wed Feb 15 10:29:23 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:29:23 2023 ] Eval epoch: 2
[ Wed Feb 15 10:39:07 2023 ] 	Mean test loss of 796 batches: 1.8535748772585212.
[ Wed Feb 15 10:39:08 2023 ] 	Top1: 47.02%
[ Wed Feb 15 10:39:08 2023 ] 	Top5: 79.56%
[ Wed Feb 15 10:39:08 2023 ] Training epoch: 3
[ Wed Feb 15 10:56:39 2023 ] 	Mean training loss: 1.6196.  Mean training acc: 54.36%.
[ Wed Feb 15 10:56:39 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:56:39 2023 ] Eval epoch: 3
[ Wed Feb 15 11:06:21 2023 ] 	Mean test loss of 796 batches: 1.6478705767111563.
[ Wed Feb 15 11:06:22 2023 ] 	Top1: 52.33%
[ Wed Feb 15 11:06:22 2023 ] 	Top5: 83.49%
[ Wed Feb 15 11:06:22 2023 ] Training epoch: 4
[ Wed Feb 15 11:23:54 2023 ] 	Mean training loss: 1.4290.  Mean training acc: 58.91%.
[ Wed Feb 15 11:23:54 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:23:54 2023 ] Eval epoch: 4
[ Wed Feb 15 11:33:33 2023 ] 	Mean test loss of 796 batches: 1.5802226865561164.
[ Wed Feb 15 11:33:33 2023 ] 	Top1: 53.68%
[ Wed Feb 15 11:33:34 2023 ] 	Top5: 85.11%
[ Wed Feb 15 11:33:34 2023 ] Training epoch: 5
[ Wed Feb 15 11:51:05 2023 ] 	Mean training loss: 1.3318.  Mean training acc: 61.47%.
[ Wed Feb 15 11:51:05 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:51:05 2023 ] Eval epoch: 5
[ Wed Feb 15 12:00:45 2023 ] 	Mean test loss of 796 batches: 1.7627266398326835.
[ Wed Feb 15 12:00:45 2023 ] 	Top1: 51.14%
[ Wed Feb 15 12:00:45 2023 ] 	Top5: 82.19%
[ Wed Feb 15 12:00:45 2023 ] Training epoch: 6
[ Wed Feb 15 12:18:16 2023 ] 	Mean training loss: 1.2146.  Mean training acc: 64.62%.
[ Wed Feb 15 12:18:16 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:18:16 2023 ] Eval epoch: 6
[ Wed Feb 15 12:27:54 2023 ] 	Mean test loss of 796 batches: 1.382467481583806.
[ Wed Feb 15 12:27:55 2023 ] 	Top1: 59.82%
[ Wed Feb 15 12:27:55 2023 ] 	Top5: 87.40%
[ Wed Feb 15 12:27:55 2023 ] Training epoch: 7
[ Wed Feb 15 12:45:33 2023 ] 	Mean training loss: 1.1393.  Mean training acc: 66.62%.
[ Wed Feb 15 12:45:33 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:45:33 2023 ] Eval epoch: 7
[ Wed Feb 15 12:55:09 2023 ] 	Mean test loss of 796 batches: 1.6973783005422085.
[ Wed Feb 15 12:55:09 2023 ] 	Top1: 53.99%
[ Wed Feb 15 12:55:10 2023 ] 	Top5: 83.39%
[ Wed Feb 15 12:55:10 2023 ] Training epoch: 8
[ Wed Feb 15 13:12:45 2023 ] 	Mean training loss: 1.1015.  Mean training acc: 67.56%.
[ Wed Feb 15 13:12:45 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:12:45 2023 ] Eval epoch: 8
[ Wed Feb 15 13:21:54 2023 ] 	Mean test loss of 796 batches: 1.443273225771123.
[ Wed Feb 15 13:21:54 2023 ] 	Top1: 59.14%
[ Wed Feb 15 13:21:55 2023 ] 	Top5: 87.81%
[ Wed Feb 15 13:21:55 2023 ] Training epoch: 9
[ Wed Feb 15 13:39:26 2023 ] 	Mean training loss: 1.0574.  Mean training acc: 68.81%.
[ Wed Feb 15 13:39:26 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:39:26 2023 ] Eval epoch: 9
[ Wed Feb 15 13:49:06 2023 ] 	Mean test loss of 796 batches: 1.5991988938357962.
[ Wed Feb 15 13:49:07 2023 ] 	Top1: 55.41%
[ Wed Feb 15 13:49:07 2023 ] 	Top5: 86.01%
[ Wed Feb 15 13:49:07 2023 ] Training epoch: 10
[ Wed Feb 15 14:06:39 2023 ] 	Mean training loss: 1.0345.  Mean training acc: 69.57%.
[ Wed Feb 15 14:06:39 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:06:39 2023 ] Eval epoch: 10
[ Wed Feb 15 14:16:19 2023 ] 	Mean test loss of 796 batches: 1.3176044705674876.
[ Wed Feb 15 14:16:19 2023 ] 	Top1: 61.55%
[ Wed Feb 15 14:16:19 2023 ] 	Top5: 89.58%
[ Wed Feb 15 14:16:19 2023 ] Training epoch: 11
[ Wed Feb 15 14:33:53 2023 ] 	Mean training loss: 1.0116.  Mean training acc: 70.15%.
[ Wed Feb 15 14:33:53 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:33:53 2023 ] Eval epoch: 11
[ Wed Feb 15 14:43:29 2023 ] 	Mean test loss of 796 batches: 1.5606684206268895.
[ Wed Feb 15 14:43:29 2023 ] 	Top1: 56.68%
[ Wed Feb 15 14:43:30 2023 ] 	Top5: 85.55%
[ Wed Feb 15 14:43:30 2023 ] Training epoch: 12
[ Wed Feb 15 15:01:01 2023 ] 	Mean training loss: 0.9869.  Mean training acc: 70.71%.
[ Wed Feb 15 15:01:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:01:01 2023 ] Eval epoch: 12
[ Wed Feb 15 15:10:37 2023 ] 	Mean test loss of 796 batches: 1.3066747214401786.
[ Wed Feb 15 15:10:38 2023 ] 	Top1: 61.63%
[ Wed Feb 15 15:10:38 2023 ] 	Top5: 89.48%
[ Wed Feb 15 15:10:38 2023 ] Training epoch: 13
[ Wed Feb 15 15:28:12 2023 ] 	Mean training loss: 0.9712.  Mean training acc: 71.09%.
[ Wed Feb 15 15:28:12 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:28:12 2023 ] Eval epoch: 13
[ Wed Feb 15 15:37:42 2023 ] 	Mean test loss of 796 batches: 1.2800476123489926.
[ Wed Feb 15 15:37:43 2023 ] 	Top1: 61.75%
[ Wed Feb 15 15:37:43 2023 ] 	Top5: 89.47%
[ Wed Feb 15 15:37:43 2023 ] Training epoch: 14
[ Wed Feb 15 15:55:19 2023 ] 	Mean training loss: 0.9592.  Mean training acc: 71.44%.
[ Wed Feb 15 15:55:19 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:55:19 2023 ] Eval epoch: 14
[ Wed Feb 15 16:04:28 2023 ] 	Mean test loss of 796 batches: 1.3439315618507226.
[ Wed Feb 15 16:04:29 2023 ] 	Top1: 61.50%
[ Wed Feb 15 16:04:29 2023 ] 	Top5: 88.71%
[ Wed Feb 15 16:04:29 2023 ] Training epoch: 15
[ Wed Feb 15 16:22:00 2023 ] 	Mean training loss: 0.9413.  Mean training acc: 72.09%.
[ Wed Feb 15 16:22:00 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 16:22:00 2023 ] Eval epoch: 15
[ Wed Feb 15 16:31:32 2023 ] 	Mean test loss of 796 batches: 1.4043130241147237.
[ Wed Feb 15 16:31:32 2023 ] 	Top1: 59.82%
[ Wed Feb 15 16:31:33 2023 ] 	Top5: 87.14%
[ Wed Feb 15 16:31:33 2023 ] Training epoch: 16
[ Wed Feb 15 16:49:06 2023 ] 	Mean training loss: 0.9328.  Mean training acc: 72.16%.
[ Wed Feb 15 16:49:06 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 16:49:06 2023 ] Eval epoch: 16
[ Wed Feb 15 16:58:27 2023 ] 	Mean test loss of 796 batches: 1.4594482029951996.
[ Wed Feb 15 16:58:27 2023 ] 	Top1: 58.70%
[ Wed Feb 15 16:58:28 2023 ] 	Top5: 86.83%
[ Wed Feb 15 16:58:28 2023 ] Training epoch: 17
[ Wed Feb 15 17:16:04 2023 ] 	Mean training loss: 0.9291.  Mean training acc: 72.14%.
[ Wed Feb 15 17:16:04 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 17:16:04 2023 ] Eval epoch: 17
[ Wed Feb 15 17:25:35 2023 ] 	Mean test loss of 796 batches: 1.1740260254123702.
[ Wed Feb 15 17:25:36 2023 ] 	Top1: 65.55%
[ Wed Feb 15 17:25:36 2023 ] 	Top5: 90.79%
[ Wed Feb 15 17:25:36 2023 ] Training epoch: 18
[ Wed Feb 15 17:43:14 2023 ] 	Mean training loss: 0.9406.  Mean training acc: 72.03%.
[ Wed Feb 15 17:43:14 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 17:43:14 2023 ] Eval epoch: 18
[ Wed Feb 15 17:52:44 2023 ] 	Mean test loss of 796 batches: 1.2736382731540719.
[ Wed Feb 15 17:52:45 2023 ] 	Top1: 63.07%
[ Wed Feb 15 17:52:45 2023 ] 	Top5: 90.12%
[ Wed Feb 15 17:52:45 2023 ] Training epoch: 19
[ Wed Feb 15 18:10:24 2023 ] 	Mean training loss: 0.9241.  Mean training acc: 72.52%.
[ Wed Feb 15 18:10:24 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 18:10:24 2023 ] Eval epoch: 19
[ Wed Feb 15 18:19:56 2023 ] 	Mean test loss of 796 batches: 1.2608329132199287.
[ Wed Feb 15 18:19:56 2023 ] 	Top1: 63.17%
[ Wed Feb 15 18:19:57 2023 ] 	Top5: 90.46%
[ Wed Feb 15 18:19:57 2023 ] Training epoch: 20
[ Wed Feb 15 18:37:36 2023 ] 	Mean training loss: 0.9202.  Mean training acc: 72.87%.
[ Wed Feb 15 18:37:36 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 18:37:36 2023 ] Eval epoch: 20
[ Wed Feb 15 18:47:06 2023 ] 	Mean test loss of 796 batches: 1.3801434889585529.
[ Wed Feb 15 18:47:07 2023 ] 	Top1: 61.91%
[ Wed Feb 15 18:47:07 2023 ] 	Top5: 88.90%
[ Wed Feb 15 18:47:07 2023 ] Training epoch: 21
[ Wed Feb 15 19:04:46 2023 ] 	Mean training loss: 0.9040.  Mean training acc: 73.05%.
[ Wed Feb 15 19:04:46 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 19:04:46 2023 ] Eval epoch: 21
[ Wed Feb 15 19:14:16 2023 ] 	Mean test loss of 796 batches: 1.2393785741311223.
[ Wed Feb 15 19:14:17 2023 ] 	Top1: 64.16%
[ Wed Feb 15 19:14:17 2023 ] 	Top5: 89.93%
[ Wed Feb 15 19:14:17 2023 ] Training epoch: 22
[ Wed Feb 15 19:31:58 2023 ] 	Mean training loss: 0.9078.  Mean training acc: 72.94%.
[ Wed Feb 15 19:31:58 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 19:31:58 2023 ] Eval epoch: 22
[ Wed Feb 15 19:41:25 2023 ] 	Mean test loss of 796 batches: 1.2575744295389808.
[ Wed Feb 15 19:41:25 2023 ] 	Top1: 63.72%
[ Wed Feb 15 19:41:26 2023 ] 	Top5: 89.01%
[ Wed Feb 15 19:41:26 2023 ] Training epoch: 23
[ Wed Feb 15 19:59:05 2023 ] 	Mean training loss: 0.8946.  Mean training acc: 73.56%.
[ Wed Feb 15 19:59:05 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 19:59:05 2023 ] Eval epoch: 23
[ Wed Feb 15 20:08:37 2023 ] 	Mean test loss of 796 batches: 1.2413255375384087.
[ Wed Feb 15 20:08:38 2023 ] 	Top1: 63.31%
[ Wed Feb 15 20:08:38 2023 ] 	Top5: 89.77%
[ Wed Feb 15 20:08:38 2023 ] Training epoch: 24
[ Wed Feb 15 20:26:18 2023 ] 	Mean training loss: 0.8951.  Mean training acc: 73.47%.
[ Wed Feb 15 20:26:18 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 20:26:18 2023 ] Eval epoch: 24
[ Wed Feb 15 20:35:42 2023 ] 	Mean test loss of 796 batches: 1.224208910523647.
[ Wed Feb 15 20:35:43 2023 ] 	Top1: 64.13%
[ Wed Feb 15 20:35:43 2023 ] 	Top5: 90.18%
[ Wed Feb 15 20:35:43 2023 ] Training epoch: 25
[ Wed Feb 15 20:53:21 2023 ] 	Mean training loss: 0.8840.  Mean training acc: 73.77%.
[ Wed Feb 15 20:53:21 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 20:53:21 2023 ] Eval epoch: 25
[ Wed Feb 15 21:02:29 2023 ] 	Mean test loss of 796 batches: 1.270932575715846.
[ Wed Feb 15 21:02:29 2023 ] 	Top1: 64.22%
[ Wed Feb 15 21:02:29 2023 ] 	Top5: 89.86%
[ Wed Feb 15 21:02:29 2023 ] Training epoch: 26
[ Wed Feb 15 21:20:01 2023 ] 	Mean training loss: 0.8850.  Mean training acc: 73.50%.
[ Wed Feb 15 21:20:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 21:20:01 2023 ] Eval epoch: 26
[ Wed Feb 15 21:29:28 2023 ] 	Mean test loss of 796 batches: 1.2202115936869353.
[ Wed Feb 15 21:29:28 2023 ] 	Top1: 66.38%
[ Wed Feb 15 21:29:28 2023 ] 	Top5: 91.14%
[ Wed Feb 15 21:29:29 2023 ] Training epoch: 27
[ Wed Feb 15 21:47:10 2023 ] 	Mean training loss: 0.8805.  Mean training acc: 73.78%.
[ Wed Feb 15 21:47:10 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 21:47:10 2023 ] Eval epoch: 27
[ Wed Feb 15 21:56:32 2023 ] 	Mean test loss of 796 batches: 1.1270086716617171.
[ Wed Feb 15 21:56:33 2023 ] 	Top1: 66.71%
[ Wed Feb 15 21:56:33 2023 ] 	Top5: 91.70%
[ Wed Feb 15 21:56:33 2023 ] Training epoch: 28
[ Wed Feb 15 22:14:10 2023 ] 	Mean training loss: 0.8928.  Mean training acc: 73.35%.
[ Wed Feb 15 22:14:10 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 22:14:10 2023 ] Eval epoch: 28
[ Wed Feb 15 22:23:29 2023 ] 	Mean test loss of 796 batches: 1.1745306122392865.
[ Wed Feb 15 22:23:29 2023 ] 	Top1: 66.19%
[ Wed Feb 15 22:23:30 2023 ] 	Top5: 90.72%
[ Wed Feb 15 22:23:30 2023 ] Training epoch: 29
[ Wed Feb 15 22:41:01 2023 ] 	Mean training loss: 0.8803.  Mean training acc: 73.93%.
[ Wed Feb 15 22:41:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 22:41:02 2023 ] Eval epoch: 29
[ Wed Feb 15 22:50:22 2023 ] 	Mean test loss of 796 batches: 1.1719922301307995.
[ Wed Feb 15 22:50:23 2023 ] 	Top1: 66.20%
[ Wed Feb 15 22:50:23 2023 ] 	Top5: 90.71%
[ Wed Feb 15 22:50:23 2023 ] Training epoch: 30
[ Wed Feb 15 23:08:05 2023 ] 	Mean training loss: 0.8711.  Mean training acc: 73.89%.
[ Wed Feb 15 23:08:05 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 23:08:06 2023 ] Eval epoch: 30
[ Wed Feb 15 23:17:28 2023 ] 	Mean test loss of 796 batches: 1.3303807139321788.
[ Wed Feb 15 23:17:28 2023 ] 	Top1: 62.85%
[ Wed Feb 15 23:17:28 2023 ] 	Top5: 88.56%
[ Wed Feb 15 23:17:28 2023 ] Training epoch: 31
[ Wed Feb 15 23:35:08 2023 ] 	Mean training loss: 0.8669.  Mean training acc: 74.21%.
[ Wed Feb 15 23:35:08 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 23:35:08 2023 ] Eval epoch: 31
[ Wed Feb 15 23:44:27 2023 ] 	Mean test loss of 796 batches: 1.19113830016486.
[ Wed Feb 15 23:44:27 2023 ] 	Top1: 65.50%
[ Wed Feb 15 23:44:28 2023 ] 	Top5: 91.08%
[ Wed Feb 15 23:44:28 2023 ] Training epoch: 32
[ Thu Feb 16 00:02:02 2023 ] 	Mean training loss: 0.8668.  Mean training acc: 74.12%.
[ Thu Feb 16 00:02:03 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 00:02:03 2023 ] Eval epoch: 32
[ Thu Feb 16 00:11:21 2023 ] 	Mean test loss of 796 batches: 1.2575883069005445.
[ Thu Feb 16 00:11:21 2023 ] 	Top1: 63.95%
[ Thu Feb 16 00:11:21 2023 ] 	Top5: 90.62%
[ Thu Feb 16 00:11:22 2023 ] Training epoch: 33
[ Thu Feb 16 00:28:58 2023 ] 	Mean training loss: 0.8617.  Mean training acc: 74.25%.
[ Thu Feb 16 00:28:58 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 00:28:58 2023 ] Eval epoch: 33
[ Thu Feb 16 00:38:14 2023 ] 	Mean test loss of 796 batches: 1.1895385405526089.
[ Thu Feb 16 00:38:15 2023 ] 	Top1: 65.53%
[ Thu Feb 16 00:38:15 2023 ] 	Top5: 91.37%
[ Thu Feb 16 00:38:15 2023 ] Training epoch: 34
[ Thu Feb 16 00:55:45 2023 ] 	Mean training loss: 0.8577.  Mean training acc: 74.23%.
[ Thu Feb 16 00:55:45 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 00:55:45 2023 ] Eval epoch: 34
[ Thu Feb 16 01:04:58 2023 ] 	Mean test loss of 796 batches: 1.1890247005164323.
[ Thu Feb 16 01:04:58 2023 ] 	Top1: 65.01%
[ Thu Feb 16 01:04:59 2023 ] 	Top5: 91.23%
[ Thu Feb 16 01:04:59 2023 ] Training epoch: 35
[ Thu Feb 16 01:22:22 2023 ] 	Mean training loss: 0.8594.  Mean training acc: 74.37%.
[ Thu Feb 16 01:22:22 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 01:22:22 2023 ] Eval epoch: 35
[ Thu Feb 16 01:31:38 2023 ] 	Mean test loss of 796 batches: 1.3008959560687818.
[ Thu Feb 16 01:31:39 2023 ] 	Top1: 64.02%
[ Thu Feb 16 01:31:39 2023 ] 	Top5: 89.91%
[ Thu Feb 16 01:31:39 2023 ] Training epoch: 36
[ Thu Feb 16 01:49:18 2023 ] 	Mean training loss: 0.5362.  Mean training acc: 83.91%.
[ Thu Feb 16 01:49:18 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 01:49:18 2023 ] Eval epoch: 36
[ Thu Feb 16 01:58:36 2023 ] 	Mean test loss of 796 batches: 0.6991425250755183.
[ Thu Feb 16 01:58:36 2023 ] 	Top1: 78.61%
[ Thu Feb 16 01:58:37 2023 ] 	Top5: 95.93%
[ Thu Feb 16 01:58:37 2023 ] Training epoch: 37
[ Thu Feb 16 02:16:17 2023 ] 	Mean training loss: 0.4411.  Mean training acc: 86.57%.
[ Thu Feb 16 02:16:17 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 02:16:17 2023 ] Eval epoch: 37
[ Thu Feb 16 02:25:31 2023 ] 	Mean test loss of 796 batches: 0.6932409295728009.
[ Thu Feb 16 02:25:32 2023 ] 	Top1: 78.62%
[ Thu Feb 16 02:25:32 2023 ] 	Top5: 95.98%
[ Thu Feb 16 02:25:32 2023 ] Training epoch: 38
[ Thu Feb 16 02:43:09 2023 ] 	Mean training loss: 0.4047.  Mean training acc: 87.65%.
[ Thu Feb 16 02:43:09 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 02:43:09 2023 ] Eval epoch: 38
[ Thu Feb 16 02:52:24 2023 ] 	Mean test loss of 796 batches: 0.682717231565609.
[ Thu Feb 16 02:52:24 2023 ] 	Top1: 79.26%
[ Thu Feb 16 02:52:24 2023 ] 	Top5: 96.05%
[ Thu Feb 16 02:52:25 2023 ] Training epoch: 39
[ Thu Feb 16 03:09:40 2023 ] 	Mean training loss: 0.3752.  Mean training acc: 88.64%.
[ Thu Feb 16 03:09:40 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 03:09:40 2023 ] Eval epoch: 39
[ Thu Feb 16 03:18:45 2023 ] 	Mean test loss of 796 batches: 0.6563051609069708.
[ Thu Feb 16 03:18:46 2023 ] 	Top1: 80.05%
[ Thu Feb 16 03:18:46 2023 ] 	Top5: 96.29%
[ Thu Feb 16 03:18:46 2023 ] Training epoch: 40
[ Thu Feb 16 03:36:01 2023 ] 	Mean training loss: 0.3515.  Mean training acc: 89.28%.
[ Thu Feb 16 03:36:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 03:36:01 2023 ] Eval epoch: 40
[ Thu Feb 16 03:45:17 2023 ] 	Mean test loss of 796 batches: 0.6700980998482087.
[ Thu Feb 16 03:45:18 2023 ] 	Top1: 79.87%
[ Thu Feb 16 03:45:18 2023 ] 	Top5: 96.15%
[ Thu Feb 16 03:45:18 2023 ] Training epoch: 41
[ Thu Feb 16 04:02:58 2023 ] 	Mean training loss: 0.3410.  Mean training acc: 89.81%.
[ Thu Feb 16 04:02:58 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 04:02:58 2023 ] Eval epoch: 41
[ Thu Feb 16 04:12:15 2023 ] 	Mean test loss of 796 batches: 0.6875023449392025.
[ Thu Feb 16 04:12:15 2023 ] 	Top1: 79.44%
[ Thu Feb 16 04:12:16 2023 ] 	Top5: 96.05%
[ Thu Feb 16 04:12:16 2023 ] Training epoch: 42
[ Thu Feb 16 04:29:52 2023 ] 	Mean training loss: 0.3265.  Mean training acc: 90.12%.
[ Thu Feb 16 04:29:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 04:29:52 2023 ] Eval epoch: 42
[ Thu Feb 16 04:39:05 2023 ] 	Mean test loss of 796 batches: 0.6871876385877255.
[ Thu Feb 16 04:39:05 2023 ] 	Top1: 79.56%
[ Thu Feb 16 04:39:06 2023 ] 	Top5: 96.17%
[ Thu Feb 16 04:39:06 2023 ] Training epoch: 43
[ Thu Feb 16 04:56:41 2023 ] 	Mean training loss: 0.3149.  Mean training acc: 90.48%.
[ Thu Feb 16 04:56:41 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 04:56:42 2023 ] Eval epoch: 43
[ Thu Feb 16 05:05:54 2023 ] 	Mean test loss of 796 batches: 0.7040203652583324.
[ Thu Feb 16 05:05:55 2023 ] 	Top1: 79.13%
[ Thu Feb 16 05:05:55 2023 ] 	Top5: 95.85%
[ Thu Feb 16 05:05:55 2023 ] Training epoch: 44
[ Thu Feb 16 05:23:13 2023 ] 	Mean training loss: 0.3028.  Mean training acc: 90.84%.
[ Thu Feb 16 05:23:13 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 05:23:13 2023 ] Eval epoch: 44
[ Thu Feb 16 05:32:22 2023 ] 	Mean test loss of 796 batches: 0.7780923404117774.
[ Thu Feb 16 05:32:23 2023 ] 	Top1: 78.28%
[ Thu Feb 16 05:32:23 2023 ] 	Top5: 95.19%
[ Thu Feb 16 05:32:23 2023 ] Training epoch: 45
[ Thu Feb 16 05:49:59 2023 ] 	Mean training loss: 0.2999.  Mean training acc: 90.99%.
[ Thu Feb 16 05:49:59 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Feb 16 05:50:00 2023 ] Eval epoch: 45
[ Thu Feb 16 05:59:08 2023 ] 	Mean test loss of 796 batches: 0.7450948228132934.
[ Thu Feb 16 05:59:08 2023 ] 	Top1: 78.58%
[ Thu Feb 16 05:59:09 2023 ] 	Top5: 95.53%
[ Thu Feb 16 05:59:09 2023 ] Training epoch: 46
