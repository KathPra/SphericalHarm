[ Mon Jan  9 12:53:01 2023 ] using warm up, epoch: 5
[ Mon Jan  9 12:54:55 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan  9 12:55:03 2023 ] # Parameters: 1508876
[ Mon Jan  9 12:55:03 2023 ] Training epoch: 1
[ Mon Jan  9 13:12:51 2023 ] 	Mean training loss: 3.0992.  Mean training acc: 23.32%.
[ Mon Jan  9 13:12:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 13:12:58 2023 ] Eval epoch: 1
[ Mon Jan  9 13:22:33 2023 ] 	Mean test loss of 796 batches: 2.35171077419166.
[ Mon Jan  9 13:22:33 2023 ] 	Top1: 34.07%
[ Mon Jan  9 13:22:34 2023 ] 	Top5: 68.93%
[ Mon Jan  9 13:22:34 2023 ] Training epoch: 2
[ Mon Jan  9 13:39:37 2023 ] 	Mean training loss: 2.0687.  Mean training acc: 42.54%.
[ Mon Jan  9 13:39:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 13:39:42 2023 ] Eval epoch: 2
[ Mon Jan  9 13:49:11 2023 ] 	Mean test loss of 796 batches: 1.8513634779944492.
[ Mon Jan  9 13:49:15 2023 ] 	Top1: 46.81%
[ Mon Jan  9 13:49:16 2023 ] 	Top5: 79.53%
[ Mon Jan  9 13:49:16 2023 ] Training epoch: 3
[ Mon Jan  9 14:06:54 2023 ] 	Mean training loss: 1.6519.  Mean training acc: 52.92%.
[ Mon Jan  9 14:06:55 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Mon Jan  9 14:06:56 2023 ] Eval epoch: 3
[ Mon Jan  9 14:16:37 2023 ] 	Mean test loss of 796 batches: 1.6291595331238742.
[ Mon Jan  9 14:16:38 2023 ] 	Top1: 53.44%
[ Mon Jan  9 14:16:38 2023 ] 	Top5: 83.62%
[ Mon Jan  9 14:16:39 2023 ] Training epoch: 4
[ Mon Jan  9 14:33:41 2023 ] 	Mean training loss: 1.4426.  Mean training acc: 58.33%.
[ Mon Jan  9 14:33:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 14:33:43 2023 ] Eval epoch: 4
[ Mon Jan  9 14:43:30 2023 ] 	Mean test loss of 796 batches: 1.5685234080307449.
[ Mon Jan  9 14:43:30 2023 ] 	Top1: 54.61%
[ Mon Jan  9 14:43:31 2023 ] 	Top5: 84.92%
[ Mon Jan  9 14:43:39 2023 ] Training epoch: 5
[ Mon Jan  9 15:00:31 2023 ] 	Mean training loss: 1.3029.  Mean training acc: 62.00%.
[ Mon Jan  9 15:00:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 15:00:34 2023 ] Eval epoch: 5
[ Mon Jan  9 15:10:09 2023 ] 	Mean test loss of 796 batches: 1.753538413038805.
[ Mon Jan  9 15:10:24 2023 ] 	Top1: 52.94%
[ Mon Jan  9 15:10:24 2023 ] 	Top5: 83.08%
[ Mon Jan  9 15:10:25 2023 ] Training epoch: 6
[ Mon Jan  9 15:27:25 2023 ] 	Mean training loss: 1.1516.  Mean training acc: 65.94%.
[ Mon Jan  9 15:27:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 15:27:27 2023 ] Eval epoch: 6
[ Mon Jan  9 15:37:15 2023 ] 	Mean test loss of 796 batches: 1.3467905573808967.
[ Mon Jan  9 15:37:22 2023 ] 	Top1: 60.81%
[ Mon Jan  9 15:37:22 2023 ] 	Top5: 88.08%
[ Mon Jan  9 15:37:23 2023 ] Training epoch: 7
[ Mon Jan  9 15:55:24 2023 ] 	Mean training loss: 1.0589.  Mean training acc: 68.52%.
[ Mon Jan  9 15:55:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 15:55:34 2023 ] Eval epoch: 7
[ Mon Jan  9 16:05:15 2023 ] 	Mean test loss of 796 batches: 1.190864752809606.
[ Mon Jan  9 16:05:22 2023 ] 	Top1: 64.32%
[ Mon Jan  9 16:05:22 2023 ] 	Top5: 90.86%
[ Mon Jan  9 16:05:23 2023 ] Training epoch: 8
[ Mon Jan  9 16:22:43 2023 ] 	Mean training loss: 0.9967.  Mean training acc: 70.19%.
[ Mon Jan  9 16:22:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 16:22:44 2023 ] Eval epoch: 8
[ Mon Jan  9 16:34:57 2023 ] 	Mean test loss of 796 batches: 1.4608138651404547.
[ Mon Jan  9 16:34:58 2023 ] 	Top1: 57.31%
[ Mon Jan  9 16:34:59 2023 ] 	Top5: 87.55%
[ Mon Jan  9 16:34:59 2023 ] Training epoch: 9
[ Mon Jan  9 17:06:40 2023 ] 	Mean training loss: 0.9447.  Mean training acc: 71.63%.
[ Mon Jan  9 17:06:40 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 17:06:42 2023 ] Eval epoch: 9
[ Mon Jan  9 17:20:42 2023 ] 	Mean test loss of 796 batches: 1.8446711266609892.
[ Mon Jan  9 17:20:43 2023 ] 	Top1: 51.61%
[ Mon Jan  9 17:20:44 2023 ] 	Top5: 85.32%
[ Mon Jan  9 17:20:44 2023 ] Training epoch: 10
[ Mon Jan  9 17:52:51 2023 ] 	Mean training loss: 0.9152.  Mean training acc: 72.59%.
[ Mon Jan  9 17:52:51 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 17:52:52 2023 ] Eval epoch: 10
[ Mon Jan  9 18:08:08 2023 ] 	Mean test loss of 796 batches: 1.1126076875619553.
[ Mon Jan  9 18:08:09 2023 ] 	Top1: 67.44%
[ Mon Jan  9 18:08:10 2023 ] 	Top5: 91.64%
[ Mon Jan  9 18:08:10 2023 ] Training epoch: 11
[ Mon Jan  9 18:40:21 2023 ] 	Mean training loss: 0.8808.  Mean training acc: 73.62%.
[ Mon Jan  9 18:40:22 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 18:40:23 2023 ] Eval epoch: 11
[ Mon Jan  9 18:55:24 2023 ] 	Mean test loss of 796 batches: 1.211741427043874.
[ Mon Jan  9 18:55:25 2023 ] 	Top1: 65.10%
[ Mon Jan  9 18:55:26 2023 ] 	Top5: 90.86%
[ Mon Jan  9 18:55:26 2023 ] Training epoch: 12
[ Mon Jan  9 19:28:12 2023 ] 	Mean training loss: 0.8573.  Mean training acc: 74.16%.
[ Mon Jan  9 19:28:13 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 19:28:14 2023 ] Eval epoch: 12
[ Mon Jan  9 19:42:51 2023 ] 	Mean test loss of 796 batches: 1.144429286633005.
[ Mon Jan  9 19:42:52 2023 ] 	Top1: 67.52%
[ Mon Jan  9 19:42:53 2023 ] 	Top5: 91.13%
[ Mon Jan  9 19:42:53 2023 ] Training epoch: 13
[ Mon Jan  9 20:15:10 2023 ] 	Mean training loss: 0.8470.  Mean training acc: 74.61%.
[ Mon Jan  9 20:15:11 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 20:15:12 2023 ] Eval epoch: 13
[ Mon Jan  9 20:30:11 2023 ] 	Mean test loss of 796 batches: 1.115865889693325.
[ Mon Jan  9 20:30:12 2023 ] 	Top1: 67.04%
[ Mon Jan  9 20:30:13 2023 ] 	Top5: 91.61%
[ Mon Jan  9 20:30:14 2023 ] Training epoch: 14
[ Mon Jan  9 21:02:46 2023 ] 	Mean training loss: 0.8334.  Mean training acc: 74.87%.
[ Mon Jan  9 21:02:54 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 21:02:55 2023 ] Eval epoch: 14
[ Mon Jan  9 21:18:37 2023 ] 	Mean test loss of 796 batches: 1.1090886786430325.
[ Mon Jan  9 21:18:38 2023 ] 	Top1: 67.04%
[ Mon Jan  9 21:18:38 2023 ] 	Top5: 91.43%
[ Mon Jan  9 21:18:39 2023 ] Training epoch: 15
[ Mon Jan  9 21:53:33 2023 ] 	Mean training loss: 0.8153.  Mean training acc: 75.32%.
[ Mon Jan  9 21:53:35 2023 ] 	Time consumption: [Data]01%, [Network]93%
[ Mon Jan  9 21:53:36 2023 ] Eval epoch: 15
[ Mon Jan  9 22:09:33 2023 ] 	Mean test loss of 796 batches: 1.166136790235438.
[ Mon Jan  9 22:09:35 2023 ] 	Top1: 66.12%
[ Mon Jan  9 22:09:35 2023 ] 	Top5: 90.89%
[ Mon Jan  9 22:09:36 2023 ] Training epoch: 16
[ Mon Jan  9 22:42:27 2023 ] 	Mean training loss: 0.8082.  Mean training acc: 75.46%.
[ Mon Jan  9 22:42:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan  9 22:42:28 2023 ] Eval epoch: 16
[ Mon Jan  9 22:59:12 2023 ] 	Mean test loss of 796 batches: 1.1631039457405032.
[ Mon Jan  9 22:59:13 2023 ] 	Top1: 65.86%
[ Mon Jan  9 22:59:14 2023 ] 	Top5: 91.88%
[ Mon Jan  9 22:59:14 2023 ] Training epoch: 17
[ Mon Jan  9 23:31:41 2023 ] 	Mean training loss: 0.8038.  Mean training acc: 75.54%.
[ Mon Jan  9 23:31:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan  9 23:31:46 2023 ] Eval epoch: 17
[ Mon Jan  9 23:48:21 2023 ] 	Mean test loss of 796 batches: 1.193360219311774.
[ Mon Jan  9 23:48:24 2023 ] 	Top1: 64.85%
[ Mon Jan  9 23:48:25 2023 ] 	Top5: 90.74%
[ Mon Jan  9 23:48:25 2023 ] Training epoch: 18
[ Tue Jan 10 00:20:50 2023 ] 	Mean training loss: 0.7929.  Mean training acc: 75.93%.
[ Tue Jan 10 00:20:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 00:20:56 2023 ] Eval epoch: 18
[ Tue Jan 10 00:37:38 2023 ] 	Mean test loss of 796 batches: 1.2814431175514682.
[ Tue Jan 10 00:37:40 2023 ] 	Top1: 64.70%
[ Tue Jan 10 00:37:40 2023 ] 	Top5: 90.01%
[ Tue Jan 10 00:37:41 2023 ] Training epoch: 19
[ Tue Jan 10 01:10:08 2023 ] 	Mean training loss: 0.7801.  Mean training acc: 76.55%.
[ Tue Jan 10 01:10:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 01:10:11 2023 ] Eval epoch: 19
[ Tue Jan 10 01:26:33 2023 ] 	Mean test loss of 796 batches: 1.175482951479042.
[ Tue Jan 10 01:26:34 2023 ] 	Top1: 66.69%
[ Tue Jan 10 01:26:34 2023 ] 	Top5: 90.65%
[ Tue Jan 10 01:26:35 2023 ] Training epoch: 20
[ Tue Jan 10 01:58:47 2023 ] 	Mean training loss: 0.7790.  Mean training acc: 76.58%.
[ Tue Jan 10 01:58:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 01:58:49 2023 ] Eval epoch: 20
[ Tue Jan 10 02:15:13 2023 ] 	Mean test loss of 796 batches: 1.1637907103078449.
[ Tue Jan 10 02:15:13 2023 ] 	Top1: 65.37%
[ Tue Jan 10 02:15:14 2023 ] 	Top5: 91.09%
[ Tue Jan 10 02:15:14 2023 ] Training epoch: 21
[ Tue Jan 10 02:47:58 2023 ] 	Mean training loss: 0.7718.  Mean training acc: 76.65%.
[ Tue Jan 10 02:47:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 02:47:59 2023 ] Eval epoch: 21
[ Tue Jan 10 03:04:18 2023 ] 	Mean test loss of 796 batches: 1.1270795383645063.
[ Tue Jan 10 03:04:22 2023 ] 	Top1: 66.83%
[ Tue Jan 10 03:04:23 2023 ] 	Top5: 92.06%
[ Tue Jan 10 03:04:23 2023 ] Training epoch: 22
[ Tue Jan 10 03:35:56 2023 ] 	Mean training loss: 0.7668.  Mean training acc: 76.81%.
[ Tue Jan 10 03:36:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 03:36:02 2023 ] Eval epoch: 22
[ Tue Jan 10 03:52:04 2023 ] 	Mean test loss of 796 batches: 1.0735511832950104.
[ Tue Jan 10 03:52:04 2023 ] 	Top1: 68.64%
[ Tue Jan 10 03:52:05 2023 ] 	Top5: 91.63%
[ Tue Jan 10 03:52:14 2023 ] Training epoch: 23
[ Tue Jan 10 04:24:33 2023 ] 	Mean training loss: 0.7597.  Mean training acc: 76.97%.
[ Tue Jan 10 04:24:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 04:24:50 2023 ] Eval epoch: 23
[ Tue Jan 10 04:40:46 2023 ] 	Mean test loss of 796 batches: 1.0713398856620993.
[ Tue Jan 10 04:40:50 2023 ] 	Top1: 68.12%
[ Tue Jan 10 04:40:51 2023 ] 	Top5: 92.93%
[ Tue Jan 10 04:40:51 2023 ] Training epoch: 24
[ Tue Jan 10 05:12:57 2023 ] 	Mean training loss: 0.7636.  Mean training acc: 76.79%.
[ Tue Jan 10 05:12:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 05:12:57 2023 ] Eval epoch: 24
[ Tue Jan 10 05:28:59 2023 ] 	Mean test loss of 796 batches: 1.0900288967780731.
[ Tue Jan 10 05:29:10 2023 ] 	Top1: 67.37%
[ Tue Jan 10 05:29:10 2023 ] 	Top5: 91.70%
[ Tue Jan 10 05:29:11 2023 ] Training epoch: 25
[ Tue Jan 10 06:00:57 2023 ] 	Mean training loss: 0.7574.  Mean training acc: 76.93%.
[ Tue Jan 10 06:00:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 06:00:58 2023 ] Eval epoch: 25
[ Tue Jan 10 06:17:04 2023 ] 	Mean test loss of 796 batches: 1.1335690388053505.
[ Tue Jan 10 06:17:05 2023 ] 	Top1: 68.28%
[ Tue Jan 10 06:17:05 2023 ] 	Top5: 90.97%
[ Tue Jan 10 06:17:05 2023 ] Training epoch: 26
[ Tue Jan 10 06:48:47 2023 ] 	Mean training loss: 0.7593.  Mean training acc: 76.90%.
[ Tue Jan 10 06:48:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 06:48:47 2023 ] Eval epoch: 26
[ Tue Jan 10 07:05:03 2023 ] 	Mean test loss of 796 batches: 0.9917631906330885.
[ Tue Jan 10 07:05:14 2023 ] 	Top1: 70.23%
[ Tue Jan 10 07:05:15 2023 ] 	Top5: 93.05%
[ Tue Jan 10 07:05:15 2023 ] Training epoch: 27
[ Tue Jan 10 07:36:13 2023 ] 	Mean training loss: 0.7470.  Mean training acc: 77.32%.
[ Tue Jan 10 07:36:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 07:36:14 2023 ] Eval epoch: 27
[ Tue Jan 10 07:51:29 2023 ] 	Mean test loss of 796 batches: 1.1297577428233683.
[ Tue Jan 10 07:51:30 2023 ] 	Top1: 67.10%
[ Tue Jan 10 07:51:30 2023 ] 	Top5: 92.02%
[ Tue Jan 10 07:51:31 2023 ] Training epoch: 28
[ Tue Jan 10 08:21:45 2023 ] 	Mean training loss: 0.7531.  Mean training acc: 77.02%.
[ Tue Jan 10 08:21:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 08:21:45 2023 ] Eval epoch: 28
[ Tue Jan 10 08:37:14 2023 ] 	Mean test loss of 796 batches: 1.0515403799225937.
[ Tue Jan 10 08:37:15 2023 ] 	Top1: 68.72%
[ Tue Jan 10 08:37:16 2023 ] 	Top5: 92.22%
[ Tue Jan 10 08:37:29 2023 ] Training epoch: 29
[ Tue Jan 10 09:07:25 2023 ] 	Mean training loss: 0.7390.  Mean training acc: 77.39%.
[ Tue Jan 10 09:07:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:07:32 2023 ] Eval epoch: 29
[ Tue Jan 10 09:22:44 2023 ] 	Mean test loss of 796 batches: 1.155073349424942.
[ Tue Jan 10 09:22:47 2023 ] 	Top1: 65.76%
[ Tue Jan 10 09:22:47 2023 ] 	Top5: 91.43%
[ Tue Jan 10 09:22:49 2023 ] Training epoch: 30
[ Tue Jan 10 09:54:04 2023 ] 	Mean training loss: 0.7342.  Mean training acc: 77.75%.
[ Tue Jan 10 09:54:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 09:54:06 2023 ] Eval epoch: 30
[ Tue Jan 10 10:08:58 2023 ] 	Mean test loss of 796 batches: 1.1529273034340173.
[ Tue Jan 10 10:08:59 2023 ] 	Top1: 66.84%
[ Tue Jan 10 10:08:59 2023 ] 	Top5: 91.14%
[ Tue Jan 10 10:09:00 2023 ] Training epoch: 31
[ Tue Jan 10 10:39:31 2023 ] 	Mean training loss: 0.7420.  Mean training acc: 77.32%.
[ Tue Jan 10 10:39:31 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Tue Jan 10 10:39:32 2023 ] Eval epoch: 31
[ Tue Jan 10 10:55:46 2023 ] 	Mean test loss of 796 batches: 1.0851433752619442.
[ Tue Jan 10 10:55:47 2023 ] 	Top1: 67.92%
[ Tue Jan 10 10:55:48 2023 ] 	Top5: 91.92%
[ Tue Jan 10 10:55:48 2023 ] Training epoch: 32
[ Tue Jan 10 11:26:01 2023 ] 	Mean training loss: 0.7376.  Mean training acc: 77.46%.
[ Tue Jan 10 11:26:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 11:26:03 2023 ] Eval epoch: 32
[ Tue Jan 10 11:40:17 2023 ] 	Mean test loss of 796 batches: 1.0973092869822703.
[ Tue Jan 10 11:40:18 2023 ] 	Top1: 69.01%
[ Tue Jan 10 11:40:18 2023 ] 	Top5: 92.37%
[ Tue Jan 10 11:40:19 2023 ] Training epoch: 33
[ Tue Jan 10 12:05:06 2023 ] 	Mean training loss: 0.7310.  Mean training acc: 77.76%.
[ Tue Jan 10 12:05:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:05:07 2023 ] Eval epoch: 33
[ Tue Jan 10 12:18:20 2023 ] 	Mean test loss of 796 batches: 1.0222837249163408.
[ Tue Jan 10 12:18:22 2023 ] 	Top1: 70.19%
[ Tue Jan 10 12:18:22 2023 ] 	Top5: 92.81%
[ Tue Jan 10 12:18:23 2023 ] Training epoch: 34
[ Tue Jan 10 12:41:30 2023 ] 	Mean training loss: 0.7286.  Mean training acc: 77.83%.
[ Tue Jan 10 12:41:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 12:41:33 2023 ] Eval epoch: 34
[ Tue Jan 10 12:54:41 2023 ] 	Mean test loss of 796 batches: 1.0600328548769256.
[ Tue Jan 10 12:54:43 2023 ] 	Top1: 68.06%
[ Tue Jan 10 12:54:43 2023 ] 	Top5: 92.79%
[ Tue Jan 10 12:54:44 2023 ] Training epoch: 35
[ Tue Jan 10 13:17:42 2023 ] 	Mean training loss: 0.7283.  Mean training acc: 77.62%.
[ Tue Jan 10 13:17:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:17:45 2023 ] Eval epoch: 35
[ Tue Jan 10 13:30:37 2023 ] 	Mean test loss of 796 batches: 1.0381252631245546.
[ Tue Jan 10 13:30:38 2023 ] 	Top1: 69.64%
[ Tue Jan 10 13:30:39 2023 ] 	Top5: 92.82%
[ Tue Jan 10 13:30:39 2023 ] Training epoch: 36
[ Tue Jan 10 13:53:22 2023 ] 	Mean training loss: 0.4286.  Mean training acc: 86.95%.
[ Tue Jan 10 13:53:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 13:53:32 2023 ] Eval epoch: 36
[ Tue Jan 10 14:07:52 2023 ] 	Mean test loss of 796 batches: 0.5395220018754802.
[ Tue Jan 10 14:07:54 2023 ] 	Top1: 83.33%
[ Tue Jan 10 14:07:54 2023 ] 	Top5: 97.21%
[ Tue Jan 10 14:07:57 2023 ] Training epoch: 37
[ Tue Jan 10 14:31:23 2023 ] 	Mean training loss: 0.3490.  Mean training acc: 89.22%.
[ Tue Jan 10 14:31:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 14:31:25 2023 ] Eval epoch: 37
[ Tue Jan 10 14:45:47 2023 ] 	Mean test loss of 796 batches: 0.5456770924972979.
[ Tue Jan 10 14:45:49 2023 ] 	Top1: 83.22%
[ Tue Jan 10 14:45:50 2023 ] 	Top5: 97.12%
[ Tue Jan 10 14:45:52 2023 ] Training epoch: 38
[ Tue Jan 10 15:09:36 2023 ] 	Mean training loss: 0.3217.  Mean training acc: 90.06%.
[ Tue Jan 10 15:09:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:09:43 2023 ] Eval epoch: 38
[ Tue Jan 10 15:23:54 2023 ] 	Mean test loss of 796 batches: 0.5262906681652644.
[ Tue Jan 10 15:23:56 2023 ] 	Top1: 83.89%
[ Tue Jan 10 15:23:57 2023 ] 	Top5: 97.28%
[ Tue Jan 10 15:23:58 2023 ] Training epoch: 39
[ Tue Jan 10 15:47:56 2023 ] 	Mean training loss: 0.2992.  Mean training acc: 90.80%.
[ Tue Jan 10 15:47:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:48:02 2023 ] Eval epoch: 39
[ Tue Jan 10 16:02:17 2023 ] 	Mean test loss of 796 batches: 0.5160716969014412.
[ Tue Jan 10 16:02:21 2023 ] 	Top1: 84.06%
[ Tue Jan 10 16:02:21 2023 ] 	Top5: 97.32%
[ Tue Jan 10 16:02:23 2023 ] Training epoch: 40
[ Tue Jan 10 16:26:16 2023 ] 	Mean training loss: 0.2819.  Mean training acc: 91.36%.
[ Tue Jan 10 16:27:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 16:27:27 2023 ] Eval epoch: 40
[ Tue Jan 10 16:42:21 2023 ] 	Mean test loss of 796 batches: 0.539439423992556.
[ Tue Jan 10 16:42:23 2023 ] 	Top1: 83.51%
[ Tue Jan 10 16:42:23 2023 ] 	Top5: 97.15%
[ Tue Jan 10 16:42:25 2023 ] Training epoch: 41
[ Tue Jan 10 17:08:32 2023 ] 	Mean training loss: 0.2680.  Mean training acc: 91.83%.
[ Tue Jan 10 17:08:37 2023 ] 	Time consumption: [Data]01%, [Network]91%
[ Tue Jan 10 17:08:45 2023 ] Eval epoch: 41
[ Tue Jan 10 17:23:26 2023 ] 	Mean test loss of 796 batches: 0.558482133399639.
[ Tue Jan 10 17:23:29 2023 ] 	Top1: 83.16%
[ Tue Jan 10 17:23:29 2023 ] 	Top5: 97.08%
[ Tue Jan 10 17:23:32 2023 ] Training epoch: 42
[ Tue Jan 10 17:48:34 2023 ] 	Mean training loss: 0.2591.  Mean training acc: 92.13%.
[ Tue Jan 10 17:48:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 17:48:43 2023 ] Eval epoch: 42
[ Tue Jan 10 18:02:56 2023 ] 	Mean test loss of 796 batches: 0.5415246487927422.
[ Tue Jan 10 18:02:59 2023 ] 	Top1: 83.73%
[ Tue Jan 10 18:03:00 2023 ] 	Top5: 97.15%
[ Tue Jan 10 18:03:02 2023 ] Training epoch: 43
[ Tue Jan 10 18:34:12 2023 ] 	Mean training loss: 0.2476.  Mean training acc: 92.51%.
[ Tue Jan 10 18:34:14 2023 ] 	Time consumption: [Data]01%, [Network]89%
[ Tue Jan 10 18:34:17 2023 ] Eval epoch: 43
[ Tue Jan 10 18:52:40 2023 ] 	Mean test loss of 796 batches: 0.5609207059532854.
[ Tue Jan 10 18:52:42 2023 ] 	Top1: 83.16%
[ Tue Jan 10 18:52:42 2023 ] 	Top5: 97.17%
[ Tue Jan 10 18:52:44 2023 ] Training epoch: 44
[ Tue Jan 10 19:20:01 2023 ] 	Mean training loss: 0.2409.  Mean training acc: 92.76%.
[ Tue Jan 10 19:20:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 19:20:37 2023 ] Eval epoch: 44
[ Tue Jan 10 19:39:40 2023 ] 	Mean test loss of 796 batches: 0.5614599812279769.
[ Tue Jan 10 19:39:42 2023 ] 	Top1: 83.41%
[ Tue Jan 10 19:39:42 2023 ] 	Top5: 97.00%
[ Tue Jan 10 19:39:44 2023 ] Training epoch: 45
[ Tue Jan 10 20:07:21 2023 ] 	Mean training loss: 0.2366.  Mean training acc: 92.83%.
[ Tue Jan 10 20:07:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:07:24 2023 ] Eval epoch: 45
[ Tue Jan 10 20:25:59 2023 ] 	Mean test loss of 796 batches: 0.5669735102123351.
[ Tue Jan 10 20:25:59 2023 ] 	Top1: 83.44%
[ Tue Jan 10 20:26:00 2023 ] 	Top5: 97.00%
[ Tue Jan 10 20:26:00 2023 ] Training epoch: 46
[ Tue Jan 10 20:53:47 2023 ] 	Mean training loss: 0.2293.  Mean training acc: 92.99%.
[ Tue Jan 10 20:53:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 20:53:50 2023 ] Eval epoch: 46
[ Tue Jan 10 21:11:53 2023 ] 	Mean test loss of 796 batches: 0.5984592609875017.
[ Tue Jan 10 21:11:56 2023 ] 	Top1: 82.58%
[ Tue Jan 10 21:11:57 2023 ] 	Top5: 96.84%
[ Tue Jan 10 21:11:58 2023 ] Training epoch: 47
[ Tue Jan 10 21:40:28 2023 ] 	Mean training loss: 0.2293.  Mean training acc: 93.04%.
[ Tue Jan 10 21:40:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 21:40:29 2023 ] Eval epoch: 47
[ Tue Jan 10 21:58:09 2023 ] 	Mean test loss of 796 batches: 0.5709412193122372.
[ Tue Jan 10 21:58:10 2023 ] 	Top1: 83.33%
[ Tue Jan 10 21:58:11 2023 ] 	Top5: 96.97%
[ Tue Jan 10 21:58:11 2023 ] Training epoch: 48
[ Tue Jan 10 22:26:59 2023 ] 	Mean training loss: 0.2253.  Mean training acc: 93.10%.
[ Tue Jan 10 22:27:00 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 22:27:02 2023 ] Eval epoch: 48
[ Tue Jan 10 22:44:44 2023 ] 	Mean test loss of 796 batches: 0.5777545928786597.
[ Tue Jan 10 22:44:46 2023 ] 	Top1: 83.16%
[ Tue Jan 10 22:44:47 2023 ] 	Top5: 96.91%
[ Tue Jan 10 22:44:47 2023 ] Training epoch: 49
[ Tue Jan 10 23:13:04 2023 ] 	Mean training loss: 0.2256.  Mean training acc: 93.16%.
[ Tue Jan 10 23:13:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 23:13:07 2023 ] Eval epoch: 49
[ Tue Jan 10 23:30:39 2023 ] 	Mean test loss of 796 batches: 0.6113588205824171.
[ Tue Jan 10 23:30:41 2023 ] 	Top1: 82.24%
[ Tue Jan 10 23:30:41 2023 ] 	Top5: 96.58%
[ Tue Jan 10 23:30:42 2023 ] Training epoch: 50
[ Wed Jan 11 00:06:17 2023 ] 	Mean training loss: 0.2203.  Mean training acc: 93.48%.
[ Wed Jan 11 00:06:18 2023 ] 	Time consumption: [Data]01%, [Network]79%
[ Wed Jan 11 00:06:19 2023 ] Eval epoch: 50
[ Wed Jan 11 00:23:25 2023 ] 	Mean test loss of 796 batches: 0.6246057339199823.
[ Wed Jan 11 00:23:27 2023 ] 	Top1: 82.16%
[ Wed Jan 11 00:23:27 2023 ] 	Top5: 96.57%
[ Wed Jan 11 00:23:28 2023 ] Training epoch: 51
[ Wed Jan 11 00:53:46 2023 ] 	Mean training loss: 0.2211.  Mean training acc: 93.19%.
[ Wed Jan 11 00:53:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 00:53:47 2023 ] Eval epoch: 51
[ Wed Jan 11 01:12:39 2023 ] 	Mean test loss of 796 batches: 0.5909610783409833.
[ Wed Jan 11 01:12:40 2023 ] 	Top1: 82.95%
[ Wed Jan 11 01:12:41 2023 ] 	Top5: 96.90%
[ Wed Jan 11 01:12:41 2023 ] Training epoch: 52
[ Wed Jan 11 01:43:03 2023 ] 	Mean training loss: 0.2223.  Mean training acc: 93.24%.
[ Wed Jan 11 01:43:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 01:43:13 2023 ] Eval epoch: 52
[ Wed Jan 11 02:02:21 2023 ] 	Mean test loss of 796 batches: 0.6351931409058559.
[ Wed Jan 11 02:02:23 2023 ] 	Top1: 81.99%
[ Wed Jan 11 02:02:23 2023 ] 	Top5: 96.71%
[ Wed Jan 11 02:02:24 2023 ] Training epoch: 53
[ Wed Jan 11 02:32:05 2023 ] 	Mean training loss: 0.2148.  Mean training acc: 93.52%.
[ Wed Jan 11 02:32:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 02:32:15 2023 ] Eval epoch: 53
[ Wed Jan 11 02:51:48 2023 ] 	Mean test loss of 796 batches: 0.573718102545894.
[ Wed Jan 11 02:51:49 2023 ] 	Top1: 83.19%
[ Wed Jan 11 02:51:49 2023 ] 	Top5: 97.04%
[ Wed Jan 11 02:51:50 2023 ] Training epoch: 54
[ Wed Jan 11 03:19:59 2023 ] 	Mean training loss: 0.2160.  Mean training acc: 93.46%.
[ Wed Jan 11 03:19:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 03:20:00 2023 ] Eval epoch: 54
[ Wed Jan 11 03:37:58 2023 ] 	Mean test loss of 796 batches: 0.6257074853995038.
[ Wed Jan 11 03:37:59 2023 ] 	Top1: 82.30%
[ Wed Jan 11 03:37:59 2023 ] 	Top5: 96.48%
[ Wed Jan 11 03:38:00 2023 ] Training epoch: 55
[ Wed Jan 11 04:06:25 2023 ] 	Mean training loss: 0.2166.  Mean training acc: 93.48%.
[ Wed Jan 11 04:06:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:06:27 2023 ] Eval epoch: 55
[ Wed Jan 11 04:23:56 2023 ] 	Mean test loss of 796 batches: 0.6257552621727014.
[ Wed Jan 11 04:23:57 2023 ] 	Top1: 82.14%
[ Wed Jan 11 04:23:58 2023 ] 	Top5: 96.70%
[ Wed Jan 11 04:23:58 2023 ] Training epoch: 56
[ Wed Jan 11 04:52:34 2023 ] 	Mean training loss: 0.1367.  Mean training acc: 96.29%.
[ Wed Jan 11 04:52:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 04:52:35 2023 ] Eval epoch: 56
[ Wed Jan 11 05:09:50 2023 ] 	Mean test loss of 796 batches: 0.530033668442325.
[ Wed Jan 11 05:09:51 2023 ] 	Top1: 84.90%
[ Wed Jan 11 05:09:52 2023 ] 	Top5: 97.36%
[ Wed Jan 11 05:09:53 2023 ] Training epoch: 57
[ Wed Jan 11 05:38:47 2023 ] 	Mean training loss: 0.1085.  Mean training acc: 97.36%.
[ Wed Jan 11 05:38:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 05:38:48 2023 ] Eval epoch: 57
[ Wed Jan 11 05:56:12 2023 ] 	Mean test loss of 796 batches: 0.522864535310535.
[ Wed Jan 11 05:56:13 2023 ] 	Top1: 85.02%
[ Wed Jan 11 05:56:13 2023 ] 	Top5: 97.34%
[ Wed Jan 11 05:56:13 2023 ] Training epoch: 58
[ Wed Jan 11 13:00:11 2023 ] Load weights from work_dir/csub/ctrgcn_local_SHT/runs-57-56088.pt.
[ Wed Jan 11 13:00:15 2023 ] using warm up, epoch: 0
[ Wed Jan 11 13:00:30 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/csub/ctrgcn_local_SHT/runs-57-56088.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 57, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Wed Jan 11 13:00:30 2023 ] # Parameters: 1508876
[ Wed Jan 11 13:00:30 2023 ] Training epoch: 58
[ Wed Jan 11 13:25:36 2023 ] 	Mean training loss: 0.0991.  Mean training acc: 97.58%.
[ Wed Jan 11 13:25:36 2023 ] 	Time consumption: [Data]01%, [Network]96%
[ Wed Jan 11 13:25:37 2023 ] Eval epoch: 58
[ Wed Jan 11 13:43:52 2023 ] 	Mean test loss of 796 batches: 0.5314283455867115.
[ Wed Jan 11 13:43:53 2023 ] 	Top1: 84.99%
[ Wed Jan 11 13:43:54 2023 ] 	Top5: 97.30%
[ Wed Jan 11 13:43:54 2023 ] Training epoch: 59
[ Wed Jan 11 14:17:48 2023 ] 	Mean training loss: 0.0891.  Mean training acc: 97.89%.
[ Wed Jan 11 14:17:49 2023 ] 	Time consumption: [Data]01%, [Network]79%
[ Wed Jan 11 14:17:50 2023 ] Eval epoch: 59
[ Wed Jan 11 14:35:34 2023 ] 	Mean test loss of 796 batches: 0.529948137822238.
[ Wed Jan 11 14:36:05 2023 ] 	Top1: 85.17%
[ Wed Jan 11 14:36:05 2023 ] 	Top5: 97.37%
[ Wed Jan 11 14:36:05 2023 ] Training epoch: 60
[ Wed Jan 11 15:07:05 2023 ] 	Mean training loss: 0.0874.  Mean training acc: 97.94%.
[ Wed Jan 11 15:07:05 2023 ] 	Time consumption: [Data]01%, [Network]92%
[ Wed Jan 11 15:07:05 2023 ] Eval epoch: 60
[ Wed Jan 11 15:23:24 2023 ] 	Mean test loss of 796 batches: 0.539895257851736.
[ Wed Jan 11 15:23:25 2023 ] 	Top1: 84.92%
[ Wed Jan 11 15:23:26 2023 ] 	Top5: 97.29%
[ Wed Jan 11 15:23:26 2023 ] Training epoch: 61
[ Wed Jan 11 15:54:56 2023 ] 	Mean training loss: 0.0820.  Mean training acc: 98.15%.
[ Wed Jan 11 15:54:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 15:54:57 2023 ] Eval epoch: 61
[ Wed Jan 11 16:06:28 2023 ] 	Mean test loss of 796 batches: 0.5487644192832873.
[ Wed Jan 11 16:15:47 2023 ] 	Top1: 84.78%
[ Wed Jan 11 16:15:47 2023 ] 	Top5: 97.24%
[ Wed Jan 11 16:15:48 2023 ] Training epoch: 62
[ Wed Jan 11 16:46:26 2023 ] 	Mean training loss: 0.0791.  Mean training acc: 98.21%.
[ Wed Jan 11 16:46:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 16:46:27 2023 ] Eval epoch: 62
[ Wed Jan 11 17:03:43 2023 ] 	Mean test loss of 796 batches: 0.5459676294741993.
[ Wed Jan 11 17:03:44 2023 ] 	Top1: 85.00%
[ Wed Jan 11 17:03:45 2023 ] 	Top5: 97.24%
[ Wed Jan 11 17:03:46 2023 ] Training epoch: 63
[ Wed Jan 11 17:30:01 2023 ] 	Mean training loss: 0.0749.  Mean training acc: 98.28%.
[ Wed Jan 11 17:30:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 17:30:01 2023 ] Eval epoch: 63
[ Wed Jan 11 17:39:43 2023 ] 	Mean test loss of 796 batches: 0.5510815458334796.
[ Wed Jan 11 17:40:21 2023 ] 	Top1: 84.89%
[ Wed Jan 11 17:40:21 2023 ] 	Top5: 97.21%
[ Wed Jan 11 17:40:22 2023 ] Training epoch: 64
[ Wed Jan 11 17:56:30 2023 ] 	Mean training loss: 0.0709.  Mean training acc: 98.53%.
[ Wed Jan 11 17:56:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan 11 17:56:30 2023 ] Eval epoch: 64
[ Wed Jan 11 18:04:44 2023 ] 	Mean test loss of 796 batches: 0.5500260364713531.
[ Wed Jan 11 18:05:28 2023 ] 	Top1: 85.04%
[ Wed Jan 11 18:05:28 2023 ] 	Top5: 97.21%
[ Wed Jan 11 18:05:28 2023 ] Training epoch: 65
[ Wed Jan 11 18:23:43 2023 ] 	Mean training loss: 0.0713.  Mean training acc: 98.46%.
[ Wed Jan 11 18:23:44 2023 ] 	Time consumption: [Data]01%, [Network]89%
[ Wed Jan 11 18:23:44 2023 ] Eval epoch: 65
[ Wed Jan 11 18:32:30 2023 ] 	Mean test loss of 796 batches: 0.5442402974267176.
[ Wed Jan 11 18:32:31 2023 ] 	Top1: 85.05%
[ Wed Jan 11 18:32:31 2023 ] 	Top5: 97.20%
[ Wed Jan 11 18:41:34 2023 ] Best accuracy: 0.8517056501502386
[ Wed Jan 11 18:41:34 2023 ] Epoch number: 59
[ Wed Jan 11 18:41:34 2023 ] Model name: work_dir/csub/ctrgcn_local_SHT
[ Wed Jan 11 18:41:34 2023 ] Model total number of params: 1508876
[ Wed Jan 11 18:41:34 2023 ] Weight decay: 0.0004
[ Wed Jan 11 18:41:34 2023 ] Base LR: 0.1
[ Wed Jan 11 18:41:34 2023 ] Batch Size: 64
[ Wed Jan 11 18:41:34 2023 ] Test Batch Size: 64
[ Wed Jan 11 18:41:34 2023 ] seed: 1
[ Wed Jan 25 13:39:32 2023 ] using warm up, epoch: 5
[ Wed Jan 25 13:41:11 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jan 25 13:41:11 2023 ] # Parameters: 1508876
[ Wed Jan 25 13:41:11 2023 ] Training epoch: 1
[ Wed Jan 25 14:04:41 2023 ] 	Mean training loss: 3.0769.  Mean training acc: 24.03%.
[ Wed Jan 25 14:04:41 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 25 14:04:41 2023 ] Eval epoch: 1
[ Wed Jan 25 14:19:16 2023 ] 	Mean test loss of 796 batches: 2.3503922950382807.
[ Wed Jan 25 14:19:17 2023 ] 	Top1: 34.27%
[ Wed Jan 25 14:19:17 2023 ] 	Top5: 68.78%
[ Wed Jan 25 14:19:17 2023 ] Training epoch: 2
[ Wed Jan 25 14:43:09 2023 ] 	Mean training loss: 2.0479.  Mean training acc: 43.21%.
[ Wed Jan 25 14:43:09 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Jan 25 14:43:09 2023 ] Eval epoch: 2
[ Wed Jan 25 14:58:18 2023 ] 	Mean test loss of 796 batches: 1.8187093360340176.
[ Wed Jan 25 14:58:19 2023 ] 	Top1: 47.77%
[ Wed Jan 25 14:58:19 2023 ] 	Top5: 80.63%
[ Wed Jan 25 14:58:19 2023 ] Training epoch: 3
[ Wed Jan 25 15:22:27 2023 ] 	Mean training loss: 1.6314.  Mean training acc: 53.31%.
[ Wed Jan 25 15:22:27 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Jan 25 15:22:28 2023 ] Eval epoch: 3
[ Wed Jan 25 15:37:26 2023 ] 	Mean test loss of 796 batches: 1.5756197216073473.
[ Wed Jan 25 15:37:26 2023 ] 	Top1: 54.76%
[ Wed Jan 25 15:37:27 2023 ] 	Top5: 84.61%
[ Wed Jan 25 15:37:27 2023 ] Training epoch: 4
[ Wed Jan 25 16:00:43 2023 ] 	Mean training loss: 1.4072.  Mean training acc: 58.99%.
[ Wed Jan 25 16:00:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Jan 25 16:00:43 2023 ] Eval epoch: 4
[ Wed Jan 25 16:26:19 2023 ] 	Mean test loss of 796 batches: 1.4933086446481734.
[ Wed Jan 25 16:26:19 2023 ] 	Top1: 56.73%
[ Wed Jan 25 16:26:20 2023 ] 	Top5: 86.24%
[ Wed Jan 25 16:26:20 2023 ] Training epoch: 5
[ Thu Jan 26 04:23:55 2023 ] 	Mean training loss: 1.2856.  Mean training acc: 62.57%.
[ Thu Jan 26 04:23:55 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Jan 26 04:23:55 2023 ] Eval epoch: 5
[ Thu Jan 26 10:05:20 2023 ] 	Mean test loss of 796 batches: 1.4409156236516771.
[ Thu Jan 26 10:05:22 2023 ] 	Top1: 59.20%
[ Thu Jan 26 10:05:22 2023 ] 	Top5: 86.88%
[ Thu Jan 26 10:05:23 2023 ] Training epoch: 6
[ Thu Jan 26 12:24:28 2023 ] 	Mean training loss: 1.1391.  Mean training acc: 66.30%.
[ Thu Jan 26 12:35:59 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Jan 26 12:36:01 2023 ] Eval epoch: 6
[ Thu Jan 26 12:50:51 2023 ] 	Mean test loss of 796 batches: 1.2440674886032566.
[ Thu Jan 26 12:50:51 2023 ] 	Top1: 63.94%
[ Thu Jan 26 12:50:52 2023 ] 	Top5: 89.96%
[ Thu Jan 26 12:50:52 2023 ] Training epoch: 7
[ Thu Jan 26 13:21:44 2023 ] 	Mean training loss: 1.0481.  Mean training acc: 68.72%.
[ Thu Jan 26 13:21:44 2023 ] 	Time consumption: [Data]00%, [Network]79%
[ Thu Jan 26 13:21:45 2023 ] Eval epoch: 7
[ Thu Jan 26 13:36:41 2023 ] 	Mean test loss of 796 batches: 1.2960279434170556.
[ Thu Jan 26 13:36:42 2023 ] 	Top1: 62.62%
[ Thu Jan 26 13:36:42 2023 ] 	Top5: 90.08%
[ Thu Jan 26 13:36:43 2023 ] Training epoch: 8
[ Thu Jan 26 14:01:01 2023 ] 	Mean training loss: 0.9913.  Mean training acc: 70.33%.
[ Thu Jan 26 14:01:01 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Jan 26 14:01:01 2023 ] Eval epoch: 8
[ Thu Jan 26 14:16:07 2023 ] 	Mean test loss of 796 batches: 1.2226672263151437.
[ Thu Jan 26 14:16:07 2023 ] 	Top1: 63.82%
[ Thu Jan 26 14:16:08 2023 ] 	Top5: 90.52%
[ Thu Jan 26 14:16:08 2023 ] Training epoch: 9
[ Thu Jan 26 14:40:19 2023 ] 	Mean training loss: 0.9377.  Mean training acc: 71.86%.
[ Thu Jan 26 14:44:35 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Jan 26 14:44:36 2023 ] Eval epoch: 9
[ Thu Jan 26 19:25:41 2023 ] 	Mean test loss of 796 batches: 1.2422854756964512.
[ Thu Jan 26 19:25:41 2023 ] 	Top1: 64.29%
[ Thu Jan 26 19:25:42 2023 ] 	Top5: 90.91%
[ Thu Jan 26 19:25:42 2023 ] Training epoch: 10
[ Thu Jan 26 22:29:40 2023 ] 	Mean training loss: 0.9101.  Mean training acc: 72.56%.
[ Thu Jan 26 22:29:40 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Thu Jan 26 22:29:40 2023 ] Eval epoch: 10
[ Fri Jan 27 07:01:15 2023 ] 	Mean test loss of 796 batches: 1.237615883986854.
[ Fri Jan 27 07:06:58 2023 ] 	Top1: 65.23%
[ Fri Jan 27 07:06:59 2023 ] 	Top5: 91.84%
[ Fri Jan 27 07:06:59 2023 ] Training epoch: 11
[ Fri Jan 27 13:18:05 2023 ] 	Mean training loss: 0.8852.  Mean training acc: 73.29%.
[ Fri Jan 27 13:18:06 2023 ] 	Time consumption: [Data]00%, [Network]95%
[ Fri Jan 27 13:18:06 2023 ] Eval epoch: 11
[ Fri Jan 27 19:17:18 2023 ] 	Mean test loss of 796 batches: 1.1236576895093797.
[ Fri Jan 27 19:17:18 2023 ] 	Top1: 66.10%
[ Fri Jan 27 19:17:19 2023 ] 	Top5: 91.93%
[ Fri Jan 27 19:17:19 2023 ] Training epoch: 12
[ Fri Jan 27 23:30:22 2023 ] 	Mean training loss: 0.8690.  Mean training acc: 73.80%.
[ Fri Jan 27 23:30:22 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Fri Jan 27 23:30:22 2023 ] Eval epoch: 12
[ Sat Jan 28 02:27:06 2023 ] 	Mean test loss of 796 batches: 1.0706920911693694.
[ Sat Jan 28 02:27:06 2023 ] 	Top1: 67.85%
[ Sat Jan 28 02:27:07 2023 ] 	Top5: 92.29%
[ Sat Jan 28 02:27:07 2023 ] Training epoch: 13
[ Sat Jan 28 06:46:38 2023 ] 	Mean training loss: 0.8543.  Mean training acc: 74.06%.
[ Sat Jan 28 06:46:38 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Jan 28 06:46:39 2023 ] Eval epoch: 13
[ Sat Jan 28 08:22:43 2023 ] 	Mean test loss of 796 batches: 1.1333315237682668.
[ Sat Jan 28 08:23:12 2023 ] 	Top1: 65.95%
[ Sat Jan 28 08:23:12 2023 ] 	Top5: 91.84%
[ Sat Jan 28 08:23:12 2023 ] Training epoch: 14
[ Sat Jan 28 12:40:48 2023 ] 	Mean training loss: 0.8334.  Mean training acc: 74.82%.
[ Sat Jan 28 12:40:48 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Sat Jan 28 12:40:48 2023 ] Eval epoch: 14
[ Sat Jan 28 15:43:39 2023 ] 	Mean test loss of 796 batches: 1.112950578182187.
[ Sat Jan 28 15:43:39 2023 ] 	Top1: 67.22%
[ Sat Jan 28 15:43:40 2023 ] 	Top5: 91.35%
[ Sat Jan 28 15:43:40 2023 ] Training epoch: 15
[ Sat Jan 28 20:05:56 2023 ] 	Mean training loss: 0.8211.  Mean training acc: 75.37%.
[ Sat Jan 28 20:05:57 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sat Jan 28 20:05:57 2023 ] Eval epoch: 15
[ Sat Jan 28 23:18:00 2023 ] 	Mean test loss of 796 batches: 1.0917128144047368.
[ Sat Jan 28 23:18:00 2023 ] 	Top1: 68.04%
[ Sat Jan 28 23:18:01 2023 ] 	Top5: 91.71%
[ Sat Jan 28 23:18:01 2023 ] Training epoch: 16
[ Sun Jan 29 03:47:20 2023 ] 	Mean training loss: 0.8115.  Mean training acc: 75.36%.
[ Sun Jan 29 03:47:20 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Sun Jan 29 03:47:20 2023 ] Eval epoch: 16
[ Sun Jan 29 06:56:12 2023 ] 	Mean test loss of 796 batches: 1.1013779669026633.
[ Sun Jan 29 06:56:13 2023 ] 	Top1: 67.00%
[ Sun Jan 29 06:56:13 2023 ] 	Top5: 92.36%
[ Sun Jan 29 06:56:13 2023 ] Training epoch: 17
[ Sun Jan 29 16:05:30 2023 ] 	Mean training loss: 0.7960.  Mean training acc: 75.99%.
[ Sun Jan 29 16:05:30 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Sun Jan 29 16:05:30 2023 ] Eval epoch: 17
[ Sun Jan 29 20:35:08 2023 ] 	Mean test loss of 796 batches: 1.025925643554884.
[ Sun Jan 29 20:35:08 2023 ] 	Top1: 69.43%
[ Sun Jan 29 20:35:08 2023 ] 	Top5: 92.38%
[ Sun Jan 29 20:35:08 2023 ] Training epoch: 18
[ Mon Jan 30 00:10:53 2023 ] 	Mean training loss: 0.7887.  Mean training acc: 75.94%.
[ Mon Jan 30 00:10:53 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 00:10:53 2023 ] Eval epoch: 18
[ Mon Jan 30 03:05:00 2023 ] 	Mean test loss of 796 batches: 1.198008897428836.
[ Mon Jan 30 03:05:00 2023 ] 	Top1: 67.90%
[ Mon Jan 30 03:05:00 2023 ] 	Top5: 92.31%
[ Mon Jan 30 03:05:00 2023 ] Training epoch: 19
[ Mon Jan 30 05:08:37 2023 ] 	Mean training loss: 0.7880.  Mean training acc: 76.07%.
[ Mon Jan 30 05:08:37 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 05:08:37 2023 ] Eval epoch: 19
[ Mon Jan 30 05:23:36 2023 ] 	Mean test loss of 796 batches: 1.0237615934793074.
[ Mon Jan 30 05:23:37 2023 ] 	Top1: 70.13%
[ Mon Jan 30 05:23:37 2023 ] 	Top5: 92.12%
[ Mon Jan 30 05:23:37 2023 ] Training epoch: 20
[ Mon Jan 30 05:47:53 2023 ] 	Mean training loss: 0.7757.  Mean training acc: 76.32%.
[ Mon Jan 30 05:47:53 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 05:47:53 2023 ] Eval epoch: 20
[ Mon Jan 30 06:02:51 2023 ] 	Mean test loss of 796 batches: 1.0594077689488928.
[ Mon Jan 30 06:02:52 2023 ] 	Top1: 69.78%
[ Mon Jan 30 06:02:52 2023 ] 	Top5: 92.68%
[ Mon Jan 30 06:02:52 2023 ] Training epoch: 21
[ Mon Jan 30 06:26:22 2023 ] 	Mean training loss: 0.7764.  Mean training acc: 76.27%.
[ Mon Jan 30 06:26:22 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 06:26:26 2023 ] Eval epoch: 21
[ Mon Jan 30 06:40:32 2023 ] 	Mean test loss of 796 batches: 1.1031977518194884.
[ Mon Jan 30 06:40:34 2023 ] 	Top1: 68.80%
[ Mon Jan 30 06:40:34 2023 ] 	Top5: 92.14%
[ Mon Jan 30 06:40:35 2023 ] Training epoch: 22
[ Mon Jan 30 07:05:03 2023 ] 	Mean training loss: 0.7720.  Mean training acc: 76.35%.
[ Mon Jan 30 07:05:06 2023 ] 	Time consumption: [Data]00%, [Network]97%
[ Mon Jan 30 07:05:07 2023 ] Eval epoch: 22
[ Mon Jan 30 07:19:56 2023 ] 	Mean test loss of 796 batches: 1.0611439379840042.
[ Mon Jan 30 07:19:57 2023 ] 	Top1: 69.46%
[ Mon Jan 30 07:19:57 2023 ] 	Top5: 92.87%
[ Mon Jan 30 07:20:04 2023 ] Training epoch: 23
[ Mon Jan 30 07:45:03 2023 ] 	Mean training loss: 0.7650.  Mean training acc: 76.87%.
[ Mon Jan 30 07:45:04 2023 ] 	Time consumption: [Data]00%, [Network]95%
[ Mon Jan 30 07:45:04 2023 ] Eval epoch: 23
[ Mon Jan 30 08:00:10 2023 ] 	Mean test loss of 796 batches: 1.0628473894979487.
[ Mon Jan 30 08:00:12 2023 ] 	Top1: 69.45%
[ Mon Jan 30 08:00:13 2023 ] 	Top5: 92.68%
[ Mon Jan 30 08:00:13 2023 ] Training epoch: 24
[ Mon Jan 30 08:25:38 2023 ] 	Mean training loss: 0.7629.  Mean training acc: 76.59%.
[ Mon Jan 30 08:25:39 2023 ] 	Time consumption: [Data]00%, [Network]96%
[ Mon Jan 30 08:25:39 2023 ] Eval epoch: 24
[ Mon Jan 30 08:40:39 2023 ] 	Mean test loss of 796 batches: 1.0077698818553034.
[ Mon Jan 30 08:40:40 2023 ] 	Top1: 69.95%
[ Mon Jan 30 08:40:40 2023 ] 	Top5: 92.89%
[ Mon Jan 30 08:40:40 2023 ] Training epoch: 25
[ Mon Jan 30 09:04:21 2023 ] 	Mean training loss: 0.7590.  Mean training acc: 77.03%.
[ Mon Jan 30 09:04:21 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Mon Jan 30 09:04:21 2023 ] Eval epoch: 25
[ Mon Jan 30 09:18:48 2023 ] 	Mean test loss of 796 batches: 1.0439088128170175.
[ Mon Jan 30 09:18:49 2023 ] 	Top1: 69.58%
[ Mon Jan 30 09:18:49 2023 ] 	Top5: 92.47%
[ Mon Jan 30 09:18:50 2023 ] Training epoch: 26
[ Mon Jan 30 09:42:51 2023 ] 	Mean training loss: 0.7642.  Mean training acc: 76.95%.
[ Mon Jan 30 09:42:51 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 09:42:52 2023 ] Eval epoch: 26
[ Mon Jan 30 09:57:31 2023 ] 	Mean test loss of 796 batches: 1.0124601090523466.
[ Mon Jan 30 09:57:31 2023 ] 	Top1: 70.59%
[ Mon Jan 30 09:57:31 2023 ] 	Top5: 93.01%
[ Mon Jan 30 09:57:32 2023 ] Training epoch: 27
[ Mon Jan 30 12:44:34 2023 ] 	Mean training loss: 0.7528.  Mean training acc: 77.08%.
[ Mon Jan 30 12:44:34 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 12:44:35 2023 ] Eval epoch: 27
[ Mon Jan 30 14:37:03 2023 ] 	Mean test loss of 796 batches: 1.1774468024322136.
[ Mon Jan 30 14:37:04 2023 ] 	Top1: 66.81%
[ Mon Jan 30 14:37:04 2023 ] 	Top5: 91.62%
[ Mon Jan 30 14:37:04 2023 ] Training epoch: 28
[ Mon Jan 30 16:08:13 2023 ] 	Mean training loss: 0.7509.  Mean training acc: 77.16%.
[ Mon Jan 30 16:08:13 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 16:08:13 2023 ] Eval epoch: 28
[ Mon Jan 30 17:43:11 2023 ] 	Mean test loss of 796 batches: 1.19769488956461.
[ Mon Jan 30 17:43:11 2023 ] 	Top1: 64.37%
[ Mon Jan 30 17:43:11 2023 ] 	Top5: 90.47%
[ Mon Jan 30 17:43:12 2023 ] Training epoch: 29
[ Mon Jan 30 19:56:57 2023 ] 	Mean training loss: 0.7430.  Mean training acc: 77.45%.
[ Mon Jan 30 19:56:57 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Mon Jan 30 19:56:57 2023 ] Eval epoch: 29
[ Mon Jan 30 21:57:16 2023 ] 	Mean test loss of 796 batches: 1.2830988925755324.
[ Mon Jan 30 21:57:16 2023 ] 	Top1: 65.39%
[ Mon Jan 30 21:57:17 2023 ] 	Top5: 91.47%
[ Mon Jan 30 21:57:17 2023 ] Training epoch: 30
[ Tue Jan 31 04:59:47 2023 ] 	Mean training loss: 0.7413.  Mean training acc: 77.43%.
[ Tue Jan 31 04:59:47 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 04:59:47 2023 ] Eval epoch: 30
[ Tue Jan 31 05:14:56 2023 ] 	Mean test loss of 796 batches: 0.9273126859910524.
[ Tue Jan 31 05:14:56 2023 ] 	Top1: 72.38%
[ Tue Jan 31 05:14:57 2023 ] 	Top5: 93.54%
[ Tue Jan 31 05:14:57 2023 ] Training epoch: 31
[ Tue Jan 31 05:39:22 2023 ] 	Mean training loss: 0.7409.  Mean training acc: 77.49%.
[ Tue Jan 31 05:39:22 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 05:39:22 2023 ] Eval epoch: 31
[ Tue Jan 31 05:54:09 2023 ] 	Mean test loss of 796 batches: 0.9241587921378002.
[ Tue Jan 31 05:54:09 2023 ] 	Top1: 72.39%
[ Tue Jan 31 05:54:09 2023 ] 	Top5: 93.96%
[ Tue Jan 31 05:54:10 2023 ] Training epoch: 32
[ Tue Jan 31 06:18:28 2023 ] 	Mean training loss: 0.7442.  Mean training acc: 77.19%.
[ Tue Jan 31 06:18:28 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 06:18:28 2023 ] Eval epoch: 32
[ Tue Jan 31 06:33:31 2023 ] 	Mean test loss of 796 batches: 0.9686159934455426.
[ Tue Jan 31 06:33:31 2023 ] 	Top1: 70.97%
[ Tue Jan 31 06:33:32 2023 ] 	Top5: 93.50%
[ Tue Jan 31 06:33:33 2023 ] Training epoch: 33
[ Tue Jan 31 06:58:51 2023 ] 	Mean training loss: 0.7442.  Mean training acc: 77.41%.
[ Tue Jan 31 06:58:51 2023 ] 	Time consumption: [Data]00%, [Network]97%
[ Tue Jan 31 06:58:51 2023 ] Eval epoch: 33
[ Tue Jan 31 07:13:47 2023 ] 	Mean test loss of 796 batches: 1.2350753216288197.
[ Tue Jan 31 07:13:48 2023 ] 	Top1: 64.51%
[ Tue Jan 31 07:13:48 2023 ] 	Top5: 90.81%
[ Tue Jan 31 07:13:48 2023 ] Training epoch: 34
[ Tue Jan 31 07:38:08 2023 ] 	Mean training loss: 0.7379.  Mean training acc: 77.63%.
[ Tue Jan 31 07:38:10 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 07:38:11 2023 ] Eval epoch: 34
[ Tue Jan 31 07:53:08 2023 ] 	Mean test loss of 796 batches: 1.010416033766677.
[ Tue Jan 31 07:53:08 2023 ] 	Top1: 70.21%
[ Tue Jan 31 07:53:09 2023 ] 	Top5: 93.41%
[ Tue Jan 31 07:53:09 2023 ] Training epoch: 35
[ Tue Jan 31 08:17:41 2023 ] 	Mean training loss: 0.7334.  Mean training acc: 77.62%.
[ Tue Jan 31 08:17:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 08:17:44 2023 ] Eval epoch: 35
[ Tue Jan 31 08:32:56 2023 ] 	Mean test loss of 796 batches: 1.1019983117529495.
[ Tue Jan 31 08:32:57 2023 ] 	Top1: 68.84%
[ Tue Jan 31 08:32:57 2023 ] 	Top5: 91.47%
[ Tue Jan 31 08:32:58 2023 ] Training epoch: 36
[ Tue Jan 31 08:57:05 2023 ] 	Mean training loss: 0.4354.  Mean training acc: 86.71%.
[ Tue Jan 31 08:57:05 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 08:57:05 2023 ] Eval epoch: 36
[ Tue Jan 31 09:11:58 2023 ] 	Mean test loss of 796 batches: 0.5473641182609539.
[ Tue Jan 31 09:11:59 2023 ] 	Top1: 82.84%
[ Tue Jan 31 09:11:59 2023 ] 	Top5: 97.06%
[ Tue Jan 31 09:12:02 2023 ] Training epoch: 37
[ Tue Jan 31 09:37:44 2023 ] 	Mean training loss: 0.3542.  Mean training acc: 89.11%.
[ Tue Jan 31 09:37:46 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 09:37:46 2023 ] Eval epoch: 37
[ Tue Jan 31 09:56:04 2023 ] 	Mean test loss of 796 batches: 0.5531931332963046.
[ Tue Jan 31 09:56:05 2023 ] 	Top1: 82.95%
[ Tue Jan 31 09:56:05 2023 ] 	Top5: 97.02%
[ Tue Jan 31 09:56:06 2023 ] Training epoch: 38
[ Tue Jan 31 10:26:36 2023 ] 	Mean training loss: 0.3272.  Mean training acc: 89.97%.
[ Tue Jan 31 10:26:36 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 10:26:37 2023 ] Eval epoch: 38
[ Tue Jan 31 10:45:12 2023 ] 	Mean test loss of 796 batches: 0.5308242082389905.
[ Tue Jan 31 10:45:13 2023 ] 	Top1: 83.41%
[ Tue Jan 31 10:45:13 2023 ] 	Top5: 97.23%
[ Tue Jan 31 10:45:13 2023 ] Training epoch: 39
[ Tue Jan 31 11:16:25 2023 ] 	Mean training loss: 0.3040.  Mean training acc: 90.59%.
[ Tue Jan 31 11:16:26 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 11:16:26 2023 ] Eval epoch: 39
[ Tue Jan 31 11:34:11 2023 ] 	Mean test loss of 796 batches: 0.5194574367236252.
[ Tue Jan 31 11:34:11 2023 ] 	Top1: 83.98%
[ Tue Jan 31 11:34:12 2023 ] 	Top5: 97.37%
[ Tue Jan 31 11:34:12 2023 ] Training epoch: 40
[ Tue Jan 31 12:03:43 2023 ] 	Mean training loss: 0.2858.  Mean training acc: 91.27%.
[ Tue Jan 31 12:03:43 2023 ] 	Time consumption: [Data]00%, [Network]98%
[ Tue Jan 31 12:03:43 2023 ] Eval epoch: 40
[ Tue Jan 31 12:21:13 2023 ] 	Mean test loss of 796 batches: 0.5357401011390003.
[ Tue Jan 31 12:21:13 2023 ] 	Top1: 83.82%
[ Tue Jan 31 12:21:14 2023 ] 	Top5: 97.18%
[ Tue Jan 31 12:21:14 2023 ] Training epoch: 41
[ Tue Jan 31 12:51:45 2023 ] 	Mean training loss: 0.2703.  Mean training acc: 91.72%.
[ Tue Jan 31 12:51:45 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 12:51:45 2023 ] Eval epoch: 41
[ Tue Jan 31 13:09:27 2023 ] 	Mean test loss of 796 batches: 0.5546806311075712.
[ Tue Jan 31 13:09:27 2023 ] 	Top1: 83.25%
[ Tue Jan 31 13:09:28 2023 ] 	Top5: 97.08%
[ Tue Jan 31 13:09:28 2023 ] Training epoch: 42
[ Tue Jan 31 13:39:01 2023 ] 	Mean training loss: 0.2624.  Mean training acc: 92.04%.
[ Tue Jan 31 13:39:01 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 13:39:01 2023 ] Eval epoch: 42
[ Tue Jan 31 13:56:46 2023 ] 	Mean test loss of 796 batches: 0.5367325221623608.
[ Tue Jan 31 13:56:46 2023 ] 	Top1: 83.73%
[ Tue Jan 31 13:56:47 2023 ] 	Top5: 97.23%
[ Tue Jan 31 13:56:47 2023 ] Training epoch: 43
[ Tue Jan 31 14:26:23 2023 ] 	Mean training loss: 0.2545.  Mean training acc: 92.32%.
[ Tue Jan 31 14:26:23 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 14:26:23 2023 ] Eval epoch: 43
[ Tue Jan 31 14:43:56 2023 ] 	Mean test loss of 796 batches: 0.555340414497084.
[ Tue Jan 31 14:43:57 2023 ] 	Top1: 83.31%
[ Tue Jan 31 14:43:57 2023 ] 	Top5: 97.12%
[ Tue Jan 31 14:43:57 2023 ] Training epoch: 44
[ Tue Jan 31 15:13:43 2023 ] 	Mean training loss: 0.2461.  Mean training acc: 92.50%.
[ Tue Jan 31 15:13:43 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 15:13:43 2023 ] Eval epoch: 44
[ Tue Jan 31 15:30:49 2023 ] 	Mean test loss of 796 batches: 0.5712243887366512.
[ Tue Jan 31 15:30:50 2023 ] 	Top1: 83.04%
[ Tue Jan 31 15:30:50 2023 ] 	Top5: 97.05%
[ Tue Jan 31 15:30:50 2023 ] Training epoch: 45
[ Tue Jan 31 15:59:56 2023 ] 	Mean training loss: 0.2404.  Mean training acc: 92.77%.
[ Tue Jan 31 15:59:56 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 15:59:56 2023 ] Eval epoch: 45
[ Tue Jan 31 16:17:07 2023 ] 	Mean test loss of 796 batches: 0.5671933715760558.
[ Tue Jan 31 16:17:08 2023 ] 	Top1: 83.43%
[ Tue Jan 31 16:17:08 2023 ] 	Top5: 97.03%
[ Tue Jan 31 16:17:08 2023 ] Training epoch: 46
[ Tue Jan 31 17:01:23 2023 ] 	Mean training loss: 0.2302.  Mean training acc: 92.98%.
[ Tue Jan 31 17:01:23 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 17:01:23 2023 ] Eval epoch: 46
[ Tue Jan 31 17:18:19 2023 ] 	Mean test loss of 796 batches: 0.5815139334068526.
[ Tue Jan 31 17:18:19 2023 ] 	Top1: 83.06%
[ Tue Jan 31 17:18:20 2023 ] 	Top5: 97.01%
[ Tue Jan 31 17:18:20 2023 ] Training epoch: 47
[ Tue Jan 31 17:47:10 2023 ] 	Mean training loss: 0.2317.  Mean training acc: 92.95%.
[ Tue Jan 31 17:47:10 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 17:47:10 2023 ] Eval epoch: 47
[ Tue Jan 31 18:03:48 2023 ] 	Mean test loss of 796 batches: 0.559522710628246.
[ Tue Jan 31 18:03:48 2023 ] 	Top1: 83.43%
[ Tue Jan 31 18:03:49 2023 ] 	Top5: 96.94%
[ Tue Jan 31 18:03:49 2023 ] Training epoch: 48
[ Tue Jan 31 18:32:31 2023 ] 	Mean training loss: 0.2315.  Mean training acc: 92.97%.
[ Tue Jan 31 18:32:31 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 18:32:31 2023 ] Eval epoch: 48
[ Tue Jan 31 18:48:59 2023 ] 	Mean test loss of 796 batches: 0.6079664834910751.
[ Tue Jan 31 18:48:59 2023 ] 	Top1: 82.39%
[ Tue Jan 31 18:48:59 2023 ] 	Top5: 96.77%
[ Tue Jan 31 18:48:59 2023 ] Training epoch: 49
[ Tue Jan 31 19:18:11 2023 ] 	Mean training loss: 0.2256.  Mean training acc: 93.10%.
[ Tue Jan 31 19:18:11 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 19:18:12 2023 ] Eval epoch: 49
[ Tue Jan 31 19:35:10 2023 ] 	Mean test loss of 796 batches: 0.5954937569928079.
[ Tue Jan 31 19:35:11 2023 ] 	Top1: 82.45%
[ Tue Jan 31 19:35:11 2023 ] 	Top5: 96.85%
[ Tue Jan 31 19:35:11 2023 ] Training epoch: 50
[ Tue Jan 31 20:03:28 2023 ] 	Mean training loss: 0.2253.  Mean training acc: 93.09%.
[ Tue Jan 31 20:03:28 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 20:03:28 2023 ] Eval epoch: 50
[ Tue Jan 31 20:20:21 2023 ] 	Mean test loss of 796 batches: 0.615354402968894.
[ Tue Jan 31 20:20:21 2023 ] 	Top1: 82.16%
[ Tue Jan 31 20:20:21 2023 ] 	Top5: 96.63%
[ Tue Jan 31 20:20:22 2023 ] Training epoch: 51
[ Tue Jan 31 20:49:02 2023 ] 	Mean training loss: 0.2205.  Mean training acc: 93.32%.
[ Tue Jan 31 20:49:02 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 20:49:02 2023 ] Eval epoch: 51
[ Tue Jan 31 21:05:31 2023 ] 	Mean test loss of 796 batches: 0.6001183013501928.
[ Tue Jan 31 21:05:31 2023 ] 	Top1: 82.84%
[ Tue Jan 31 21:05:32 2023 ] 	Top5: 96.87%
[ Tue Jan 31 21:05:32 2023 ] Training epoch: 52
[ Tue Jan 31 21:34:44 2023 ] 	Mean training loss: 0.2244.  Mean training acc: 93.19%.
[ Tue Jan 31 21:34:44 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 21:34:44 2023 ] Eval epoch: 52
[ Tue Jan 31 21:51:26 2023 ] 	Mean test loss of 796 batches: 0.6399873980700072.
[ Tue Jan 31 21:51:26 2023 ] 	Top1: 81.71%
[ Tue Jan 31 21:51:26 2023 ] 	Top5: 96.56%
[ Tue Jan 31 21:51:26 2023 ] Training epoch: 53
[ Tue Jan 31 22:20:13 2023 ] 	Mean training loss: 0.2182.  Mean training acc: 93.47%.
[ Tue Jan 31 22:20:13 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 22:20:14 2023 ] Eval epoch: 53
[ Tue Jan 31 22:37:44 2023 ] 	Mean test loss of 796 batches: 0.6102707653713586.
[ Tue Jan 31 22:37:44 2023 ] 	Top1: 82.73%
[ Tue Jan 31 22:37:44 2023 ] 	Top5: 96.87%
[ Tue Jan 31 22:37:45 2023 ] Training epoch: 54
[ Tue Jan 31 23:07:32 2023 ] 	Mean training loss: 0.2186.  Mean training acc: 93.37%.
[ Tue Jan 31 23:07:32 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 23:07:33 2023 ] Eval epoch: 54
[ Tue Jan 31 23:24:55 2023 ] 	Mean test loss of 796 batches: 0.6261730940647461.
[ Tue Jan 31 23:24:56 2023 ] 	Top1: 82.23%
[ Tue Jan 31 23:24:56 2023 ] 	Top5: 96.81%
[ Tue Jan 31 23:24:56 2023 ] Training epoch: 55
[ Tue Jan 31 23:54:38 2023 ] 	Mean training loss: 0.2189.  Mean training acc: 93.43%.
[ Tue Jan 31 23:54:38 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Tue Jan 31 23:54:38 2023 ] Eval epoch: 55
[ Wed Feb  1 00:11:22 2023 ] 	Mean test loss of 796 batches: 0.6311063588919801.
[ Wed Feb  1 00:11:22 2023 ] 	Top1: 81.96%
[ Wed Feb  1 00:11:22 2023 ] 	Top5: 96.77%
[ Wed Feb  1 00:11:22 2023 ] Training epoch: 56
[ Wed Feb  1 00:39:19 2023 ] 	Mean training loss: 0.1384.  Mean training acc: 96.32%.
[ Wed Feb  1 00:39:19 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 00:39:19 2023 ] Eval epoch: 56
[ Wed Feb  1 00:55:55 2023 ] 	Mean test loss of 796 batches: 0.5302014990180881.
[ Wed Feb  1 00:55:56 2023 ] 	Top1: 84.68%
[ Wed Feb  1 00:55:56 2023 ] 	Top5: 97.32%
[ Wed Feb  1 00:55:56 2023 ] Training epoch: 57
[ Wed Feb  1 01:25:45 2023 ] 	Mean training loss: 0.1089.  Mean training acc: 97.29%.
[ Wed Feb  1 01:25:45 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 01:25:45 2023 ] Eval epoch: 57
[ Wed Feb  1 01:42:50 2023 ] 	Mean test loss of 796 batches: 0.5325175438347698.
[ Wed Feb  1 01:42:51 2023 ] 	Top1: 84.79%
[ Wed Feb  1 01:42:51 2023 ] 	Top5: 97.31%
[ Wed Feb  1 01:42:51 2023 ] Training epoch: 58
[ Wed Feb  1 02:11:57 2023 ] 	Mean training loss: 0.0969.  Mean training acc: 97.61%.
[ Wed Feb  1 02:11:57 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 02:11:58 2023 ] Eval epoch: 58
[ Wed Feb  1 02:29:30 2023 ] 	Mean test loss of 796 batches: 0.5337373676882992.
[ Wed Feb  1 02:29:30 2023 ] 	Top1: 84.88%
[ Wed Feb  1 02:29:31 2023 ] 	Top5: 97.34%
[ Wed Feb  1 02:29:31 2023 ] Training epoch: 59
[ Wed Feb  1 02:58:40 2023 ] 	Mean training loss: 0.0917.  Mean training acc: 97.78%.
[ Wed Feb  1 02:58:40 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 02:58:40 2023 ] Eval epoch: 59
[ Wed Feb  1 03:16:00 2023 ] 	Mean test loss of 796 batches: 0.5349630840642181.
[ Wed Feb  1 03:16:00 2023 ] 	Top1: 85.04%
[ Wed Feb  1 03:16:00 2023 ] 	Top5: 97.31%
[ Wed Feb  1 03:16:01 2023 ] Training epoch: 60
[ Wed Feb  1 03:46:06 2023 ] 	Mean training loss: 0.0866.  Mean training acc: 97.97%.
[ Wed Feb  1 03:46:06 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 03:46:06 2023 ] Eval epoch: 60
[ Wed Feb  1 04:03:20 2023 ] 	Mean test loss of 796 batches: 0.5424176616027914.
[ Wed Feb  1 04:03:20 2023 ] 	Top1: 84.98%
[ Wed Feb  1 04:03:21 2023 ] 	Top5: 97.21%
[ Wed Feb  1 04:03:21 2023 ] Training epoch: 61
[ Wed Feb  1 04:33:05 2023 ] 	Mean training loss: 0.0840.  Mean training acc: 98.05%.
[ Wed Feb  1 04:33:05 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 04:33:05 2023 ] Eval epoch: 61
[ Wed Feb  1 04:49:00 2023 ] 	Mean test loss of 796 batches: 0.5504359726035902.
[ Wed Feb  1 04:49:00 2023 ] 	Top1: 84.71%
[ Wed Feb  1 04:49:01 2023 ] 	Top5: 97.11%
[ Wed Feb  1 04:49:01 2023 ] Training epoch: 62
[ Wed Feb  1 05:12:34 2023 ] 	Mean training loss: 0.0770.  Mean training acc: 98.25%.
[ Wed Feb  1 05:12:34 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 05:12:34 2023 ] Eval epoch: 62
[ Wed Feb  1 05:26:38 2023 ] 	Mean test loss of 796 batches: 0.5450527920790167.
[ Wed Feb  1 05:26:38 2023 ] 	Top1: 84.96%
[ Wed Feb  1 05:26:39 2023 ] 	Top5: 97.25%
[ Wed Feb  1 05:26:39 2023 ] Training epoch: 63
[ Wed Feb  1 05:49:55 2023 ] 	Mean training loss: 0.0751.  Mean training acc: 98.30%.
[ Wed Feb  1 05:49:55 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 05:49:55 2023 ] Eval epoch: 63
[ Wed Feb  1 06:03:58 2023 ] 	Mean test loss of 796 batches: 0.5489075211854886.
[ Wed Feb  1 06:03:59 2023 ] 	Top1: 84.82%
[ Wed Feb  1 06:03:59 2023 ] 	Top5: 97.21%
[ Wed Feb  1 06:03:59 2023 ] Training epoch: 64
[ Wed Feb  1 06:27:04 2023 ] 	Mean training loss: 0.0731.  Mean training acc: 98.38%.
[ Wed Feb  1 06:27:04 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 06:27:04 2023 ] Eval epoch: 64
[ Wed Feb  1 06:41:11 2023 ] 	Mean test loss of 796 batches: 0.5391352989186706.
[ Wed Feb  1 06:41:14 2023 ] 	Top1: 85.08%
[ Wed Feb  1 06:41:14 2023 ] 	Top5: 97.28%
[ Wed Feb  1 06:41:14 2023 ] Training epoch: 65
[ Wed Feb  1 07:04:51 2023 ] 	Mean training loss: 0.0703.  Mean training acc: 98.46%.
[ Wed Feb  1 07:04:53 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Feb  1 07:04:54 2023 ] Eval epoch: 65
[ Wed Feb  1 07:18:57 2023 ] 	Mean test loss of 796 batches: 0.5618397819683255.
[ Wed Feb  1 07:18:58 2023 ] 	Top1: 84.70%
[ Wed Feb  1 07:18:58 2023 ] 	Top5: 97.10%
[ Wed Feb  1 07:33:14 2023 ] Best accuracy: 0.8508218935957108
[ Wed Feb  1 07:33:14 2023 ] Epoch number: 64
[ Wed Feb  1 07:33:14 2023 ] Model name: work_dir/csub/ctrgcn_local_SHT
[ Wed Feb  1 07:33:14 2023 ] Model total number of params: 1508876
[ Wed Feb  1 07:33:14 2023 ] Weight decay: 0.0004
[ Wed Feb  1 07:33:14 2023 ] Base LR: 0.1
[ Wed Feb  1 07:33:14 2023 ] Batch Size: 64
[ Wed Feb  1 07:33:14 2023 ] Test Batch Size: 64
[ Wed Feb  1 07:33:14 2023 ] seed: 1
[ Tue Feb 14 19:43:05 2023 ] using warm up, epoch: 5
[ Tue Feb 14 19:43:20 2023 ] Parameters:
{'work_dir': 'work_dir/csub/ctrgcn_local_SHT', 'model_saved_name': 'work_dir/csub/ctrgcn_local_SHT/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Feb 14 19:43:20 2023 ] # Parameters: 1508876
[ Tue Feb 14 19:43:20 2023 ] Training epoch: 1
[ Tue Feb 14 20:00:43 2023 ] 	Mean training loss: 3.0705.  Mean training acc: 23.97%.
[ Tue Feb 14 20:00:43 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:00:43 2023 ] Eval epoch: 1
[ Tue Feb 14 20:10:27 2023 ] 	Mean test loss of 796 batches: 2.3624897858305793.
[ Tue Feb 14 20:10:27 2023 ] 	Top1: 34.06%
[ Tue Feb 14 20:10:27 2023 ] 	Top5: 69.13%
[ Tue Feb 14 20:10:27 2023 ] Training epoch: 2
[ Tue Feb 14 20:27:52 2023 ] 	Mean training loss: 2.0492.  Mean training acc: 43.30%.
[ Tue Feb 14 20:27:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:27:52 2023 ] Eval epoch: 2
[ Tue Feb 14 20:37:35 2023 ] 	Mean test loss of 796 batches: 1.783535722287456.
[ Tue Feb 14 20:37:36 2023 ] 	Top1: 48.56%
[ Tue Feb 14 20:37:36 2023 ] 	Top5: 81.21%
[ Tue Feb 14 20:37:36 2023 ] Training epoch: 3
[ Tue Feb 14 20:54:59 2023 ] 	Mean training loss: 1.6459.  Mean training acc: 53.04%.
[ Tue Feb 14 20:54:59 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 20:54:59 2023 ] Eval epoch: 3
[ Tue Feb 14 21:04:40 2023 ] 	Mean test loss of 796 batches: 1.5608494120776353.
[ Tue Feb 14 21:04:40 2023 ] 	Top1: 54.22%
[ Tue Feb 14 21:04:41 2023 ] 	Top5: 84.88%
[ Tue Feb 14 21:04:41 2023 ] Training epoch: 4
[ Tue Feb 14 21:22:04 2023 ] 	Mean training loss: 1.4350.  Mean training acc: 58.57%.
[ Tue Feb 14 21:22:04 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 21:22:04 2023 ] Eval epoch: 4
[ Tue Feb 14 21:31:23 2023 ] 	Mean test loss of 796 batches: 1.405674771972038.
[ Tue Feb 14 21:31:24 2023 ] 	Top1: 59.46%
[ Tue Feb 14 21:31:24 2023 ] 	Top5: 86.88%
[ Tue Feb 14 21:31:24 2023 ] Training epoch: 5
[ Tue Feb 14 21:48:24 2023 ] 	Mean training loss: 1.3092.  Mean training acc: 61.84%.
[ Tue Feb 14 21:48:24 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 21:48:24 2023 ] Eval epoch: 5
[ Tue Feb 14 21:57:45 2023 ] 	Mean test loss of 796 batches: 1.4647139257671844.
[ Tue Feb 14 21:57:45 2023 ] 	Top1: 58.41%
[ Tue Feb 14 21:57:46 2023 ] 	Top5: 86.04%
[ Tue Feb 14 21:57:46 2023 ] Training epoch: 6
[ Tue Feb 14 22:14:47 2023 ] 	Mean training loss: 1.1711.  Mean training acc: 65.46%.
[ Tue Feb 14 22:14:47 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 22:14:47 2023 ] Eval epoch: 6
[ Tue Feb 14 22:24:09 2023 ] 	Mean test loss of 796 batches: 1.3517309735019003.
[ Tue Feb 14 22:24:09 2023 ] 	Top1: 60.73%
[ Tue Feb 14 22:24:10 2023 ] 	Top5: 87.48%
[ Tue Feb 14 22:24:10 2023 ] Training epoch: 7
[ Tue Feb 14 22:41:09 2023 ] 	Mean training loss: 1.0768.  Mean training acc: 67.98%.
[ Tue Feb 14 22:41:09 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 22:41:09 2023 ] Eval epoch: 7
[ Tue Feb 14 22:50:30 2023 ] 	Mean test loss of 796 batches: 1.402863996112766.
[ Tue Feb 14 22:50:30 2023 ] 	Top1: 59.85%
[ Tue Feb 14 22:50:31 2023 ] 	Top5: 87.56%
[ Tue Feb 14 22:50:31 2023 ] Training epoch: 8
[ Tue Feb 14 23:07:31 2023 ] 	Mean training loss: 1.0073.  Mean training acc: 69.93%.
[ Tue Feb 14 23:07:31 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 23:07:31 2023 ] Eval epoch: 8
[ Tue Feb 14 23:16:52 2023 ] 	Mean test loss of 796 batches: 1.4774912559806401.
[ Tue Feb 14 23:16:52 2023 ] 	Top1: 57.98%
[ Tue Feb 14 23:16:53 2023 ] 	Top5: 87.48%
[ Tue Feb 14 23:16:53 2023 ] Training epoch: 9
[ Tue Feb 14 23:33:52 2023 ] 	Mean training loss: 0.9494.  Mean training acc: 71.57%.
[ Tue Feb 14 23:33:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Feb 14 23:33:52 2023 ] Eval epoch: 9
[ Tue Feb 14 23:43:10 2023 ] 	Mean test loss of 796 batches: 1.5952763077451955.
[ Tue Feb 14 23:43:10 2023 ] 	Top1: 57.03%
[ Tue Feb 14 23:43:11 2023 ] 	Top5: 86.65%
[ Tue Feb 14 23:43:11 2023 ] Training epoch: 10
[ Wed Feb 15 00:00:10 2023 ] 	Mean training loss: 0.9184.  Mean training acc: 72.55%.
[ Wed Feb 15 00:00:10 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 00:00:10 2023 ] Eval epoch: 10
[ Wed Feb 15 00:09:26 2023 ] 	Mean test loss of 796 batches: 1.1374590360564203.
[ Wed Feb 15 00:09:26 2023 ] 	Top1: 65.34%
[ Wed Feb 15 00:09:27 2023 ] 	Top5: 91.69%
[ Wed Feb 15 00:09:27 2023 ] Training epoch: 11
[ Wed Feb 15 00:26:26 2023 ] 	Mean training loss: 0.8834.  Mean training acc: 73.67%.
[ Wed Feb 15 00:26:26 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 00:26:26 2023 ] Eval epoch: 11
[ Wed Feb 15 00:35:39 2023 ] 	Mean test loss of 796 batches: 1.1061889555810684.
[ Wed Feb 15 00:35:40 2023 ] 	Top1: 67.27%
[ Wed Feb 15 00:35:40 2023 ] 	Top5: 91.93%
[ Wed Feb 15 00:35:40 2023 ] Training epoch: 12
[ Wed Feb 15 00:52:39 2023 ] 	Mean training loss: 0.8649.  Mean training acc: 73.88%.
[ Wed Feb 15 00:52:39 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 00:52:39 2023 ] Eval epoch: 12
[ Wed Feb 15 01:01:45 2023 ] 	Mean test loss of 796 batches: 1.039157291340768.
[ Wed Feb 15 01:01:46 2023 ] 	Top1: 69.22%
[ Wed Feb 15 01:01:46 2023 ] 	Top5: 92.08%
[ Wed Feb 15 01:01:46 2023 ] Training epoch: 13
[ Wed Feb 15 01:18:39 2023 ] 	Mean training loss: 0.8485.  Mean training acc: 74.39%.
[ Wed Feb 15 01:18:39 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 01:18:39 2023 ] Eval epoch: 13
[ Wed Feb 15 01:27:39 2023 ] 	Mean test loss of 796 batches: 1.1253070481982663.
[ Wed Feb 15 01:27:39 2023 ] 	Top1: 66.68%
[ Wed Feb 15 01:27:40 2023 ] 	Top5: 91.37%
[ Wed Feb 15 01:27:40 2023 ] Training epoch: 14
[ Wed Feb 15 01:44:34 2023 ] 	Mean training loss: 0.8377.  Mean training acc: 74.73%.
[ Wed Feb 15 01:44:34 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 01:44:34 2023 ] Eval epoch: 14
[ Wed Feb 15 01:53:34 2023 ] 	Mean test loss of 796 batches: 1.284532861194419.
[ Wed Feb 15 01:53:35 2023 ] 	Top1: 64.06%
[ Wed Feb 15 01:53:35 2023 ] 	Top5: 90.12%
[ Wed Feb 15 01:53:35 2023 ] Training epoch: 15
[ Wed Feb 15 02:10:33 2023 ] 	Mean training loss: 0.8228.  Mean training acc: 75.10%.
[ Wed Feb 15 02:10:33 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 02:10:33 2023 ] Eval epoch: 15
[ Wed Feb 15 02:19:34 2023 ] 	Mean test loss of 796 batches: 1.2001387455954624.
[ Wed Feb 15 02:19:34 2023 ] 	Top1: 65.16%
[ Wed Feb 15 02:19:35 2023 ] 	Top5: 91.13%
[ Wed Feb 15 02:19:35 2023 ] Training epoch: 16
[ Wed Feb 15 02:36:31 2023 ] 	Mean training loss: 0.8080.  Mean training acc: 75.53%.
[ Wed Feb 15 02:36:31 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 02:36:31 2023 ] Eval epoch: 16
[ Wed Feb 15 02:45:32 2023 ] 	Mean test loss of 796 batches: 1.0342830904764146.
[ Wed Feb 15 02:45:32 2023 ] 	Top1: 70.46%
[ Wed Feb 15 02:45:33 2023 ] 	Top5: 92.63%
[ Wed Feb 15 02:45:33 2023 ] Training epoch: 17
[ Wed Feb 15 03:02:30 2023 ] 	Mean training loss: 0.7980.  Mean training acc: 75.76%.
[ Wed Feb 15 03:02:30 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 03:02:30 2023 ] Eval epoch: 17
[ Wed Feb 15 03:11:32 2023 ] 	Mean test loss of 796 batches: 1.0822787800026898.
[ Wed Feb 15 03:11:33 2023 ] 	Top1: 67.99%
[ Wed Feb 15 03:11:33 2023 ] 	Top5: 91.95%
[ Wed Feb 15 03:11:33 2023 ] Training epoch: 18
[ Wed Feb 15 03:28:30 2023 ] 	Mean training loss: 0.7961.  Mean training acc: 75.80%.
[ Wed Feb 15 03:28:30 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 03:28:30 2023 ] Eval epoch: 18
[ Wed Feb 15 03:37:33 2023 ] 	Mean test loss of 796 batches: 1.2248687703330912.
[ Wed Feb 15 03:37:33 2023 ] 	Top1: 65.95%
[ Wed Feb 15 03:37:34 2023 ] 	Top5: 91.09%
[ Wed Feb 15 03:37:34 2023 ] Training epoch: 19
[ Wed Feb 15 03:54:28 2023 ] 	Mean training loss: 0.7814.  Mean training acc: 76.09%.
[ Wed Feb 15 03:54:28 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 03:54:28 2023 ] Eval epoch: 19
[ Wed Feb 15 04:03:32 2023 ] 	Mean test loss of 796 batches: 1.0415915224944527.
[ Wed Feb 15 04:03:32 2023 ] 	Top1: 69.43%
[ Wed Feb 15 04:03:32 2023 ] 	Top5: 92.28%
[ Wed Feb 15 04:03:32 2023 ] Training epoch: 20
[ Wed Feb 15 04:20:29 2023 ] 	Mean training loss: 0.7764.  Mean training acc: 76.42%.
[ Wed Feb 15 04:20:29 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 04:20:29 2023 ] Eval epoch: 20
[ Wed Feb 15 04:29:30 2023 ] 	Mean test loss of 796 batches: 1.0005092407441019.
[ Wed Feb 15 04:29:31 2023 ] 	Top1: 70.44%
[ Wed Feb 15 04:29:31 2023 ] 	Top5: 92.65%
[ Wed Feb 15 04:29:31 2023 ] Training epoch: 21
[ Wed Feb 15 04:46:30 2023 ] 	Mean training loss: 0.7676.  Mean training acc: 76.69%.
[ Wed Feb 15 04:46:30 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 04:46:30 2023 ] Eval epoch: 21
[ Wed Feb 15 04:55:30 2023 ] 	Mean test loss of 796 batches: 1.034277367569394.
[ Wed Feb 15 04:55:30 2023 ] 	Top1: 68.96%
[ Wed Feb 15 04:55:30 2023 ] 	Top5: 92.87%
[ Wed Feb 15 04:55:31 2023 ] Training epoch: 22
[ Wed Feb 15 05:12:27 2023 ] 	Mean training loss: 0.7588.  Mean training acc: 77.00%.
[ Wed Feb 15 05:12:27 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 05:12:28 2023 ] Eval epoch: 22
[ Wed Feb 15 05:21:33 2023 ] 	Mean test loss of 796 batches: 0.9619807995780928.
[ Wed Feb 15 05:21:34 2023 ] 	Top1: 71.38%
[ Wed Feb 15 05:21:34 2023 ] 	Top5: 93.40%
[ Wed Feb 15 05:21:34 2023 ] Training epoch: 23
[ Wed Feb 15 05:38:27 2023 ] 	Mean training loss: 0.7671.  Mean training acc: 76.78%.
[ Wed Feb 15 05:38:27 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 05:38:27 2023 ] Eval epoch: 23
[ Wed Feb 15 05:47:28 2023 ] 	Mean test loss of 796 batches: 0.9184388806996633.
[ Wed Feb 15 05:47:29 2023 ] 	Top1: 72.65%
[ Wed Feb 15 05:47:29 2023 ] 	Top5: 94.08%
[ Wed Feb 15 05:47:29 2023 ] Training epoch: 24
[ Wed Feb 15 06:04:25 2023 ] 	Mean training loss: 0.7504.  Mean training acc: 77.13%.
[ Wed Feb 15 06:04:25 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:04:25 2023 ] Eval epoch: 24
[ Wed Feb 15 06:13:22 2023 ] 	Mean test loss of 796 batches: 1.1603378055607854.
[ Wed Feb 15 06:13:22 2023 ] 	Top1: 67.61%
[ Wed Feb 15 06:13:23 2023 ] 	Top5: 91.41%
[ Wed Feb 15 06:13:23 2023 ] Training epoch: 25
[ Wed Feb 15 06:30:19 2023 ] 	Mean training loss: 0.7496.  Mean training acc: 77.02%.
[ Wed Feb 15 06:30:19 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:30:19 2023 ] Eval epoch: 25
[ Wed Feb 15 06:38:57 2023 ] 	Mean test loss of 796 batches: 1.172450119152141.
[ Wed Feb 15 06:38:58 2023 ] 	Top1: 67.76%
[ Wed Feb 15 06:38:58 2023 ] 	Top5: 91.66%
[ Wed Feb 15 06:38:58 2023 ] Training epoch: 26
[ Wed Feb 15 06:55:44 2023 ] 	Mean training loss: 0.7476.  Mean training acc: 77.38%.
[ Wed Feb 15 06:55:44 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 06:55:44 2023 ] Eval epoch: 26
[ Wed Feb 15 07:04:42 2023 ] 	Mean test loss of 796 batches: 0.9679434282246546.
[ Wed Feb 15 07:04:42 2023 ] 	Top1: 70.57%
[ Wed Feb 15 07:04:42 2023 ] 	Top5: 93.39%
[ Wed Feb 15 07:04:42 2023 ] Training epoch: 27
[ Wed Feb 15 07:21:37 2023 ] 	Mean training loss: 0.7426.  Mean training acc: 77.52%.
[ Wed Feb 15 07:21:37 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 07:21:37 2023 ] Eval epoch: 27
[ Wed Feb 15 07:30:46 2023 ] 	Mean test loss of 796 batches: 1.005524718431971.
[ Wed Feb 15 07:30:46 2023 ] 	Top1: 69.95%
[ Wed Feb 15 07:30:46 2023 ] 	Top5: 92.70%
[ Wed Feb 15 07:30:47 2023 ] Training epoch: 28
[ Wed Feb 15 07:47:43 2023 ] 	Mean training loss: 0.7431.  Mean training acc: 77.38%.
[ Wed Feb 15 07:47:43 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 07:47:43 2023 ] Eval epoch: 28
[ Wed Feb 15 07:56:50 2023 ] 	Mean test loss of 796 batches: 1.011241728074886.
[ Wed Feb 15 07:56:51 2023 ] 	Top1: 69.59%
[ Wed Feb 15 07:56:51 2023 ] 	Top5: 92.76%
[ Wed Feb 15 07:56:51 2023 ] Training epoch: 29
[ Wed Feb 15 08:13:49 2023 ] 	Mean training loss: 0.7317.  Mean training acc: 77.67%.
[ Wed Feb 15 08:13:49 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 08:13:49 2023 ] Eval epoch: 29
[ Wed Feb 15 08:22:56 2023 ] 	Mean test loss of 796 batches: 1.1057447454138616.
[ Wed Feb 15 08:22:57 2023 ] 	Top1: 67.77%
[ Wed Feb 15 08:22:57 2023 ] 	Top5: 92.41%
[ Wed Feb 15 08:22:57 2023 ] Training epoch: 30
[ Wed Feb 15 08:39:54 2023 ] 	Mean training loss: 0.7390.  Mean training acc: 77.42%.
[ Wed Feb 15 08:39:54 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 08:39:54 2023 ] Eval epoch: 30
[ Wed Feb 15 08:48:57 2023 ] 	Mean test loss of 796 batches: 1.0897122831575234.
[ Wed Feb 15 08:48:57 2023 ] 	Top1: 68.88%
[ Wed Feb 15 08:48:58 2023 ] 	Top5: 92.09%
[ Wed Feb 15 08:48:58 2023 ] Training epoch: 31
[ Wed Feb 15 09:05:53 2023 ] 	Mean training loss: 0.7362.  Mean training acc: 77.62%.
[ Wed Feb 15 09:05:53 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 09:05:53 2023 ] Eval epoch: 31
[ Wed Feb 15 09:14:53 2023 ] 	Mean test loss of 796 batches: 1.0134614989461013.
[ Wed Feb 15 09:14:53 2023 ] 	Top1: 69.59%
[ Wed Feb 15 09:14:54 2023 ] 	Top5: 92.84%
[ Wed Feb 15 09:14:54 2023 ] Training epoch: 32
[ Wed Feb 15 09:31:48 2023 ] 	Mean training loss: 0.7340.  Mean training acc: 77.61%.
[ Wed Feb 15 09:31:48 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 09:31:48 2023 ] Eval epoch: 32
[ Wed Feb 15 09:40:56 2023 ] 	Mean test loss of 796 batches: 1.2913633927178743.
[ Wed Feb 15 09:40:56 2023 ] 	Top1: 64.01%
[ Wed Feb 15 09:40:57 2023 ] 	Top5: 89.72%
[ Wed Feb 15 09:40:57 2023 ] Training epoch: 33
[ Wed Feb 15 09:57:52 2023 ] 	Mean training loss: 0.7297.  Mean training acc: 77.80%.
[ Wed Feb 15 09:57:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 09:57:52 2023 ] Eval epoch: 33
[ Wed Feb 15 10:06:58 2023 ] 	Mean test loss of 796 batches: 1.0191320785550615.
[ Wed Feb 15 10:06:59 2023 ] 	Top1: 69.76%
[ Wed Feb 15 10:06:59 2023 ] 	Top5: 93.42%
[ Wed Feb 15 10:06:59 2023 ] Training epoch: 34
[ Wed Feb 15 10:23:57 2023 ] 	Mean training loss: 0.7318.  Mean training acc: 77.85%.
[ Wed Feb 15 10:23:57 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:23:57 2023 ] Eval epoch: 34
[ Wed Feb 15 10:33:04 2023 ] 	Mean test loss of 796 batches: 0.9514412858228588.
[ Wed Feb 15 10:33:04 2023 ] 	Top1: 71.80%
[ Wed Feb 15 10:33:05 2023 ] 	Top5: 93.42%
[ Wed Feb 15 10:33:05 2023 ] Training epoch: 35
[ Wed Feb 15 10:50:00 2023 ] 	Mean training loss: 0.7228.  Mean training acc: 78.09%.
[ Wed Feb 15 10:50:00 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 10:50:00 2023 ] Eval epoch: 35
[ Wed Feb 15 10:59:00 2023 ] 	Mean test loss of 796 batches: 1.1891936580814308.
[ Wed Feb 15 10:59:01 2023 ] 	Top1: 66.56%
[ Wed Feb 15 10:59:01 2023 ] 	Top5: 91.70%
[ Wed Feb 15 10:59:01 2023 ] Training epoch: 36
[ Wed Feb 15 11:15:54 2023 ] 	Mean training loss: 0.4264.  Mean training acc: 87.01%.
[ Wed Feb 15 11:15:54 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:15:54 2023 ] Eval epoch: 36
[ Wed Feb 15 11:25:01 2023 ] 	Mean test loss of 796 batches: 0.5350667512484232.
[ Wed Feb 15 11:25:01 2023 ] 	Top1: 83.19%
[ Wed Feb 15 11:25:02 2023 ] 	Top5: 97.36%
[ Wed Feb 15 11:25:02 2023 ] Training epoch: 37
[ Wed Feb 15 11:41:57 2023 ] 	Mean training loss: 0.3473.  Mean training acc: 89.35%.
[ Wed Feb 15 11:41:57 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 11:41:57 2023 ] Eval epoch: 37
[ Wed Feb 15 11:51:01 2023 ] 	Mean test loss of 796 batches: 0.5352137663013222.
[ Wed Feb 15 11:51:02 2023 ] 	Top1: 83.50%
[ Wed Feb 15 11:51:02 2023 ] 	Top5: 97.24%
[ Wed Feb 15 11:51:02 2023 ] Training epoch: 38
[ Wed Feb 15 12:07:58 2023 ] 	Mean training loss: 0.3194.  Mean training acc: 90.22%.
[ Wed Feb 15 12:07:58 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:07:58 2023 ] Eval epoch: 38
[ Wed Feb 15 12:17:03 2023 ] 	Mean test loss of 796 batches: 0.5179986821103785.
[ Wed Feb 15 12:17:04 2023 ] 	Top1: 84.02%
[ Wed Feb 15 12:17:04 2023 ] 	Top5: 97.37%
[ Wed Feb 15 12:17:04 2023 ] Training epoch: 39
[ Wed Feb 15 12:34:01 2023 ] 	Mean training loss: 0.2986.  Mean training acc: 90.73%.
[ Wed Feb 15 12:34:01 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:34:01 2023 ] Eval epoch: 39
[ Wed Feb 15 12:43:00 2023 ] 	Mean test loss of 796 batches: 0.5117436068778362.
[ Wed Feb 15 12:43:01 2023 ] 	Top1: 84.14%
[ Wed Feb 15 12:43:01 2023 ] 	Top5: 97.48%
[ Wed Feb 15 12:43:01 2023 ] Training epoch: 40
[ Wed Feb 15 12:59:55 2023 ] 	Mean training loss: 0.2773.  Mean training acc: 91.56%.
[ Wed Feb 15 12:59:55 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 12:59:55 2023 ] Eval epoch: 40
[ Wed Feb 15 13:08:55 2023 ] 	Mean test loss of 796 batches: 0.535133758194782.
[ Wed Feb 15 13:08:56 2023 ] 	Top1: 83.73%
[ Wed Feb 15 13:08:56 2023 ] 	Top5: 97.20%
[ Wed Feb 15 13:08:56 2023 ] Training epoch: 41
[ Wed Feb 15 13:25:56 2023 ] 	Mean training loss: 0.2649.  Mean training acc: 91.93%.
[ Wed Feb 15 13:25:56 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:25:56 2023 ] Eval epoch: 41
[ Wed Feb 15 13:34:50 2023 ] 	Mean test loss of 796 batches: 0.5391477000848133.
[ Wed Feb 15 13:34:51 2023 ] 	Top1: 83.59%
[ Wed Feb 15 13:34:51 2023 ] 	Top5: 97.08%
[ Wed Feb 15 13:34:51 2023 ] Training epoch: 42
[ Wed Feb 15 13:51:51 2023 ] 	Mean training loss: 0.2559.  Mean training acc: 92.27%.
[ Wed Feb 15 13:51:51 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 13:51:51 2023 ] Eval epoch: 42
[ Wed Feb 15 14:00:56 2023 ] 	Mean test loss of 796 batches: 0.5374162098364764.
[ Wed Feb 15 14:00:56 2023 ] 	Top1: 83.84%
[ Wed Feb 15 14:00:57 2023 ] 	Top5: 97.26%
[ Wed Feb 15 14:00:57 2023 ] Training epoch: 43
[ Wed Feb 15 14:17:51 2023 ] 	Mean training loss: 0.2450.  Mean training acc: 92.56%.
[ Wed Feb 15 14:17:51 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:17:51 2023 ] Eval epoch: 43
[ Wed Feb 15 14:26:55 2023 ] 	Mean test loss of 796 batches: 0.571830454081222.
[ Wed Feb 15 14:26:56 2023 ] 	Top1: 83.12%
[ Wed Feb 15 14:26:56 2023 ] 	Top5: 97.13%
[ Wed Feb 15 14:26:56 2023 ] Training epoch: 44
[ Wed Feb 15 14:43:53 2023 ] 	Mean training loss: 0.2397.  Mean training acc: 92.82%.
[ Wed Feb 15 14:43:53 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 14:43:53 2023 ] Eval epoch: 44
[ Wed Feb 15 14:52:58 2023 ] 	Mean test loss of 796 batches: 0.5562767449991038.
[ Wed Feb 15 14:52:58 2023 ] 	Top1: 83.55%
[ Wed Feb 15 14:52:59 2023 ] 	Top5: 97.23%
[ Wed Feb 15 14:52:59 2023 ] Training epoch: 45
[ Wed Feb 15 15:09:52 2023 ] 	Mean training loss: 0.2317.  Mean training acc: 93.00%.
[ Wed Feb 15 15:09:52 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:09:52 2023 ] Eval epoch: 45
[ Wed Feb 15 15:18:56 2023 ] 	Mean test loss of 796 batches: 0.5352431022978608.
[ Wed Feb 15 15:18:56 2023 ] 	Top1: 84.00%
[ Wed Feb 15 15:18:57 2023 ] 	Top5: 97.23%
[ Wed Feb 15 15:18:57 2023 ] Training epoch: 46
[ Wed Feb 15 15:35:49 2023 ] 	Mean training loss: 0.2226.  Mean training acc: 93.31%.
[ Wed Feb 15 15:35:49 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 15:35:49 2023 ] Eval epoch: 46
[ Wed Feb 15 15:44:53 2023 ] 	Mean test loss of 796 batches: 0.5633635553133548.
[ Wed Feb 15 15:44:53 2023 ] 	Top1: 83.55%
[ Wed Feb 15 15:44:53 2023 ] 	Top5: 97.22%
[ Wed Feb 15 15:44:53 2023 ] Training epoch: 47
[ Wed Feb 15 16:01:53 2023 ] 	Mean training loss: 0.2229.  Mean training acc: 93.29%.
[ Wed Feb 15 16:01:53 2023 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Feb 15 16:01:53 2023 ] Eval epoch: 47
[ Wed Feb 15 16:10:59 2023 ] 	Mean test loss of 796 batches: 0.5706535210580232.
[ Wed Feb 15 16:10:59 2023 ] 	Top1: 83.19%
[ Wed Feb 15 16:11:00 2023 ] 	Top5: 96.94%
[ Wed Feb 15 16:11:00 2023 ] Training epoch: 48
