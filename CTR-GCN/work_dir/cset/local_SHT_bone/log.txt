[ Sun Nov  6 22:49:53 2022 ] using warm up, epoch: 5
[ Sun Nov  6 22:53:10 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/cset/local_SHTg_bone', 'model_saved_name': 'work_dir/ntu120/cset/local_SHTg_bone/runs', 'config': 'config/nturgbd120-cross-set/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Sun Nov  6 22:53:10 2022 ] # Parameters: 2141090
[ Sun Nov  6 22:53:10 2022 ] Training epoch: 1
[ Sun Nov  6 23:30:20 2022 ] 	Mean training loss: 3.4243.  Mean training acc: 17.38%.
[ Sun Nov  6 23:30:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Sun Nov  6 23:30:20 2022 ] Eval epoch: 1
[ Mon Nov  7 00:07:12 2022 ] 	Mean test loss of 930 batches: 2.749989579826273.
[ Mon Nov  7 00:07:13 2022 ] 	Top1: 28.17%
[ Mon Nov  7 00:07:14 2022 ] 	Top5: 61.95%
[ Mon Nov  7 00:07:14 2022 ] Training epoch: 2
[ Mon Nov  7 00:43:01 2022 ] 	Mean training loss: 2.3129.  Mean training acc: 36.64%.
[ Mon Nov  7 00:43:01 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 00:43:01 2022 ] Eval epoch: 2
[ Mon Nov  7 01:20:45 2022 ] 	Mean test loss of 930 batches: 2.0646991715636305.
[ Mon Nov  7 01:20:47 2022 ] 	Top1: 41.60%
[ Mon Nov  7 01:20:49 2022 ] 	Top5: 78.10%
[ Mon Nov  7 01:20:50 2022 ] Training epoch: 3
[ Mon Nov  7 01:57:48 2022 ] 	Mean training loss: 1.7732.  Mean training acc: 49.11%.
[ Mon Nov  7 01:57:48 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 01:57:48 2022 ] Eval epoch: 3
[ Mon Nov  7 02:34:52 2022 ] 	Mean test loss of 930 batches: 1.6929882170051658.
[ Mon Nov  7 02:34:53 2022 ] 	Top1: 50.78%
[ Mon Nov  7 02:34:55 2022 ] 	Top5: 84.42%
[ Mon Nov  7 02:34:55 2022 ] Training epoch: 4
[ Mon Nov  7 03:10:44 2022 ] 	Mean training loss: 1.4959.  Mean training acc: 56.03%.
[ Mon Nov  7 03:10:44 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 03:10:44 2022 ] Eval epoch: 4
[ Mon Nov  7 03:45:58 2022 ] 	Mean test loss of 930 batches: 1.6862836040476317.
[ Mon Nov  7 03:45:59 2022 ] 	Top1: 52.49%
[ Mon Nov  7 03:46:00 2022 ] 	Top5: 83.97%
[ Mon Nov  7 03:46:00 2022 ] Training epoch: 5
[ Mon Nov  7 04:20:18 2022 ] 	Mean training loss: 1.3441.  Mean training acc: 60.34%.
[ Mon Nov  7 04:20:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 04:20:18 2022 ] Eval epoch: 5
[ Mon Nov  7 04:55:25 2022 ] 	Mean test loss of 930 batches: 1.5137340051512564.
[ Mon Nov  7 04:55:26 2022 ] 	Top1: 57.22%
[ Mon Nov  7 04:55:28 2022 ] 	Top5: 87.76%
[ Mon Nov  7 04:55:28 2022 ] Training epoch: 6
[ Mon Nov  7 05:29:43 2022 ] 	Mean training loss: 1.1829.  Mean training acc: 64.89%.
[ Mon Nov  7 05:29:43 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 05:29:43 2022 ] Eval epoch: 6
[ Mon Nov  7 06:04:20 2022 ] 	Mean test loss of 930 batches: 2.0200297278101726.
[ Mon Nov  7 06:04:21 2022 ] 	Top1: 51.28%
[ Mon Nov  7 06:04:22 2022 ] 	Top5: 81.32%
[ Mon Nov  7 06:04:23 2022 ] Training epoch: 7
[ Mon Nov  7 06:43:22 2022 ] 	Mean training loss: 1.0899.  Mean training acc: 67.20%.
[ Mon Nov  7 06:43:22 2022 ] 	Time consumption: [Data]01%, [Network]86%
[ Mon Nov  7 06:43:22 2022 ] Eval epoch: 7
[ Mon Nov  7 07:17:51 2022 ] 	Mean test loss of 930 batches: 1.2270484423124661.
[ Mon Nov  7 07:17:52 2022 ] 	Top1: 64.36%
[ Mon Nov  7 07:17:53 2022 ] 	Top5: 90.19%
[ Mon Nov  7 07:17:54 2022 ] Training epoch: 8
[ Mon Nov  7 07:51:59 2022 ] 	Mean training loss: 1.0239.  Mean training acc: 69.32%.
[ Mon Nov  7 07:51:59 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 07:51:59 2022 ] Eval epoch: 8
[ Mon Nov  7 08:27:06 2022 ] 	Mean test loss of 930 batches: 1.1806860714830378.
[ Mon Nov  7 08:27:08 2022 ] 	Top1: 64.99%
[ Mon Nov  7 08:27:09 2022 ] 	Top5: 91.09%
[ Mon Nov  7 08:27:10 2022 ] Training epoch: 9
[ Mon Nov  7 09:02:06 2022 ] 	Mean training loss: 0.9807.  Mean training acc: 70.43%.
[ Mon Nov  7 09:02:06 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 09:02:06 2022 ] Eval epoch: 9
[ Mon Nov  7 09:40:29 2022 ] 	Mean test loss of 930 batches: 1.3140030639145963.
[ Mon Nov  7 09:40:30 2022 ] 	Top1: 63.31%
[ Mon Nov  7 09:40:31 2022 ] 	Top5: 89.10%
[ Mon Nov  7 09:40:31 2022 ] Training epoch: 10
[ Mon Nov  7 10:18:04 2022 ] 	Mean training loss: 0.9403.  Mean training acc: 71.53%.
[ Mon Nov  7 10:18:04 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 10:18:04 2022 ] Eval epoch: 10
[ Mon Nov  7 10:55:44 2022 ] 	Mean test loss of 930 batches: 1.1051116064030637.
[ Mon Nov  7 10:55:46 2022 ] 	Top1: 68.61%
[ Mon Nov  7 10:55:47 2022 ] 	Top5: 91.75%
[ Mon Nov  7 10:55:47 2022 ] Training epoch: 11
[ Mon Nov  7 11:36:07 2022 ] 	Mean training loss: 0.9083.  Mean training acc: 72.55%.
[ Mon Nov  7 11:36:07 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 11:36:07 2022 ] Eval epoch: 11
[ Mon Nov  7 12:16:08 2022 ] 	Mean test loss of 930 batches: 1.0783585917885585.
[ Mon Nov  7 12:16:09 2022 ] 	Top1: 68.34%
[ Mon Nov  7 12:16:11 2022 ] 	Top5: 92.21%
[ Mon Nov  7 12:16:11 2022 ] Training epoch: 12
[ Mon Nov  7 12:56:31 2022 ] 	Mean training loss: 0.8899.  Mean training acc: 73.06%.
[ Mon Nov  7 12:56:31 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 12:56:31 2022 ] Eval epoch: 12
[ Mon Nov  7 13:36:32 2022 ] 	Mean test loss of 930 batches: 1.1168422106453169.
[ Mon Nov  7 13:36:34 2022 ] 	Top1: 67.90%
[ Mon Nov  7 13:36:34 2022 ] 	Top5: 91.89%
[ Mon Nov  7 13:36:35 2022 ] Training epoch: 13
[ Mon Nov  7 14:16:52 2022 ] 	Mean training loss: 0.8619.  Mean training acc: 73.79%.
[ Mon Nov  7 14:16:52 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 14:16:52 2022 ] Eval epoch: 13
[ Mon Nov  7 14:56:25 2022 ] 	Mean test loss of 930 batches: 1.202915670955053.
[ Mon Nov  7 14:56:26 2022 ] 	Top1: 66.55%
[ Mon Nov  7 14:56:28 2022 ] 	Top5: 91.08%
[ Mon Nov  7 14:56:28 2022 ] Training epoch: 14
[ Mon Nov  7 15:37:15 2022 ] 	Mean training loss: 0.8480.  Mean training acc: 74.31%.
[ Mon Nov  7 15:37:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 15:37:15 2022 ] Eval epoch: 14
[ Mon Nov  7 16:16:16 2022 ] 	Mean test loss of 930 batches: 1.2353076350945298.
[ Mon Nov  7 16:16:17 2022 ] 	Top1: 65.37%
[ Mon Nov  7 16:16:18 2022 ] 	Top5: 91.23%
[ Mon Nov  7 16:16:18 2022 ] Training epoch: 15
[ Mon Nov  7 16:57:01 2022 ] 	Mean training loss: 0.8389.  Mean training acc: 74.61%.
[ Mon Nov  7 16:57:01 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 16:57:01 2022 ] Eval epoch: 15
[ Mon Nov  7 17:37:57 2022 ] 	Mean test loss of 930 batches: 1.3184248860164356.
[ Mon Nov  7 17:37:59 2022 ] 	Top1: 66.03%
[ Mon Nov  7 17:38:00 2022 ] 	Top5: 89.27%
[ Mon Nov  7 17:38:00 2022 ] Training epoch: 16
[ Mon Nov  7 18:21:08 2022 ] 	Mean training loss: 0.8200.  Mean training acc: 75.22%.
[ Mon Nov  7 18:21:08 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 18:21:08 2022 ] Eval epoch: 16
[ Mon Nov  7 19:03:20 2022 ] 	Mean test loss of 930 batches: 1.2944618134088415.
[ Mon Nov  7 19:03:21 2022 ] 	Top1: 65.79%
[ Mon Nov  7 19:03:22 2022 ] 	Top5: 89.69%
[ Mon Nov  7 19:03:22 2022 ] Training epoch: 17
[ Mon Nov  7 19:46:39 2022 ] 	Mean training loss: 0.8130.  Mean training acc: 75.38%.
[ Mon Nov  7 19:46:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 19:46:39 2022 ] Eval epoch: 17
[ Mon Nov  7 20:30:57 2022 ] 	Mean test loss of 930 batches: 1.0106673961365096.
[ Mon Nov  7 20:30:58 2022 ] 	Top1: 70.51%
[ Mon Nov  7 20:31:00 2022 ] 	Top5: 92.94%
[ Mon Nov  7 20:31:00 2022 ] Training epoch: 18
[ Mon Nov  7 21:18:29 2022 ] 	Mean training loss: 0.8043.  Mean training acc: 75.58%.
[ Mon Nov  7 21:18:29 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 21:18:29 2022 ] Eval epoch: 18
[ Mon Nov  7 22:04:18 2022 ] 	Mean test loss of 930 batches: 1.2389796140373395.
[ Mon Nov  7 22:04:20 2022 ] 	Top1: 65.96%
[ Mon Nov  7 22:04:22 2022 ] 	Top5: 90.33%
[ Mon Nov  7 22:04:22 2022 ] Training epoch: 19
[ Mon Nov  7 22:49:42 2022 ] 	Mean training loss: 0.7994.  Mean training acc: 75.81%.
[ Mon Nov  7 22:49:42 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 22:49:42 2022 ] Eval epoch: 19
[ Mon Nov  7 23:32:37 2022 ] 	Mean test loss of 930 batches: 1.136241061777197.
[ Mon Nov  7 23:32:39 2022 ] 	Top1: 68.06%
[ Mon Nov  7 23:32:41 2022 ] 	Top5: 91.74%
[ Mon Nov  7 23:32:41 2022 ] Training epoch: 20
[ Tue Nov  8 00:15:39 2022 ] 	Mean training loss: 0.7936.  Mean training acc: 76.08%.
[ Tue Nov  8 00:15:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 00:15:39 2022 ] Eval epoch: 20
[ Tue Nov  8 00:59:53 2022 ] 	Mean test loss of 930 batches: 0.9428752081048104.
[ Tue Nov  8 00:59:55 2022 ] 	Top1: 72.77%
[ Tue Nov  8 00:59:57 2022 ] 	Top5: 93.60%
[ Tue Nov  8 00:59:57 2022 ] Training epoch: 21
[ Tue Nov  8 01:44:54 2022 ] 	Mean training loss: 0.7805.  Mean training acc: 76.38%.
[ Tue Nov  8 01:44:54 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 01:44:54 2022 ] Eval epoch: 21
[ Tue Nov  8 02:28:51 2022 ] 	Mean test loss of 930 batches: 0.9095752719429231.
[ Tue Nov  8 02:28:53 2022 ] 	Top1: 73.20%
[ Tue Nov  8 02:28:54 2022 ] 	Top5: 93.88%
[ Tue Nov  8 02:28:55 2022 ] Training epoch: 22
[ Tue Nov  8 03:13:32 2022 ] 	Mean training loss: 0.7739.  Mean training acc: 76.64%.
[ Tue Nov  8 03:13:32 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 03:13:32 2022 ] Eval epoch: 22
[ Tue Nov  8 03:57:31 2022 ] 	Mean test loss of 930 batches: 1.0303235731618379.
[ Tue Nov  8 03:57:32 2022 ] 	Top1: 70.96%
[ Tue Nov  8 03:57:34 2022 ] 	Top5: 93.10%
[ Tue Nov  8 03:57:34 2022 ] Training epoch: 23
[ Tue Nov  8 04:42:14 2022 ] 	Mean training loss: 0.7669.  Mean training acc: 76.76%.
[ Tue Nov  8 04:42:14 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 04:42:14 2022 ] Eval epoch: 23
[ Tue Nov  8 05:26:41 2022 ] 	Mean test loss of 930 batches: 1.1143280999634855.
[ Tue Nov  8 05:26:43 2022 ] 	Top1: 69.27%
[ Tue Nov  8 05:26:45 2022 ] 	Top5: 91.65%
[ Tue Nov  8 05:26:45 2022 ] Training epoch: 24
[ Tue Nov  8 06:10:09 2022 ] 	Mean training loss: 0.7558.  Mean training acc: 77.20%.
[ Tue Nov  8 06:10:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 06:10:09 2022 ] Eval epoch: 24
[ Tue Nov  8 06:51:31 2022 ] 	Mean test loss of 930 batches: 1.0091498991174082.
[ Tue Nov  8 06:51:33 2022 ] 	Top1: 71.17%
[ Tue Nov  8 06:51:34 2022 ] 	Top5: 92.89%
[ Tue Nov  8 06:51:34 2022 ] Training epoch: 25
[ Tue Nov  8 07:34:21 2022 ] 	Mean training loss: 0.7533.  Mean training acc: 77.45%.
[ Tue Nov  8 07:34:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 07:34:21 2022 ] Eval epoch: 25
[ Tue Nov  8 08:17:37 2022 ] 	Mean test loss of 930 batches: 1.207642356490576.
[ Tue Nov  8 08:17:38 2022 ] 	Top1: 66.67%
[ Tue Nov  8 08:17:40 2022 ] 	Top5: 91.19%
[ Tue Nov  8 08:17:40 2022 ] Training epoch: 26
[ Tue Nov  8 09:02:47 2022 ] 	Mean training loss: 0.7483.  Mean training acc: 77.44%.
[ Tue Nov  8 09:02:47 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 09:02:47 2022 ] Eval epoch: 26
[ Tue Nov  8 09:46:01 2022 ] 	Mean test loss of 930 batches: 1.1935141808563663.
[ Tue Nov  8 09:46:03 2022 ] 	Top1: 66.99%
[ Tue Nov  8 09:46:05 2022 ] 	Top5: 91.13%
[ Tue Nov  8 09:46:05 2022 ] Training epoch: 27
[ Tue Nov  8 10:29:55 2022 ] 	Mean training loss: 0.7387.  Mean training acc: 77.77%.
[ Tue Nov  8 10:29:55 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 10:29:55 2022 ] Eval epoch: 27
[ Tue Nov  8 11:11:27 2022 ] 	Mean test loss of 930 batches: 0.9932475197058852.
[ Tue Nov  8 11:11:29 2022 ] 	Top1: 71.76%
[ Tue Nov  8 11:11:31 2022 ] 	Top5: 93.00%
[ Tue Nov  8 11:11:31 2022 ] Training epoch: 28
[ Tue Nov  8 11:55:39 2022 ] 	Mean training loss: 0.7348.  Mean training acc: 78.00%.
[ Tue Nov  8 11:55:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 11:55:39 2022 ] Eval epoch: 28
[ Tue Nov  8 12:41:00 2022 ] 	Mean test loss of 930 batches: 0.9525738766436935.
[ Tue Nov  8 12:41:02 2022 ] 	Top1: 72.60%
[ Tue Nov  8 12:41:04 2022 ] 	Top5: 93.42%
[ Tue Nov  8 12:41:04 2022 ] Training epoch: 29
[ Tue Nov  8 13:28:50 2022 ] 	Mean training loss: 0.7333.  Mean training acc: 77.80%.
[ Tue Nov  8 13:28:50 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 13:28:50 2022 ] Eval epoch: 29
[ Tue Nov  8 14:15:09 2022 ] 	Mean test loss of 930 batches: 1.043372276585589.
[ Tue Nov  8 14:15:11 2022 ] 	Top1: 71.14%
[ Tue Nov  8 14:15:13 2022 ] 	Top5: 92.05%
[ Tue Nov  8 14:15:14 2022 ] Training epoch: 30
[ Tue Nov  8 15:01:24 2022 ] 	Mean training loss: 0.7305.  Mean training acc: 77.93%.
[ Tue Nov  8 15:01:24 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 15:01:24 2022 ] Eval epoch: 30
[ Tue Nov  8 15:45:41 2022 ] 	Mean test loss of 930 batches: 0.9631683502786903.
[ Tue Nov  8 15:45:42 2022 ] 	Top1: 72.98%
[ Tue Nov  8 15:45:43 2022 ] 	Top5: 93.13%
[ Tue Nov  8 15:45:44 2022 ] Training epoch: 31
[ Tue Nov  8 16:28:21 2022 ] 	Mean training loss: 0.7280.  Mean training acc: 77.92%.
[ Tue Nov  8 16:28:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 16:28:21 2022 ] Eval epoch: 31
[ Tue Nov  8 17:11:39 2022 ] 	Mean test loss of 930 batches: 1.0432238786130823.
[ Tue Nov  8 17:11:40 2022 ] 	Top1: 70.21%
[ Tue Nov  8 17:11:42 2022 ] 	Top5: 92.83%
[ Tue Nov  8 17:11:42 2022 ] Training epoch: 32
[ Tue Nov  8 17:56:06 2022 ] 	Mean training loss: 0.7228.  Mean training acc: 78.22%.
[ Tue Nov  8 17:56:06 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 17:56:06 2022 ] Eval epoch: 32
[ Tue Nov  8 18:39:56 2022 ] 	Mean test loss of 930 batches: 0.9173790884594764.
[ Tue Nov  8 18:39:58 2022 ] 	Top1: 73.03%
[ Tue Nov  8 18:39:59 2022 ] 	Top5: 93.94%
[ Tue Nov  8 18:39:59 2022 ] Training epoch: 33
[ Tue Nov  8 19:21:50 2022 ] 	Mean training loss: 0.7246.  Mean training acc: 78.14%.
[ Tue Nov  8 19:21:50 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 19:21:50 2022 ] Eval epoch: 33
[ Tue Nov  8 20:02:29 2022 ] 	Mean test loss of 930 batches: 0.9633327804906394.
[ Tue Nov  8 20:02:31 2022 ] 	Top1: 72.17%
[ Tue Nov  8 20:02:32 2022 ] 	Top5: 93.54%
[ Tue Nov  8 20:02:32 2022 ] Training epoch: 34
[ Tue Nov  8 20:43:02 2022 ] 	Mean training loss: 0.7174.  Mean training acc: 78.25%.
[ Tue Nov  8 20:43:02 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 20:43:02 2022 ] Eval epoch: 34
[ Tue Nov  8 21:22:36 2022 ] 	Mean test loss of 930 batches: 0.9550967054341429.
[ Tue Nov  8 21:22:37 2022 ] 	Top1: 72.24%
[ Tue Nov  8 21:22:38 2022 ] 	Top5: 93.38%
[ Tue Nov  8 21:22:39 2022 ] Training epoch: 35
[ Tue Nov  8 22:01:13 2022 ] 	Mean training loss: 0.7166.  Mean training acc: 78.13%.
[ Tue Nov  8 22:01:13 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 22:01:13 2022 ] Eval epoch: 35
[ Tue Nov  8 22:46:17 2022 ] 	Mean test loss of 930 batches: 1.0042474892511162.
[ Tue Nov  8 22:46:18 2022 ] 	Top1: 71.79%
[ Tue Nov  8 22:46:20 2022 ] 	Top5: 93.12%
[ Tue Nov  8 22:46:20 2022 ] Training epoch: 36
[ Tue Nov  8 23:28:17 2022 ] 	Mean training loss: 0.3832.  Mean training acc: 88.54%.
[ Tue Nov  8 23:28:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 23:28:17 2022 ] Eval epoch: 36
[ Wed Nov  9 00:07:47 2022 ] 	Mean test loss of 930 batches: 0.5213458849137188.
[ Wed Nov  9 00:07:48 2022 ] 	Top1: 84.65%
[ Wed Nov  9 00:07:50 2022 ] 	Top5: 96.90%
[ Wed Nov  9 00:07:50 2022 ] Training epoch: 37
[ Wed Nov  9 00:45:14 2022 ] 	Mean training loss: 0.2918.  Mean training acc: 91.45%.
[ Wed Nov  9 00:45:14 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 00:45:14 2022 ] Eval epoch: 37
[ Wed Nov  9 01:24:36 2022 ] 	Mean test loss of 930 batches: 0.5078541312567009.
[ Wed Nov  9 01:24:37 2022 ] 	Top1: 85.11%
[ Wed Nov  9 01:24:38 2022 ] 	Top5: 96.98%
[ Wed Nov  9 01:24:38 2022 ] Training epoch: 38
[ Wed Nov  9 02:03:50 2022 ] 	Mean training loss: 0.2574.  Mean training acc: 92.54%.
[ Wed Nov  9 02:03:50 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 02:03:50 2022 ] Eval epoch: 38
[ Wed Nov  9 02:44:43 2022 ] 	Mean test loss of 930 batches: 0.5050507192289637.
[ Wed Nov  9 02:44:44 2022 ] 	Top1: 85.23%
[ Wed Nov  9 02:44:45 2022 ] 	Top5: 97.03%
[ Wed Nov  9 02:44:45 2022 ] Training epoch: 39
[ Wed Nov  9 03:23:35 2022 ] 	Mean training loss: 0.2294.  Mean training acc: 93.35%.
[ Wed Nov  9 03:23:35 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 03:23:35 2022 ] Eval epoch: 39
[ Wed Nov  9 04:03:29 2022 ] 	Mean test loss of 930 batches: 0.5065739795485491.
[ Wed Nov  9 04:03:30 2022 ] 	Top1: 85.34%
[ Wed Nov  9 04:03:32 2022 ] 	Top5: 97.03%
[ Wed Nov  9 04:03:32 2022 ] Training epoch: 40
[ Wed Nov  9 04:40:00 2022 ] 	Mean training loss: 0.2084.  Mean training acc: 93.99%.
[ Wed Nov  9 04:40:00 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 04:40:00 2022 ] Eval epoch: 40
[ Wed Nov  9 05:17:38 2022 ] 	Mean test loss of 930 batches: 0.5122026178825606.
[ Wed Nov  9 05:17:39 2022 ] 	Top1: 85.39%
[ Wed Nov  9 05:17:41 2022 ] 	Top5: 96.97%
[ Wed Nov  9 05:17:41 2022 ] Training epoch: 41
[ Wed Nov  9 05:52:39 2022 ] 	Mean training loss: 0.1884.  Mean training acc: 94.86%.
[ Wed Nov  9 05:52:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 05:52:39 2022 ] Eval epoch: 41
[ Wed Nov  9 06:29:12 2022 ] 	Mean test loss of 930 batches: 0.5229652469356855.
[ Wed Nov  9 06:32:52 2022 ] 	Top1: 85.21%
[ Wed Nov  9 06:32:54 2022 ] 	Top5: 96.93%
[ Wed Nov  9 06:32:54 2022 ] Training epoch: 42
[ Wed Nov  9 07:13:07 2022 ] 	Mean training loss: 0.1718.  Mean training acc: 95.35%.
[ Wed Nov  9 07:13:08 2022 ] 	Time consumption: [Data]01%, [Network]87%
[ Wed Nov  9 07:13:08 2022 ] Eval epoch: 42
[ Wed Nov  9 07:49:29 2022 ] 	Mean test loss of 930 batches: 0.529356201225391.
[ Wed Nov  9 07:49:31 2022 ] 	Top1: 85.04%
[ Wed Nov  9 07:49:32 2022 ] 	Top5: 96.85%
[ Wed Nov  9 07:49:32 2022 ] Training epoch: 43
[ Wed Nov  9 08:24:18 2022 ] 	Mean training loss: 0.1572.  Mean training acc: 95.89%.
[ Wed Nov  9 08:24:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 08:24:19 2022 ] Eval epoch: 43
[ Wed Nov  9 09:00:06 2022 ] 	Mean test loss of 930 batches: 0.5358965657571311.
[ Wed Nov  9 09:00:08 2022 ] 	Top1: 85.10%
[ Wed Nov  9 09:00:09 2022 ] 	Top5: 96.86%
[ Wed Nov  9 09:00:09 2022 ] Training epoch: 44
[ Wed Nov  9 09:34:45 2022 ] 	Mean training loss: 0.1486.  Mean training acc: 96.07%.
[ Wed Nov  9 09:34:45 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 09:34:45 2022 ] Eval epoch: 44
[ Wed Nov  9 10:10:53 2022 ] 	Mean test loss of 930 batches: 0.5317680355081315.
[ Wed Nov  9 10:10:54 2022 ] 	Top1: 85.17%
[ Wed Nov  9 10:10:55 2022 ] 	Top5: 96.79%
[ Wed Nov  9 10:10:56 2022 ] Training epoch: 45
[ Wed Nov  9 10:47:17 2022 ] 	Mean training loss: 0.1365.  Mean training acc: 96.53%.
[ Wed Nov  9 10:47:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 10:47:17 2022 ] Eval epoch: 45
[ Wed Nov  9 11:25:46 2022 ] 	Mean test loss of 930 batches: 0.5473923220669711.
[ Wed Nov  9 11:25:47 2022 ] 	Top1: 84.86%
[ Wed Nov  9 11:25:48 2022 ] 	Top5: 96.83%
[ Wed Nov  9 11:25:48 2022 ] Training epoch: 46
[ Wed Nov  9 12:03:21 2022 ] 	Mean training loss: 0.1292.  Mean training acc: 96.75%.
[ Wed Nov  9 12:03:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 12:03:21 2022 ] Eval epoch: 46
[ Wed Nov  9 12:41:49 2022 ] 	Mean test loss of 930 batches: 0.5564417084258411.
[ Wed Nov  9 12:41:50 2022 ] 	Top1: 84.75%
[ Wed Nov  9 12:41:51 2022 ] 	Top5: 96.72%
[ Wed Nov  9 12:41:51 2022 ] Training epoch: 47
[ Wed Nov  9 13:19:24 2022 ] 	Mean training loss: 0.1249.  Mean training acc: 96.87%.
[ Wed Nov  9 13:19:24 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 13:19:24 2022 ] Eval epoch: 47
[ Wed Nov  9 13:57:51 2022 ] 	Mean test loss of 930 batches: 0.5721950364449332.
[ Wed Nov  9 13:57:52 2022 ] 	Top1: 84.43%
[ Wed Nov  9 13:57:53 2022 ] 	Top5: 96.59%
[ Wed Nov  9 13:57:53 2022 ] Training epoch: 48
[ Wed Nov  9 14:35:17 2022 ] 	Mean training loss: 0.1211.  Mean training acc: 97.00%.
[ Wed Nov  9 14:35:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 14:35:17 2022 ] Eval epoch: 48
[ Wed Nov  9 15:13:42 2022 ] 	Mean test loss of 930 batches: 0.5790622290263894.
[ Wed Nov  9 15:13:43 2022 ] 	Top1: 84.43%
[ Wed Nov  9 15:13:44 2022 ] 	Top5: 96.43%
[ Wed Nov  9 15:13:44 2022 ] Training epoch: 49
[ Tue Jan  3 17:28:39 2023 ] Load weights from work_dir/cset/local_SHTg_bone/runs-48-40848.pt.
[ Tue Jan  3 17:28:44 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:29:30 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHTg_bone', 'model_saved_name': 'work_dir/cset/local_SHTg_bone/runs', 'config': 'work_dir/cset/local_SHTg_bone/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': False, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': False, 'window_size': 64}, 'model': 'model.local_SHTg.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/cset/local_SHTg_bone/runs-48-40848.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 17:29:30 2023 ] # Parameters: 2141090
[ Tue Jan  3 17:29:30 2023 ] Training epoch: 49
[ Tue Jan  3 17:52:58 2023 ] 	Mean training loss: 0.1224.  Mean training acc: 96.91%.
[ Tue Jan  3 17:52:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 17:52:58 2023 ] Eval epoch: 49
[ Tue Jan  3 18:16:27 2023 ] 	Mean test loss of 930 batches: 0.5942105742632061.
[ Tue Jan  3 18:16:28 2023 ] 	Top1: 84.07%
[ Tue Jan  3 18:16:28 2023 ] 	Top5: 96.42%
[ Tue Jan  3 18:16:29 2023 ] Training epoch: 50
[ Tue Jan  3 18:40:05 2023 ] 	Mean training loss: 0.1199.  Mean training acc: 97.06%.
[ Tue Jan  3 18:40:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 18:40:05 2023 ] Eval epoch: 50
[ Tue Jan  3 19:03:28 2023 ] 	Mean test loss of 930 batches: 0.5982449511847189.
[ Tue Jan  3 19:03:29 2023 ] 	Top1: 84.29%
[ Tue Jan  3 19:03:29 2023 ] 	Top5: 96.38%
[ Tue Jan  3 19:03:29 2023 ] Training epoch: 51
[ Tue Jan  3 19:27:04 2023 ] 	Mean training loss: 0.1143.  Mean training acc: 97.23%.
[ Tue Jan  3 19:27:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 19:27:04 2023 ] Eval epoch: 51
[ Tue Jan  3 19:50:27 2023 ] 	Mean test loss of 930 batches: 0.6103043264238744.
[ Tue Jan  3 19:50:28 2023 ] 	Top1: 83.80%
[ Tue Jan  3 19:50:28 2023 ] 	Top5: 96.35%
[ Tue Jan  3 19:50:28 2023 ] Training epoch: 52
[ Tue Jan  3 20:14:46 2023 ] 	Mean training loss: 0.1143.  Mean training acc: 97.20%.
[ Tue Jan  3 20:14:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 20:14:46 2023 ] Eval epoch: 52
[ Tue Jan  3 20:38:41 2023 ] 	Mean test loss of 930 batches: 0.6053328102795027.
[ Tue Jan  3 20:38:43 2023 ] 	Top1: 83.85%
[ Tue Jan  3 20:38:44 2023 ] 	Top5: 96.34%
[ Tue Jan  3 20:38:44 2023 ] Training epoch: 53
[ Tue Jan  3 21:04:01 2023 ] 	Mean training loss: 0.1150.  Mean training acc: 97.16%.
[ Tue Jan  3 21:04:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 21:04:02 2023 ] Eval epoch: 53
[ Tue Jan  3 21:28:19 2023 ] 	Mean test loss of 930 batches: 0.5988903980181423.
[ Tue Jan  3 21:28:20 2023 ] 	Top1: 84.04%
[ Tue Jan  3 21:28:21 2023 ] 	Top5: 96.31%
[ Tue Jan  3 21:28:21 2023 ] Training epoch: 54
[ Tue Jan  3 21:53:52 2023 ] 	Mean training loss: 0.1135.  Mean training acc: 97.22%.
[ Tue Jan  3 21:53:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 21:53:52 2023 ] Eval epoch: 54
[ Tue Jan  3 22:18:04 2023 ] 	Mean test loss of 930 batches: 0.5997479131305089.
[ Tue Jan  3 22:18:04 2023 ] 	Top1: 84.09%
[ Tue Jan  3 22:18:05 2023 ] 	Top5: 96.33%
[ Tue Jan  3 22:18:05 2023 ] Training epoch: 55
[ Tue Jan  3 22:43:53 2023 ] 	Mean training loss: 0.1161.  Mean training acc: 97.07%.
[ Tue Jan  3 22:43:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 22:43:53 2023 ] Eval epoch: 55
[ Tue Jan  3 23:08:45 2023 ] 	Mean test loss of 930 batches: 0.6287948825066129.
[ Tue Jan  3 23:08:46 2023 ] 	Top1: 83.42%
[ Tue Jan  3 23:08:47 2023 ] 	Top5: 96.20%
[ Tue Jan  3 23:08:47 2023 ] Training epoch: 56
[ Tue Jan  3 23:34:00 2023 ] 	Mean training loss: 0.0659.  Mean training acc: 98.75%.
[ Tue Jan  3 23:34:00 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 23:34:01 2023 ] Eval epoch: 56
[ Tue Jan  3 23:58:06 2023 ] 	Mean test loss of 930 batches: 0.5511797034572209.
[ Tue Jan  3 23:58:07 2023 ] 	Top1: 85.48%
[ Tue Jan  3 23:58:07 2023 ] 	Top5: 96.68%
[ Tue Jan  3 23:58:07 2023 ] Training epoch: 57
[ Wed Jan  4 00:25:36 2023 ] 	Mean training loss: 0.0468.  Mean training acc: 99.34%.
[ Wed Jan  4 00:25:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 00:25:37 2023 ] Eval epoch: 57
[ Wed Jan  4 00:50:04 2023 ] 	Mean test loss of 930 batches: 0.5437037140651736.
[ Wed Jan  4 00:50:05 2023 ] 	Top1: 85.71%
[ Wed Jan  4 00:50:06 2023 ] 	Top5: 96.73%
[ Wed Jan  4 00:50:06 2023 ] Training epoch: 58
[ Wed Jan  4 01:17:40 2023 ] 	Mean training loss: 0.0410.  Mean training acc: 99.48%.
[ Wed Jan  4 01:17:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 01:17:40 2023 ] Eval epoch: 58
[ Wed Jan  4 01:42:16 2023 ] 	Mean test loss of 930 batches: 0.5435116296714192.
[ Wed Jan  4 01:42:17 2023 ] 	Top1: 85.71%
[ Wed Jan  4 01:42:17 2023 ] 	Top5: 96.72%
[ Wed Jan  4 01:42:18 2023 ] Training epoch: 59
[ Wed Jan  4 02:09:40 2023 ] 	Mean training loss: 0.0379.  Mean training acc: 99.52%.
[ Wed Jan  4 02:09:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 02:09:40 2023 ] Eval epoch: 59
[ Wed Jan  4 02:34:02 2023 ] 	Mean test loss of 930 batches: 0.5442142206494526.
[ Wed Jan  4 02:34:03 2023 ] 	Top1: 85.82%
[ Wed Jan  4 02:34:03 2023 ] 	Top5: 96.72%
[ Wed Jan  4 02:34:03 2023 ] Training epoch: 60
[ Wed Jan  4 02:59:39 2023 ] 	Mean training loss: 0.0354.  Mean training acc: 99.57%.
[ Wed Jan  4 02:59:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 02:59:39 2023 ] Eval epoch: 60
[ Wed Jan  4 03:20:12 2023 ] 	Mean test loss of 930 batches: 0.5438937492628572.
[ Wed Jan  4 03:20:13 2023 ] 	Top1: 85.87%
[ Wed Jan  4 03:20:14 2023 ] 	Top5: 96.72%
[ Wed Jan  4 03:20:14 2023 ] Training epoch: 61
[ Wed Jan  4 03:44:29 2023 ] 	Mean training loss: 0.0334.  Mean training acc: 99.62%.
[ Wed Jan  4 03:44:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 03:44:29 2023 ] Eval epoch: 61
[ Wed Jan  4 04:05:05 2023 ] 	Mean test loss of 930 batches: 0.5442027088014348.
[ Wed Jan  4 04:05:06 2023 ] 	Top1: 85.83%
[ Wed Jan  4 04:05:06 2023 ] 	Top5: 96.69%
[ Wed Jan  4 04:05:06 2023 ] Training epoch: 62
[ Wed Jan  4 04:29:13 2023 ] 	Mean training loss: 0.0328.  Mean training acc: 99.64%.
[ Wed Jan  4 04:29:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 04:29:14 2023 ] Eval epoch: 62
[ Wed Jan  4 04:49:43 2023 ] 	Mean test loss of 930 batches: 0.540633024840105.
[ Wed Jan  4 04:49:44 2023 ] 	Top1: 85.91%
[ Wed Jan  4 04:49:44 2023 ] 	Top5: 96.68%
[ Wed Jan  4 04:49:45 2023 ] Training epoch: 63
[ Wed Jan  4 05:13:48 2023 ] 	Mean training loss: 0.0315.  Mean training acc: 99.62%.
[ Wed Jan  4 05:13:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 05:13:50 2023 ] Eval epoch: 63
[ Wed Jan  4 05:34:25 2023 ] 	Mean test loss of 930 batches: 0.5457062411332323.
[ Wed Jan  4 05:34:26 2023 ] 	Top1: 85.83%
[ Wed Jan  4 05:34:26 2023 ] 	Top5: 96.72%
[ Wed Jan  4 05:34:27 2023 ] Training epoch: 64
[ Wed Jan  4 05:56:15 2023 ] 	Mean training loss: 0.0295.  Mean training acc: 99.67%.
[ Wed Jan  4 05:56:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 05:56:15 2023 ] Eval epoch: 64
[ Wed Jan  4 06:16:28 2023 ] 	Mean test loss of 930 batches: 0.54689317088454.
[ Wed Jan  4 06:16:29 2023 ] 	Top1: 85.86%
[ Wed Jan  4 06:16:29 2023 ] 	Top5: 96.66%
[ Wed Jan  4 06:16:29 2023 ] Training epoch: 65
[ Wed Jan  4 06:38:29 2023 ] 	Mean training loss: 0.0298.  Mean training acc: 99.67%.
[ Wed Jan  4 06:38:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 06:38:29 2023 ] Eval epoch: 65
[ Wed Jan  4 06:56:33 2023 ] 	Mean test loss of 930 batches: 0.5480716063971481.
[ Wed Jan  4 06:56:33 2023 ] 	Top1: 85.79%
[ Wed Jan  4 06:56:34 2023 ] 	Top5: 96.64%
[ Wed Jan  4 07:11:42 2023 ] Best accuracy: 0.8591220135514569
[ Wed Jan  4 07:11:42 2023 ] Epoch number: 62
[ Wed Jan  4 07:11:42 2023 ] Model name: work_dir/cset/local_SHTg_bone
[ Wed Jan  4 07:11:42 2023 ] Model total number of params: 2141090
[ Wed Jan  4 07:11:42 2023 ] Weight decay: 0.0004
[ Wed Jan  4 07:11:42 2023 ] Base LR: 0.1
[ Wed Jan  4 07:11:42 2023 ] Batch Size: 64
[ Wed Jan  4 07:11:42 2023 ] Test Batch Size: 64
[ Wed Jan  4 07:11:42 2023 ] seed: 1
[ Fri Jan 13 18:09:18 2023 ] Load weights from work_dir/cset/local_SHT_bone/runs-48-40848.pt.
[ Fri Jan 13 18:09:20 2023 ] using warm up, epoch: 0
[ Fri Jan 13 18:09:33 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHT_bone', 'model_saved_name': 'work_dir/cset/local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-set/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/cset/local_SHT_bone/runs-48-40848.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 48, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Fri Jan 13 18:09:33 2023 ] # Parameters: 2141090
[ Fri Jan 13 18:09:33 2023 ] Training epoch: 49
[ Fri Jan 13 18:20:13 2023 ] 	Mean training loss: 0.1225.  Mean training acc: 96.90%.
[ Fri Jan 13 18:20:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 18:20:14 2023 ] Eval epoch: 49
[ Fri Jan 13 18:31:15 2023 ] 	Mean test loss of 930 batches: 0.5949314477703264.
[ Fri Jan 13 18:31:15 2023 ] 	Top1: 84.05%
[ Fri Jan 13 18:31:16 2023 ] 	Top5: 96.44%
[ Fri Jan 13 18:31:16 2023 ] Training epoch: 50
[ Fri Jan 13 18:44:28 2023 ] 	Mean training loss: 0.1200.  Mean training acc: 97.04%.
[ Fri Jan 13 18:44:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 18:44:28 2023 ] Eval epoch: 50
[ Fri Jan 13 18:57:46 2023 ] 	Mean test loss of 930 batches: 0.592240764693387.
[ Fri Jan 13 18:57:47 2023 ] 	Top1: 84.41%
[ Fri Jan 13 18:57:47 2023 ] 	Top5: 96.39%
[ Fri Jan 13 18:57:47 2023 ] Training epoch: 51
[ Fri Jan 13 19:13:12 2023 ] 	Mean training loss: 0.1135.  Mean training acc: 97.32%.
[ Fri Jan 13 19:13:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 19:13:12 2023 ] Eval epoch: 51
[ Fri Jan 13 19:26:13 2023 ] 	Mean test loss of 930 batches: 0.6041145947271137.
[ Fri Jan 13 19:26:14 2023 ] 	Top1: 83.89%
[ Fri Jan 13 19:26:14 2023 ] 	Top5: 96.44%
[ Fri Jan 13 19:26:14 2023 ] Training epoch: 52
[ Fri Jan 13 19:41:50 2023 ] 	Mean training loss: 0.1129.  Mean training acc: 97.24%.
[ Fri Jan 13 19:41:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 19:41:50 2023 ] Eval epoch: 52
[ Fri Jan 13 19:54:45 2023 ] 	Mean test loss of 930 batches: 0.6177514853416591.
[ Fri Jan 13 19:54:45 2023 ] 	Top1: 83.54%
[ Fri Jan 13 19:54:46 2023 ] 	Top5: 96.36%
[ Fri Jan 13 19:54:46 2023 ] Training epoch: 53
[ Fri Jan 13 20:10:25 2023 ] 	Mean training loss: 0.1193.  Mean training acc: 97.09%.
[ Fri Jan 13 20:10:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 20:10:25 2023 ] Eval epoch: 53
[ Fri Jan 13 20:23:10 2023 ] 	Mean test loss of 930 batches: 0.6030603644588302.
[ Fri Jan 13 20:23:11 2023 ] 	Top1: 84.15%
[ Fri Jan 13 20:23:11 2023 ] 	Top5: 96.38%
[ Fri Jan 13 20:23:11 2023 ] Training epoch: 54
[ Fri Jan 13 20:38:44 2023 ] 	Mean training loss: 0.1166.  Mean training acc: 97.07%.
[ Fri Jan 13 20:38:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 20:38:44 2023 ] Eval epoch: 54
[ Fri Jan 13 20:51:05 2023 ] 	Mean test loss of 930 batches: 0.5926703935749428.
[ Fri Jan 13 20:51:06 2023 ] 	Top1: 84.01%
[ Fri Jan 13 20:51:06 2023 ] 	Top5: 96.45%
[ Fri Jan 13 20:51:06 2023 ] Training epoch: 55
[ Fri Jan 13 21:06:21 2023 ] 	Mean training loss: 0.1171.  Mean training acc: 97.15%.
[ Fri Jan 13 21:06:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 21:06:21 2023 ] Eval epoch: 55
[ Fri Jan 13 21:18:50 2023 ] 	Mean test loss of 930 batches: 0.6323358117252268.
[ Fri Jan 13 21:18:50 2023 ] 	Top1: 83.25%
[ Fri Jan 13 21:18:51 2023 ] 	Top5: 96.27%
[ Fri Jan 13 21:18:51 2023 ] Training epoch: 56
[ Fri Jan 13 21:34:03 2023 ] 	Mean training loss: 0.0659.  Mean training acc: 98.76%.
[ Fri Jan 13 21:34:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 21:34:03 2023 ] Eval epoch: 56
[ Fri Jan 13 21:46:59 2023 ] 	Mean test loss of 930 batches: 0.5504838186887002.
[ Fri Jan 13 21:47:00 2023 ] 	Top1: 85.40%
[ Fri Jan 13 21:47:00 2023 ] 	Top5: 96.79%
[ Fri Jan 13 21:47:00 2023 ] Training epoch: 57
[ Fri Jan 13 21:59:42 2023 ] 	Mean training loss: 0.0470.  Mean training acc: 99.31%.
[ Fri Jan 13 21:59:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 21:59:42 2023 ] Eval epoch: 57
[ Fri Jan 13 22:11:54 2023 ] 	Mean test loss of 930 batches: 0.5413675878357183.
[ Fri Jan 13 22:11:54 2023 ] 	Top1: 85.62%
[ Fri Jan 13 22:11:55 2023 ] 	Top5: 96.80%
[ Fri Jan 13 22:11:55 2023 ] Training epoch: 58
[ Fri Jan 13 22:24:18 2023 ] 	Mean training loss: 0.0416.  Mean training acc: 99.43%.
[ Fri Jan 13 22:24:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 22:24:18 2023 ] Eval epoch: 58
[ Fri Jan 13 22:36:09 2023 ] 	Mean test loss of 930 batches: 0.5426864544550578.
[ Fri Jan 13 22:36:09 2023 ] 	Top1: 85.71%
[ Fri Jan 13 22:36:10 2023 ] 	Top5: 96.77%
[ Fri Jan 13 22:36:10 2023 ] Training epoch: 59
[ Fri Jan 13 22:48:43 2023 ] 	Mean training loss: 0.0379.  Mean training acc: 99.52%.
[ Fri Jan 13 22:48:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 22:48:43 2023 ] Eval epoch: 59
[ Fri Jan 13 23:00:00 2023 ] 	Mean test loss of 930 batches: 0.5433625854551792.
[ Fri Jan 13 23:00:00 2023 ] 	Top1: 85.69%
[ Fri Jan 13 23:00:01 2023 ] 	Top5: 96.78%
[ Fri Jan 13 23:00:01 2023 ] Training epoch: 60
[ Fri Jan 13 23:12:57 2023 ] 	Mean training loss: 0.0349.  Mean training acc: 99.62%.
[ Fri Jan 13 23:12:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 23:12:57 2023 ] Eval epoch: 60
[ Fri Jan 13 23:23:49 2023 ] 	Mean test loss of 930 batches: 0.5434312291082836.
[ Fri Jan 13 23:23:50 2023 ] 	Top1: 85.83%
[ Fri Jan 13 23:23:50 2023 ] 	Top5: 96.84%
[ Fri Jan 13 23:23:50 2023 ] Training epoch: 61
[ Fri Jan 13 23:36:58 2023 ] 	Mean training loss: 0.0342.  Mean training acc: 99.58%.
[ Fri Jan 13 23:36:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 23:36:58 2023 ] Eval epoch: 61
[ Fri Jan 13 23:48:09 2023 ] 	Mean test loss of 930 batches: 0.5406329508670555.
[ Fri Jan 13 23:48:09 2023 ] 	Top1: 85.84%
[ Fri Jan 13 23:48:10 2023 ] 	Top5: 96.82%
[ Fri Jan 13 23:48:10 2023 ] Training epoch: 62
[ Sat Jan 14 00:00:40 2023 ] 	Mean training loss: 0.0330.  Mean training acc: 99.61%.
[ Sat Jan 14 00:00:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:00:40 2023 ] Eval epoch: 62
[ Sat Jan 14 00:11:58 2023 ] 	Mean test loss of 930 batches: 0.5392448597377346.
[ Sat Jan 14 00:11:58 2023 ] 	Top1: 85.84%
[ Sat Jan 14 00:11:59 2023 ] 	Top5: 96.80%
[ Sat Jan 14 00:11:59 2023 ] Training epoch: 63
[ Sat Jan 14 00:24:13 2023 ] 	Mean training loss: 0.0313.  Mean training acc: 99.65%.
[ Sat Jan 14 00:24:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:24:13 2023 ] Eval epoch: 63
[ Sat Jan 14 00:35:12 2023 ] 	Mean test loss of 930 batches: 0.5462153878423476.
[ Sat Jan 14 00:35:13 2023 ] 	Top1: 85.78%
[ Sat Jan 14 00:35:13 2023 ] 	Top5: 96.79%
[ Sat Jan 14 00:35:13 2023 ] Training epoch: 64
[ Sat Jan 14 00:47:30 2023 ] 	Mean training loss: 0.0300.  Mean training acc: 99.66%.
[ Sat Jan 14 00:47:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:47:30 2023 ] Eval epoch: 64
[ Sat Jan 14 00:58:26 2023 ] 	Mean test loss of 930 batches: 0.5459567961593469.
[ Sat Jan 14 00:58:27 2023 ] 	Top1: 85.77%
[ Sat Jan 14 00:58:27 2023 ] 	Top5: 96.72%
[ Sat Jan 14 00:58:27 2023 ] Training epoch: 65
[ Sat Jan 14 01:09:36 2023 ] 	Mean training loss: 0.0299.  Mean training acc: 99.68%.
[ Sat Jan 14 01:09:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 01:09:36 2023 ] Eval epoch: 65
[ Sat Jan 14 01:19:31 2023 ] 	Mean test loss of 930 batches: 0.5450781792402267.
[ Sat Jan 14 01:19:32 2023 ] 	Top1: 85.86%
[ Sat Jan 14 01:19:32 2023 ] 	Top5: 96.70%
[ Sat Jan 14 01:27:50 2023 ] Best accuracy: 0.8585503640062545
[ Sat Jan 14 01:27:50 2023 ] Epoch number: 65
[ Sat Jan 14 01:27:50 2023 ] Model name: work_dir/cset/local_SHT_bone
[ Sat Jan 14 01:27:50 2023 ] Model total number of params: 2141090
[ Sat Jan 14 01:27:50 2023 ] Weight decay: 0.0004
[ Sat Jan 14 01:27:50 2023 ] Base LR: 0.1
[ Sat Jan 14 01:27:50 2023 ] Batch Size: 64
[ Sat Jan 14 01:27:50 2023 ] Test Batch Size: 64
[ Sat Jan 14 01:27:50 2023 ] seed: 1
[ Mon Jan 30 13:55:20 2023 ] using warm up, epoch: 5
[ Mon Jan 30 13:57:30 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHT_bone', 'model_saved_name': 'work_dir/cset/local_SHT_bone/runs', 'config': 'config/nturgbd120-cross-set/bone.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Jan 30 13:57:30 2023 ] # Parameters: 2141090
[ Mon Jan 30 13:57:30 2023 ] Training epoch: 1
[ Mon Jan 30 14:10:18 2023 ] 	Mean training loss: 3.3997.  Mean training acc: 17.60%.
[ Mon Jan 30 14:10:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 14:10:18 2023 ] Eval epoch: 1
[ Mon Jan 30 14:20:19 2023 ] 	Mean test loss of 930 batches: 2.78720421560349.
[ Mon Jan 30 14:20:19 2023 ] 	Top1: 27.30%
[ Mon Jan 30 14:20:20 2023 ] 	Top5: 60.61%
[ Mon Jan 30 14:20:20 2023 ] Training epoch: 2
[ Mon Jan 30 14:34:56 2023 ] 	Mean training loss: 2.2966.  Mean training acc: 36.88%.
[ Mon Jan 30 14:34:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 14:34:57 2023 ] Eval epoch: 2
[ Mon Jan 30 14:45:46 2023 ] 	Mean test loss of 930 batches: 1.9662044975065416.
[ Mon Jan 30 14:45:47 2023 ] 	Top1: 44.08%
[ Mon Jan 30 14:45:47 2023 ] 	Top5: 79.57%
[ Mon Jan 30 14:45:47 2023 ] Training epoch: 3
[ Mon Jan 30 15:00:37 2023 ] 	Mean training loss: 1.7684.  Mean training acc: 49.17%.
[ Mon Jan 30 15:00:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 15:00:37 2023 ] Eval epoch: 3
[ Mon Jan 30 15:10:44 2023 ] 	Mean test loss of 930 batches: 1.7197692769829944.
[ Mon Jan 30 15:10:44 2023 ] 	Top1: 49.62%
[ Mon Jan 30 15:10:45 2023 ] 	Top5: 84.27%
[ Mon Jan 30 15:10:45 2023 ] Training epoch: 4
[ Mon Jan 30 15:25:11 2023 ] 	Mean training loss: 1.5117.  Mean training acc: 55.64%.
[ Mon Jan 30 15:25:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 15:25:11 2023 ] Eval epoch: 4
[ Mon Jan 30 15:34:47 2023 ] 	Mean test loss of 930 batches: 1.9296130869337307.
[ Mon Jan 30 15:34:48 2023 ] 	Top1: 47.26%
[ Mon Jan 30 15:34:48 2023 ] 	Top5: 81.44%
[ Mon Jan 30 15:34:48 2023 ] Training epoch: 5
[ Mon Jan 30 15:49:11 2023 ] 	Mean training loss: 1.3656.  Mean training acc: 59.48%.
[ Mon Jan 30 15:49:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 15:49:11 2023 ] Eval epoch: 5
[ Mon Jan 30 15:58:57 2023 ] 	Mean test loss of 930 batches: 1.5239197194576264.
[ Mon Jan 30 15:58:58 2023 ] 	Top1: 56.53%
[ Mon Jan 30 15:58:58 2023 ] 	Top5: 87.60%
[ Mon Jan 30 15:58:58 2023 ] Training epoch: 6
[ Mon Jan 30 16:13:28 2023 ] 	Mean training loss: 1.1978.  Mean training acc: 64.27%.
[ Mon Jan 30 16:13:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 16:13:28 2023 ] Eval epoch: 6
[ Mon Jan 30 16:23:15 2023 ] 	Mean test loss of 930 batches: 1.4081678296930047.
[ Mon Jan 30 16:23:16 2023 ] 	Top1: 59.88%
[ Mon Jan 30 16:23:17 2023 ] 	Top5: 89.20%
[ Mon Jan 30 16:23:17 2023 ] Training epoch: 7
[ Mon Jan 30 16:37:35 2023 ] 	Mean training loss: 1.1007.  Mean training acc: 66.85%.
[ Mon Jan 30 16:37:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 16:37:35 2023 ] Eval epoch: 7
[ Mon Jan 30 16:47:19 2023 ] 	Mean test loss of 930 batches: 1.3252138204792494.
[ Mon Jan 30 16:47:20 2023 ] 	Top1: 62.75%
[ Mon Jan 30 16:47:20 2023 ] 	Top5: 89.60%
[ Mon Jan 30 16:47:20 2023 ] Training epoch: 8
[ Mon Jan 30 17:01:41 2023 ] 	Mean training loss: 1.0404.  Mean training acc: 68.69%.
[ Mon Jan 30 17:01:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 17:01:41 2023 ] Eval epoch: 8
[ Mon Jan 30 17:11:31 2023 ] 	Mean test loss of 930 batches: 1.1142524638163147.
[ Mon Jan 30 17:11:31 2023 ] 	Top1: 67.04%
[ Mon Jan 30 17:11:32 2023 ] 	Top5: 91.77%
[ Mon Jan 30 17:11:32 2023 ] Training epoch: 9
[ Mon Jan 30 17:25:52 2023 ] 	Mean training loss: 0.9910.  Mean training acc: 70.16%.
[ Mon Jan 30 17:25:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 17:25:52 2023 ] Eval epoch: 9
[ Mon Jan 30 17:35:51 2023 ] 	Mean test loss of 930 batches: 1.1940313232842312.
[ Mon Jan 30 17:35:51 2023 ] 	Top1: 65.83%
[ Mon Jan 30 17:35:52 2023 ] 	Top5: 90.66%
[ Mon Jan 30 17:35:52 2023 ] Training epoch: 10
[ Mon Jan 30 17:50:21 2023 ] 	Mean training loss: 0.9512.  Mean training acc: 71.47%.
[ Mon Jan 30 17:50:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 17:50:21 2023 ] Eval epoch: 10
[ Mon Jan 30 18:00:16 2023 ] 	Mean test loss of 930 batches: 1.2287013441003778.
[ Mon Jan 30 18:00:16 2023 ] 	Top1: 65.10%
[ Mon Jan 30 18:00:17 2023 ] 	Top5: 90.53%
[ Mon Jan 30 18:00:17 2023 ] Training epoch: 11
[ Mon Jan 30 18:14:37 2023 ] 	Mean training loss: 0.9202.  Mean training acc: 72.15%.
[ Mon Jan 30 18:14:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 18:14:37 2023 ] Eval epoch: 11
[ Mon Jan 30 18:24:42 2023 ] 	Mean test loss of 930 batches: 1.1635256950893709.
[ Mon Jan 30 18:24:42 2023 ] 	Top1: 65.89%
[ Mon Jan 30 18:24:43 2023 ] 	Top5: 91.45%
[ Mon Jan 30 18:24:43 2023 ] Training epoch: 12
[ Mon Jan 30 18:39:23 2023 ] 	Mean training loss: 0.8959.  Mean training acc: 72.71%.
[ Mon Jan 30 18:39:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 18:39:23 2023 ] Eval epoch: 12
[ Mon Jan 30 18:49:11 2023 ] 	Mean test loss of 930 batches: 1.3537318960633329.
[ Mon Jan 30 18:49:11 2023 ] 	Top1: 62.28%
[ Mon Jan 30 18:49:12 2023 ] 	Top5: 89.08%
[ Mon Jan 30 18:49:12 2023 ] Training epoch: 13
[ Mon Jan 30 19:03:45 2023 ] 	Mean training loss: 0.8732.  Mean training acc: 73.63%.
[ Mon Jan 30 19:03:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 19:03:45 2023 ] Eval epoch: 13
[ Mon Jan 30 19:13:29 2023 ] 	Mean test loss of 930 batches: 1.3649950217816138.
[ Mon Jan 30 19:13:29 2023 ] 	Top1: 62.07%
[ Mon Jan 30 19:13:29 2023 ] 	Top5: 89.78%
[ Mon Jan 30 19:13:30 2023 ] Training epoch: 14
[ Mon Jan 30 19:27:42 2023 ] 	Mean training loss: 0.8540.  Mean training acc: 74.36%.
[ Mon Jan 30 19:27:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 19:27:42 2023 ] Eval epoch: 14
[ Mon Jan 30 19:37:35 2023 ] 	Mean test loss of 930 batches: 1.0675127730254204.
[ Mon Jan 30 19:37:35 2023 ] 	Top1: 68.97%
[ Mon Jan 30 19:37:36 2023 ] 	Top5: 92.80%
[ Mon Jan 30 19:37:36 2023 ] Training epoch: 15
[ Mon Jan 30 19:52:01 2023 ] 	Mean training loss: 0.8419.  Mean training acc: 74.36%.
[ Mon Jan 30 19:52:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 19:52:02 2023 ] Eval epoch: 15
[ Mon Jan 30 20:01:53 2023 ] 	Mean test loss of 930 batches: 1.0884477302592288.
[ Mon Jan 30 20:01:53 2023 ] 	Top1: 69.02%
[ Mon Jan 30 20:01:54 2023 ] 	Top5: 91.76%
[ Mon Jan 30 20:01:54 2023 ] Training epoch: 16
[ Mon Jan 30 20:16:17 2023 ] 	Mean training loss: 0.8238.  Mean training acc: 75.01%.
[ Mon Jan 30 20:16:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 20:16:17 2023 ] Eval epoch: 16
[ Mon Jan 30 20:26:06 2023 ] 	Mean test loss of 930 batches: 1.0141506530584827.
[ Mon Jan 30 20:26:07 2023 ] 	Top1: 70.59%
[ Mon Jan 30 20:26:07 2023 ] 	Top5: 93.10%
[ Mon Jan 30 20:26:07 2023 ] Training epoch: 17
[ Mon Jan 30 20:40:34 2023 ] 	Mean training loss: 0.8146.  Mean training acc: 75.44%.
[ Mon Jan 30 20:40:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 20:40:34 2023 ] Eval epoch: 17
[ Mon Jan 30 20:50:18 2023 ] 	Mean test loss of 930 batches: 1.131560858443219.
[ Mon Jan 30 20:50:18 2023 ] 	Top1: 67.29%
[ Mon Jan 30 20:50:19 2023 ] 	Top5: 91.88%
[ Mon Jan 30 20:50:19 2023 ] Training epoch: 18
[ Mon Jan 30 21:04:36 2023 ] 	Mean training loss: 0.8000.  Mean training acc: 75.66%.
[ Mon Jan 30 21:04:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 21:04:36 2023 ] Eval epoch: 18
[ Mon Jan 30 21:14:24 2023 ] 	Mean test loss of 930 batches: 1.110453272891301.
[ Mon Jan 30 21:14:24 2023 ] 	Top1: 68.36%
[ Mon Jan 30 21:14:24 2023 ] 	Top5: 92.06%
[ Mon Jan 30 21:14:24 2023 ] Training epoch: 19
[ Mon Jan 30 21:28:47 2023 ] 	Mean training loss: 0.7970.  Mean training acc: 75.81%.
[ Mon Jan 30 21:28:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 21:28:47 2023 ] Eval epoch: 19
[ Mon Jan 30 21:38:21 2023 ] 	Mean test loss of 930 batches: 1.2606953257514584.
[ Mon Jan 30 21:38:22 2023 ] 	Top1: 65.04%
[ Mon Jan 30 21:38:22 2023 ] 	Top5: 90.33%
[ Mon Jan 30 21:38:22 2023 ] Training epoch: 20
[ Mon Jan 30 21:52:31 2023 ] 	Mean training loss: 0.7893.  Mean training acc: 75.86%.
[ Mon Jan 30 21:52:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 21:52:31 2023 ] Eval epoch: 20
[ Mon Jan 30 22:02:09 2023 ] 	Mean test loss of 930 batches: 0.9764603405229507.
[ Mon Jan 30 22:02:10 2023 ] 	Top1: 71.82%
[ Mon Jan 30 22:02:10 2023 ] 	Top5: 93.28%
[ Mon Jan 30 22:02:10 2023 ] Training epoch: 21
[ Mon Jan 30 22:16:36 2023 ] 	Mean training loss: 0.7729.  Mean training acc: 76.76%.
[ Mon Jan 30 22:16:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 22:16:36 2023 ] Eval epoch: 21
[ Mon Jan 30 22:26:03 2023 ] 	Mean test loss of 930 batches: 0.9811758585514561.
[ Mon Jan 30 22:26:03 2023 ] 	Top1: 71.62%
[ Mon Jan 30 22:26:04 2023 ] 	Top5: 92.96%
[ Mon Jan 30 22:26:04 2023 ] Training epoch: 22
[ Mon Jan 30 22:40:25 2023 ] 	Mean training loss: 0.7687.  Mean training acc: 76.55%.
[ Mon Jan 30 22:40:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 22:40:25 2023 ] Eval epoch: 22
[ Mon Jan 30 22:50:16 2023 ] 	Mean test loss of 930 batches: 1.1980058622616594.
[ Mon Jan 30 22:50:17 2023 ] 	Top1: 66.29%
[ Mon Jan 30 22:50:17 2023 ] 	Top5: 91.44%
[ Mon Jan 30 22:50:17 2023 ] Training epoch: 23
[ Mon Jan 30 23:04:46 2023 ] 	Mean training loss: 0.7634.  Mean training acc: 76.62%.
[ Mon Jan 30 23:04:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 23:04:46 2023 ] Eval epoch: 23
[ Mon Jan 30 23:14:33 2023 ] 	Mean test loss of 930 batches: 1.1711811242565031.
[ Mon Jan 30 23:14:33 2023 ] 	Top1: 67.29%
[ Mon Jan 30 23:14:34 2023 ] 	Top5: 91.39%
[ Mon Jan 30 23:14:34 2023 ] Training epoch: 24
[ Mon Jan 30 23:28:54 2023 ] 	Mean training loss: 0.7566.  Mean training acc: 77.05%.
[ Mon Jan 30 23:28:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 23:28:54 2023 ] Eval epoch: 24
[ Mon Jan 30 23:38:34 2023 ] 	Mean test loss of 930 batches: 1.0201716543525778.
[ Mon Jan 30 23:38:35 2023 ] 	Top1: 71.71%
[ Mon Jan 30 23:38:35 2023 ] 	Top5: 92.57%
[ Mon Jan 30 23:38:35 2023 ] Training epoch: 25
[ Mon Jan 30 23:52:13 2023 ] 	Mean training loss: 0.7470.  Mean training acc: 77.50%.
[ Mon Jan 30 23:52:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jan 30 23:52:13 2023 ] Eval epoch: 25
[ Tue Jan 31 00:00:52 2023 ] 	Mean test loss of 930 batches: 1.0717152346526422.
[ Tue Jan 31 00:00:53 2023 ] 	Top1: 69.18%
[ Tue Jan 31 00:00:53 2023 ] 	Top5: 92.32%
[ Tue Jan 31 00:00:53 2023 ] Training epoch: 26
[ Tue Jan 31 00:12:25 2023 ] 	Mean training loss: 0.7422.  Mean training acc: 77.53%.
[ Tue Jan 31 00:12:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 00:12:25 2023 ] Eval epoch: 26
[ Tue Jan 31 00:20:28 2023 ] 	Mean test loss of 930 batches: 1.1088895189826207.
[ Tue Jan 31 00:20:29 2023 ] 	Top1: 69.24%
[ Tue Jan 31 00:20:29 2023 ] 	Top5: 91.81%
[ Tue Jan 31 00:20:29 2023 ] Training epoch: 27
[ Tue Jan 31 00:29:53 2023 ] 	Mean training loss: 0.7382.  Mean training acc: 77.48%.
[ Tue Jan 31 00:29:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 00:29:53 2023 ] Eval epoch: 27
[ Tue Jan 31 00:38:47 2023 ] 	Mean test loss of 930 batches: 0.9993073570151483.
[ Tue Jan 31 00:38:47 2023 ] 	Top1: 71.69%
[ Tue Jan 31 00:38:48 2023 ] 	Top5: 92.86%
[ Tue Jan 31 00:38:48 2023 ] Training epoch: 28
[ Tue Jan 31 00:51:00 2023 ] 	Mean training loss: 0.7347.  Mean training acc: 77.82%.
[ Tue Jan 31 00:51:00 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 00:51:00 2023 ] Eval epoch: 28
[ Tue Jan 31 00:59:53 2023 ] 	Mean test loss of 930 batches: 1.565011703583502.
[ Tue Jan 31 00:59:54 2023 ] 	Top1: 60.58%
[ Tue Jan 31 00:59:54 2023 ] 	Top5: 85.04%
[ Tue Jan 31 00:59:54 2023 ] Training epoch: 29
[ Tue Jan 31 01:11:37 2023 ] 	Mean training loss: 0.7322.  Mean training acc: 77.98%.
[ Tue Jan 31 01:11:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 01:11:38 2023 ] Eval epoch: 29
[ Tue Jan 31 01:20:37 2023 ] 	Mean test loss of 930 batches: 1.1059256715159262.
[ Tue Jan 31 01:20:37 2023 ] 	Top1: 69.84%
[ Tue Jan 31 01:20:38 2023 ] 	Top5: 92.06%
[ Tue Jan 31 01:20:38 2023 ] Training epoch: 30
[ Tue Jan 31 01:32:49 2023 ] 	Mean training loss: 0.7206.  Mean training acc: 78.27%.
[ Tue Jan 31 01:32:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 01:32:49 2023 ] Eval epoch: 30
[ Tue Jan 31 01:41:52 2023 ] 	Mean test loss of 930 batches: 1.0614932720058707.
[ Tue Jan 31 01:41:53 2023 ] 	Top1: 71.11%
[ Tue Jan 31 01:41:53 2023 ] 	Top5: 92.29%
[ Tue Jan 31 01:41:53 2023 ] Training epoch: 31
[ Tue Jan 31 01:54:19 2023 ] 	Mean training loss: 0.7241.  Mean training acc: 78.06%.
[ Tue Jan 31 01:54:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 01:54:19 2023 ] Eval epoch: 31
[ Tue Jan 31 02:03:14 2023 ] 	Mean test loss of 930 batches: 0.9402562197498096.
[ Tue Jan 31 02:03:15 2023 ] 	Top1: 72.80%
[ Tue Jan 31 02:03:15 2023 ] 	Top5: 93.77%
[ Tue Jan 31 02:03:15 2023 ] Training epoch: 32
[ Tue Jan 31 02:15:47 2023 ] 	Mean training loss: 0.7222.  Mean training acc: 78.03%.
[ Tue Jan 31 02:15:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 02:15:47 2023 ] Eval epoch: 32
[ Tue Jan 31 02:24:43 2023 ] 	Mean test loss of 930 batches: 0.9774221430542649.
[ Tue Jan 31 02:24:44 2023 ] 	Top1: 72.37%
[ Tue Jan 31 02:24:44 2023 ] 	Top5: 93.06%
[ Tue Jan 31 02:24:44 2023 ] Training epoch: 33
[ Tue Jan 31 02:37:11 2023 ] 	Mean training loss: 0.7173.  Mean training acc: 78.37%.
[ Tue Jan 31 02:37:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 02:37:11 2023 ] Eval epoch: 33
[ Tue Jan 31 02:46:09 2023 ] 	Mean test loss of 930 batches: 1.0140019336054402.
[ Tue Jan 31 02:46:09 2023 ] 	Top1: 71.12%
[ Tue Jan 31 02:46:10 2023 ] 	Top5: 92.62%
[ Tue Jan 31 02:46:10 2023 ] Training epoch: 34
[ Tue Jan 31 02:58:51 2023 ] 	Mean training loss: 0.7073.  Mean training acc: 78.56%.
[ Tue Jan 31 02:58:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 02:58:51 2023 ] Eval epoch: 34
[ Tue Jan 31 03:07:54 2023 ] 	Mean test loss of 930 batches: 1.1714876598568373.
[ Tue Jan 31 03:07:54 2023 ] 	Top1: 69.06%
[ Tue Jan 31 03:07:54 2023 ] 	Top5: 91.11%
[ Tue Jan 31 03:07:54 2023 ] Training epoch: 35
[ Tue Jan 31 03:20:30 2023 ] 	Mean training loss: 0.7082.  Mean training acc: 78.38%.
[ Tue Jan 31 03:20:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 03:20:31 2023 ] Eval epoch: 35
[ Tue Jan 31 03:29:37 2023 ] 	Mean test loss of 930 batches: 0.9113564679859787.
[ Tue Jan 31 03:29:38 2023 ] 	Top1: 73.78%
[ Tue Jan 31 03:29:38 2023 ] 	Top5: 93.90%
[ Tue Jan 31 03:29:38 2023 ] Training epoch: 36
[ Tue Jan 31 03:42:14 2023 ] 	Mean training loss: 0.3778.  Mean training acc: 88.75%.
[ Tue Jan 31 03:42:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 03:42:14 2023 ] Eval epoch: 36
[ Tue Jan 31 03:51:20 2023 ] 	Mean test loss of 930 batches: 0.5135566991944146.
[ Tue Jan 31 03:51:20 2023 ] 	Top1: 85.00%
[ Tue Jan 31 03:51:21 2023 ] 	Top5: 96.99%
[ Tue Jan 31 03:51:21 2023 ] Training epoch: 37
[ Tue Jan 31 04:03:58 2023 ] 	Mean training loss: 0.2917.  Mean training acc: 91.28%.
[ Tue Jan 31 04:03:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 04:03:58 2023 ] Eval epoch: 37
[ Tue Jan 31 04:13:10 2023 ] 	Mean test loss of 930 batches: 0.4992677652307095.
[ Tue Jan 31 04:13:11 2023 ] 	Top1: 85.37%
[ Tue Jan 31 04:13:11 2023 ] 	Top5: 97.06%
[ Tue Jan 31 04:13:11 2023 ] Training epoch: 38
[ Tue Jan 31 04:25:13 2023 ] 	Mean training loss: 0.2574.  Mean training acc: 92.42%.
[ Tue Jan 31 04:25:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 04:25:14 2023 ] Eval epoch: 38
[ Tue Jan 31 04:34:14 2023 ] 	Mean test loss of 930 batches: 0.5032939963283077.
[ Tue Jan 31 04:34:15 2023 ] 	Top1: 85.38%
[ Tue Jan 31 04:34:15 2023 ] 	Top5: 97.00%
[ Tue Jan 31 04:34:15 2023 ] Training epoch: 39
[ Tue Jan 31 04:46:21 2023 ] 	Mean training loss: 0.2315.  Mean training acc: 93.33%.
[ Tue Jan 31 04:46:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 04:46:21 2023 ] Eval epoch: 39
[ Tue Jan 31 04:55:26 2023 ] 	Mean test loss of 930 batches: 0.4966796717416215.
[ Tue Jan 31 04:55:26 2023 ] 	Top1: 85.64%
[ Tue Jan 31 04:55:27 2023 ] 	Top5: 97.07%
[ Tue Jan 31 04:55:27 2023 ] Training epoch: 40
[ Tue Jan 31 05:07:56 2023 ] 	Mean training loss: 0.2091.  Mean training acc: 94.14%.
[ Tue Jan 31 05:07:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 05:07:56 2023 ] Eval epoch: 40
[ Tue Jan 31 05:16:55 2023 ] 	Mean test loss of 930 batches: 0.4946330022026775.
[ Tue Jan 31 05:16:55 2023 ] 	Top1: 85.70%
[ Tue Jan 31 05:16:56 2023 ] 	Top5: 97.04%
[ Tue Jan 31 05:16:56 2023 ] Training epoch: 41
[ Tue Jan 31 05:29:22 2023 ] 	Mean training loss: 0.1915.  Mean training acc: 94.63%.
[ Tue Jan 31 05:29:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 05:29:22 2023 ] Eval epoch: 41
[ Tue Jan 31 05:38:23 2023 ] 	Mean test loss of 930 batches: 0.5218805417458536.
[ Tue Jan 31 05:38:24 2023 ] 	Top1: 85.18%
[ Tue Jan 31 05:38:24 2023 ] 	Top5: 96.91%
[ Tue Jan 31 05:38:24 2023 ] Training epoch: 42
[ Tue Jan 31 05:49:07 2023 ] 	Mean training loss: 0.1758.  Mean training acc: 95.10%.
[ Tue Jan 31 05:49:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 05:49:07 2023 ] Eval epoch: 42
[ Tue Jan 31 05:57:03 2023 ] 	Mean test loss of 930 batches: 0.5193721067641051.
[ Tue Jan 31 05:57:03 2023 ] 	Top1: 85.18%
[ Tue Jan 31 05:57:03 2023 ] 	Top5: 96.96%
[ Tue Jan 31 05:57:04 2023 ] Training epoch: 43
[ Tue Jan 31 06:06:04 2023 ] 	Mean training loss: 0.1594.  Mean training acc: 95.76%.
[ Tue Jan 31 06:06:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 06:06:04 2023 ] Eval epoch: 43
[ Tue Jan 31 06:14:02 2023 ] 	Mean test loss of 930 batches: 0.5194727792294436.
[ Tue Jan 31 06:14:02 2023 ] 	Top1: 85.30%
[ Tue Jan 31 06:14:03 2023 ] 	Top5: 96.92%
[ Tue Jan 31 06:14:03 2023 ] Training epoch: 44
[ Tue Jan 31 06:23:15 2023 ] 	Mean training loss: 0.1485.  Mean training acc: 96.11%.
[ Tue Jan 31 06:23:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 06:23:15 2023 ] Eval epoch: 44
[ Tue Jan 31 06:31:17 2023 ] 	Mean test loss of 930 batches: 0.5334499226863025.
[ Tue Jan 31 06:31:18 2023 ] 	Top1: 85.12%
[ Tue Jan 31 06:31:18 2023 ] 	Top5: 96.83%
[ Tue Jan 31 06:31:20 2023 ] Training epoch: 45
[ Tue Jan 31 06:40:19 2023 ] 	Mean training loss: 0.1387.  Mean training acc: 96.36%.
[ Tue Jan 31 06:40:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 06:40:20 2023 ] Eval epoch: 45
[ Tue Jan 31 06:48:22 2023 ] 	Mean test loss of 930 batches: 0.5509420347830621.
[ Tue Jan 31 06:48:22 2023 ] 	Top1: 84.78%
[ Tue Jan 31 06:48:22 2023 ] 	Top5: 96.65%
[ Tue Jan 31 06:48:26 2023 ] Training epoch: 46
[ Tue Jan 31 06:57:46 2023 ] 	Mean training loss: 0.1341.  Mean training acc: 96.50%.
[ Tue Jan 31 06:57:46 2023 ] 	Time consumption: [Data]01%, [Network]97%
[ Tue Jan 31 06:57:47 2023 ] Eval epoch: 46
[ Tue Jan 31 07:05:50 2023 ] 	Mean test loss of 930 batches: 0.5404016479168848.
[ Tue Jan 31 07:05:51 2023 ] 	Top1: 85.22%
[ Tue Jan 31 07:05:51 2023 ] 	Top5: 96.74%
[ Tue Jan 31 07:05:51 2023 ] Training epoch: 47
[ Tue Jan 31 07:14:57 2023 ] 	Mean training loss: 0.1289.  Mean training acc: 96.70%.
[ Tue Jan 31 07:14:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 07:14:57 2023 ] Eval epoch: 47
[ Tue Jan 31 07:22:57 2023 ] 	Mean test loss of 930 batches: 0.5644117622866586.
[ Tue Jan 31 07:23:00 2023 ] 	Top1: 84.71%
[ Tue Jan 31 07:23:00 2023 ] 	Top5: 96.64%
[ Tue Jan 31 07:23:00 2023 ] Training epoch: 48
[ Tue Jan 31 07:32:10 2023 ] 	Mean training loss: 0.1222.  Mean training acc: 96.96%.
[ Tue Jan 31 07:32:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 07:32:19 2023 ] Eval epoch: 48
[ Tue Jan 31 07:40:22 2023 ] 	Mean test loss of 930 batches: 0.6075207215323243.
[ Tue Jan 31 07:40:25 2023 ] 	Top1: 83.78%
[ Tue Jan 31 07:40:25 2023 ] 	Top5: 96.30%
[ Tue Jan 31 07:40:28 2023 ] Training epoch: 49
[ Tue Jan 31 07:49:44 2023 ] 	Mean training loss: 0.1199.  Mean training acc: 96.91%.
[ Tue Jan 31 07:49:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 07:49:45 2023 ] Eval epoch: 49
[ Tue Jan 31 07:57:43 2023 ] 	Mean test loss of 930 batches: 0.5721060219431116.
[ Tue Jan 31 07:57:43 2023 ] 	Top1: 84.50%
[ Tue Jan 31 07:57:43 2023 ] 	Top5: 96.68%
[ Tue Jan 31 07:57:44 2023 ] Training epoch: 50
[ Tue Jan 31 08:06:56 2023 ] 	Mean training loss: 0.1218.  Mean training acc: 96.86%.
[ Tue Jan 31 08:06:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 08:06:57 2023 ] Eval epoch: 50
[ Tue Jan 31 08:15:00 2023 ] 	Mean test loss of 930 batches: 0.5988946586406679.
[ Tue Jan 31 08:15:01 2023 ] 	Top1: 84.01%
[ Tue Jan 31 08:15:01 2023 ] 	Top5: 96.40%
[ Tue Jan 31 08:15:04 2023 ] Training epoch: 51
[ Tue Jan 31 08:24:13 2023 ] 	Mean training loss: 0.1182.  Mean training acc: 97.02%.
[ Tue Jan 31 08:24:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 08:24:15 2023 ] Eval epoch: 51
[ Tue Jan 31 08:32:04 2023 ] 	Mean test loss of 930 batches: 0.5978526199617052.
[ Tue Jan 31 08:32:05 2023 ] 	Top1: 84.09%
[ Tue Jan 31 08:32:05 2023 ] 	Top5: 96.46%
[ Tue Jan 31 08:32:05 2023 ] Training epoch: 52
[ Tue Jan 31 08:41:02 2023 ] 	Mean training loss: 0.1160.  Mean training acc: 97.19%.
[ Tue Jan 31 08:41:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 08:41:02 2023 ] Eval epoch: 52
[ Tue Jan 31 08:48:50 2023 ] 	Mean test loss of 930 batches: 0.6214462077785884.
[ Tue Jan 31 08:48:50 2023 ] 	Top1: 83.69%
[ Tue Jan 31 08:48:51 2023 ] 	Top5: 96.19%
[ Tue Jan 31 08:48:51 2023 ] Training epoch: 53
[ Tue Jan 31 08:57:42 2023 ] 	Mean training loss: 0.1151.  Mean training acc: 97.18%.
[ Tue Jan 31 08:57:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 08:57:43 2023 ] Eval epoch: 53
[ Tue Jan 31 09:05:26 2023 ] 	Mean test loss of 930 batches: 0.6165387295346747.
[ Tue Jan 31 09:05:27 2023 ] 	Top1: 83.66%
[ Tue Jan 31 09:05:27 2023 ] 	Top5: 96.30%
[ Tue Jan 31 09:05:27 2023 ] Training epoch: 54
[ Tue Jan 31 09:14:22 2023 ] 	Mean training loss: 0.1207.  Mean training acc: 96.96%.
[ Tue Jan 31 09:14:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 09:14:25 2023 ] Eval epoch: 54
[ Tue Jan 31 09:22:18 2023 ] 	Mean test loss of 930 batches: 0.6178200309395149.
[ Tue Jan 31 09:22:19 2023 ] 	Top1: 83.51%
[ Tue Jan 31 09:22:19 2023 ] 	Top5: 96.34%
[ Tue Jan 31 09:22:19 2023 ] Training epoch: 55
[ Tue Jan 31 09:31:19 2023 ] 	Mean training loss: 0.1193.  Mean training acc: 97.02%.
[ Tue Jan 31 09:31:20 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 31 09:31:20 2023 ] Eval epoch: 55
[ Tue Jan 31 09:40:17 2023 ] 	Mean test loss of 930 batches: 0.590846536012106.
[ Tue Jan 31 09:40:18 2023 ] 	Top1: 84.19%
[ Tue Jan 31 09:40:19 2023 ] 	Top5: 96.53%
[ Tue Jan 31 09:40:19 2023 ] Training epoch: 56
[ Tue Jan 31 09:52:42 2023 ] 	Mean training loss: 0.0675.  Mean training acc: 98.70%.
[ Tue Jan 31 09:52:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 09:52:43 2023 ] Eval epoch: 56
[ Tue Jan 31 10:02:09 2023 ] 	Mean test loss of 930 batches: 0.5338540448656967.
[ Tue Jan 31 10:02:10 2023 ] 	Top1: 85.57%
[ Tue Jan 31 10:02:11 2023 ] 	Top5: 96.83%
[ Tue Jan 31 10:02:12 2023 ] Training epoch: 57
[ Tue Jan 31 10:14:26 2023 ] 	Mean training loss: 0.0490.  Mean training acc: 99.27%.
[ Tue Jan 31 10:14:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:14:26 2023 ] Eval epoch: 57
[ Tue Jan 31 10:23:56 2023 ] 	Mean test loss of 930 batches: 0.5328791620350012.
[ Tue Jan 31 10:23:57 2023 ] 	Top1: 85.82%
[ Tue Jan 31 10:23:57 2023 ] 	Top5: 96.81%
[ Tue Jan 31 10:23:59 2023 ] Training epoch: 58
[ Tue Jan 31 10:36:20 2023 ] 	Mean training loss: 0.0429.  Mean training acc: 99.38%.
[ Tue Jan 31 10:36:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:36:22 2023 ] Eval epoch: 58
[ Tue Jan 31 10:45:59 2023 ] 	Mean test loss of 930 batches: 0.5318808578876077.
[ Tue Jan 31 10:45:59 2023 ] 	Top1: 85.94%
[ Tue Jan 31 10:45:59 2023 ] 	Top5: 96.81%
[ Tue Jan 31 10:46:00 2023 ] Training epoch: 59
[ Tue Jan 31 10:58:10 2023 ] 	Mean training loss: 0.0403.  Mean training acc: 99.47%.
[ Tue Jan 31 10:58:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:58:11 2023 ] Eval epoch: 59
[ Tue Jan 31 11:08:00 2023 ] 	Mean test loss of 930 batches: 0.536503922174214.
[ Tue Jan 31 11:08:00 2023 ] 	Top1: 85.85%
[ Tue Jan 31 11:08:01 2023 ] 	Top5: 96.78%
[ Tue Jan 31 11:08:02 2023 ] Training epoch: 60
[ Tue Jan 31 11:19:59 2023 ] 	Mean training loss: 0.0370.  Mean training acc: 99.57%.
[ Tue Jan 31 11:19:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 11:19:59 2023 ] Eval epoch: 60
[ Tue Jan 31 11:28:58 2023 ] 	Mean test loss of 930 batches: 0.536063684298787.
[ Tue Jan 31 11:28:58 2023 ] 	Top1: 86.00%
[ Tue Jan 31 11:28:59 2023 ] 	Top5: 96.73%
[ Tue Jan 31 11:28:59 2023 ] Training epoch: 61
[ Tue Jan 31 11:40:53 2023 ] 	Mean training loss: 0.0351.  Mean training acc: 99.57%.
[ Tue Jan 31 11:40:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 11:40:53 2023 ] Eval epoch: 61
[ Tue Jan 31 11:49:42 2023 ] 	Mean test loss of 930 batches: 0.531895973970012.
[ Tue Jan 31 11:49:44 2023 ] 	Top1: 86.01%
[ Tue Jan 31 11:49:44 2023 ] 	Top5: 96.80%
[ Tue Jan 31 11:49:45 2023 ] Training epoch: 62
[ Tue Jan 31 12:01:32 2023 ] 	Mean training loss: 0.0325.  Mean training acc: 99.60%.
[ Tue Jan 31 12:01:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:01:33 2023 ] Eval epoch: 62
[ Tue Jan 31 12:10:19 2023 ] 	Mean test loss of 930 batches: 0.5321847559303365.
[ Tue Jan 31 12:10:20 2023 ] 	Top1: 86.08%
[ Tue Jan 31 12:10:20 2023 ] 	Top5: 96.81%
[ Tue Jan 31 12:10:21 2023 ] Training epoch: 63
[ Tue Jan 31 12:22:01 2023 ] 	Mean training loss: 0.0320.  Mean training acc: 99.65%.
[ Tue Jan 31 12:22:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:22:01 2023 ] Eval epoch: 63
[ Tue Jan 31 12:30:53 2023 ] 	Mean test loss of 930 batches: 0.5344671067491334.
[ Tue Jan 31 12:30:54 2023 ] 	Top1: 86.08%
[ Tue Jan 31 12:30:54 2023 ] 	Top5: 96.74%
[ Tue Jan 31 12:30:54 2023 ] Training epoch: 64
[ Tue Jan 31 12:42:43 2023 ] 	Mean training loss: 0.0308.  Mean training acc: 99.68%.
[ Tue Jan 31 12:42:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:42:43 2023 ] Eval epoch: 64
[ Tue Jan 31 12:51:46 2023 ] 	Mean test loss of 930 batches: 0.5344535630556845.
[ Tue Jan 31 12:51:46 2023 ] 	Top1: 86.06%
[ Tue Jan 31 12:51:47 2023 ] 	Top5: 96.71%
[ Tue Jan 31 12:51:47 2023 ] Training epoch: 65
[ Tue Jan 31 13:03:43 2023 ] 	Mean training loss: 0.0313.  Mean training acc: 99.65%.
[ Tue Jan 31 13:03:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 13:03:43 2023 ] Eval epoch: 65
[ Tue Jan 31 13:12:36 2023 ] 	Mean test loss of 930 batches: 0.5364241441571584.
[ Tue Jan 31 13:12:37 2023 ] 	Top1: 85.96%
[ Tue Jan 31 13:12:37 2023 ] 	Top5: 96.75%
[ Tue Jan 31 13:21:37 2023 ] Best accuracy: 0.860836962187064
[ Tue Jan 31 13:21:37 2023 ] Epoch number: 63
[ Tue Jan 31 13:21:37 2023 ] Model name: work_dir/cset/local_SHT_bone
[ Tue Jan 31 13:21:37 2023 ] Model total number of params: 2141090
[ Tue Jan 31 13:21:37 2023 ] Weight decay: 0.0004
[ Tue Jan 31 13:21:37 2023 ] Base LR: 0.1
[ Tue Jan 31 13:21:37 2023 ] Batch Size: 64
[ Tue Jan 31 13:21:37 2023 ] Test Batch Size: 64
[ Tue Jan 31 13:21:37 2023 ] seed: 1
