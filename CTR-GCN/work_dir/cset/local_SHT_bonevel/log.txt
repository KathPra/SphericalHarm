[ Sun Nov  6 22:49:09 2022 ] using warm up, epoch: 5
[ Sun Nov  6 22:53:05 2022 ] using warm up, epoch: 5
[ Sun Nov  6 22:54:07 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/cset/local_SHTg_bonevel', 'model_saved_name': 'work_dir/ntu120/cset/local_SHTg_bonevel/runs', 'config': 'config/nturgbd120-cross-set/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Sun Nov  6 22:54:07 2022 ] # Parameters: 2141090
[ Sun Nov  6 22:54:07 2022 ] Training epoch: 1
[ Sun Nov  6 23:34:07 2022 ] 	Mean training loss: 3.4740.  Mean training acc: 16.12%.
[ Sun Nov  6 23:34:07 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Sun Nov  6 23:34:07 2022 ] Eval epoch: 1
[ Mon Nov  7 00:14:01 2022 ] 	Mean test loss of 930 batches: 281.47955812843895.
[ Mon Nov  7 00:14:02 2022 ] 	Top1: 1.13%
[ Mon Nov  7 00:14:03 2022 ] 	Top5: 5.27%
[ Mon Nov  7 00:14:03 2022 ] Training epoch: 2
[ Mon Nov  7 00:53:03 2022 ] 	Mean training loss: 2.2489.  Mean training acc: 38.19%.
[ Mon Nov  7 00:53:03 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 00:53:03 2022 ] Eval epoch: 2
[ Mon Nov  7 01:32:55 2022 ] 	Mean test loss of 930 batches: 336.9069772699828.
[ Mon Nov  7 01:32:57 2022 ] 	Top1: 0.76%
[ Mon Nov  7 01:32:58 2022 ] 	Top5: 4.60%
[ Mon Nov  7 01:32:58 2022 ] Training epoch: 3
[ Mon Nov  7 02:11:20 2022 ] 	Mean training loss: 1.7691.  Mean training acc: 49.51%.
[ Mon Nov  7 02:11:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 02:11:20 2022 ] Eval epoch: 3
[ Mon Nov  7 02:50:34 2022 ] 	Mean test loss of 930 batches: 209.2247419377809.
[ Mon Nov  7 02:50:35 2022 ] 	Top1: 0.83%
[ Mon Nov  7 02:50:36 2022 ] 	Top5: 4.32%
[ Mon Nov  7 02:50:36 2022 ] Training epoch: 4
[ Mon Nov  7 03:29:03 2022 ] 	Mean training loss: 1.5617.  Mean training acc: 54.78%.
[ Mon Nov  7 03:29:03 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 03:29:03 2022 ] Eval epoch: 4
[ Mon Nov  7 04:04:29 2022 ] 	Mean test loss of 930 batches: 98.2704883165257.
[ Mon Nov  7 04:04:30 2022 ] 	Top1: 1.42%
[ Mon Nov  7 04:04:32 2022 ] 	Top5: 4.93%
[ Mon Nov  7 04:04:32 2022 ] Training epoch: 5
[ Mon Nov  7 04:39:39 2022 ] 	Mean training loss: 1.4425.  Mean training acc: 57.92%.
[ Mon Nov  7 04:39:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 04:39:39 2022 ] Eval epoch: 5
[ Mon Nov  7 05:14:54 2022 ] 	Mean test loss of 930 batches: 49.97279711282381.
[ Mon Nov  7 05:14:55 2022 ] 	Top1: 1.50%
[ Mon Nov  7 05:14:56 2022 ] 	Top5: 5.98%
[ Mon Nov  7 05:14:56 2022 ] Training epoch: 6
[ Mon Nov  7 05:50:09 2022 ] 	Mean training loss: 1.3039.  Mean training acc: 61.76%.
[ Mon Nov  7 05:50:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 05:50:09 2022 ] Eval epoch: 6
[ Mon Nov  7 06:26:15 2022 ] 	Mean test loss of 930 batches: 41.558196340581425.
[ Mon Nov  7 06:26:17 2022 ] 	Top1: 1.82%
[ Mon Nov  7 06:26:17 2022 ] 	Top5: 6.41%
[ Mon Nov  7 06:26:17 2022 ] Training epoch: 7
[ Mon Nov  7 07:05:00 2022 ] 	Mean training loss: 1.2301.  Mean training acc: 63.75%.
[ Mon Nov  7 07:05:01 2022 ] 	Time consumption: [Data]01%, [Network]89%
[ Mon Nov  7 07:05:01 2022 ] Eval epoch: 7
[ Mon Nov  7 07:40:39 2022 ] 	Mean test loss of 930 batches: 64.08215071155179.
[ Mon Nov  7 07:40:40 2022 ] 	Top1: 0.98%
[ Mon Nov  7 07:40:41 2022 ] 	Top5: 5.46%
[ Mon Nov  7 07:40:42 2022 ] Training epoch: 8
[ Mon Nov  7 08:16:00 2022 ] 	Mean training loss: 1.1820.  Mean training acc: 65.05%.
[ Mon Nov  7 08:16:00 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 08:16:00 2022 ] Eval epoch: 8
[ Mon Nov  7 08:52:32 2022 ] 	Mean test loss of 930 batches: 69.52866518984558.
[ Mon Nov  7 08:52:33 2022 ] 	Top1: 1.35%
[ Mon Nov  7 08:52:34 2022 ] 	Top5: 4.74%
[ Mon Nov  7 08:52:34 2022 ] Training epoch: 9
[ Mon Nov  7 09:29:48 2022 ] 	Mean training loss: 1.1446.  Mean training acc: 66.13%.
[ Mon Nov  7 09:29:48 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 09:29:48 2022 ] Eval epoch: 9
[ Mon Nov  7 10:05:56 2022 ] 	Mean test loss of 930 batches: 62.09169905877882.
[ Mon Nov  7 10:05:57 2022 ] 	Top1: 1.18%
[ Mon Nov  7 10:05:59 2022 ] 	Top5: 5.18%
[ Mon Nov  7 10:05:59 2022 ] Training epoch: 10
[ Mon Nov  7 10:22:44 2022 ] using warm up, epoch: 5
[ Mon Nov  7 10:26:00 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/cset/local_SHTg_bonevel', 'model_saved_name': 'work_dir/ntu120/cset/local_SHTg_bonevel/runs', 'config': 'config/nturgbd120-cross-set/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHTg.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Nov  7 10:26:00 2022 ] # Parameters: 2141090
[ Mon Nov  7 10:26:00 2022 ] Training epoch: 1
[ Mon Nov  7 11:03:29 2022 ] 	Mean training loss: 3.4749.  Mean training acc: 16.17%.
[ Mon Nov  7 11:03:29 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 11:03:29 2022 ] Eval epoch: 1
[ Mon Nov  7 11:43:09 2022 ] 	Mean test loss of 930 batches: 2.79748480268704.
[ Mon Nov  7 11:43:10 2022 ] 	Top1: 25.72%
[ Mon Nov  7 11:43:12 2022 ] 	Top5: 58.62%
[ Mon Nov  7 11:43:12 2022 ] Training epoch: 2
[ Mon Nov  7 12:20:17 2022 ] 	Mean training loss: 2.2599.  Mean training acc: 38.02%.
[ Mon Nov  7 12:20:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 12:20:17 2022 ] Eval epoch: 2
[ Mon Nov  7 12:59:14 2022 ] 	Mean test loss of 930 batches: 2.140271706991298.
[ Mon Nov  7 12:59:15 2022 ] 	Top1: 41.04%
[ Mon Nov  7 12:59:17 2022 ] 	Top5: 76.09%
[ Mon Nov  7 12:59:17 2022 ] Training epoch: 3
[ Mon Nov  7 13:37:24 2022 ] 	Mean training loss: 1.7706.  Mean training acc: 49.47%.
[ Mon Nov  7 13:37:24 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 13:37:24 2022 ] Eval epoch: 3
[ Mon Nov  7 14:16:44 2022 ] 	Mean test loss of 930 batches: 1.7221871726615454.
[ Mon Nov  7 14:16:45 2022 ] 	Top1: 50.11%
[ Mon Nov  7 14:16:47 2022 ] 	Top5: 83.59%
[ Mon Nov  7 14:16:47 2022 ] Training epoch: 4
[ Mon Nov  7 14:53:58 2022 ] 	Mean training loss: 1.5610.  Mean training acc: 54.68%.
[ Mon Nov  7 14:53:58 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 14:53:58 2022 ] Eval epoch: 4
[ Mon Nov  7 15:33:48 2022 ] 	Mean test loss of 930 batches: 1.7594569804206972.
[ Mon Nov  7 15:33:50 2022 ] 	Top1: 50.55%
[ Mon Nov  7 15:33:51 2022 ] 	Top5: 83.27%
[ Mon Nov  7 15:33:52 2022 ] Training epoch: 5
[ Mon Nov  7 16:11:10 2022 ] 	Mean training loss: 1.4398.  Mean training acc: 57.94%.
[ Mon Nov  7 16:11:10 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 16:11:10 2022 ] Eval epoch: 5
[ Mon Nov  7 16:49:50 2022 ] 	Mean test loss of 930 batches: 1.634679187433694.
[ Mon Nov  7 16:49:52 2022 ] 	Top1: 53.71%
[ Mon Nov  7 16:49:53 2022 ] 	Top5: 83.98%
[ Mon Nov  7 16:49:53 2022 ] Training epoch: 6
[ Mon Nov  7 17:30:10 2022 ] 	Mean training loss: 1.3036.  Mean training acc: 61.83%.
[ Mon Nov  7 17:30:10 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 17:30:10 2022 ] Eval epoch: 6
[ Mon Nov  7 18:13:08 2022 ] 	Mean test loss of 930 batches: 1.5915356880234133.
[ Mon Nov  7 18:13:09 2022 ] 	Top1: 55.68%
[ Mon Nov  7 18:13:11 2022 ] 	Top5: 85.41%
[ Mon Nov  7 18:13:11 2022 ] Training epoch: 7
[ Mon Nov  7 18:55:06 2022 ] 	Mean training loss: 1.2242.  Mean training acc: 63.97%.
[ Mon Nov  7 18:55:06 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 18:55:07 2022 ] Eval epoch: 7
[ Mon Nov  7 19:36:11 2022 ] 	Mean test loss of 930 batches: 1.5781734908780745.
[ Mon Nov  7 19:36:13 2022 ] 	Top1: 55.91%
[ Mon Nov  7 19:36:14 2022 ] 	Top5: 84.99%
[ Mon Nov  7 19:36:14 2022 ] Training epoch: 8
[ Mon Nov  7 20:18:36 2022 ] 	Mean training loss: 1.1806.  Mean training acc: 65.02%.
[ Mon Nov  7 20:18:36 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 20:18:36 2022 ] Eval epoch: 8
[ Mon Nov  7 21:02:58 2022 ] 	Mean test loss of 930 batches: 1.7198781274980115.
[ Mon Nov  7 21:02:59 2022 ] 	Top1: 52.52%
[ Mon Nov  7 21:03:01 2022 ] 	Top5: 83.68%
[ Mon Nov  7 21:03:01 2022 ] Training epoch: 9
[ Mon Nov  7 21:47:32 2022 ] 	Mean training loss: 1.1356.  Mean training acc: 66.34%.
[ Mon Nov  7 21:47:32 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 21:47:32 2022 ] Eval epoch: 9
[ Mon Nov  7 22:31:22 2022 ] 	Mean test loss of 930 batches: 1.5284006274195128.
[ Mon Nov  7 22:31:23 2022 ] 	Top1: 57.48%
[ Mon Nov  7 22:31:24 2022 ] 	Top5: 85.39%
[ Mon Nov  7 22:31:25 2022 ] Training epoch: 10
[ Mon Nov  7 23:14:20 2022 ] 	Mean training loss: 1.1075.  Mean training acc: 67.16%.
[ Mon Nov  7 23:14:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 23:14:21 2022 ] Eval epoch: 10
[ Mon Nov  7 23:56:39 2022 ] 	Mean test loss of 930 batches: 1.249564714136944.
[ Mon Nov  7 23:56:40 2022 ] 	Top1: 63.87%
[ Mon Nov  7 23:56:42 2022 ] 	Top5: 90.01%
[ Mon Nov  7 23:56:42 2022 ] Training epoch: 11
[ Tue Nov  8 00:39:05 2022 ] 	Mean training loss: 1.0766.  Mean training acc: 68.23%.
[ Tue Nov  8 00:39:05 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 00:39:05 2022 ] Eval epoch: 11
[ Tue Nov  8 01:22:27 2022 ] 	Mean test loss of 930 batches: 1.338358166845896.
[ Tue Nov  8 01:22:28 2022 ] 	Top1: 62.48%
[ Tue Nov  8 01:22:30 2022 ] 	Top5: 88.54%
[ Tue Nov  8 01:22:30 2022 ] Training epoch: 12
[ Tue Nov  8 02:05:44 2022 ] 	Mean training loss: 1.0448.  Mean training acc: 68.76%.
[ Tue Nov  8 02:05:44 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 02:05:44 2022 ] Eval epoch: 12
[ Tue Nov  8 02:49:20 2022 ] 	Mean test loss of 930 batches: 1.4551911518778853.
[ Tue Nov  8 02:49:21 2022 ] 	Top1: 58.77%
[ Tue Nov  8 02:49:23 2022 ] 	Top5: 86.64%
[ Tue Nov  8 02:49:23 2022 ] Training epoch: 13
[ Tue Nov  8 03:32:40 2022 ] 	Mean training loss: 1.0271.  Mean training acc: 69.60%.
[ Tue Nov  8 03:32:40 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 03:32:40 2022 ] Eval epoch: 13
[ Tue Nov  8 04:16:12 2022 ] 	Mean test loss of 930 batches: 1.6021369189985337.
[ Tue Nov  8 04:16:13 2022 ] 	Top1: 56.87%
[ Tue Nov  8 04:16:15 2022 ] 	Top5: 85.18%
[ Tue Nov  8 04:16:15 2022 ] Training epoch: 14
[ Tue Nov  8 04:59:14 2022 ] 	Mean training loss: 1.0018.  Mean training acc: 70.19%.
[ Tue Nov  8 04:59:14 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 04:59:14 2022 ] Eval epoch: 14
[ Tue Nov  8 05:42:32 2022 ] 	Mean test loss of 930 batches: 1.3012647985771137.
[ Tue Nov  8 05:42:33 2022 ] 	Top1: 62.64%
[ Tue Nov  8 05:42:35 2022 ] 	Top5: 89.48%
[ Tue Nov  8 05:42:35 2022 ] Training epoch: 15
[ Tue Nov  8 06:24:09 2022 ] 	Mean training loss: 0.9974.  Mean training acc: 70.29%.
[ Tue Nov  8 06:24:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 06:24:09 2022 ] Eval epoch: 15
[ Tue Nov  8 07:05:37 2022 ] 	Mean test loss of 930 batches: 1.4580185870329538.
[ Tue Nov  8 07:05:39 2022 ] 	Top1: 60.29%
[ Tue Nov  8 07:05:40 2022 ] 	Top5: 86.61%
[ Tue Nov  8 07:05:40 2022 ] Training epoch: 16
[ Tue Nov  8 07:45:52 2022 ] 	Mean training loss: 0.9787.  Mean training acc: 70.80%.
[ Tue Nov  8 07:45:52 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 07:45:53 2022 ] Eval epoch: 16
[ Tue Nov  8 08:27:34 2022 ] 	Mean test loss of 930 batches: 1.2535372711958424.
[ Tue Nov  8 08:27:36 2022 ] 	Top1: 64.55%
[ Tue Nov  8 08:27:37 2022 ] 	Top5: 89.42%
[ Tue Nov  8 08:27:38 2022 ] Training epoch: 17
[ Tue Nov  8 09:07:33 2022 ] 	Mean training loss: 0.9632.  Mean training acc: 71.37%.
[ Tue Nov  8 09:07:33 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 09:07:33 2022 ] Eval epoch: 17
[ Tue Nov  8 09:49:42 2022 ] 	Mean test loss of 930 batches: 1.4192758232675573.
[ Tue Nov  8 09:49:44 2022 ] 	Top1: 61.53%
[ Tue Nov  8 09:49:46 2022 ] 	Top5: 88.03%
[ Tue Nov  8 09:49:46 2022 ] Training epoch: 18
[ Tue Nov  8 10:30:37 2022 ] 	Mean training loss: 0.9504.  Mean training acc: 71.63%.
[ Tue Nov  8 10:30:37 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 10:30:37 2022 ] Eval epoch: 18
[ Tue Nov  8 11:12:30 2022 ] 	Mean test loss of 930 batches: 1.3094088932198862.
[ Tue Nov  8 11:12:32 2022 ] 	Top1: 63.45%
[ Tue Nov  8 11:12:34 2022 ] 	Top5: 88.55%
[ Tue Nov  8 11:12:34 2022 ] Training epoch: 19
[ Tue Nov  8 11:54:42 2022 ] 	Mean training loss: 0.9383.  Mean training acc: 71.81%.
[ Tue Nov  8 11:54:42 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 11:54:42 2022 ] Eval epoch: 19
[ Tue Nov  8 12:41:19 2022 ] 	Mean test loss of 930 batches: 1.3701378758235645.
[ Tue Nov  8 12:41:20 2022 ] 	Top1: 62.04%
[ Tue Nov  8 12:41:23 2022 ] 	Top5: 88.78%
[ Tue Nov  8 12:41:23 2022 ] Training epoch: 20
[ Tue Nov  8 13:27:40 2022 ] 	Mean training loss: 0.9349.  Mean training acc: 72.11%.
[ Tue Nov  8 13:27:40 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 13:27:40 2022 ] Eval epoch: 20
[ Tue Nov  8 14:13:43 2022 ] 	Mean test loss of 930 batches: 1.140653559116907.
[ Tue Nov  8 14:13:45 2022 ] 	Top1: 67.02%
[ Tue Nov  8 14:13:47 2022 ] 	Top5: 91.43%
[ Tue Nov  8 14:13:48 2022 ] Training epoch: 21
[ Tue Nov  8 14:55:55 2022 ] 	Mean training loss: 0.9215.  Mean training acc: 72.46%.
[ Tue Nov  8 14:55:55 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 14:55:55 2022 ] Eval epoch: 21
[ Tue Nov  8 15:37:11 2022 ] 	Mean test loss of 930 batches: 1.578872775711039.
[ Tue Nov  8 15:37:13 2022 ] 	Top1: 58.25%
[ Tue Nov  8 15:37:14 2022 ] 	Top5: 85.52%
[ Tue Nov  8 15:37:15 2022 ] Training epoch: 22
[ Tue Nov  8 16:16:51 2022 ] 	Mean training loss: 0.9210.  Mean training acc: 72.59%.
[ Tue Nov  8 16:16:51 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 16:16:51 2022 ] Eval epoch: 22
[ Tue Nov  8 16:57:28 2022 ] 	Mean test loss of 930 batches: 1.3766584029441238.
[ Tue Nov  8 16:57:30 2022 ] 	Top1: 61.11%
[ Tue Nov  8 16:57:31 2022 ] 	Top5: 88.81%
[ Tue Nov  8 16:57:31 2022 ] Training epoch: 23
[ Tue Nov  8 17:37:38 2022 ] 	Mean training loss: 0.9094.  Mean training acc: 72.70%.
[ Tue Nov  8 17:37:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 17:37:38 2022 ] Eval epoch: 23
[ Tue Nov  8 18:18:48 2022 ] 	Mean test loss of 930 batches: 1.2058862735186853.
[ Tue Nov  8 18:18:50 2022 ] 	Top1: 65.86%
[ Tue Nov  8 18:18:52 2022 ] 	Top5: 90.17%
[ Tue Nov  8 18:18:52 2022 ] Training epoch: 24
[ Tue Nov  8 18:58:27 2022 ] 	Mean training loss: 0.8939.  Mean training acc: 73.33%.
[ Tue Nov  8 18:58:27 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 18:58:27 2022 ] Eval epoch: 24
[ Tue Nov  8 19:38:23 2022 ] 	Mean test loss of 930 batches: 1.0944946823902029.
[ Tue Nov  8 19:38:24 2022 ] 	Top1: 68.31%
[ Tue Nov  8 19:38:26 2022 ] 	Top5: 91.30%
[ Tue Nov  8 19:38:26 2022 ] Training epoch: 25
[ Tue Nov  8 20:17:34 2022 ] 	Mean training loss: 0.8881.  Mean training acc: 73.51%.
[ Tue Nov  8 20:17:34 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 20:17:34 2022 ] Eval epoch: 25
[ Tue Nov  8 20:57:00 2022 ] 	Mean test loss of 930 batches: 1.1595597553958175.
[ Tue Nov  8 20:57:01 2022 ] 	Top1: 67.44%
[ Tue Nov  8 20:57:03 2022 ] 	Top5: 90.14%
[ Tue Nov  8 20:57:03 2022 ] Training epoch: 26
[ Tue Nov  8 21:35:27 2022 ] 	Mean training loss: 0.8987.  Mean training acc: 73.08%.
[ Tue Nov  8 21:35:27 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 21:35:27 2022 ] Eval epoch: 26
[ Tue Nov  8 22:17:17 2022 ] 	Mean test loss of 930 batches: 1.1970975532006192.
[ Tue Nov  8 22:17:18 2022 ] 	Top1: 65.95%
[ Tue Nov  8 22:17:20 2022 ] 	Top5: 90.59%
[ Tue Nov  8 22:17:21 2022 ] Training epoch: 27
[ Tue Nov  8 23:01:46 2022 ] 	Mean training loss: 0.8758.  Mean training acc: 73.81%.
[ Tue Nov  8 23:01:46 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 23:01:46 2022 ] Eval epoch: 27
[ Tue Nov  8 23:44:44 2022 ] 	Mean test loss of 930 batches: 1.1298524687046645.
[ Tue Nov  8 23:44:46 2022 ] 	Top1: 67.55%
[ Tue Nov  8 23:44:47 2022 ] 	Top5: 90.96%
[ Tue Nov  8 23:44:47 2022 ] Training epoch: 28
[ Wed Nov  9 00:23:41 2022 ] 	Mean training loss: 0.8771.  Mean training acc: 73.69%.
[ Wed Nov  9 00:23:41 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 00:23:41 2022 ] Eval epoch: 28
[ Wed Nov  9 01:02:50 2022 ] 	Mean test loss of 930 batches: 1.1604684358002038.
[ Wed Nov  9 01:02:51 2022 ] 	Top1: 67.29%
[ Wed Nov  9 01:02:52 2022 ] 	Top5: 90.63%
[ Wed Nov  9 01:02:53 2022 ] Training epoch: 29
[ Wed Nov  9 01:42:15 2022 ] 	Mean training loss: 0.8693.  Mean training acc: 73.96%.
[ Wed Nov  9 01:42:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 01:42:16 2022 ] Eval epoch: 29
[ Wed Nov  9 02:23:25 2022 ] 	Mean test loss of 930 batches: 1.1568558866939238.
[ Wed Nov  9 02:23:27 2022 ] 	Top1: 67.38%
[ Wed Nov  9 02:23:28 2022 ] 	Top5: 91.20%
[ Wed Nov  9 02:23:28 2022 ] Training epoch: 30
[ Wed Nov  9 03:03:17 2022 ] 	Mean training loss: 0.8607.  Mean training acc: 74.31%.
[ Wed Nov  9 03:03:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 03:03:17 2022 ] Eval epoch: 30
[ Wed Nov  9 03:43:43 2022 ] 	Mean test loss of 930 batches: 1.1766760006386747.
[ Wed Nov  9 03:43:44 2022 ] 	Top1: 66.65%
[ Wed Nov  9 03:43:45 2022 ] 	Top5: 90.55%
[ Wed Nov  9 03:43:45 2022 ] Training epoch: 31
[ Wed Nov  9 04:22:18 2022 ] 	Mean training loss: 0.8630.  Mean training acc: 73.99%.
[ Wed Nov  9 04:22:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 04:22:19 2022 ] Eval epoch: 31
[ Wed Nov  9 05:00:12 2022 ] 	Mean test loss of 930 batches: 1.2016765169238532.
[ Wed Nov  9 05:00:14 2022 ] 	Top1: 66.40%
[ Wed Nov  9 05:00:15 2022 ] 	Top5: 89.69%
[ Wed Nov  9 05:00:15 2022 ] Training epoch: 32
[ Wed Nov  9 05:36:38 2022 ] 	Mean training loss: 0.8639.  Mean training acc: 74.23%.
[ Wed Nov  9 05:36:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 05:36:38 2022 ] Eval epoch: 32
[ Wed Nov  9 06:12:58 2022 ] 	Mean test loss of 930 batches: 1.0987489207137016.
[ Wed Nov  9 06:12:59 2022 ] 	Top1: 68.98%
[ Wed Nov  9 06:13:00 2022 ] 	Top5: 91.27%
[ Wed Nov  9 06:13:00 2022 ] Training epoch: 33
[ Wed Nov  9 06:58:11 2022 ] 	Mean training loss: 0.8536.  Mean training acc: 74.27%.
[ Wed Nov  9 06:58:11 2022 ] 	Time consumption: [Data]01%, [Network]80%
[ Wed Nov  9 06:58:12 2022 ] Eval epoch: 33
[ Wed Nov  9 07:34:25 2022 ] 	Mean test loss of 930 batches: 1.6249112013847598.
[ Wed Nov  9 07:34:26 2022 ] 	Top1: 58.64%
[ Wed Nov  9 07:34:28 2022 ] 	Top5: 88.11%
[ Wed Nov  9 07:34:28 2022 ] Training epoch: 34
[ Wed Nov  9 08:09:38 2022 ] 	Mean training loss: 0.8496.  Mean training acc: 74.40%.
[ Wed Nov  9 08:09:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 08:09:38 2022 ] Eval epoch: 34
[ Wed Nov  9 08:45:52 2022 ] 	Mean test loss of 930 batches: 1.2327176699715277.
[ Wed Nov  9 08:45:54 2022 ] 	Top1: 65.17%
[ Wed Nov  9 08:45:55 2022 ] 	Top5: 90.73%
[ Wed Nov  9 08:45:55 2022 ] Training epoch: 35
[ Wed Nov  9 09:20:58 2022 ] 	Mean training loss: 0.8451.  Mean training acc: 74.69%.
[ Wed Nov  9 09:20:58 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 09:20:59 2022 ] Eval epoch: 35
[ Wed Nov  9 09:57:05 2022 ] 	Mean test loss of 930 batches: 1.1361823727366744.
[ Wed Nov  9 09:57:06 2022 ] 	Top1: 68.36%
[ Wed Nov  9 09:57:07 2022 ] 	Top5: 90.85%
[ Wed Nov  9 09:57:07 2022 ] Training epoch: 36
[ Wed Nov  9 10:33:12 2022 ] 	Mean training loss: 0.4890.  Mean training acc: 85.34%.
[ Wed Nov  9 10:33:12 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 10:33:12 2022 ] Eval epoch: 36
[ Wed Nov  9 11:12:08 2022 ] 	Mean test loss of 930 batches: 0.6696583115125215.
[ Wed Nov  9 11:12:10 2022 ] 	Top1: 80.24%
[ Wed Nov  9 11:12:12 2022 ] 	Top5: 95.59%
[ Wed Nov  9 11:12:12 2022 ] Training epoch: 37
[ Wed Nov  9 11:50:09 2022 ] 	Mean training loss: 0.3840.  Mean training acc: 88.47%.
[ Wed Nov  9 11:50:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 11:50:09 2022 ] Eval epoch: 37
[ Wed Nov  9 12:28:51 2022 ] 	Mean test loss of 930 batches: 0.6450700035338761.
[ Wed Nov  9 12:28:53 2022 ] 	Top1: 81.22%
[ Wed Nov  9 12:28:54 2022 ] 	Top5: 95.83%
[ Wed Nov  9 12:28:54 2022 ] Training epoch: 38
[ Wed Nov  9 13:06:34 2022 ] 	Mean training loss: 0.3423.  Mean training acc: 89.92%.
[ Wed Nov  9 13:06:34 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 13:06:34 2022 ] Eval epoch: 38
[ Wed Nov  9 13:45:05 2022 ] 	Mean test loss of 930 batches: 0.6495304542203103.
[ Wed Nov  9 13:45:06 2022 ] 	Top1: 81.23%
[ Wed Nov  9 13:45:07 2022 ] 	Top5: 95.75%
[ Wed Nov  9 13:45:07 2022 ] Training epoch: 39
[ Wed Nov  9 14:22:46 2022 ] 	Mean training loss: 0.3086.  Mean training acc: 90.99%.
[ Wed Nov  9 14:22:46 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 14:22:46 2022 ] Eval epoch: 39
[ Wed Nov  9 15:01:24 2022 ] 	Mean test loss of 930 batches: 0.6460428452860284.
[ Wed Nov  9 15:01:25 2022 ] 	Top1: 81.24%
[ Wed Nov  9 15:01:26 2022 ] 	Top5: 95.83%
[ Wed Nov  9 15:01:27 2022 ] Training epoch: 40
[ Tue Jan  3 17:23:49 2023 ] Load weights from work_dir/cset/local_SHTg_bonevel/runs-39-33189.pt.
[ Tue Jan  3 17:23:53 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:24:44 2023 ] Load weights from work_dir/cset/local_SHTg_bonevel/runs-39-33189.pt.
[ Tue Jan  3 17:24:48 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:25:05 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHTg_bonevel', 'model_saved_name': 'work_dir/cset/local_SHTg_bonevel/runs', 'config': 'work_dir/cset/local_SHTg_bonevel/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': True, 'window_size': 64}, 'test_feeder_args': {'bone': True, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': True, 'window_size': 64}, 'model': 'model.local_SHTg.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/cset/local_SHTg_bonevel/runs-39-33189.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 39, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 17:25:05 2023 ] # Parameters: 2141090
[ Tue Jan  3 17:25:05 2023 ] Training epoch: 40
[ Tue Jan  3 17:47:34 2023 ] 	Mean training loss: 0.2800.  Mean training acc: 91.98%.
[ Tue Jan  3 17:47:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 17:47:34 2023 ] Eval epoch: 40
[ Tue Jan  3 18:11:11 2023 ] 	Mean test loss of 930 batches: 0.6576024626852364.
[ Tue Jan  3 18:11:12 2023 ] 	Top1: 81.11%
[ Tue Jan  3 18:11:13 2023 ] 	Top5: 95.74%
[ Tue Jan  3 18:11:13 2023 ] Training epoch: 41
[ Tue Jan  3 18:37:15 2023 ] 	Mean training loss: 0.2575.  Mean training acc: 92.75%.
[ Tue Jan  3 18:37:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 18:37:15 2023 ] Eval epoch: 41
[ Tue Jan  3 19:01:53 2023 ] 	Mean test loss of 930 batches: 0.6640987902078578.
[ Tue Jan  3 19:01:54 2023 ] 	Top1: 81.19%
[ Tue Jan  3 19:01:55 2023 ] 	Top5: 95.76%
[ Tue Jan  3 19:01:55 2023 ] Training epoch: 42
[ Tue Jan  3 19:28:17 2023 ] 	Mean training loss: 0.2410.  Mean training acc: 93.23%.
[ Tue Jan  3 19:28:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 19:28:17 2023 ] Eval epoch: 42
[ Tue Jan  3 19:53:17 2023 ] 	Mean test loss of 930 batches: 0.6831150946998468.
[ Tue Jan  3 19:53:18 2023 ] 	Top1: 80.83%
[ Tue Jan  3 19:53:19 2023 ] 	Top5: 95.63%
[ Tue Jan  3 19:53:19 2023 ] Training epoch: 43
[ Tue Jan  3 20:19:29 2023 ] 	Mean training loss: 0.2237.  Mean training acc: 93.75%.
[ Tue Jan  3 20:19:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 20:19:29 2023 ] Eval epoch: 43
[ Tue Jan  3 20:44:39 2023 ] 	Mean test loss of 930 batches: 0.6867359296288541.
[ Tue Jan  3 20:44:40 2023 ] 	Top1: 80.78%
[ Tue Jan  3 20:44:41 2023 ] 	Top5: 95.64%
[ Tue Jan  3 20:44:41 2023 ] Training epoch: 44
[ Tue Jan  3 21:10:18 2023 ] 	Mean training loss: 0.2082.  Mean training acc: 94.24%.
[ Tue Jan  3 21:10:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 21:10:19 2023 ] Eval epoch: 44
[ Tue Jan  3 21:35:01 2023 ] 	Mean test loss of 930 batches: 0.7055619904270736.
[ Tue Jan  3 21:35:02 2023 ] 	Top1: 80.71%
[ Tue Jan  3 21:35:03 2023 ] 	Top5: 95.35%
[ Tue Jan  3 21:35:03 2023 ] Training epoch: 45
[ Tue Jan  3 22:01:40 2023 ] 	Mean training loss: 0.1961.  Mean training acc: 94.63%.
[ Tue Jan  3 22:01:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 22:01:40 2023 ] Eval epoch: 45
[ Tue Jan  3 22:25:36 2023 ] 	Mean test loss of 930 batches: 0.7305163025215108.
[ Tue Jan  3 22:25:36 2023 ] 	Top1: 80.15%
[ Tue Jan  3 22:25:37 2023 ] 	Top5: 95.08%
[ Tue Jan  3 22:25:37 2023 ] Training epoch: 46
[ Tue Jan  3 22:52:53 2023 ] 	Mean training loss: 0.1905.  Mean training acc: 94.84%.
[ Tue Jan  3 22:52:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 22:52:53 2023 ] Eval epoch: 46
[ Tue Jan  3 23:19:13 2023 ] 	Mean test loss of 930 batches: 0.7216637609386316.
[ Tue Jan  3 23:19:14 2023 ] 	Top1: 80.27%
[ Tue Jan  3 23:19:15 2023 ] 	Top5: 95.33%
[ Tue Jan  3 23:19:15 2023 ] Training epoch: 47
[ Tue Jan  3 23:46:12 2023 ] 	Mean training loss: 0.1757.  Mean training acc: 95.44%.
[ Tue Jan  3 23:46:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 23:46:13 2023 ] Eval epoch: 47
[ Wed Jan  4 00:09:28 2023 ] 	Mean test loss of 930 batches: 0.7391894293248013.
[ Wed Jan  4 00:09:29 2023 ] 	Top1: 79.82%
[ Wed Jan  4 00:09:30 2023 ] 	Top5: 95.32%
[ Wed Jan  4 00:09:30 2023 ] Training epoch: 48
[ Wed Jan  4 00:32:43 2023 ] 	Mean training loss: 0.1734.  Mean training acc: 95.42%.
[ Wed Jan  4 00:32:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 00:32:43 2023 ] Eval epoch: 48
[ Wed Jan  4 00:56:05 2023 ] 	Mean test loss of 930 batches: 0.7458323850106168.
[ Wed Jan  4 00:56:06 2023 ] 	Top1: 79.53%
[ Wed Jan  4 00:56:07 2023 ] 	Top5: 95.13%
[ Wed Jan  4 00:56:07 2023 ] Training epoch: 49
[ Wed Jan  4 01:19:01 2023 ] 	Mean training loss: 0.1741.  Mean training acc: 95.37%.
[ Wed Jan  4 01:19:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 01:19:01 2023 ] Eval epoch: 49
[ Wed Jan  4 01:42:42 2023 ] 	Mean test loss of 930 batches: 0.7548170295934523.
[ Wed Jan  4 01:42:43 2023 ] 	Top1: 79.77%
[ Wed Jan  4 01:42:44 2023 ] 	Top5: 95.19%
[ Wed Jan  4 01:42:44 2023 ] Training epoch: 50
[ Wed Jan  4 02:05:33 2023 ] 	Mean training loss: 0.1704.  Mean training acc: 95.51%.
[ Wed Jan  4 02:05:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 02:05:33 2023 ] Eval epoch: 50
[ Wed Jan  4 02:29:09 2023 ] 	Mean test loss of 930 batches: 0.7868023270721076.
[ Wed Jan  4 02:29:10 2023 ] 	Top1: 79.09%
[ Wed Jan  4 02:29:10 2023 ] 	Top5: 94.75%
[ Wed Jan  4 02:29:11 2023 ] Training epoch: 51
[ Wed Jan  4 02:51:21 2023 ] 	Mean training loss: 0.1655.  Mean training acc: 95.74%.
[ Wed Jan  4 02:51:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 02:51:21 2023 ] Eval epoch: 51
[ Wed Jan  4 03:10:23 2023 ] 	Mean test loss of 930 batches: 0.7680610777549847.
[ Wed Jan  4 03:10:24 2023 ] 	Top1: 79.45%
[ Wed Jan  4 03:10:25 2023 ] 	Top5: 95.01%
[ Wed Jan  4 03:10:25 2023 ] Training epoch: 52
[ Wed Jan  4 03:30:19 2023 ] 	Mean training loss: 0.1685.  Mean training acc: 95.60%.
[ Wed Jan  4 03:30:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 03:30:19 2023 ] Eval epoch: 52
[ Wed Jan  4 03:49:08 2023 ] 	Mean test loss of 930 batches: 0.7548797362994764.
[ Wed Jan  4 03:49:08 2023 ] 	Top1: 80.00%
[ Wed Jan  4 03:49:09 2023 ] 	Top5: 95.09%
[ Wed Jan  4 03:49:09 2023 ] Training epoch: 53
[ Wed Jan  4 04:08:56 2023 ] 	Mean training loss: 0.1678.  Mean training acc: 95.44%.
[ Wed Jan  4 04:08:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 04:08:56 2023 ] Eval epoch: 53
[ Wed Jan  4 04:27:50 2023 ] 	Mean test loss of 930 batches: 0.7907784530552485.
[ Wed Jan  4 04:27:51 2023 ] 	Top1: 78.71%
[ Wed Jan  4 04:27:51 2023 ] 	Top5: 94.55%
[ Wed Jan  4 04:27:51 2023 ] Training epoch: 54
[ Wed Jan  4 04:47:42 2023 ] 	Mean training loss: 0.1682.  Mean training acc: 95.52%.
[ Wed Jan  4 04:47:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 04:47:42 2023 ] Eval epoch: 54
[ Wed Jan  4 05:06:53 2023 ] 	Mean test loss of 930 batches: 0.7877417621673435.
[ Wed Jan  4 05:06:55 2023 ] 	Top1: 79.37%
[ Wed Jan  4 05:06:55 2023 ] 	Top5: 94.96%
[ Wed Jan  4 05:06:55 2023 ] Training epoch: 55
[ Wed Jan  4 05:26:06 2023 ] 	Mean training loss: 0.1627.  Mean training acc: 95.70%.
[ Wed Jan  4 05:26:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 05:26:07 2023 ] Eval epoch: 55
[ Wed Jan  4 05:46:36 2023 ] 	Mean test loss of 930 batches: 0.8396780039033582.
[ Wed Jan  4 05:46:37 2023 ] 	Top1: 78.21%
[ Wed Jan  4 05:46:38 2023 ] 	Top5: 94.40%
[ Wed Jan  4 05:46:38 2023 ] Training epoch: 56
[ Wed Jan  4 06:07:52 2023 ] 	Mean training loss: 0.0962.  Mean training acc: 97.92%.
[ Wed Jan  4 06:07:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 06:07:52 2023 ] Eval epoch: 56
[ Wed Jan  4 06:26:15 2023 ] 	Mean test loss of 930 batches: 0.7111038567237956.
[ Wed Jan  4 06:26:16 2023 ] 	Top1: 81.25%
[ Wed Jan  4 06:26:16 2023 ] 	Top5: 95.51%
[ Wed Jan  4 06:26:16 2023 ] Training epoch: 57
[ Wed Jan  4 06:44:18 2023 ] 	Mean training loss: 0.0717.  Mean training acc: 98.68%.
[ Wed Jan  4 06:44:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 06:44:18 2023 ] Eval epoch: 57
[ Wed Jan  4 07:00:24 2023 ] 	Mean test loss of 930 batches: 0.7138366071767704.
[ Wed Jan  4 07:00:25 2023 ] 	Top1: 81.23%
[ Wed Jan  4 07:00:26 2023 ] 	Top5: 95.52%
[ Wed Jan  4 07:00:26 2023 ] Training epoch: 58
[ Wed Jan  4 07:14:18 2023 ] 	Mean training loss: 0.0633.  Mean training acc: 98.87%.
[ Wed Jan  4 07:14:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 07:14:18 2023 ] Eval epoch: 58
[ Wed Jan  4 07:24:44 2023 ] 	Mean test loss of 930 batches: 0.7143867907424768.
[ Wed Jan  4 07:24:44 2023 ] 	Top1: 81.32%
[ Wed Jan  4 07:24:45 2023 ] 	Top5: 95.46%
[ Wed Jan  4 07:24:45 2023 ] Training epoch: 59
[ Wed Jan  4 07:36:24 2023 ] 	Mean training loss: 0.0594.  Mean training acc: 98.99%.
[ Wed Jan  4 07:36:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 07:36:24 2023 ] Eval epoch: 59
[ Wed Jan  4 07:46:49 2023 ] 	Mean test loss of 930 batches: 0.7114246120055516.
[ Wed Jan  4 07:46:49 2023 ] 	Top1: 81.49%
[ Wed Jan  4 07:46:50 2023 ] 	Top5: 95.50%
[ Wed Jan  4 07:46:50 2023 ] Training epoch: 60
[ Wed Jan  4 07:58:23 2023 ] 	Mean training loss: 0.0573.  Mean training acc: 99.02%.
[ Wed Jan  4 07:58:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 07:58:23 2023 ] Eval epoch: 60
[ Wed Jan  4 08:08:44 2023 ] 	Mean test loss of 930 batches: 0.7165636623178118.
[ Wed Jan  4 08:08:44 2023 ] 	Top1: 81.30%
[ Wed Jan  4 08:08:45 2023 ] 	Top5: 95.44%
[ Wed Jan  4 08:08:45 2023 ] Training epoch: 61
[ Wed Jan  4 08:20:13 2023 ] 	Mean training loss: 0.0522.  Mean training acc: 99.11%.
[ Wed Jan  4 08:20:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 08:20:13 2023 ] Eval epoch: 61
[ Wed Jan  4 08:31:55 2023 ] 	Mean test loss of 930 batches: 0.7163252607789091.
[ Wed Jan  4 08:31:56 2023 ] 	Top1: 81.45%
[ Wed Jan  4 08:31:56 2023 ] 	Top5: 95.45%
[ Wed Jan  4 08:31:57 2023 ] Training epoch: 62
[ Wed Jan  4 08:44:44 2023 ] 	Mean training loss: 0.0507.  Mean training acc: 99.19%.
[ Wed Jan  4 08:44:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 08:44:44 2023 ] Eval epoch: 62
[ Wed Jan  4 08:56:30 2023 ] 	Mean test loss of 930 batches: 0.7130824731082045.
[ Wed Jan  4 08:56:30 2023 ] 	Top1: 81.56%
[ Wed Jan  4 08:56:31 2023 ] 	Top5: 95.47%
[ Wed Jan  4 08:56:31 2023 ] Training epoch: 63
[ Wed Jan  4 09:08:04 2023 ] 	Mean training loss: 0.0467.  Mean training acc: 99.30%.
[ Wed Jan  4 09:08:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 09:08:04 2023 ] Eval epoch: 63
[ Wed Jan  4 09:19:18 2023 ] 	Mean test loss of 930 batches: 0.7098398013060452.
[ Wed Jan  4 09:19:19 2023 ] 	Top1: 81.65%
[ Wed Jan  4 09:19:19 2023 ] 	Top5: 95.44%
[ Wed Jan  4 09:19:19 2023 ] Training epoch: 64
[ Wed Jan  4 09:30:47 2023 ] 	Mean training loss: 0.0461.  Mean training acc: 99.28%.
[ Wed Jan  4 09:30:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 09:30:47 2023 ] Eval epoch: 64
[ Wed Jan  4 09:41:54 2023 ] 	Mean test loss of 930 batches: 0.7185189977047904.
[ Wed Jan  4 09:41:55 2023 ] 	Top1: 81.38%
[ Wed Jan  4 09:41:55 2023 ] 	Top5: 95.42%
[ Wed Jan  4 09:41:55 2023 ] Training epoch: 65
[ Wed Jan  4 09:53:35 2023 ] 	Mean training loss: 0.0461.  Mean training acc: 99.27%.
[ Wed Jan  4 09:53:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 09:53:35 2023 ] Eval epoch: 65
[ Wed Jan  4 10:04:20 2023 ] 	Mean test loss of 930 batches: 0.7178353473624235.
[ Wed Jan  4 10:04:20 2023 ] 	Top1: 81.49%
[ Wed Jan  4 10:04:21 2023 ] 	Top5: 95.41%
[ Wed Jan  4 10:15:36 2023 ] Best accuracy: 0.8165173092119643
[ Wed Jan  4 10:15:36 2023 ] Epoch number: 63
[ Wed Jan  4 10:15:36 2023 ] Model name: work_dir/cset/local_SHTg_bonevel
[ Wed Jan  4 10:15:36 2023 ] Model total number of params: 2141090
[ Wed Jan  4 10:15:36 2023 ] Weight decay: 0.0004
[ Wed Jan  4 10:15:36 2023 ] Base LR: 0.1
[ Wed Jan  4 10:15:36 2023 ] Batch Size: 64
[ Wed Jan  4 10:15:36 2023 ] Test Batch Size: 64
[ Wed Jan  4 10:15:36 2023 ] seed: 1
[ Fri Jan 13 18:12:50 2023 ] Load weights from work_dir/cset/local_SHT_bonevel/runs-39-33189.pt.
[ Fri Jan 13 18:12:53 2023 ] using warm up, epoch: 0
[ Fri Jan 13 18:13:06 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHT_bonevel', 'model_saved_name': 'work_dir/cset/local_SHT_bonevel/runs', 'config': 'config/nturgbd120-cross-set/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/cset/local_SHT_bonevel/runs-39-33189.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 39, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Fri Jan 13 18:13:06 2023 ] # Parameters: 2141090
[ Fri Jan 13 18:13:06 2023 ] Training epoch: 40
[ Fri Jan 13 18:24:46 2023 ] 	Mean training loss: 0.2801.  Mean training acc: 91.97%.
[ Fri Jan 13 18:24:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 18:24:46 2023 ] Eval epoch: 40
[ Fri Jan 13 18:36:38 2023 ] 	Mean test loss of 930 batches: 0.6573267500246724.
[ Fri Jan 13 18:36:38 2023 ] 	Top1: 81.08%
[ Fri Jan 13 18:36:39 2023 ] 	Top5: 95.76%
[ Fri Jan 13 18:36:39 2023 ] Training epoch: 41
[ Fri Jan 13 18:50:41 2023 ] 	Mean training loss: 0.2573.  Mean training acc: 92.75%.
[ Fri Jan 13 18:50:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 18:50:41 2023 ] Eval epoch: 41
[ Fri Jan 13 19:03:11 2023 ] 	Mean test loss of 930 batches: 0.6648955980295777.
[ Fri Jan 13 19:03:11 2023 ] 	Top1: 81.13%
[ Fri Jan 13 19:03:12 2023 ] 	Top5: 95.75%
[ Fri Jan 13 19:03:12 2023 ] Training epoch: 42
[ Fri Jan 13 19:15:35 2023 ] 	Mean training loss: 0.2408.  Mean training acc: 93.22%.
[ Fri Jan 13 19:15:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 19:15:35 2023 ] Eval epoch: 42
[ Fri Jan 13 19:27:46 2023 ] 	Mean test loss of 930 batches: 0.6851922228932381.
[ Fri Jan 13 19:27:46 2023 ] 	Top1: 80.85%
[ Fri Jan 13 19:27:47 2023 ] 	Top5: 95.61%
[ Fri Jan 13 19:27:47 2023 ] Training epoch: 43
[ Fri Jan 13 19:40:24 2023 ] 	Mean training loss: 0.2243.  Mean training acc: 93.71%.
[ Fri Jan 13 19:40:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 19:40:24 2023 ] Eval epoch: 43
[ Fri Jan 13 19:52:19 2023 ] 	Mean test loss of 930 batches: 0.6893743687659822.
[ Fri Jan 13 19:52:19 2023 ] 	Top1: 80.69%
[ Fri Jan 13 19:52:20 2023 ] 	Top5: 95.54%
[ Fri Jan 13 19:52:20 2023 ] Training epoch: 44
[ Fri Jan 13 20:05:20 2023 ] 	Mean training loss: 0.2087.  Mean training acc: 94.25%.
[ Fri Jan 13 20:05:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 20:05:20 2023 ] Eval epoch: 44
[ Fri Jan 13 20:17:00 2023 ] 	Mean test loss of 930 batches: 0.7066354699512963.
[ Fri Jan 13 20:17:01 2023 ] 	Top1: 80.71%
[ Fri Jan 13 20:17:01 2023 ] 	Top5: 95.31%
[ Fri Jan 13 20:17:02 2023 ] Training epoch: 45
[ Fri Jan 13 20:29:42 2023 ] 	Mean training loss: 0.1956.  Mean training acc: 94.74%.
[ Fri Jan 13 20:29:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 20:29:42 2023 ] Eval epoch: 45
[ Fri Jan 13 20:41:14 2023 ] 	Mean test loss of 930 batches: 0.7254080715759467.
[ Fri Jan 13 20:41:14 2023 ] 	Top1: 80.23%
[ Fri Jan 13 20:41:15 2023 ] 	Top5: 95.23%
[ Fri Jan 13 20:41:15 2023 ] Training epoch: 46
[ Fri Jan 13 20:53:38 2023 ] 	Mean training loss: 0.1900.  Mean training acc: 94.87%.
[ Fri Jan 13 20:53:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 20:53:39 2023 ] Eval epoch: 46
[ Fri Jan 13 21:05:09 2023 ] 	Mean test loss of 930 batches: 0.7266467939381317.
[ Fri Jan 13 21:05:10 2023 ] 	Top1: 80.14%
[ Fri Jan 13 21:05:10 2023 ] 	Top5: 95.32%
[ Fri Jan 13 21:05:10 2023 ] Training epoch: 47
[ Fri Jan 13 21:17:39 2023 ] 	Mean training loss: 0.1761.  Mean training acc: 95.30%.
[ Fri Jan 13 21:17:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 21:17:39 2023 ] Eval epoch: 47
[ Fri Jan 13 21:29:14 2023 ] 	Mean test loss of 930 batches: 0.7498881527172622.
[ Fri Jan 13 21:29:14 2023 ] 	Top1: 79.66%
[ Fri Jan 13 21:29:15 2023 ] 	Top5: 95.25%
[ Fri Jan 13 21:29:15 2023 ] Training epoch: 48
[ Fri Jan 13 21:41:55 2023 ] 	Mean training loss: 0.1755.  Mean training acc: 95.37%.
[ Fri Jan 13 21:41:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 21:41:55 2023 ] Eval epoch: 48
[ Fri Jan 13 21:53:38 2023 ] 	Mean test loss of 930 batches: 0.7506802440490774.
[ Fri Jan 13 21:53:39 2023 ] 	Top1: 79.58%
[ Fri Jan 13 21:53:39 2023 ] 	Top5: 95.09%
[ Fri Jan 13 21:53:39 2023 ] Training epoch: 49
[ Fri Jan 13 22:06:32 2023 ] 	Mean training loss: 0.1727.  Mean training acc: 95.42%.
[ Fri Jan 13 22:06:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 22:06:32 2023 ] Eval epoch: 49
[ Fri Jan 13 22:18:41 2023 ] 	Mean test loss of 930 batches: 0.7674285309609546.
[ Fri Jan 13 22:18:42 2023 ] 	Top1: 79.47%
[ Fri Jan 13 22:18:42 2023 ] 	Top5: 95.14%
[ Fri Jan 13 22:18:42 2023 ] Training epoch: 50
[ Fri Jan 13 22:31:12 2023 ] 	Mean training loss: 0.1677.  Mean training acc: 95.64%.
[ Fri Jan 13 22:31:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 22:31:12 2023 ] Eval epoch: 50
[ Fri Jan 13 22:43:29 2023 ] 	Mean test loss of 930 batches: 0.7825772403388895.
[ Fri Jan 13 22:43:30 2023 ] 	Top1: 79.11%
[ Fri Jan 13 22:43:30 2023 ] 	Top5: 94.82%
[ Fri Jan 13 22:43:31 2023 ] Training epoch: 51
[ Fri Jan 13 22:55:41 2023 ] 	Mean training loss: 0.1634.  Mean training acc: 95.77%.
[ Fri Jan 13 22:55:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 22:55:41 2023 ] Eval epoch: 51
[ Fri Jan 13 23:08:05 2023 ] 	Mean test loss of 930 batches: 0.7778292097872304.
[ Fri Jan 13 23:08:05 2023 ] 	Top1: 79.21%
[ Fri Jan 13 23:08:06 2023 ] 	Top5: 94.92%
[ Fri Jan 13 23:08:06 2023 ] Training epoch: 52
[ Fri Jan 13 23:20:24 2023 ] 	Mean training loss: 0.1673.  Mean training acc: 95.55%.
[ Fri Jan 13 23:20:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 23:20:24 2023 ] Eval epoch: 52
[ Fri Jan 13 23:32:11 2023 ] 	Mean test loss of 930 batches: 0.7812467374468363.
[ Fri Jan 13 23:32:12 2023 ] 	Top1: 79.40%
[ Fri Jan 13 23:32:12 2023 ] 	Top5: 95.00%
[ Fri Jan 13 23:32:12 2023 ] Training epoch: 53
[ Fri Jan 13 23:44:57 2023 ] 	Mean training loss: 0.1661.  Mean training acc: 95.64%.
[ Fri Jan 13 23:44:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Fri Jan 13 23:44:57 2023 ] Eval epoch: 53
[ Fri Jan 13 23:56:27 2023 ] 	Mean test loss of 930 batches: 0.7880455414774598.
[ Fri Jan 13 23:56:27 2023 ] 	Top1: 79.20%
[ Fri Jan 13 23:56:28 2023 ] 	Top5: 94.67%
[ Fri Jan 13 23:56:28 2023 ] Training epoch: 54
[ Sat Jan 14 00:09:01 2023 ] 	Mean training loss: 0.1696.  Mean training acc: 95.53%.
[ Sat Jan 14 00:09:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:09:01 2023 ] Eval epoch: 54
[ Sat Jan 14 00:20:20 2023 ] 	Mean test loss of 930 batches: 0.7937438406771229.
[ Sat Jan 14 00:20:20 2023 ] 	Top1: 79.04%
[ Sat Jan 14 00:20:21 2023 ] 	Top5: 94.86%
[ Sat Jan 14 00:20:21 2023 ] Training epoch: 55
[ Sat Jan 14 00:32:39 2023 ] 	Mean training loss: 0.1619.  Mean training acc: 95.82%.
[ Sat Jan 14 00:32:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:32:39 2023 ] Eval epoch: 55
[ Sat Jan 14 00:43:58 2023 ] 	Mean test loss of 930 batches: 0.843047523770922.
[ Sat Jan 14 00:43:58 2023 ] 	Top1: 78.17%
[ Sat Jan 14 00:43:59 2023 ] 	Top5: 94.50%
[ Sat Jan 14 00:43:59 2023 ] Training epoch: 56
[ Sat Jan 14 00:56:18 2023 ] 	Mean training loss: 0.0948.  Mean training acc: 97.94%.
[ Sat Jan 14 00:56:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 00:56:18 2023 ] Eval epoch: 56
[ Sat Jan 14 01:06:36 2023 ] 	Mean test loss of 930 batches: 0.710235913218029.
[ Sat Jan 14 01:06:37 2023 ] 	Top1: 81.35%
[ Sat Jan 14 01:06:37 2023 ] 	Top5: 95.48%
[ Sat Jan 14 01:06:37 2023 ] Training epoch: 57
[ Sat Jan 14 01:17:49 2023 ] 	Mean training loss: 0.0701.  Mean training acc: 98.70%.
[ Sat Jan 14 01:17:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 01:17:49 2023 ] Eval epoch: 57
[ Sat Jan 14 01:26:20 2023 ] 	Mean test loss of 930 batches: 0.7116360248016413.
[ Sat Jan 14 01:26:21 2023 ] 	Top1: 81.32%
[ Sat Jan 14 01:26:21 2023 ] 	Top5: 95.59%
[ Sat Jan 14 01:26:21 2023 ] Training epoch: 58
[ Sat Jan 14 01:35:28 2023 ] 	Mean training loss: 0.0627.  Mean training acc: 98.89%.
[ Sat Jan 14 01:35:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 01:35:28 2023 ] Eval epoch: 58
[ Sat Jan 14 01:43:17 2023 ] 	Mean test loss of 930 batches: 0.7108885261720868.
[ Sat Jan 14 01:43:18 2023 ] 	Top1: 81.31%
[ Sat Jan 14 01:43:18 2023 ] 	Top5: 95.54%
[ Sat Jan 14 01:43:18 2023 ] Training epoch: 59
[ Sat Jan 14 01:52:15 2023 ] 	Mean training loss: 0.0589.  Mean training acc: 99.01%.
[ Sat Jan 14 01:52:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 01:52:15 2023 ] Eval epoch: 59
[ Sat Jan 14 02:00:05 2023 ] 	Mean test loss of 930 batches: 0.7080554715487906.
[ Sat Jan 14 02:00:06 2023 ] 	Top1: 81.52%
[ Sat Jan 14 02:00:06 2023 ] 	Top5: 95.55%
[ Sat Jan 14 02:00:06 2023 ] Training epoch: 60
[ Sat Jan 14 02:09:08 2023 ] 	Mean training loss: 0.0557.  Mean training acc: 99.06%.
[ Sat Jan 14 02:09:08 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 02:09:08 2023 ] Eval epoch: 60
[ Sat Jan 14 02:16:49 2023 ] 	Mean test loss of 930 batches: 0.7108482667996038.
[ Sat Jan 14 02:16:50 2023 ] 	Top1: 81.46%
[ Sat Jan 14 02:16:50 2023 ] 	Top5: 95.47%
[ Sat Jan 14 02:16:50 2023 ] Training epoch: 61
[ Sat Jan 14 02:25:43 2023 ] 	Mean training loss: 0.0519.  Mean training acc: 99.14%.
[ Sat Jan 14 02:25:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 02:25:43 2023 ] Eval epoch: 61
[ Sat Jan 14 02:33:12 2023 ] 	Mean test loss of 930 batches: 0.7125925914734923.
[ Sat Jan 14 02:33:12 2023 ] 	Top1: 81.50%
[ Sat Jan 14 02:33:13 2023 ] 	Top5: 95.51%
[ Sat Jan 14 02:33:13 2023 ] Training epoch: 62
[ Sat Jan 14 02:41:54 2023 ] 	Mean training loss: 0.0505.  Mean training acc: 99.17%.
[ Sat Jan 14 02:41:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 02:41:54 2023 ] Eval epoch: 62
[ Sat Jan 14 02:49:27 2023 ] 	Mean test loss of 930 batches: 0.710564503065681.
[ Sat Jan 14 02:49:27 2023 ] 	Top1: 81.55%
[ Sat Jan 14 02:49:28 2023 ] 	Top5: 95.51%
[ Sat Jan 14 02:49:28 2023 ] Training epoch: 63
[ Sat Jan 14 02:58:14 2023 ] 	Mean training loss: 0.0467.  Mean training acc: 99.31%.
[ Sat Jan 14 02:58:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 02:58:14 2023 ] Eval epoch: 63
[ Sat Jan 14 03:05:48 2023 ] 	Mean test loss of 930 batches: 0.706645381066107.
[ Sat Jan 14 03:05:49 2023 ] 	Top1: 81.62%
[ Sat Jan 14 03:05:49 2023 ] 	Top5: 95.50%
[ Sat Jan 14 03:05:49 2023 ] Training epoch: 64
[ Sat Jan 14 03:14:24 2023 ] 	Mean training loss: 0.0467.  Mean training acc: 99.30%.
[ Sat Jan 14 03:14:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 03:14:24 2023 ] Eval epoch: 64
[ Sat Jan 14 03:21:45 2023 ] 	Mean test loss of 930 batches: 0.7124953595861312.
[ Sat Jan 14 03:21:46 2023 ] 	Top1: 81.52%
[ Sat Jan 14 03:21:46 2023 ] 	Top5: 95.46%
[ Sat Jan 14 03:21:46 2023 ] Training epoch: 65
[ Sat Jan 14 03:30:25 2023 ] 	Mean training loss: 0.0461.  Mean training acc: 99.31%.
[ Sat Jan 14 03:30:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sat Jan 14 03:30:25 2023 ] Eval epoch: 65
[ Sat Jan 14 03:37:56 2023 ] 	Mean test loss of 930 batches: 0.7146964247348488.
[ Sat Jan 14 03:37:56 2023 ] 	Top1: 81.46%
[ Sat Jan 14 03:37:56 2023 ] 	Top5: 95.43%
[ Tue Jan 31 09:31:31 2023 ] using warm up, epoch: 5
[ Tue Jan 31 09:31:48 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHT_bonevel', 'model_saved_name': 'work_dir/cset/local_SHT_bonevel/runs', 'config': 'config/nturgbd120-cross-set/bonevel.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan 31 09:31:48 2023 ] # Parameters: 2141090
[ Tue Jan 31 09:31:48 2023 ] Training epoch: 1
[ Tue Jan 31 09:42:03 2023 ] 	Mean training loss: 3.4794.  Mean training acc: 16.13%.
[ Tue Jan 31 09:42:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 09:42:06 2023 ] Eval epoch: 1
[ Tue Jan 31 09:50:43 2023 ] 	Mean test loss of 930 batches: 2.821671547940982.
[ Tue Jan 31 09:50:47 2023 ] 	Top1: 25.56%
[ Tue Jan 31 09:50:47 2023 ] 	Top5: 57.73%
[ Tue Jan 31 09:50:47 2023 ] Training epoch: 2
[ Tue Jan 31 10:00:57 2023 ] 	Mean training loss: 2.2608.  Mean training acc: 37.85%.
[ Tue Jan 31 10:00:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:01:02 2023 ] Eval epoch: 2
[ Tue Jan 31 10:09:56 2023 ] 	Mean test loss of 930 batches: 2.16890714950459.
[ Tue Jan 31 10:09:57 2023 ] 	Top1: 40.60%
[ Tue Jan 31 10:09:58 2023 ] 	Top5: 76.08%
[ Tue Jan 31 10:09:58 2023 ] Training epoch: 3
[ Tue Jan 31 10:20:20 2023 ] 	Mean training loss: 1.7726.  Mean training acc: 49.30%.
[ Tue Jan 31 10:20:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:20:21 2023 ] Eval epoch: 3
[ Tue Jan 31 10:29:21 2023 ] 	Mean test loss of 930 batches: 1.8763485751485312.
[ Tue Jan 31 10:29:24 2023 ] 	Top1: 47.00%
[ Tue Jan 31 10:29:25 2023 ] 	Top5: 80.38%
[ Tue Jan 31 10:29:25 2023 ] Training epoch: 4
[ Tue Jan 31 10:39:25 2023 ] 	Mean training loss: 1.5581.  Mean training acc: 54.82%.
[ Tue Jan 31 10:39:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 31 10:39:25 2023 ] Eval epoch: 4
[ Tue Jan 31 10:48:21 2023 ] 	Mean test loss of 930 batches: 1.776927492631379.
[ Tue Jan 31 10:48:22 2023 ] 	Top1: 50.76%
[ Tue Jan 31 10:48:22 2023 ] 	Top5: 82.55%
[ Tue Jan 31 10:48:22 2023 ] Training epoch: 5
[ Tue Jan 31 10:58:44 2023 ] 	Mean training loss: 1.4414.  Mean training acc: 57.90%.
[ Tue Jan 31 10:58:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 10:58:45 2023 ] Eval epoch: 5
[ Tue Jan 31 11:07:52 2023 ] 	Mean test loss of 930 batches: 1.5959497226181851.
[ Tue Jan 31 11:07:53 2023 ] 	Top1: 54.91%
[ Tue Jan 31 11:07:53 2023 ] 	Top5: 84.86%
[ Tue Jan 31 11:07:54 2023 ] Training epoch: 6
[ Tue Jan 31 11:18:10 2023 ] 	Mean training loss: 1.3052.  Mean training acc: 61.67%.
[ Tue Jan 31 11:18:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 11:18:10 2023 ] Eval epoch: 6
[ Tue Jan 31 11:26:22 2023 ] 	Mean test loss of 930 batches: 1.7039832021600456.
[ Tue Jan 31 11:26:22 2023 ] 	Top1: 52.94%
[ Tue Jan 31 11:26:23 2023 ] 	Top5: 83.92%
[ Tue Jan 31 11:26:23 2023 ] Training epoch: 7
[ Tue Jan 31 11:36:03 2023 ] 	Mean training loss: 1.2305.  Mean training acc: 63.80%.
[ Tue Jan 31 11:36:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 11:36:04 2023 ] Eval epoch: 7
[ Tue Jan 31 11:44:22 2023 ] 	Mean test loss of 930 batches: 1.530956607544294.
[ Tue Jan 31 11:44:22 2023 ] 	Top1: 57.04%
[ Tue Jan 31 11:44:23 2023 ] 	Top5: 86.01%
[ Tue Jan 31 11:44:24 2023 ] Training epoch: 8
[ Tue Jan 31 11:54:24 2023 ] 	Mean training loss: 1.1816.  Mean training acc: 65.15%.
[ Tue Jan 31 11:54:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 11:54:24 2023 ] Eval epoch: 8
[ Tue Jan 31 12:02:45 2023 ] 	Mean test loss of 930 batches: 1.4911862958503026.
[ Tue Jan 31 12:02:46 2023 ] 	Top1: 57.57%
[ Tue Jan 31 12:02:46 2023 ] 	Top5: 86.23%
[ Tue Jan 31 12:02:47 2023 ] Training epoch: 9
[ Tue Jan 31 12:12:18 2023 ] 	Mean training loss: 1.1425.  Mean training acc: 66.34%.
[ Tue Jan 31 12:12:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:12:19 2023 ] Eval epoch: 9
[ Tue Jan 31 12:20:29 2023 ] 	Mean test loss of 930 batches: 1.6829624840008315.
[ Tue Jan 31 12:20:30 2023 ] 	Top1: 54.36%
[ Tue Jan 31 12:20:30 2023 ] 	Top5: 83.75%
[ Tue Jan 31 12:20:31 2023 ] Training epoch: 10
[ Tue Jan 31 12:30:24 2023 ] 	Mean training loss: 1.1042.  Mean training acc: 67.27%.
[ Tue Jan 31 12:30:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:30:25 2023 ] Eval epoch: 10
[ Tue Jan 31 12:38:57 2023 ] 	Mean test loss of 930 batches: 1.4098518276727328.
[ Tue Jan 31 12:38:57 2023 ] 	Top1: 59.84%
[ Tue Jan 31 12:38:58 2023 ] 	Top5: 88.19%
[ Tue Jan 31 12:38:58 2023 ] Training epoch: 11
[ Tue Jan 31 12:48:53 2023 ] 	Mean training loss: 1.0691.  Mean training acc: 68.26%.
[ Tue Jan 31 12:48:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 12:48:53 2023 ] Eval epoch: 11
[ Tue Jan 31 12:57:13 2023 ] 	Mean test loss of 930 batches: 1.621859077804832.
[ Tue Jan 31 12:57:14 2023 ] 	Top1: 56.38%
[ Tue Jan 31 12:57:14 2023 ] 	Top5: 83.52%
[ Tue Jan 31 12:57:14 2023 ] Training epoch: 12
[ Tue Jan 31 13:06:43 2023 ] 	Mean training loss: 1.0399.  Mean training acc: 69.07%.
[ Tue Jan 31 13:06:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 13:06:43 2023 ] Eval epoch: 12
[ Tue Jan 31 13:15:08 2023 ] 	Mean test loss of 930 batches: 1.1321767613451967.
[ Tue Jan 31 13:15:08 2023 ] 	Top1: 67.47%
[ Tue Jan 31 13:15:09 2023 ] 	Top5: 91.04%
[ Tue Jan 31 13:15:09 2023 ] Training epoch: 13
[ Tue Jan 31 13:25:02 2023 ] 	Mean training loss: 1.0188.  Mean training acc: 69.80%.
[ Tue Jan 31 13:25:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 13:25:02 2023 ] Eval epoch: 13
[ Tue Jan 31 13:33:04 2023 ] 	Mean test loss of 930 batches: 1.2906706701363286.
[ Tue Jan 31 13:33:04 2023 ] 	Top1: 64.29%
[ Tue Jan 31 13:33:05 2023 ] 	Top5: 88.90%
[ Tue Jan 31 13:33:05 2023 ] Training epoch: 14
[ Tue Jan 31 13:42:35 2023 ] 	Mean training loss: 1.0012.  Mean training acc: 69.92%.
[ Tue Jan 31 13:42:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 13:42:35 2023 ] Eval epoch: 14
[ Tue Jan 31 13:50:22 2023 ] 	Mean test loss of 930 batches: 1.4944984425780594.
[ Tue Jan 31 13:50:22 2023 ] 	Top1: 59.55%
[ Tue Jan 31 13:50:23 2023 ] 	Top5: 87.17%
[ Tue Jan 31 13:50:23 2023 ] Training epoch: 15
[ Tue Jan 31 13:59:49 2023 ] 	Mean training loss: 0.9910.  Mean training acc: 70.47%.
[ Tue Jan 31 13:59:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 13:59:50 2023 ] Eval epoch: 15
[ Tue Jan 31 14:07:49 2023 ] 	Mean test loss of 930 batches: 1.2783450925542463.
[ Tue Jan 31 14:07:49 2023 ] 	Top1: 64.25%
[ Tue Jan 31 14:07:50 2023 ] 	Top5: 88.95%
[ Tue Jan 31 14:07:50 2023 ] Training epoch: 16
[ Tue Jan 31 14:17:36 2023 ] 	Mean training loss: 0.9738.  Mean training acc: 71.15%.
[ Tue Jan 31 14:17:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 14:17:37 2023 ] Eval epoch: 16
[ Tue Jan 31 14:25:44 2023 ] 	Mean test loss of 930 batches: 1.3844779572820152.
[ Tue Jan 31 14:25:44 2023 ] 	Top1: 60.97%
[ Tue Jan 31 14:25:45 2023 ] 	Top5: 87.29%
[ Tue Jan 31 14:25:45 2023 ] Training epoch: 17
[ Tue Jan 31 14:35:00 2023 ] 	Mean training loss: 0.9593.  Mean training acc: 71.15%.
[ Tue Jan 31 14:35:00 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 14:35:00 2023 ] Eval epoch: 17
[ Tue Jan 31 14:43:01 2023 ] 	Mean test loss of 930 batches: 1.6327409099507075.
[ Tue Jan 31 14:43:02 2023 ] 	Top1: 58.18%
[ Tue Jan 31 14:43:02 2023 ] 	Top5: 84.46%
[ Tue Jan 31 14:43:02 2023 ] Training epoch: 18
[ Tue Jan 31 14:52:46 2023 ] 	Mean training loss: 0.9451.  Mean training acc: 71.72%.
[ Tue Jan 31 14:52:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 14:52:47 2023 ] Eval epoch: 18
[ Tue Jan 31 15:01:08 2023 ] 	Mean test loss of 930 batches: 1.2752767214211085.
[ Tue Jan 31 15:01:08 2023 ] 	Top1: 63.85%
[ Tue Jan 31 15:01:09 2023 ] 	Top5: 89.79%
[ Tue Jan 31 15:01:09 2023 ] Training epoch: 19
[ Tue Jan 31 15:10:59 2023 ] 	Mean training loss: 0.9334.  Mean training acc: 72.06%.
[ Tue Jan 31 15:10:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 15:10:59 2023 ] Eval epoch: 19
[ Tue Jan 31 15:19:05 2023 ] 	Mean test loss of 930 batches: 1.2310701673710218.
[ Tue Jan 31 15:19:06 2023 ] 	Top1: 64.90%
[ Tue Jan 31 15:19:06 2023 ] 	Top5: 90.41%
[ Tue Jan 31 15:19:06 2023 ] Training epoch: 20
[ Tue Jan 31 15:28:20 2023 ] 	Mean training loss: 0.9350.  Mean training acc: 72.08%.
[ Tue Jan 31 15:28:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 15:28:20 2023 ] Eval epoch: 20
[ Tue Jan 31 15:36:24 2023 ] 	Mean test loss of 930 batches: 1.1570835490380564.
[ Tue Jan 31 15:36:24 2023 ] 	Top1: 66.82%
[ Tue Jan 31 15:36:25 2023 ] 	Top5: 91.35%
[ Tue Jan 31 15:36:25 2023 ] Training epoch: 21
[ Tue Jan 31 15:46:03 2023 ] 	Mean training loss: 0.9160.  Mean training acc: 72.74%.
[ Tue Jan 31 15:46:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 15:46:04 2023 ] Eval epoch: 21
[ Tue Jan 31 15:54:12 2023 ] 	Mean test loss of 930 batches: 1.2628259895309326.
[ Tue Jan 31 15:54:12 2023 ] 	Top1: 64.50%
[ Tue Jan 31 15:54:13 2023 ] 	Top5: 89.72%
[ Tue Jan 31 15:54:13 2023 ] Training epoch: 22
[ Tue Jan 31 16:03:50 2023 ] 	Mean training loss: 0.9138.  Mean training acc: 72.77%.
[ Tue Jan 31 16:03:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 16:03:51 2023 ] Eval epoch: 22
[ Tue Jan 31 16:11:44 2023 ] 	Mean test loss of 930 batches: 1.3636800453867963.
[ Tue Jan 31 16:11:45 2023 ] 	Top1: 62.23%
[ Tue Jan 31 16:11:45 2023 ] 	Top5: 88.26%
[ Tue Jan 31 16:11:45 2023 ] Training epoch: 23
[ Tue Jan 31 16:21:14 2023 ] 	Mean training loss: 0.9016.  Mean training acc: 72.95%.
[ Tue Jan 31 16:21:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 16:21:14 2023 ] Eval epoch: 23
[ Tue Jan 31 16:29:06 2023 ] 	Mean test loss of 930 batches: 1.1869319666136977.
[ Tue Jan 31 16:29:06 2023 ] 	Top1: 65.98%
[ Tue Jan 31 16:29:07 2023 ] 	Top5: 90.31%
[ Tue Jan 31 16:29:07 2023 ] Training epoch: 24
[ Tue Jan 31 16:38:39 2023 ] 	Mean training loss: 0.8921.  Mean training acc: 73.22%.
[ Tue Jan 31 16:38:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 16:38:39 2023 ] Eval epoch: 24
[ Tue Jan 31 16:47:10 2023 ] 	Mean test loss of 930 batches: 1.1244012095274465.
[ Tue Jan 31 16:47:11 2023 ] 	Top1: 67.35%
[ Tue Jan 31 16:47:11 2023 ] 	Top5: 91.32%
[ Tue Jan 31 16:47:11 2023 ] Training epoch: 25
[ Tue Jan 31 16:58:42 2023 ] 	Mean training loss: 0.8880.  Mean training acc: 73.40%.
[ Tue Jan 31 16:58:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 16:58:43 2023 ] Eval epoch: 25
[ Tue Jan 31 17:06:29 2023 ] 	Mean test loss of 930 batches: 1.2696548399104868.
[ Tue Jan 31 17:06:29 2023 ] 	Top1: 64.33%
[ Tue Jan 31 17:06:30 2023 ] 	Top5: 88.76%
[ Tue Jan 31 17:06:30 2023 ] Training epoch: 26
[ Tue Jan 31 17:15:33 2023 ] 	Mean training loss: 0.8892.  Mean training acc: 73.23%.
[ Tue Jan 31 17:15:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 17:15:33 2023 ] Eval epoch: 26
[ Tue Jan 31 17:23:27 2023 ] 	Mean test loss of 930 batches: 1.1458463429443297.
[ Tue Jan 31 17:23:27 2023 ] 	Top1: 67.37%
[ Tue Jan 31 17:23:27 2023 ] 	Top5: 91.13%
[ Tue Jan 31 17:23:27 2023 ] Training epoch: 27
[ Tue Jan 31 17:33:03 2023 ] 	Mean training loss: 0.8728.  Mean training acc: 73.80%.
[ Tue Jan 31 17:33:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 17:33:03 2023 ] Eval epoch: 27
[ Tue Jan 31 17:41:07 2023 ] 	Mean test loss of 930 batches: 1.1147416260293734.
[ Tue Jan 31 17:41:08 2023 ] 	Top1: 68.06%
[ Tue Jan 31 17:41:08 2023 ] 	Top5: 91.43%
[ Tue Jan 31 17:41:08 2023 ] Training epoch: 28
[ Tue Jan 31 17:50:32 2023 ] 	Mean training loss: 0.8726.  Mean training acc: 73.62%.
[ Tue Jan 31 17:50:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 17:50:32 2023 ] Eval epoch: 28
[ Tue Jan 31 17:58:18 2023 ] 	Mean test loss of 930 batches: 1.0284300355501073.
[ Tue Jan 31 17:58:19 2023 ] 	Top1: 70.25%
[ Tue Jan 31 17:58:19 2023 ] 	Top5: 92.25%
[ Tue Jan 31 17:58:19 2023 ] Training epoch: 29
[ Tue Jan 31 18:07:33 2023 ] 	Mean training loss: 0.8621.  Mean training acc: 74.26%.
[ Tue Jan 31 18:07:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 18:07:33 2023 ] Eval epoch: 29
[ Tue Jan 31 18:15:31 2023 ] 	Mean test loss of 930 batches: 1.1298939110771302.
[ Tue Jan 31 18:15:31 2023 ] 	Top1: 68.17%
[ Tue Jan 31 18:15:32 2023 ] 	Top5: 91.61%
[ Tue Jan 31 18:15:32 2023 ] Training epoch: 30
[ Tue Jan 31 18:25:13 2023 ] 	Mean training loss: 0.8614.  Mean training acc: 74.23%.
[ Tue Jan 31 18:25:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 18:25:13 2023 ] Eval epoch: 30
[ Tue Jan 31 18:33:21 2023 ] 	Mean test loss of 930 batches: 1.1029161938736516.
[ Tue Jan 31 18:33:22 2023 ] 	Top1: 68.78%
[ Tue Jan 31 18:33:22 2023 ] 	Top5: 90.90%
[ Tue Jan 31 18:33:22 2023 ] Training epoch: 31
[ Tue Jan 31 18:42:34 2023 ] 	Mean training loss: 0.8560.  Mean training acc: 74.21%.
[ Tue Jan 31 18:42:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 18:42:34 2023 ] Eval epoch: 31
[ Tue Jan 31 18:50:21 2023 ] 	Mean test loss of 930 batches: 1.1259092728296916.
[ Tue Jan 31 18:50:21 2023 ] 	Top1: 67.98%
[ Tue Jan 31 18:50:22 2023 ] 	Top5: 90.71%
[ Tue Jan 31 18:50:22 2023 ] Training epoch: 32
[ Tue Jan 31 19:00:02 2023 ] 	Mean training loss: 0.8558.  Mean training acc: 74.39%.
[ Tue Jan 31 19:00:02 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 19:00:02 2023 ] Eval epoch: 32
[ Tue Jan 31 19:08:12 2023 ] 	Mean test loss of 930 batches: 1.0783297265729597.
[ Tue Jan 31 19:08:13 2023 ] 	Top1: 68.89%
[ Tue Jan 31 19:08:13 2023 ] 	Top5: 92.01%
[ Tue Jan 31 19:08:13 2023 ] Training epoch: 33
[ Tue Jan 31 19:17:52 2023 ] 	Mean training loss: 0.8543.  Mean training acc: 74.44%.
[ Tue Jan 31 19:17:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 19:17:52 2023 ] Eval epoch: 33
[ Tue Jan 31 19:25:37 2023 ] 	Mean test loss of 930 batches: 1.1747254374206708.
[ Tue Jan 31 19:25:37 2023 ] 	Top1: 66.78%
[ Tue Jan 31 19:25:38 2023 ] 	Top5: 90.92%
[ Tue Jan 31 19:25:38 2023 ] Training epoch: 34
[ Tue Jan 31 19:34:43 2023 ] 	Mean training loss: 0.8442.  Mean training acc: 74.71%.
[ Tue Jan 31 19:34:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 19:34:43 2023 ] Eval epoch: 34
[ Tue Jan 31 19:42:49 2023 ] 	Mean test loss of 930 batches: 1.1923841649806628.
[ Tue Jan 31 19:42:49 2023 ] 	Top1: 65.61%
[ Tue Jan 31 19:42:50 2023 ] 	Top5: 91.24%
[ Tue Jan 31 19:42:50 2023 ] Training epoch: 35
[ Tue Jan 31 19:52:28 2023 ] 	Mean training loss: 0.8401.  Mean training acc: 74.49%.
[ Tue Jan 31 19:52:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 19:52:28 2023 ] Eval epoch: 35
[ Tue Jan 31 20:00:21 2023 ] 	Mean test loss of 930 batches: 1.3253406632010656.
[ Tue Jan 31 20:00:22 2023 ] 	Top1: 63.83%
[ Tue Jan 31 20:00:22 2023 ] 	Top5: 89.09%
[ Tue Jan 31 20:00:22 2023 ] Training epoch: 36
[ Tue Jan 31 20:09:38 2023 ] 	Mean training loss: 0.4849.  Mean training acc: 85.61%.
[ Tue Jan 31 20:09:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 20:09:38 2023 ] Eval epoch: 36
[ Tue Jan 31 20:17:25 2023 ] 	Mean test loss of 930 batches: 0.662273944657977.
[ Tue Jan 31 20:17:25 2023 ] 	Top1: 80.57%
[ Tue Jan 31 20:17:26 2023 ] 	Top5: 95.64%
[ Tue Jan 31 20:17:26 2023 ] Training epoch: 37
[ Tue Jan 31 20:26:56 2023 ] 	Mean training loss: 0.3808.  Mean training acc: 88.67%.
[ Tue Jan 31 20:26:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 20:26:56 2023 ] Eval epoch: 37
[ Tue Jan 31 20:35:08 2023 ] 	Mean test loss of 930 batches: 0.6466229035008338.
[ Tue Jan 31 20:35:08 2023 ] 	Top1: 81.23%
[ Tue Jan 31 20:35:09 2023 ] 	Top5: 95.86%
[ Tue Jan 31 20:35:09 2023 ] Training epoch: 38
[ Tue Jan 31 20:44:47 2023 ] 	Mean training loss: 0.3432.  Mean training acc: 89.80%.
[ Tue Jan 31 20:44:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 20:44:47 2023 ] Eval epoch: 38
[ Tue Jan 31 20:52:41 2023 ] 	Mean test loss of 930 batches: 0.6481662256903545.
[ Tue Jan 31 20:52:42 2023 ] 	Top1: 81.12%
[ Tue Jan 31 20:52:42 2023 ] 	Top5: 95.84%
[ Tue Jan 31 20:52:43 2023 ] Training epoch: 39
[ Tue Jan 31 21:01:47 2023 ] 	Mean training loss: 0.3055.  Mean training acc: 91.10%.
[ Tue Jan 31 21:01:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 21:01:47 2023 ] Eval epoch: 39
[ Tue Jan 31 21:09:41 2023 ] 	Mean test loss of 930 batches: 0.643170502589595.
[ Tue Jan 31 21:09:41 2023 ] 	Top1: 81.51%
[ Tue Jan 31 21:09:41 2023 ] 	Top5: 95.90%
[ Tue Jan 31 21:09:42 2023 ] Training epoch: 40
[ Tue Jan 31 21:19:19 2023 ] 	Mean training loss: 0.2815.  Mean training acc: 91.93%.
[ Tue Jan 31 21:19:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 21:19:19 2023 ] Eval epoch: 40
[ Tue Jan 31 21:27:32 2023 ] 	Mean test loss of 930 batches: 0.6566591738052265.
[ Tue Jan 31 21:27:32 2023 ] 	Top1: 81.24%
[ Tue Jan 31 21:27:32 2023 ] 	Top5: 95.86%
[ Tue Jan 31 21:27:32 2023 ] Training epoch: 41
[ Tue Jan 31 21:37:07 2023 ] 	Mean training loss: 0.2585.  Mean training acc: 92.63%.
[ Tue Jan 31 21:37:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 21:37:07 2023 ] Eval epoch: 41
[ Tue Jan 31 21:44:51 2023 ] 	Mean test loss of 930 batches: 0.6569695579108371.
[ Tue Jan 31 21:44:52 2023 ] 	Top1: 81.20%
[ Tue Jan 31 21:44:52 2023 ] 	Top5: 95.85%
[ Tue Jan 31 21:44:52 2023 ] Training epoch: 42
[ Tue Jan 31 21:54:09 2023 ] 	Mean training loss: 0.2377.  Mean training acc: 93.35%.
[ Tue Jan 31 21:54:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 21:54:09 2023 ] Eval epoch: 42
[ Tue Jan 31 22:02:10 2023 ] 	Mean test loss of 930 batches: 0.6790695877645605.
[ Tue Jan 31 22:02:11 2023 ] 	Top1: 80.77%
[ Tue Jan 31 22:02:11 2023 ] 	Top5: 95.66%
[ Tue Jan 31 22:02:12 2023 ] Training epoch: 43
[ Tue Jan 31 22:11:52 2023 ] 	Mean training loss: 0.2188.  Mean training acc: 93.93%.
[ Tue Jan 31 22:11:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 22:11:52 2023 ] Eval epoch: 43
[ Tue Jan 31 22:19:49 2023 ] 	Mean test loss of 930 batches: 0.6924991253162583.
[ Tue Jan 31 22:19:49 2023 ] 	Top1: 80.69%
[ Tue Jan 31 22:19:50 2023 ] 	Top5: 95.52%
[ Tue Jan 31 22:19:50 2023 ] Training epoch: 44
[ Tue Jan 31 22:28:56 2023 ] 	Mean training loss: 0.2047.  Mean training acc: 94.39%.
[ Tue Jan 31 22:28:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 22:28:56 2023 ] Eval epoch: 44
[ Tue Jan 31 22:36:41 2023 ] 	Mean test loss of 930 batches: 0.7039967889587084.
[ Tue Jan 31 22:36:42 2023 ] 	Top1: 80.65%
[ Tue Jan 31 22:36:42 2023 ] 	Top5: 95.45%
[ Tue Jan 31 22:36:42 2023 ] Training epoch: 45
[ Tue Jan 31 22:46:14 2023 ] 	Mean training loss: 0.1923.  Mean training acc: 94.75%.
[ Tue Jan 31 22:46:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 22:46:14 2023 ] Eval epoch: 45
[ Tue Jan 31 22:54:18 2023 ] 	Mean test loss of 930 batches: 0.7164114355079589.
[ Tue Jan 31 22:54:18 2023 ] 	Top1: 80.42%
[ Tue Jan 31 22:54:19 2023 ] 	Top5: 95.40%
[ Tue Jan 31 22:54:19 2023 ] Training epoch: 46
[ Tue Jan 31 23:03:50 2023 ] 	Mean training loss: 0.1870.  Mean training acc: 94.96%.
[ Tue Jan 31 23:03:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 23:03:50 2023 ] Eval epoch: 46
[ Tue Jan 31 23:11:44 2023 ] 	Mean test loss of 930 batches: 0.7198737184206645.
[ Tue Jan 31 23:11:44 2023 ] 	Top1: 80.27%
[ Tue Jan 31 23:11:45 2023 ] 	Top5: 95.50%
[ Tue Jan 31 23:11:45 2023 ] Training epoch: 47
[ Tue Jan 31 23:20:54 2023 ] 	Mean training loss: 0.1784.  Mean training acc: 95.35%.
[ Tue Jan 31 23:20:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 23:20:54 2023 ] Eval epoch: 47
[ Tue Jan 31 23:28:45 2023 ] 	Mean test loss of 930 batches: 0.7197315820923416.
[ Tue Jan 31 23:28:46 2023 ] 	Top1: 80.37%
[ Tue Jan 31 23:28:46 2023 ] 	Top5: 95.45%
[ Tue Jan 31 23:28:46 2023 ] Training epoch: 48
[ Tue Jan 31 23:38:33 2023 ] 	Mean training loss: 0.1738.  Mean training acc: 95.36%.
[ Tue Jan 31 23:38:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 23:38:33 2023 ] Eval epoch: 48
[ Tue Jan 31 23:46:31 2023 ] 	Mean test loss of 930 batches: 0.75164347560175.
[ Tue Jan 31 23:46:32 2023 ] 	Top1: 79.89%
[ Tue Jan 31 23:46:32 2023 ] 	Top5: 95.24%
[ Tue Jan 31 23:46:32 2023 ] Training epoch: 49
[ Tue Jan 31 23:56:01 2023 ] 	Mean training loss: 0.1708.  Mean training acc: 95.57%.
[ Tue Jan 31 23:56:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 31 23:56:01 2023 ] Eval epoch: 49
[ Wed Feb  1 00:03:50 2023 ] 	Mean test loss of 930 batches: 0.7394489415630858.
[ Wed Feb  1 00:03:50 2023 ] 	Top1: 80.17%
[ Wed Feb  1 00:03:51 2023 ] 	Top5: 95.15%
[ Wed Feb  1 00:03:51 2023 ] Training epoch: 50
[ Wed Feb  1 00:13:05 2023 ] 	Mean training loss: 0.1654.  Mean training acc: 95.75%.
[ Wed Feb  1 00:13:05 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 00:13:05 2023 ] Eval epoch: 50
[ Wed Feb  1 00:21:19 2023 ] 	Mean test loss of 930 batches: 0.7811492327079979.
[ Wed Feb  1 00:21:20 2023 ] 	Top1: 79.29%
[ Wed Feb  1 00:21:20 2023 ] 	Top5: 94.80%
[ Wed Feb  1 00:21:20 2023 ] Training epoch: 51
[ Wed Feb  1 00:31:14 2023 ] 	Mean training loss: 0.1629.  Mean training acc: 95.72%.
[ Wed Feb  1 00:31:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 00:31:14 2023 ] Eval epoch: 51
[ Wed Feb  1 00:39:20 2023 ] 	Mean test loss of 930 batches: 0.7821728618715399.
[ Wed Feb  1 00:39:20 2023 ] 	Top1: 79.16%
[ Wed Feb  1 00:39:20 2023 ] 	Top5: 94.83%
[ Wed Feb  1 00:39:21 2023 ] Training epoch: 52
[ Wed Feb  1 00:48:29 2023 ] 	Mean training loss: 0.1732.  Mean training acc: 95.45%.
[ Wed Feb  1 00:48:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 00:48:29 2023 ] Eval epoch: 52
[ Wed Feb  1 00:56:29 2023 ] 	Mean test loss of 930 batches: 0.7819501489881546.
[ Wed Feb  1 00:56:29 2023 ] 	Top1: 79.49%
[ Wed Feb  1 00:56:30 2023 ] 	Top5: 94.70%
[ Wed Feb  1 00:56:30 2023 ] Training epoch: 53
[ Wed Feb  1 01:06:10 2023 ] 	Mean training loss: 0.1670.  Mean training acc: 95.62%.
[ Wed Feb  1 01:06:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 01:06:10 2023 ] Eval epoch: 53
[ Wed Feb  1 01:14:16 2023 ] 	Mean test loss of 930 batches: 0.7701163353618755.
[ Wed Feb  1 01:14:17 2023 ] 	Top1: 79.54%
[ Wed Feb  1 01:14:17 2023 ] 	Top5: 94.99%
[ Wed Feb  1 01:14:17 2023 ] Training epoch: 54
[ Wed Feb  1 01:23:56 2023 ] 	Mean training loss: 0.1655.  Mean training acc: 95.71%.
[ Wed Feb  1 01:23:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 01:23:57 2023 ] Eval epoch: 54
[ Wed Feb  1 01:31:47 2023 ] 	Mean test loss of 930 batches: 0.7802937943928985.
[ Wed Feb  1 01:31:47 2023 ] 	Top1: 79.36%
[ Wed Feb  1 01:31:48 2023 ] 	Top5: 94.92%
[ Wed Feb  1 01:31:48 2023 ] Training epoch: 55
[ Wed Feb  1 01:40:55 2023 ] 	Mean training loss: 0.1604.  Mean training acc: 95.85%.
[ Wed Feb  1 01:40:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 01:40:55 2023 ] Eval epoch: 55
[ Wed Feb  1 01:48:55 2023 ] 	Mean test loss of 930 batches: 0.7869684863314834.
[ Wed Feb  1 01:48:55 2023 ] 	Top1: 79.29%
[ Wed Feb  1 01:48:56 2023 ] 	Top5: 94.94%
[ Wed Feb  1 01:48:56 2023 ] Training epoch: 56
[ Wed Feb  1 01:58:35 2023 ] 	Mean training loss: 0.0928.  Mean training acc: 98.10%.
[ Wed Feb  1 01:58:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 01:58:35 2023 ] Eval epoch: 56
[ Wed Feb  1 02:06:44 2023 ] 	Mean test loss of 930 batches: 0.7045299365555727.
[ Wed Feb  1 02:06:45 2023 ] 	Top1: 81.35%
[ Wed Feb  1 02:06:45 2023 ] 	Top5: 95.50%
[ Wed Feb  1 02:06:45 2023 ] Training epoch: 57
[ Wed Feb  1 02:16:12 2023 ] 	Mean training loss: 0.0702.  Mean training acc: 98.67%.
[ Wed Feb  1 02:16:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 02:16:12 2023 ] Eval epoch: 57
[ Wed Feb  1 02:23:55 2023 ] 	Mean test loss of 930 batches: 0.7027090156270611.
[ Wed Feb  1 02:23:56 2023 ] 	Top1: 81.53%
[ Wed Feb  1 02:23:56 2023 ] 	Top5: 95.56%
[ Wed Feb  1 02:23:56 2023 ] Training epoch: 58
[ Wed Feb  1 02:33:15 2023 ] 	Mean training loss: 0.0625.  Mean training acc: 98.83%.
[ Wed Feb  1 02:33:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 02:33:15 2023 ] Eval epoch: 58
[ Wed Feb  1 02:41:13 2023 ] 	Mean test loss of 930 batches: 0.6988241102666625.
[ Wed Feb  1 02:41:14 2023 ] 	Top1: 81.71%
[ Wed Feb  1 02:41:14 2023 ] 	Top5: 95.56%
[ Wed Feb  1 02:41:14 2023 ] Training epoch: 59
[ Wed Feb  1 02:50:44 2023 ] 	Mean training loss: 0.0596.  Mean training acc: 98.98%.
[ Wed Feb  1 02:50:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 02:50:44 2023 ] Eval epoch: 59
[ Wed Feb  1 02:58:45 2023 ] 	Mean test loss of 930 batches: 0.6981890067538267.
[ Wed Feb  1 02:58:46 2023 ] 	Top1: 81.75%
[ Wed Feb  1 02:58:46 2023 ] 	Top5: 95.60%
[ Wed Feb  1 02:58:46 2023 ] Training epoch: 60
[ Wed Feb  1 03:07:53 2023 ] 	Mean training loss: 0.0537.  Mean training acc: 99.13%.
[ Wed Feb  1 03:07:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 03:07:53 2023 ] Eval epoch: 60
[ Wed Feb  1 03:15:44 2023 ] 	Mean test loss of 930 batches: 0.7064788622000525.
[ Wed Feb  1 03:15:44 2023 ] 	Top1: 81.60%
[ Wed Feb  1 03:15:45 2023 ] 	Top5: 95.50%
[ Wed Feb  1 03:15:45 2023 ] Training epoch: 61
[ Wed Feb  1 03:25:21 2023 ] 	Mean training loss: 0.0509.  Mean training acc: 99.16%.
[ Wed Feb  1 03:25:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 03:25:21 2023 ] Eval epoch: 61
[ Wed Feb  1 03:33:20 2023 ] 	Mean test loss of 930 batches: 0.7045295349452444.
[ Wed Feb  1 03:33:20 2023 ] 	Top1: 81.74%
[ Wed Feb  1 03:33:21 2023 ] 	Top5: 95.56%
[ Wed Feb  1 03:33:21 2023 ] Training epoch: 62
[ Wed Feb  1 03:42:55 2023 ] 	Mean training loss: 0.0485.  Mean training acc: 99.22%.
[ Wed Feb  1 03:42:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 03:42:55 2023 ] Eval epoch: 62
[ Wed Feb  1 03:50:49 2023 ] 	Mean test loss of 930 batches: 0.7078664204526333.
[ Wed Feb  1 03:50:50 2023 ] 	Top1: 81.50%
[ Wed Feb  1 03:50:50 2023 ] 	Top5: 95.49%
[ Wed Feb  1 03:50:50 2023 ] Training epoch: 63
[ Wed Feb  1 03:59:56 2023 ] 	Mean training loss: 0.0479.  Mean training acc: 99.27%.
[ Wed Feb  1 03:59:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 03:59:56 2023 ] Eval epoch: 63
[ Wed Feb  1 04:07:50 2023 ] 	Mean test loss of 930 batches: 0.707785451372144.
[ Wed Feb  1 04:07:51 2023 ] 	Top1: 81.50%
[ Wed Feb  1 04:07:51 2023 ] 	Top5: 95.46%
[ Wed Feb  1 04:07:51 2023 ] Training epoch: 64
[ Wed Feb  1 04:17:27 2023 ] 	Mean training loss: 0.0450.  Mean training acc: 99.32%.
[ Wed Feb  1 04:17:27 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 04:17:27 2023 ] Eval epoch: 64
[ Wed Feb  1 04:25:32 2023 ] 	Mean test loss of 930 batches: 0.7010556458465514.
[ Wed Feb  1 04:25:33 2023 ] 	Top1: 81.97%
[ Wed Feb  1 04:25:33 2023 ] 	Top5: 95.57%
[ Wed Feb  1 04:25:33 2023 ] Training epoch: 65
[ Wed Feb  1 04:35:06 2023 ] 	Mean training loss: 0.0467.  Mean training acc: 99.29%.
[ Wed Feb  1 04:35:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Feb  1 04:35:06 2023 ] Eval epoch: 65
[ Wed Feb  1 04:42:53 2023 ] 	Mean test loss of 930 batches: 0.7091448102346671.
[ Wed Feb  1 04:42:54 2023 ] 	Top1: 81.60%
[ Wed Feb  1 04:42:54 2023 ] 	Top5: 95.39%
[ Wed Feb  1 04:50:50 2023 ] Best accuracy: 0.8196613817105772
[ Wed Feb  1 04:50:50 2023 ] Epoch number: 64
[ Wed Feb  1 04:50:50 2023 ] Model name: work_dir/cset/local_SHT_bonevel
[ Wed Feb  1 04:50:50 2023 ] Model total number of params: 2141090
[ Wed Feb  1 04:50:50 2023 ] Weight decay: 0.0004
[ Wed Feb  1 04:50:50 2023 ] Base LR: 0.1
[ Wed Feb  1 04:50:50 2023 ] Batch Size: 64
[ Wed Feb  1 04:50:50 2023 ] Test Batch Size: 64
[ Wed Feb  1 04:50:50 2023 ] seed: 1
