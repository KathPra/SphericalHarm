[ Tue Jan  3 17:09:07 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:09:47 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHTg_vel_BL', 'model_saved_name': 'work_dir/cset/local_SHTg_vel_BL/runs', 'config': 'config/nturgbd120-cross-set/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 17:09:47 2023 ] # Parameters: 2141090
[ Tue Jan  3 17:09:47 2023 ] Training epoch: 1
[ Tue Jan  3 17:18:43 2023 ] 	Mean training loss: 3.1801.  Mean training acc: 21.97%.
[ Tue Jan  3 17:18:43 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan  3 17:18:43 2023 ] Eval epoch: 1
[ Tue Jan  3 17:22:17 2023 ] 	Mean test loss of 930 batches: 2.8341921831971857.
[ Tue Jan  3 17:22:17 2023 ] 	Top1: 26.53%
[ Tue Jan  3 17:22:18 2023 ] 	Top5: 58.74%
[ Tue Jan  3 17:22:18 2023 ] Training epoch: 2
[ Tue Jan  3 17:31:21 2023 ] 	Mean training loss: 2.1795.  Mean training acc: 40.27%.
[ Tue Jan  3 17:31:21 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:31:21 2023 ] Eval epoch: 2
[ Tue Jan  3 17:35:15 2023 ] 	Mean test loss of 930 batches: 2.693994427624569.
[ Tue Jan  3 17:35:15 2023 ] 	Top1: 34.41%
[ Tue Jan  3 17:35:16 2023 ] 	Top5: 64.55%
[ Tue Jan  3 17:35:16 2023 ] Training epoch: 3
[ Tue Jan  3 17:44:20 2023 ] 	Mean training loss: 1.7937.  Mean training acc: 49.47%.
[ Tue Jan  3 17:44:20 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:44:20 2023 ] Eval epoch: 3
[ Tue Jan  3 17:48:22 2023 ] 	Mean test loss of 930 batches: 2.699910136704804.
[ Tue Jan  3 17:48:23 2023 ] 	Top1: 37.10%
[ Tue Jan  3 17:48:24 2023 ] 	Top5: 69.51%
[ Tue Jan  3 17:48:24 2023 ] Training epoch: 4
[ Tue Jan  3 17:57:13 2023 ] 	Mean training loss: 1.5797.  Mean training acc: 54.83%.
[ Tue Jan  3 17:57:13 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:57:14 2023 ] Eval epoch: 4
[ Tue Jan  3 18:01:12 2023 ] 	Mean test loss of 930 batches: 1.579490105823804.
[ Tue Jan  3 18:01:13 2023 ] 	Top1: 54.32%
[ Tue Jan  3 18:01:13 2023 ] 	Top5: 85.05%
[ Tue Jan  3 18:01:13 2023 ] Training epoch: 5
[ Tue Jan  3 18:10:16 2023 ] 	Mean training loss: 1.4501.  Mean training acc: 58.07%.
[ Tue Jan  3 18:10:16 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:10:16 2023 ] Eval epoch: 5
[ Tue Jan  3 18:14:20 2023 ] 	Mean test loss of 930 batches: 1.5332911421534836.
[ Tue Jan  3 18:14:21 2023 ] 	Top1: 56.77%
[ Tue Jan  3 18:14:21 2023 ] 	Top5: 86.37%
[ Tue Jan  3 18:14:22 2023 ] Training epoch: 6
[ Tue Jan  3 18:23:10 2023 ] 	Mean training loss: 1.3194.  Mean training acc: 61.26%.
[ Tue Jan  3 18:23:10 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:23:10 2023 ] Eval epoch: 6
[ Tue Jan  3 18:27:09 2023 ] 	Mean test loss of 930 batches: 1.439417528401139.
[ Tue Jan  3 18:27:09 2023 ] 	Top1: 59.22%
[ Tue Jan  3 18:27:10 2023 ] 	Top5: 86.46%
[ Tue Jan  3 18:27:10 2023 ] Training epoch: 7
[ Tue Jan  3 18:35:45 2023 ] 	Mean training loss: 1.2332.  Mean training acc: 63.79%.
[ Tue Jan  3 18:35:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:35:45 2023 ] Eval epoch: 7
[ Tue Jan  3 18:39:51 2023 ] 	Mean test loss of 930 batches: 1.5929295900688376.
[ Tue Jan  3 18:39:52 2023 ] 	Top1: 55.63%
[ Tue Jan  3 18:39:53 2023 ] 	Top5: 85.50%
[ Tue Jan  3 18:39:53 2023 ] Training epoch: 8
[ Tue Jan  3 18:48:32 2023 ] 	Mean training loss: 1.1693.  Mean training acc: 65.56%.
[ Tue Jan  3 18:48:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:48:32 2023 ] Eval epoch: 8
[ Tue Jan  3 18:52:43 2023 ] 	Mean test loss of 930 batches: 1.2178891410430273.
[ Tue Jan  3 18:52:44 2023 ] 	Top1: 64.20%
[ Tue Jan  3 18:52:45 2023 ] 	Top5: 90.22%
[ Tue Jan  3 18:52:45 2023 ] Training epoch: 9
[ Tue Jan  3 19:01:18 2023 ] 	Mean training loss: 1.1294.  Mean training acc: 66.66%.
[ Tue Jan  3 19:01:18 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 19:01:18 2023 ] Eval epoch: 9
[ Tue Jan  3 19:05:36 2023 ] 	Mean test loss of 930 batches: 1.5297645569488567.
[ Tue Jan  3 19:05:37 2023 ] 	Top1: 57.72%
[ Tue Jan  3 19:05:37 2023 ] 	Top5: 85.99%
[ Tue Jan  3 19:05:37 2023 ] Training epoch: 10
[ Tue Jan  3 19:14:09 2023 ] 	Mean training loss: 1.0904.  Mean training acc: 67.62%.
[ Tue Jan  3 19:14:09 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:14:09 2023 ] Eval epoch: 10
[ Tue Jan  3 19:18:22 2023 ] 	Mean test loss of 930 batches: 1.3516850954742843.
[ Tue Jan  3 19:18:23 2023 ] 	Top1: 61.82%
[ Tue Jan  3 19:18:24 2023 ] 	Top5: 87.78%
[ Tue Jan  3 19:18:24 2023 ] Training epoch: 11
[ Tue Jan  3 19:26:48 2023 ] 	Mean training loss: 1.0555.  Mean training acc: 68.58%.
[ Tue Jan  3 19:26:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:26:49 2023 ] Eval epoch: 11
[ Tue Jan  3 19:31:05 2023 ] 	Mean test loss of 930 batches: 1.4589986561447061.
[ Tue Jan  3 19:31:06 2023 ] 	Top1: 59.63%
[ Tue Jan  3 19:31:07 2023 ] 	Top5: 85.37%
[ Tue Jan  3 19:31:07 2023 ] Training epoch: 12
[ Tue Jan  3 19:39:26 2023 ] 	Mean training loss: 1.0396.  Mean training acc: 69.13%.
[ Tue Jan  3 19:39:26 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:39:26 2023 ] Eval epoch: 12
[ Tue Jan  3 19:43:52 2023 ] 	Mean test loss of 930 batches: 1.4363692763351625.
[ Tue Jan  3 19:43:53 2023 ] 	Top1: 60.40%
[ Tue Jan  3 19:43:54 2023 ] 	Top5: 86.86%
[ Tue Jan  3 19:43:54 2023 ] Training epoch: 13
[ Tue Jan  3 19:52:16 2023 ] 	Mean training loss: 1.0070.  Mean training acc: 69.88%.
[ Tue Jan  3 19:52:16 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:52:16 2023 ] Eval epoch: 13
[ Tue Jan  3 19:56:39 2023 ] 	Mean test loss of 930 batches: 1.2240192689241902.
[ Tue Jan  3 19:56:40 2023 ] 	Top1: 64.74%
[ Tue Jan  3 19:56:41 2023 ] 	Top5: 89.86%
[ Tue Jan  3 19:56:41 2023 ] Training epoch: 14
[ Tue Jan  3 20:04:59 2023 ] 	Mean training loss: 0.9902.  Mean training acc: 70.60%.
[ Tue Jan  3 20:04:59 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 20:04:59 2023 ] Eval epoch: 14
[ Tue Jan  3 20:09:15 2023 ] 	Mean test loss of 930 batches: 1.4964336596829917.
[ Tue Jan  3 20:09:16 2023 ] 	Top1: 58.64%
[ Tue Jan  3 20:09:17 2023 ] 	Top5: 86.09%
[ Tue Jan  3 20:09:17 2023 ] Training epoch: 15
[ Tue Jan  3 20:17:27 2023 ] 	Mean training loss: 0.9689.  Mean training acc: 71.22%.
[ Tue Jan  3 20:17:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 20:17:27 2023 ] Eval epoch: 15
[ Tue Jan  3 20:22:02 2023 ] 	Mean test loss of 930 batches: 1.234603476203898.
[ Tue Jan  3 20:22:03 2023 ] 	Top1: 64.47%
[ Tue Jan  3 20:22:03 2023 ] 	Top5: 90.12%
[ Tue Jan  3 20:22:03 2023 ] Training epoch: 16
[ Tue Jan  3 20:30:10 2023 ] 	Mean training loss: 0.9609.  Mean training acc: 71.34%.
[ Tue Jan  3 20:30:10 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:30:10 2023 ] Eval epoch: 16
[ Tue Jan  3 20:34:36 2023 ] 	Mean test loss of 930 batches: 1.2710621165972884.
[ Tue Jan  3 20:34:37 2023 ] 	Top1: 63.68%
[ Tue Jan  3 20:34:37 2023 ] 	Top5: 89.14%
[ Tue Jan  3 20:34:38 2023 ] Training epoch: 17
[ Tue Jan  3 20:42:54 2023 ] 	Mean training loss: 0.9458.  Mean training acc: 71.84%.
[ Tue Jan  3 20:42:54 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:42:54 2023 ] Eval epoch: 17
[ Tue Jan  3 20:47:35 2023 ] 	Mean test loss of 930 batches: 1.2526798194775017.
[ Tue Jan  3 20:47:36 2023 ] 	Top1: 64.83%
[ Tue Jan  3 20:47:37 2023 ] 	Top5: 90.07%
[ Tue Jan  3 20:47:37 2023 ] Training epoch: 18
[ Tue Jan  3 20:55:50 2023 ] 	Mean training loss: 0.9334.  Mean training acc: 72.12%.
[ Tue Jan  3 20:55:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:55:50 2023 ] Eval epoch: 18
[ Tue Jan  3 21:00:14 2023 ] 	Mean test loss of 930 batches: 1.1715455299744042.
[ Tue Jan  3 21:00:14 2023 ] 	Top1: 67.09%
[ Tue Jan  3 21:00:15 2023 ] 	Top5: 89.94%
[ Tue Jan  3 21:00:15 2023 ] Training epoch: 19
[ Tue Jan  3 21:08:35 2023 ] 	Mean training loss: 0.9221.  Mean training acc: 72.51%.
[ Tue Jan  3 21:08:35 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 21:08:35 2023 ] Eval epoch: 19
[ Tue Jan  3 21:13:00 2023 ] 	Mean test loss of 930 batches: 1.303867579531926.
[ Tue Jan  3 21:13:00 2023 ] 	Top1: 63.00%
[ Tue Jan  3 21:13:01 2023 ] 	Top5: 89.63%
[ Tue Jan  3 21:13:01 2023 ] Training epoch: 20
[ Tue Jan  3 21:21:21 2023 ] 	Mean training loss: 0.9161.  Mean training acc: 72.50%.
[ Tue Jan  3 21:21:21 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 21:21:22 2023 ] Eval epoch: 20
[ Tue Jan  3 21:25:40 2023 ] 	Mean test loss of 930 batches: 1.6050905831398503.
[ Tue Jan  3 21:25:40 2023 ] 	Top1: 56.49%
[ Tue Jan  3 21:25:41 2023 ] 	Top5: 84.20%
[ Tue Jan  3 21:25:41 2023 ] Training epoch: 21
[ Tue Jan  3 21:34:01 2023 ] 	Mean training loss: 0.9050.  Mean training acc: 73.05%.
[ Tue Jan  3 21:34:02 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:34:02 2023 ] Eval epoch: 21
[ Tue Jan  3 21:38:26 2023 ] 	Mean test loss of 930 batches: 1.3442849749198524.
[ Tue Jan  3 21:38:27 2023 ] 	Top1: 63.56%
[ Tue Jan  3 21:38:28 2023 ] 	Top5: 88.56%
[ Tue Jan  3 21:38:28 2023 ] Training epoch: 22
[ Tue Jan  3 21:47:03 2023 ] 	Mean training loss: 0.8950.  Mean training acc: 73.11%.
[ Tue Jan  3 21:47:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:47:04 2023 ] Eval epoch: 22
[ Tue Jan  3 21:51:37 2023 ] 	Mean test loss of 930 batches: 1.617811579345375.
[ Tue Jan  3 21:51:38 2023 ] 	Top1: 56.88%
[ Tue Jan  3 21:51:39 2023 ] 	Top5: 86.01%
[ Tue Jan  3 21:51:39 2023 ] Training epoch: 23
[ Tue Jan  3 22:00:08 2023 ] 	Mean training loss: 0.8882.  Mean training acc: 73.34%.
[ Tue Jan  3 22:00:08 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:00:08 2023 ] Eval epoch: 23
[ Tue Jan  3 22:04:24 2023 ] 	Mean test loss of 930 batches: 1.7125658953061669.
[ Tue Jan  3 22:04:25 2023 ] 	Top1: 57.41%
[ Tue Jan  3 22:04:26 2023 ] 	Top5: 85.47%
[ Tue Jan  3 22:04:26 2023 ] Training epoch: 24
[ Tue Jan  3 22:12:49 2023 ] 	Mean training loss: 0.8778.  Mean training acc: 73.50%.
[ Tue Jan  3 22:12:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:12:49 2023 ] Eval epoch: 24
[ Tue Jan  3 22:17:00 2023 ] 	Mean test loss of 930 batches: 1.2287496099548956.
[ Tue Jan  3 22:17:00 2023 ] 	Top1: 66.02%
[ Tue Jan  3 22:17:01 2023 ] 	Top5: 90.01%
[ Tue Jan  3 22:17:01 2023 ] Training epoch: 25
[ Tue Jan  3 22:25:36 2023 ] 	Mean training loss: 0.8758.  Mean training acc: 73.62%.
[ Tue Jan  3 22:25:36 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:25:37 2023 ] Eval epoch: 25
[ Tue Jan  3 22:29:56 2023 ] 	Mean test loss of 930 batches: 1.1509917827383165.
[ Tue Jan  3 22:29:56 2023 ] 	Top1: 67.05%
[ Tue Jan  3 22:29:57 2023 ] 	Top5: 90.69%
[ Tue Jan  3 22:29:57 2023 ] Training epoch: 26
[ Tue Jan  3 22:38:32 2023 ] 	Mean training loss: 0.8676.  Mean training acc: 73.87%.
[ Tue Jan  3 22:38:32 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 22:38:33 2023 ] Eval epoch: 26
[ Tue Jan  3 22:42:46 2023 ] 	Mean test loss of 930 batches: 1.3519699721567093.
[ Tue Jan  3 22:42:47 2023 ] 	Top1: 62.81%
[ Tue Jan  3 22:42:48 2023 ] 	Top5: 88.30%
[ Tue Jan  3 22:42:48 2023 ] Training epoch: 27
[ Tue Jan  3 22:51:26 2023 ] 	Mean training loss: 0.8716.  Mean training acc: 73.87%.
[ Tue Jan  3 22:51:26 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:51:27 2023 ] Eval epoch: 27
[ Tue Jan  3 22:55:45 2023 ] 	Mean test loss of 930 batches: 1.268751597212207.
[ Tue Jan  3 22:55:46 2023 ] 	Top1: 65.42%
[ Tue Jan  3 22:55:47 2023 ] 	Top5: 89.36%
[ Tue Jan  3 22:55:47 2023 ] Training epoch: 28
[ Tue Jan  3 23:04:28 2023 ] 	Mean training loss: 0.8531.  Mean training acc: 74.20%.
[ Tue Jan  3 23:04:28 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:04:29 2023 ] Eval epoch: 28
[ Tue Jan  3 23:08:48 2023 ] 	Mean test loss of 930 batches: 1.1951237941621453.
[ Tue Jan  3 23:08:50 2023 ] 	Top1: 65.97%
[ Tue Jan  3 23:08:50 2023 ] 	Top5: 90.29%
[ Tue Jan  3 23:08:51 2023 ] Training epoch: 29
[ Tue Jan  3 23:17:41 2023 ] 	Mean training loss: 0.8576.  Mean training acc: 74.21%.
[ Tue Jan  3 23:17:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:17:41 2023 ] Eval epoch: 29
[ Tue Jan  3 23:22:06 2023 ] 	Mean test loss of 930 batches: 1.1224218841201516.
[ Tue Jan  3 23:22:07 2023 ] 	Top1: 68.08%
[ Tue Jan  3 23:22:08 2023 ] 	Top5: 91.46%
[ Tue Jan  3 23:22:08 2023 ] Training epoch: 30
[ Tue Jan  3 23:31:08 2023 ] 	Mean training loss: 0.8545.  Mean training acc: 74.34%.
[ Tue Jan  3 23:31:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:31:08 2023 ] Eval epoch: 30
[ Tue Jan  3 23:35:10 2023 ] 	Mean test loss of 930 batches: 1.0112908865495394.
[ Tue Jan  3 23:35:11 2023 ] 	Top1: 70.23%
[ Tue Jan  3 23:35:12 2023 ] 	Top5: 92.52%
[ Tue Jan  3 23:35:12 2023 ] Training epoch: 31
[ Tue Jan  3 23:44:00 2023 ] 	Mean training loss: 0.8385.  Mean training acc: 74.85%.
[ Tue Jan  3 23:44:00 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 23:44:00 2023 ] Eval epoch: 31
[ Tue Jan  3 23:47:54 2023 ] 	Mean test loss of 930 batches: 1.5137153426485677.
[ Tue Jan  3 23:47:56 2023 ] 	Top1: 61.08%
[ Tue Jan  3 23:47:57 2023 ] 	Top5: 86.37%
[ Tue Jan  3 23:47:57 2023 ] Training epoch: 32
[ Tue Jan  3 23:56:49 2023 ] 	Mean training loss: 0.8522.  Mean training acc: 74.42%.
[ Tue Jan  3 23:56:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 23:56:49 2023 ] Eval epoch: 32
[ Wed Jan  4 00:00:49 2023 ] 	Mean test loss of 930 batches: 1.3460728165603453.
[ Wed Jan  4 00:00:50 2023 ] 	Top1: 62.07%
[ Wed Jan  4 00:00:51 2023 ] 	Top5: 89.76%
[ Wed Jan  4 00:00:51 2023 ] Training epoch: 33
[ Wed Jan  4 00:09:33 2023 ] 	Mean training loss: 0.8377.  Mean training acc: 75.00%.
[ Wed Jan  4 00:09:34 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:09:34 2023 ] Eval epoch: 33
[ Wed Jan  4 00:13:37 2023 ] 	Mean test loss of 930 batches: 1.2089465669726813.
[ Wed Jan  4 00:13:38 2023 ] 	Top1: 66.42%
[ Wed Jan  4 00:13:39 2023 ] 	Top5: 90.10%
[ Wed Jan  4 00:13:39 2023 ] Training epoch: 34
[ Wed Jan  4 00:22:19 2023 ] 	Mean training loss: 0.8363.  Mean training acc: 74.91%.
[ Wed Jan  4 00:22:20 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 00:22:20 2023 ] Eval epoch: 34
[ Wed Jan  4 00:26:31 2023 ] 	Mean test loss of 930 batches: 1.2147187267259885.
[ Wed Jan  4 00:26:32 2023 ] 	Top1: 66.24%
[ Wed Jan  4 00:26:33 2023 ] 	Top5: 90.15%
[ Wed Jan  4 00:26:33 2023 ] Training epoch: 35
[ Wed Jan  4 00:35:11 2023 ] 	Mean training loss: 0.8354.  Mean training acc: 74.93%.
[ Wed Jan  4 00:35:11 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:35:11 2023 ] Eval epoch: 35
[ Wed Jan  4 00:39:20 2023 ] 	Mean test loss of 930 batches: 1.1585185093264425.
[ Wed Jan  4 00:39:21 2023 ] 	Top1: 67.91%
[ Wed Jan  4 00:39:21 2023 ] 	Top5: 90.50%
[ Wed Jan  4 00:39:21 2023 ] Training epoch: 36
[ Wed Jan  4 00:47:45 2023 ] 	Mean training loss: 0.4880.  Mean training acc: 85.48%.
[ Wed Jan  4 00:47:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:47:45 2023 ] Eval epoch: 36
[ Wed Jan  4 00:52:01 2023 ] 	Mean test loss of 930 batches: 0.6415949185929631.
[ Wed Jan  4 00:52:02 2023 ] 	Top1: 80.84%
[ Wed Jan  4 00:52:03 2023 ] 	Top5: 95.93%
[ Wed Jan  4 00:52:03 2023 ] Training epoch: 37
[ Wed Jan  4 01:00:18 2023 ] 	Mean training loss: 0.3917.  Mean training acc: 88.39%.
[ Wed Jan  4 01:00:18 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:00:19 2023 ] Eval epoch: 37
[ Wed Jan  4 01:04:43 2023 ] 	Mean test loss of 930 batches: 0.6263615305465395.
[ Wed Jan  4 01:04:43 2023 ] 	Top1: 81.44%
[ Wed Jan  4 01:04:44 2023 ] 	Top5: 96.09%
[ Wed Jan  4 01:04:44 2023 ] Training epoch: 38
[ Wed Jan  4 01:12:57 2023 ] 	Mean training loss: 0.3510.  Mean training acc: 89.54%.
[ Wed Jan  4 01:12:57 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 01:12:57 2023 ] Eval epoch: 38
[ Wed Jan  4 01:17:20 2023 ] 	Mean test loss of 930 batches: 0.6246155981895745.
[ Wed Jan  4 01:17:21 2023 ] 	Top1: 81.62%
[ Wed Jan  4 01:17:21 2023 ] 	Top5: 96.19%
[ Wed Jan  4 01:17:21 2023 ] Training epoch: 39
[ Wed Jan  4 01:25:25 2023 ] 	Mean training loss: 0.3188.  Mean training acc: 90.48%.
[ Wed Jan  4 01:25:25 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:25:25 2023 ] Eval epoch: 39
[ Wed Jan  4 01:29:51 2023 ] 	Mean test loss of 930 batches: 0.6468145332028788.
[ Wed Jan  4 01:29:52 2023 ] 	Top1: 81.05%
[ Wed Jan  4 01:29:53 2023 ] 	Top5: 95.99%
[ Wed Jan  4 01:29:53 2023 ] Training epoch: 40
[ Wed Jan  4 01:37:51 2023 ] 	Mean training loss: 0.2979.  Mean training acc: 91.31%.
[ Wed Jan  4 01:37:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:37:51 2023 ] Eval epoch: 40
[ Wed Jan  4 01:42:19 2023 ] 	Mean test loss of 930 batches: 0.635816650629364.
[ Wed Jan  4 01:42:20 2023 ] 	Top1: 81.46%
[ Wed Jan  4 01:42:21 2023 ] 	Top5: 96.02%
[ Wed Jan  4 01:42:21 2023 ] Training epoch: 41
[ Wed Jan  4 01:50:12 2023 ] 	Mean training loss: 0.2724.  Mean training acc: 92.14%.
[ Wed Jan  4 01:50:12 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:50:13 2023 ] Eval epoch: 41
[ Wed Jan  4 01:54:49 2023 ] 	Mean test loss of 930 batches: 0.6571534542947687.
[ Wed Jan  4 01:54:50 2023 ] 	Top1: 81.04%
[ Wed Jan  4 01:54:51 2023 ] 	Top5: 96.08%
[ Wed Jan  4 01:54:51 2023 ] Training epoch: 42
[ Wed Jan  4 02:02:36 2023 ] 	Mean training loss: 0.2541.  Mean training acc: 92.72%.
[ Wed Jan  4 02:02:36 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:02:36 2023 ] Eval epoch: 42
[ Wed Jan  4 02:07:08 2023 ] 	Mean test loss of 930 batches: 0.6531411626005685.
[ Wed Jan  4 02:07:08 2023 ] 	Top1: 81.33%
[ Wed Jan  4 02:07:09 2023 ] 	Top5: 95.83%
[ Wed Jan  4 02:07:09 2023 ] Training epoch: 43
[ Wed Jan  4 02:15:07 2023 ] 	Mean training loss: 0.2417.  Mean training acc: 93.14%.
[ Wed Jan  4 02:15:07 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:15:07 2023 ] Eval epoch: 43
[ Wed Jan  4 02:19:54 2023 ] 	Mean test loss of 930 batches: 0.6647214284026495.
[ Wed Jan  4 02:19:55 2023 ] 	Top1: 81.12%
[ Wed Jan  4 02:19:56 2023 ] 	Top5: 95.71%
[ Wed Jan  4 02:19:56 2023 ] Training epoch: 44
[ Wed Jan  4 02:27:35 2023 ] 	Mean training loss: 0.2268.  Mean training acc: 93.64%.
[ Wed Jan  4 02:27:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:27:35 2023 ] Eval epoch: 44
[ Wed Jan  4 02:32:12 2023 ] 	Mean test loss of 930 batches: 0.658828459607978.
[ Wed Jan  4 02:32:12 2023 ] 	Top1: 81.51%
[ Wed Jan  4 02:32:13 2023 ] 	Top5: 95.84%
[ Wed Jan  4 02:32:13 2023 ] Training epoch: 45
[ Wed Jan  4 02:40:03 2023 ] 	Mean training loss: 0.2147.  Mean training acc: 94.07%.
[ Wed Jan  4 02:40:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 02:40:04 2023 ] Eval epoch: 45
[ Wed Jan  4 02:44:34 2023 ] 	Mean test loss of 930 batches: 0.6714187097245006.
[ Wed Jan  4 02:44:35 2023 ] 	Top1: 81.01%
[ Wed Jan  4 02:44:36 2023 ] 	Top5: 95.96%
[ Wed Jan  4 02:44:36 2023 ] Training epoch: 46
[ Wed Jan  4 02:52:24 2023 ] 	Mean training loss: 0.1985.  Mean training acc: 94.59%.
[ Wed Jan  4 02:52:24 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 02:52:24 2023 ] Eval epoch: 46
[ Wed Jan  4 02:56:40 2023 ] 	Mean test loss of 930 batches: 0.6982739195708305.
[ Wed Jan  4 02:56:41 2023 ] 	Top1: 80.70%
[ Wed Jan  4 02:56:41 2023 ] 	Top5: 95.63%
[ Wed Jan  4 02:56:42 2023 ] Training epoch: 47
[ Wed Jan  4 03:04:39 2023 ] 	Mean training loss: 0.1994.  Mean training acc: 94.48%.
[ Wed Jan  4 03:04:39 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:04:39 2023 ] Eval epoch: 47
[ Wed Jan  4 03:08:59 2023 ] 	Mean test loss of 930 batches: 0.7093822765334319.
[ Wed Jan  4 03:09:00 2023 ] 	Top1: 80.34%
[ Wed Jan  4 03:09:01 2023 ] 	Top5: 95.42%
[ Wed Jan  4 03:09:01 2023 ] Training epoch: 48
[ Wed Jan  4 03:17:06 2023 ] 	Mean training loss: 0.1944.  Mean training acc: 94.70%.
[ Wed Jan  4 03:17:06 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:17:07 2023 ] Eval epoch: 48
[ Wed Jan  4 03:21:24 2023 ] 	Mean test loss of 930 batches: 0.6977571702772571.
[ Wed Jan  4 03:21:26 2023 ] 	Top1: 80.47%
[ Wed Jan  4 03:21:26 2023 ] 	Top5: 95.60%
[ Wed Jan  4 03:21:26 2023 ] Training epoch: 49
[ Wed Jan  4 03:29:32 2023 ] 	Mean training loss: 0.1906.  Mean training acc: 94.73%.
[ Wed Jan  4 03:29:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:29:33 2023 ] Eval epoch: 49
[ Wed Jan  4 03:33:49 2023 ] 	Mean test loss of 930 batches: 0.731043587737186.
[ Wed Jan  4 03:33:49 2023 ] 	Top1: 79.99%
[ Wed Jan  4 03:33:50 2023 ] 	Top5: 95.59%
[ Wed Jan  4 03:33:50 2023 ] Training epoch: 50
[ Wed Jan  4 03:42:04 2023 ] 	Mean training loss: 0.1827.  Mean training acc: 95.17%.
[ Wed Jan  4 03:42:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:42:04 2023 ] Eval epoch: 50
[ Wed Jan  4 03:46:29 2023 ] 	Mean test loss of 930 batches: 0.7785884504997602.
[ Wed Jan  4 03:46:30 2023 ] 	Top1: 78.69%
[ Wed Jan  4 03:46:30 2023 ] 	Top5: 95.04%
[ Wed Jan  4 03:46:30 2023 ] Training epoch: 51
[ Wed Jan  4 03:54:33 2023 ] 	Mean training loss: 0.1818.  Mean training acc: 95.17%.
[ Wed Jan  4 03:54:33 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:54:33 2023 ] Eval epoch: 51
[ Wed Jan  4 03:58:53 2023 ] 	Mean test loss of 930 batches: 0.740078846613566.
[ Wed Jan  4 03:58:54 2023 ] 	Top1: 79.92%
[ Wed Jan  4 03:58:55 2023 ] 	Top5: 95.28%
[ Wed Jan  4 03:58:55 2023 ] Training epoch: 52
[ Wed Jan  4 04:06:58 2023 ] 	Mean training loss: 0.1805.  Mean training acc: 95.24%.
[ Wed Jan  4 04:06:58 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:06:58 2023 ] Eval epoch: 52
[ Wed Jan  4 04:11:16 2023 ] 	Mean test loss of 930 batches: 0.7824336846749629.
[ Wed Jan  4 04:11:17 2023 ] 	Top1: 79.06%
[ Wed Jan  4 04:11:17 2023 ] 	Top5: 95.01%
[ Wed Jan  4 04:11:17 2023 ] Training epoch: 53
[ Wed Jan  4 04:19:26 2023 ] 	Mean training loss: 0.1792.  Mean training acc: 95.14%.
[ Wed Jan  4 04:19:26 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:19:27 2023 ] Eval epoch: 53
[ Wed Jan  4 04:23:54 2023 ] 	Mean test loss of 930 batches: 0.7509462126080066.
[ Wed Jan  4 04:23:55 2023 ] 	Top1: 79.77%
[ Wed Jan  4 04:23:55 2023 ] 	Top5: 95.24%
[ Wed Jan  4 04:23:55 2023 ] Training epoch: 54
[ Wed Jan  4 04:32:03 2023 ] 	Mean training loss: 0.1768.  Mean training acc: 95.19%.
[ Wed Jan  4 04:32:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:32:04 2023 ] Eval epoch: 54
[ Wed Jan  4 04:36:30 2023 ] 	Mean test loss of 930 batches: 0.804243899801726.
[ Wed Jan  4 04:36:31 2023 ] 	Top1: 78.92%
[ Wed Jan  4 04:36:31 2023 ] 	Top5: 94.79%
[ Wed Jan  4 04:36:31 2023 ] Training epoch: 55
[ Wed Jan  4 04:44:30 2023 ] 	Mean training loss: 0.1796.  Mean training acc: 95.21%.
[ Wed Jan  4 04:44:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:44:30 2023 ] Eval epoch: 55
[ Wed Jan  4 04:48:52 2023 ] 	Mean test loss of 930 batches: 0.822960324505324.
[ Wed Jan  4 04:48:52 2023 ] 	Top1: 78.16%
[ Wed Jan  4 04:48:53 2023 ] 	Top5: 94.62%
[ Wed Jan  4 04:48:53 2023 ] Training epoch: 56
[ Wed Jan  4 04:56:52 2023 ] 	Mean training loss: 0.1098.  Mean training acc: 97.45%.
[ Wed Jan  4 04:56:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:56:53 2023 ] Eval epoch: 56
[ Wed Jan  4 05:01:12 2023 ] 	Mean test loss of 930 batches: 0.6898906964528304.
[ Wed Jan  4 05:01:12 2023 ] 	Top1: 81.46%
[ Wed Jan  4 05:01:13 2023 ] 	Top5: 95.67%
[ Wed Jan  4 05:01:13 2023 ] Training epoch: 57
[ Wed Jan  4 05:09:22 2023 ] 	Mean training loss: 0.0828.  Mean training acc: 98.35%.
[ Wed Jan  4 05:09:22 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:09:22 2023 ] Eval epoch: 57
[ Wed Jan  4 05:13:44 2023 ] 	Mean test loss of 930 batches: 0.7211287153664455.
[ Wed Jan  4 05:13:45 2023 ] 	Top1: 80.75%
[ Wed Jan  4 05:13:46 2023 ] 	Top5: 95.45%
[ Wed Jan  4 05:13:46 2023 ] Training epoch: 58
[ Wed Jan  4 05:21:49 2023 ] 	Mean training loss: 0.0754.  Mean training acc: 98.58%.
[ Wed Jan  4 05:21:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:21:49 2023 ] Eval epoch: 58
[ Wed Jan  4 05:26:06 2023 ] 	Mean test loss of 930 batches: 0.6936248554657864.
[ Wed Jan  4 05:26:06 2023 ] 	Top1: 81.57%
[ Wed Jan  4 05:26:07 2023 ] 	Top5: 95.69%
[ Wed Jan  4 05:26:07 2023 ] Training epoch: 59
[ Wed Jan  4 05:34:07 2023 ] 	Mean training loss: 0.0682.  Mean training acc: 98.73%.
[ Wed Jan  4 05:34:07 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:34:07 2023 ] Eval epoch: 59
[ Wed Jan  4 05:38:23 2023 ] 	Mean test loss of 930 batches: 0.6727192751182023.
[ Wed Jan  4 05:38:24 2023 ] 	Top1: 82.05%
[ Wed Jan  4 05:38:25 2023 ] 	Top5: 95.84%
[ Wed Jan  4 05:38:25 2023 ] Training epoch: 60
[ Wed Jan  4 05:46:29 2023 ] 	Mean training loss: 0.0644.  Mean training acc: 98.79%.
[ Wed Jan  4 05:46:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:46:30 2023 ] Eval epoch: 60
[ Wed Jan  4 05:50:54 2023 ] 	Mean test loss of 930 batches: 0.6805466804773577.
[ Wed Jan  4 05:50:55 2023 ] 	Top1: 81.85%
[ Wed Jan  4 05:50:56 2023 ] 	Top5: 95.73%
[ Wed Jan  4 05:50:56 2023 ] Training epoch: 61
[ Wed Jan  4 05:59:11 2023 ] 	Mean training loss: 0.0626.  Mean training acc: 98.90%.
[ Wed Jan  4 05:59:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:59:11 2023 ] Eval epoch: 61
[ Wed Jan  4 06:03:37 2023 ] 	Mean test loss of 930 batches: 0.6923758941392104.
[ Wed Jan  4 06:03:38 2023 ] 	Top1: 81.52%
[ Wed Jan  4 06:03:39 2023 ] 	Top5: 95.67%
[ Wed Jan  4 06:03:39 2023 ] Training epoch: 62
[ Wed Jan  4 06:11:49 2023 ] 	Mean training loss: 0.0575.  Mean training acc: 99.00%.
[ Wed Jan  4 06:11:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:11:49 2023 ] Eval epoch: 62
[ Wed Jan  4 06:15:57 2023 ] 	Mean test loss of 930 batches: 0.6842821652209887.
[ Wed Jan  4 06:15:57 2023 ] 	Top1: 81.89%
[ Wed Jan  4 06:15:58 2023 ] 	Top5: 95.75%
[ Wed Jan  4 06:15:58 2023 ] Training epoch: 63
[ Wed Jan  4 06:24:05 2023 ] 	Mean training loss: 0.0558.  Mean training acc: 99.05%.
[ Wed Jan  4 06:24:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:24:05 2023 ] Eval epoch: 63
[ Wed Jan  4 06:28:13 2023 ] 	Mean test loss of 930 batches: 0.6924446041064878.
[ Wed Jan  4 06:28:13 2023 ] 	Top1: 81.89%
[ Wed Jan  4 06:28:14 2023 ] 	Top5: 95.59%
[ Wed Jan  4 06:28:14 2023 ] Training epoch: 64
[ Wed Jan  4 06:36:29 2023 ] 	Mean training loss: 0.0538.  Mean training acc: 99.11%.
[ Wed Jan  4 06:36:29 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:36:29 2023 ] Eval epoch: 64
[ Wed Jan  4 06:40:33 2023 ] 	Mean test loss of 930 batches: 0.6796768307926193.
[ Wed Jan  4 06:40:34 2023 ] 	Top1: 82.02%
[ Wed Jan  4 06:40:34 2023 ] 	Top5: 95.78%
[ Wed Jan  4 06:40:35 2023 ] Training epoch: 65
[ Wed Jan  4 06:48:56 2023 ] 	Mean training loss: 0.0519.  Mean training acc: 99.20%.
[ Wed Jan  4 06:48:56 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:48:56 2023 ] Eval epoch: 65
[ Wed Jan  4 06:52:55 2023 ] 	Mean test loss of 930 batches: 0.6810338290628567.
[ Wed Jan  4 06:52:56 2023 ] 	Top1: 82.01%
[ Wed Jan  4 06:52:57 2023 ] 	Top5: 95.79%
[ Wed Jan  4 06:57:06 2023 ] Best accuracy: 0.8205356692502984
[ Wed Jan  4 06:57:06 2023 ] Epoch number: 1
[ Wed Jan  4 06:57:06 2023 ] Model name: work_dir/cset/local_SHTg_vel_BL
[ Wed Jan  4 06:57:06 2023 ] Model total number of params: 2141090
[ Wed Jan  4 06:57:06 2023 ] Weight decay: 0.0004
[ Wed Jan  4 06:57:06 2023 ] Base LR: 0.1
[ Wed Jan  4 06:57:06 2023 ] Batch Size: 64
[ Wed Jan  4 06:57:06 2023 ] Test Batch Size: 64
[ Wed Jan  4 06:57:06 2023 ] seed: 1
[ Thu Feb  2 11:32:11 2023 ] using warm up, epoch: 5
[ Thu Feb  2 11:32:26 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHT_vel_BL', 'model_saved_name': 'work_dir/cset/local_SHT_vel_BL/runs', 'config': 'config/nturgbd120-cross-set/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Feb  2 11:32:26 2023 ] # Parameters: 2141090
[ Thu Feb  2 11:32:26 2023 ] Training epoch: 1
[ Thu Feb  2 11:35:56 2023 ] 	Mean training loss: 3.1742.  Mean training acc: 22.02%.
[ Thu Feb  2 11:35:56 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 11:35:56 2023 ] Eval epoch: 1
[ Thu Feb  2 11:37:40 2023 ] 	Mean test loss of 930 batches: 2.7801208256393353.
[ Thu Feb  2 11:37:41 2023 ] 	Top1: 27.79%
[ Thu Feb  2 11:37:41 2023 ] 	Top5: 59.54%
[ Thu Feb  2 11:37:41 2023 ] Training epoch: 2
[ Thu Feb  2 11:41:11 2023 ] 	Mean training loss: 2.1860.  Mean training acc: 40.02%.
[ Thu Feb  2 11:41:11 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 11:41:11 2023 ] Eval epoch: 2
[ Thu Feb  2 11:42:56 2023 ] 	Mean test loss of 930 batches: 2.8830877774505206.
[ Thu Feb  2 11:42:56 2023 ] 	Top1: 31.72%
[ Thu Feb  2 11:42:57 2023 ] 	Top5: 61.12%
[ Thu Feb  2 11:42:57 2023 ] Training epoch: 3
[ Thu Feb  2 11:46:28 2023 ] 	Mean training loss: 1.8007.  Mean training acc: 49.32%.
[ Thu Feb  2 11:46:28 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 11:46:28 2023 ] Eval epoch: 3
[ Thu Feb  2 11:48:12 2023 ] 	Mean test loss of 930 batches: 2.0864202130225395.
[ Thu Feb  2 11:48:12 2023 ] 	Top1: 45.09%
[ Thu Feb  2 11:48:13 2023 ] 	Top5: 77.66%
[ Thu Feb  2 11:48:13 2023 ] Training epoch: 4
[ Thu Feb  2 11:53:53 2023 ] 	Mean training loss: 1.5798.  Mean training acc: 54.67%.
[ Thu Feb  2 11:53:53 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 11:53:53 2023 ] Eval epoch: 4
[ Thu Feb  2 11:56:35 2023 ] 	Mean test loss of 930 batches: 1.9642002044185516.
[ Thu Feb  2 11:56:35 2023 ] 	Top1: 46.81%
[ Thu Feb  2 11:56:36 2023 ] 	Top5: 77.54%
[ Thu Feb  2 11:56:36 2023 ] Training epoch: 5
[ Thu Feb  2 12:03:04 2023 ] 	Mean training loss: 1.4538.  Mean training acc: 58.19%.
[ Thu Feb  2 12:03:04 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:03:04 2023 ] Eval epoch: 5
[ Thu Feb  2 12:05:47 2023 ] 	Mean test loss of 930 batches: 2.048725700250236.
[ Thu Feb  2 12:05:47 2023 ] 	Top1: 49.68%
[ Thu Feb  2 12:05:48 2023 ] 	Top5: 77.38%
[ Thu Feb  2 12:05:48 2023 ] Training epoch: 6
[ Thu Feb  2 12:12:15 2023 ] 	Mean training loss: 1.3223.  Mean training acc: 61.40%.
[ Thu Feb  2 12:12:15 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:12:16 2023 ] Eval epoch: 6
[ Thu Feb  2 12:14:55 2023 ] 	Mean test loss of 930 batches: 1.4636907090422928.
[ Thu Feb  2 12:14:55 2023 ] 	Top1: 58.13%
[ Thu Feb  2 12:14:56 2023 ] 	Top5: 86.55%
[ Thu Feb  2 12:14:56 2023 ] Training epoch: 7
[ Thu Feb  2 12:21:22 2023 ] 	Mean training loss: 1.2376.  Mean training acc: 63.84%.
[ Thu Feb  2 12:21:22 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:21:22 2023 ] Eval epoch: 7
[ Thu Feb  2 12:24:04 2023 ] 	Mean test loss of 930 batches: 1.5488040344048573.
[ Thu Feb  2 12:24:04 2023 ] 	Top1: 56.83%
[ Thu Feb  2 12:24:05 2023 ] 	Top5: 86.20%
[ Thu Feb  2 12:24:05 2023 ] Training epoch: 8
[ Thu Feb  2 12:30:33 2023 ] 	Mean training loss: 1.1803.  Mean training acc: 65.36%.
[ Thu Feb  2 12:30:33 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:30:33 2023 ] Eval epoch: 8
[ Thu Feb  2 12:33:16 2023 ] 	Mean test loss of 930 batches: 1.637679604368825.
[ Thu Feb  2 12:33:16 2023 ] 	Top1: 56.83%
[ Thu Feb  2 12:33:16 2023 ] 	Top5: 83.27%
[ Thu Feb  2 12:33:16 2023 ] Training epoch: 9
[ Thu Feb  2 12:40:14 2023 ] 	Mean training loss: 1.1311.  Mean training acc: 66.59%.
[ Thu Feb  2 12:40:14 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:40:14 2023 ] Eval epoch: 9
[ Thu Feb  2 12:43:30 2023 ] 	Mean test loss of 930 batches: 1.4543032064232775.
[ Thu Feb  2 12:43:30 2023 ] 	Top1: 58.37%
[ Thu Feb  2 12:43:31 2023 ] 	Top5: 87.17%
[ Thu Feb  2 12:43:31 2023 ] Training epoch: 10
[ Thu Feb  2 12:51:37 2023 ] 	Mean training loss: 1.0916.  Mean training acc: 67.72%.
[ Thu Feb  2 12:51:37 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 12:51:38 2023 ] Eval epoch: 10
[ Thu Feb  2 12:54:52 2023 ] 	Mean test loss of 930 batches: 1.2998071671173137.
[ Thu Feb  2 12:54:52 2023 ] 	Top1: 62.64%
[ Thu Feb  2 12:54:52 2023 ] 	Top5: 88.65%
[ Thu Feb  2 12:54:53 2023 ] Training epoch: 11
[ Thu Feb  2 13:03:00 2023 ] 	Mean training loss: 1.0633.  Mean training acc: 68.47%.
[ Thu Feb  2 13:03:00 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:03:00 2023 ] Eval epoch: 11
[ Thu Feb  2 13:06:14 2023 ] 	Mean test loss of 930 batches: 1.2615555844319764.
[ Thu Feb  2 13:06:14 2023 ] 	Top1: 63.85%
[ Thu Feb  2 13:06:15 2023 ] 	Top5: 88.93%
[ Thu Feb  2 13:06:15 2023 ] Training epoch: 12
[ Thu Feb  2 13:14:23 2023 ] 	Mean training loss: 1.0403.  Mean training acc: 69.07%.
[ Thu Feb  2 13:14:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:14:23 2023 ] Eval epoch: 12
[ Thu Feb  2 13:17:36 2023 ] 	Mean test loss of 930 batches: 1.4226885759702292.
[ Thu Feb  2 13:17:37 2023 ] 	Top1: 60.04%
[ Thu Feb  2 13:17:37 2023 ] 	Top5: 88.13%
[ Thu Feb  2 13:17:37 2023 ] Training epoch: 13
[ Thu Feb  2 13:25:40 2023 ] 	Mean training loss: 1.0112.  Mean training acc: 70.15%.
[ Thu Feb  2 13:25:41 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:25:41 2023 ] Eval epoch: 13
[ Thu Feb  2 13:28:56 2023 ] 	Mean test loss of 930 batches: 1.4215500900822302.
[ Thu Feb  2 13:28:57 2023 ] 	Top1: 60.01%
[ Thu Feb  2 13:28:57 2023 ] 	Top5: 87.11%
[ Thu Feb  2 13:28:57 2023 ] Training epoch: 14
[ Thu Feb  2 13:37:03 2023 ] 	Mean training loss: 0.9879.  Mean training acc: 70.49%.
[ Thu Feb  2 13:37:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:37:03 2023 ] Eval epoch: 14
[ Thu Feb  2 13:40:20 2023 ] 	Mean test loss of 930 batches: 1.3139758054607658.
[ Thu Feb  2 13:40:20 2023 ] 	Top1: 63.01%
[ Thu Feb  2 13:40:21 2023 ] 	Top5: 88.34%
[ Thu Feb  2 13:40:21 2023 ] Training epoch: 15
[ Thu Feb  2 13:48:06 2023 ] 	Mean training loss: 0.9761.  Mean training acc: 71.09%.
[ Thu Feb  2 13:48:06 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:48:06 2023 ] Eval epoch: 15
[ Thu Feb  2 13:51:25 2023 ] 	Mean test loss of 930 batches: 1.176286548920857.
[ Thu Feb  2 13:51:26 2023 ] 	Top1: 66.35%
[ Thu Feb  2 13:51:26 2023 ] 	Top5: 90.71%
[ Thu Feb  2 13:51:27 2023 ] Training epoch: 16
[ Thu Feb  2 13:59:24 2023 ] 	Mean training loss: 0.9615.  Mean training acc: 71.27%.
[ Thu Feb  2 13:59:24 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 13:59:24 2023 ] Eval epoch: 16
[ Thu Feb  2 14:02:47 2023 ] 	Mean test loss of 930 batches: 1.2765544607113766.
[ Thu Feb  2 14:02:48 2023 ] 	Top1: 63.55%
[ Thu Feb  2 14:02:48 2023 ] 	Top5: 89.12%
[ Thu Feb  2 14:02:48 2023 ] Training epoch: 17
[ Thu Feb  2 14:11:08 2023 ] 	Mean training loss: 0.9421.  Mean training acc: 71.85%.
[ Thu Feb  2 14:11:08 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 14:11:08 2023 ] Eval epoch: 17
[ Thu Feb  2 14:14:26 2023 ] 	Mean test loss of 930 batches: 1.192954864296862.
[ Thu Feb  2 14:14:27 2023 ] 	Top1: 66.30%
[ Thu Feb  2 14:14:27 2023 ] 	Top5: 90.66%
[ Thu Feb  2 14:14:27 2023 ] Training epoch: 18
[ Thu Feb  2 14:22:16 2023 ] 	Mean training loss: 0.9366.  Mean training acc: 71.97%.
[ Thu Feb  2 14:22:16 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 14:22:16 2023 ] Eval epoch: 18
[ Thu Feb  2 14:25:23 2023 ] 	Mean test loss of 930 batches: 1.1487020760133702.
[ Thu Feb  2 14:25:23 2023 ] 	Top1: 66.83%
[ Thu Feb  2 14:25:24 2023 ] 	Top5: 91.03%
[ Thu Feb  2 14:25:24 2023 ] Training epoch: 19
[ Thu Feb  2 14:33:29 2023 ] 	Mean training loss: 0.9176.  Mean training acc: 72.49%.
[ Thu Feb  2 14:33:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 14:33:29 2023 ] Eval epoch: 19
[ Thu Feb  2 14:36:47 2023 ] 	Mean test loss of 930 batches: 1.1179290159415174.
[ Thu Feb  2 14:36:47 2023 ] 	Top1: 67.70%
[ Thu Feb  2 14:36:47 2023 ] 	Top5: 91.51%
[ Thu Feb  2 14:36:47 2023 ] Training epoch: 20
[ Thu Feb  2 14:44:56 2023 ] 	Mean training loss: 0.9101.  Mean training acc: 72.81%.
[ Thu Feb  2 14:44:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 14:44:56 2023 ] Eval epoch: 20
[ Thu Feb  2 14:48:11 2023 ] 	Mean test loss of 930 batches: 1.3249312339931405.
[ Thu Feb  2 14:48:11 2023 ] 	Top1: 62.09%
[ Thu Feb  2 14:48:12 2023 ] 	Top5: 88.29%
[ Thu Feb  2 14:48:12 2023 ] Training epoch: 21
[ Thu Feb  2 14:56:21 2023 ] 	Mean training loss: 0.9061.  Mean training acc: 73.00%.
[ Thu Feb  2 14:56:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 14:56:21 2023 ] Eval epoch: 21
[ Thu Feb  2 14:59:38 2023 ] 	Mean test loss of 930 batches: 1.3032394043540443.
[ Thu Feb  2 14:59:38 2023 ] 	Top1: 63.77%
[ Thu Feb  2 14:59:39 2023 ] 	Top5: 89.42%
[ Thu Feb  2 14:59:39 2023 ] Training epoch: 22
[ Thu Feb  2 15:07:45 2023 ] 	Mean training loss: 0.8927.  Mean training acc: 73.35%.
[ Thu Feb  2 15:07:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 15:07:45 2023 ] Eval epoch: 22
[ Thu Feb  2 15:11:02 2023 ] 	Mean test loss of 930 batches: 1.1045107306011261.
[ Thu Feb  2 15:11:03 2023 ] 	Top1: 68.38%
[ Thu Feb  2 15:11:03 2023 ] 	Top5: 91.03%
[ Thu Feb  2 15:11:03 2023 ] Training epoch: 23
[ Thu Feb  2 15:19:12 2023 ] 	Mean training loss: 0.8842.  Mean training acc: 73.44%.
[ Thu Feb  2 15:19:12 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 15:19:12 2023 ] Eval epoch: 23
[ Thu Feb  2 15:22:28 2023 ] 	Mean test loss of 930 batches: 1.5399336996898856.
[ Thu Feb  2 15:22:28 2023 ] 	Top1: 59.52%
[ Thu Feb  2 15:22:28 2023 ] 	Top5: 87.77%
[ Thu Feb  2 15:22:28 2023 ] Training epoch: 24
[ Thu Feb  2 15:30:38 2023 ] 	Mean training loss: 0.8722.  Mean training acc: 74.02%.
[ Thu Feb  2 15:30:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 15:30:38 2023 ] Eval epoch: 24
[ Thu Feb  2 15:33:54 2023 ] 	Mean test loss of 930 batches: 1.223583023971127.
[ Thu Feb  2 15:33:55 2023 ] 	Top1: 66.12%
[ Thu Feb  2 15:33:55 2023 ] 	Top5: 89.94%
[ Thu Feb  2 15:33:55 2023 ] Training epoch: 25
[ Thu Feb  2 15:42:00 2023 ] 	Mean training loss: 0.8679.  Mean training acc: 74.06%.
[ Thu Feb  2 15:42:00 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 15:42:00 2023 ] Eval epoch: 25
[ Thu Feb  2 15:45:15 2023 ] 	Mean test loss of 930 batches: 1.2517599308683027.
[ Thu Feb  2 15:45:16 2023 ] 	Top1: 65.13%
[ Thu Feb  2 15:45:16 2023 ] 	Top5: 89.53%
[ Thu Feb  2 15:45:16 2023 ] Training epoch: 26
[ Thu Feb  2 15:53:29 2023 ] 	Mean training loss: 0.8600.  Mean training acc: 74.41%.
[ Thu Feb  2 15:53:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 15:53:29 2023 ] Eval epoch: 26
[ Thu Feb  2 15:56:47 2023 ] 	Mean test loss of 930 batches: 1.141825280811197.
[ Thu Feb  2 15:56:47 2023 ] 	Top1: 67.99%
[ Thu Feb  2 15:56:47 2023 ] 	Top5: 90.89%
[ Thu Feb  2 15:56:47 2023 ] Training epoch: 27
[ Thu Feb  2 16:04:48 2023 ] 	Mean training loss: 0.8693.  Mean training acc: 74.12%.
[ Thu Feb  2 16:04:48 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 16:04:48 2023 ] Eval epoch: 27
[ Thu Feb  2 16:08:02 2023 ] 	Mean test loss of 930 batches: 1.1827424093279788.
[ Thu Feb  2 16:08:02 2023 ] 	Top1: 66.84%
[ Thu Feb  2 16:08:03 2023 ] 	Top5: 90.53%
[ Thu Feb  2 16:08:03 2023 ] Training epoch: 28
[ Thu Feb  2 16:16:22 2023 ] 	Mean training loss: 0.8548.  Mean training acc: 74.07%.
[ Thu Feb  2 16:16:22 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 16:16:22 2023 ] Eval epoch: 28
[ Thu Feb  2 16:19:42 2023 ] 	Mean test loss of 930 batches: 1.2657178163848897.
[ Thu Feb  2 16:19:42 2023 ] 	Top1: 65.07%
[ Thu Feb  2 16:19:42 2023 ] 	Top5: 89.72%
[ Thu Feb  2 16:19:43 2023 ] Training epoch: 29
[ Thu Feb  2 16:28:03 2023 ] 	Mean training loss: 0.8518.  Mean training acc: 74.50%.
[ Thu Feb  2 16:28:03 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 16:28:03 2023 ] Eval epoch: 29
[ Thu Feb  2 16:31:24 2023 ] 	Mean test loss of 930 batches: 1.0413929546071636.
[ Thu Feb  2 16:31:24 2023 ] 	Top1: 69.67%
[ Thu Feb  2 16:31:25 2023 ] 	Top5: 92.16%
[ Thu Feb  2 16:31:25 2023 ] Training epoch: 30
[ Thu Feb  2 16:39:46 2023 ] 	Mean training loss: 0.8467.  Mean training acc: 74.60%.
[ Thu Feb  2 16:39:46 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 16:39:46 2023 ] Eval epoch: 30
[ Thu Feb  2 16:43:18 2023 ] 	Mean test loss of 930 batches: 1.330255528323112.
[ Thu Feb  2 16:43:18 2023 ] 	Top1: 62.71%
[ Thu Feb  2 16:43:19 2023 ] 	Top5: 89.06%
[ Thu Feb  2 16:43:19 2023 ] Training epoch: 31
[ Thu Feb  2 16:51:39 2023 ] 	Mean training loss: 0.8359.  Mean training acc: 74.99%.
[ Thu Feb  2 16:51:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 16:51:39 2023 ] Eval epoch: 31
[ Thu Feb  2 16:55:01 2023 ] 	Mean test loss of 930 batches: 1.0502118230827393.
[ Thu Feb  2 16:55:01 2023 ] 	Top1: 69.92%
[ Thu Feb  2 16:55:01 2023 ] 	Top5: 91.49%
[ Thu Feb  2 16:55:02 2023 ] Training epoch: 32
[ Thu Feb  2 17:03:29 2023 ] 	Mean training loss: 0.8431.  Mean training acc: 74.52%.
[ Thu Feb  2 17:03:29 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 17:03:29 2023 ] Eval epoch: 32
[ Thu Feb  2 17:08:00 2023 ] 	Mean test loss of 930 batches: 1.2187771568054795.
[ Thu Feb  2 17:08:01 2023 ] 	Top1: 65.99%
[ Thu Feb  2 17:08:02 2023 ] 	Top5: 90.56%
[ Thu Feb  2 17:08:02 2023 ] Training epoch: 33
[ Thu Feb  2 17:16:28 2023 ] 	Mean training loss: 0.8374.  Mean training acc: 74.93%.
[ Thu Feb  2 17:16:28 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 17:16:28 2023 ] Eval epoch: 33
[ Thu Feb  2 17:20:30 2023 ] 	Mean test loss of 930 batches: 1.134061015389299.
[ Thu Feb  2 17:20:32 2023 ] 	Top1: 68.42%
[ Thu Feb  2 17:20:33 2023 ] 	Top5: 90.99%
[ Thu Feb  2 17:20:33 2023 ] Training epoch: 34
[ Thu Feb  2 17:29:27 2023 ] 	Mean training loss: 0.8260.  Mean training acc: 75.04%.
[ Thu Feb  2 17:29:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 17:29:27 2023 ] Eval epoch: 34
[ Thu Feb  2 17:33:18 2023 ] 	Mean test loss of 930 batches: 1.1304043537506494.
[ Thu Feb  2 17:33:19 2023 ] 	Top1: 68.53%
[ Thu Feb  2 17:33:19 2023 ] 	Top5: 90.83%
[ Thu Feb  2 17:33:19 2023 ] Training epoch: 35
[ Thu Feb  2 17:41:53 2023 ] 	Mean training loss: 0.8284.  Mean training acc: 75.17%.
[ Thu Feb  2 17:41:53 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 17:41:53 2023 ] Eval epoch: 35
[ Thu Feb  2 17:45:36 2023 ] 	Mean test loss of 930 batches: 1.2929789830279608.
[ Thu Feb  2 17:45:37 2023 ] 	Top1: 64.58%
[ Thu Feb  2 17:45:37 2023 ] 	Top5: 88.22%
[ Thu Feb  2 17:45:37 2023 ] Training epoch: 36
[ Thu Feb  2 17:55:05 2023 ] 	Mean training loss: 0.4821.  Mean training acc: 85.52%.
[ Thu Feb  2 17:55:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 17:55:05 2023 ] Eval epoch: 36
[ Thu Feb  2 18:00:35 2023 ] 	Mean test loss of 930 batches: 0.641617992640503.
[ Thu Feb  2 18:00:36 2023 ] 	Top1: 80.93%
[ Thu Feb  2 18:00:37 2023 ] 	Top5: 96.02%
[ Thu Feb  2 18:00:37 2023 ] Training epoch: 37
[ Thu Feb  2 18:10:19 2023 ] 	Mean training loss: 0.3857.  Mean training acc: 88.52%.
[ Thu Feb  2 18:10:19 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Thu Feb  2 18:10:19 2023 ] Eval epoch: 37
[ Thu Feb  2 18:13:52 2023 ] 	Mean test loss of 930 batches: 0.6209011700605193.
[ Thu Feb  2 18:13:53 2023 ] 	Top1: 81.43%
[ Thu Feb  2 18:13:54 2023 ] 	Top5: 96.20%
[ Thu Feb  2 18:13:54 2023 ] Training epoch: 38
[ Thu Feb  2 18:22:27 2023 ] 	Mean training loss: 0.3423.  Mean training acc: 89.86%.
[ Thu Feb  2 18:22:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Feb  2 18:22:27 2023 ] Eval epoch: 38
[ Thu Feb  2 18:26:10 2023 ] 	Mean test loss of 930 batches: 0.6318644478837008.
[ Thu Feb  2 18:26:11 2023 ] 	Top1: 81.54%
[ Thu Feb  2 18:26:12 2023 ] 	Top5: 96.14%
[ Thu Feb  2 18:26:12 2023 ] Training epoch: 39
[ Thu Feb  2 18:34:30 2023 ] 	Mean training loss: 0.3114.  Mean training acc: 90.83%.
[ Thu Feb  2 18:34:30 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 18:34:30 2023 ] Eval epoch: 39
[ Thu Feb  2 18:37:48 2023 ] 	Mean test loss of 930 batches: 0.6656760492792694.
[ Thu Feb  2 18:37:48 2023 ] 	Top1: 80.62%
[ Thu Feb  2 18:37:49 2023 ] 	Top5: 95.81%
[ Thu Feb  2 18:37:49 2023 ] Training epoch: 40
[ Thu Feb  2 18:46:01 2023 ] 	Mean training loss: 0.2909.  Mean training acc: 91.39%.
[ Thu Feb  2 18:46:01 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 18:46:01 2023 ] Eval epoch: 40
[ Thu Feb  2 18:49:24 2023 ] 	Mean test loss of 930 batches: 0.6344636667239409.
[ Thu Feb  2 18:49:25 2023 ] 	Top1: 81.62%
[ Thu Feb  2 18:49:25 2023 ] 	Top5: 96.04%
[ Thu Feb  2 18:49:25 2023 ] Training epoch: 41
[ Thu Feb  2 18:57:34 2023 ] 	Mean training loss: 0.2646.  Mean training acc: 92.48%.
[ Thu Feb  2 18:57:34 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 18:57:34 2023 ] Eval epoch: 41
[ Thu Feb  2 19:00:51 2023 ] 	Mean test loss of 930 batches: 0.6577055983966397.
[ Thu Feb  2 19:00:51 2023 ] 	Top1: 81.17%
[ Thu Feb  2 19:00:52 2023 ] 	Top5: 96.02%
[ Thu Feb  2 19:00:52 2023 ] Training epoch: 42
[ Thu Feb  2 19:08:58 2023 ] 	Mean training loss: 0.2475.  Mean training acc: 92.86%.
[ Thu Feb  2 19:08:58 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 19:08:58 2023 ] Eval epoch: 42
[ Thu Feb  2 19:12:09 2023 ] 	Mean test loss of 930 batches: 0.6599069612000579.
[ Thu Feb  2 19:12:10 2023 ] 	Top1: 81.36%
[ Thu Feb  2 19:12:11 2023 ] 	Top5: 95.88%
[ Thu Feb  2 19:12:11 2023 ] Training epoch: 43
[ Thu Feb  2 19:19:52 2023 ] 	Mean training loss: 0.2343.  Mean training acc: 93.39%.
[ Thu Feb  2 19:19:52 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 19:19:52 2023 ] Eval epoch: 43
[ Thu Feb  2 19:23:21 2023 ] 	Mean test loss of 930 batches: 0.6774445779861943.
[ Thu Feb  2 19:23:22 2023 ] 	Top1: 80.74%
[ Thu Feb  2 19:23:23 2023 ] 	Top5: 95.75%
[ Thu Feb  2 19:23:23 2023 ] Training epoch: 44
[ Thu Feb  2 19:31:36 2023 ] 	Mean training loss: 0.2240.  Mean training acc: 93.70%.
[ Thu Feb  2 19:31:36 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 19:31:36 2023 ] Eval epoch: 44
[ Thu Feb  2 19:34:55 2023 ] 	Mean test loss of 930 batches: 0.68344742247975.
[ Thu Feb  2 19:34:56 2023 ] 	Top1: 80.90%
[ Thu Feb  2 19:34:56 2023 ] 	Top5: 95.77%
[ Thu Feb  2 19:34:56 2023 ] Training epoch: 45
[ Thu Feb  2 19:43:08 2023 ] 	Mean training loss: 0.2091.  Mean training acc: 94.19%.
[ Thu Feb  2 19:43:08 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 19:43:08 2023 ] Eval epoch: 45
[ Thu Feb  2 19:46:25 2023 ] 	Mean test loss of 930 batches: 0.7308933904414536.
[ Thu Feb  2 19:46:25 2023 ] 	Top1: 79.80%
[ Thu Feb  2 19:46:26 2023 ] 	Top5: 95.34%
[ Thu Feb  2 19:46:26 2023 ] Training epoch: 46
[ Thu Feb  2 19:54:35 2023 ] 	Mean training loss: 0.1936.  Mean training acc: 94.79%.
[ Thu Feb  2 19:54:35 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 19:54:35 2023 ] Eval epoch: 46
[ Thu Feb  2 19:57:50 2023 ] 	Mean test loss of 930 batches: 0.7250756948385187.
[ Thu Feb  2 19:57:51 2023 ] 	Top1: 80.14%
[ Thu Feb  2 19:57:51 2023 ] 	Top5: 95.50%
[ Thu Feb  2 19:57:51 2023 ] Training epoch: 47
[ Thu Feb  2 20:06:01 2023 ] 	Mean training loss: 0.1947.  Mean training acc: 94.57%.
[ Thu Feb  2 20:06:01 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 20:06:01 2023 ] Eval epoch: 47
[ Thu Feb  2 20:09:18 2023 ] 	Mean test loss of 930 batches: 0.7263488815276212.
[ Thu Feb  2 20:09:18 2023 ] 	Top1: 80.09%
[ Thu Feb  2 20:09:18 2023 ] 	Top5: 95.48%
[ Thu Feb  2 20:09:19 2023 ] Training epoch: 48
[ Thu Feb  2 20:17:23 2023 ] 	Mean training loss: 0.1863.  Mean training acc: 94.90%.
[ Thu Feb  2 20:17:23 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 20:17:23 2023 ] Eval epoch: 48
[ Thu Feb  2 20:20:36 2023 ] 	Mean test loss of 930 batches: 0.7465627154675863.
[ Thu Feb  2 20:20:36 2023 ] 	Top1: 79.77%
[ Thu Feb  2 20:20:36 2023 ] 	Top5: 95.57%
[ Thu Feb  2 20:20:37 2023 ] Training epoch: 49
[ Thu Feb  2 20:26:04 2023 ] 	Mean training loss: 0.1854.  Mean training acc: 94.99%.
[ Thu Feb  2 20:26:04 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 20:26:04 2023 ] Eval epoch: 49
[ Thu Feb  2 20:28:25 2023 ] 	Mean test loss of 930 batches: 0.7439777520234867.
[ Thu Feb  2 20:28:25 2023 ] 	Top1: 79.74%
[ Thu Feb  2 20:28:26 2023 ] 	Top5: 95.36%
[ Thu Feb  2 20:28:26 2023 ] Training epoch: 50
[ Thu Feb  2 20:33:40 2023 ] 	Mean training loss: 0.1773.  Mean training acc: 95.24%.
[ Thu Feb  2 20:33:40 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 20:33:40 2023 ] Eval epoch: 50
[ Thu Feb  2 20:36:05 2023 ] 	Mean test loss of 930 batches: 0.7830666787201358.
[ Thu Feb  2 20:36:06 2023 ] 	Top1: 78.89%
[ Thu Feb  2 20:36:06 2023 ] 	Top5: 95.08%
[ Thu Feb  2 20:36:07 2023 ] Training epoch: 51
[ Thu Feb  2 20:41:21 2023 ] 	Mean training loss: 0.1758.  Mean training acc: 95.34%.
[ Thu Feb  2 20:41:21 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 20:41:21 2023 ] Eval epoch: 51
[ Thu Feb  2 20:43:11 2023 ] 	Mean test loss of 930 batches: 0.75702597878633.
[ Thu Feb  2 20:43:11 2023 ] 	Top1: 79.45%
[ Thu Feb  2 20:43:12 2023 ] 	Top5: 95.21%
[ Thu Feb  2 20:43:12 2023 ] Training epoch: 52
[ Thu Feb  2 20:46:40 2023 ] 	Mean training loss: 0.1773.  Mean training acc: 95.18%.
[ Thu Feb  2 20:46:40 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 20:46:40 2023 ] Eval epoch: 52
[ Thu Feb  2 20:48:24 2023 ] 	Mean test loss of 930 batches: 0.7579821907063966.
[ Thu Feb  2 20:48:25 2023 ] 	Top1: 79.51%
[ Thu Feb  2 20:48:25 2023 ] 	Top5: 95.19%
[ Thu Feb  2 20:48:25 2023 ] Training epoch: 53
[ Thu Feb  2 20:51:52 2023 ] 	Mean training loss: 0.1784.  Mean training acc: 95.22%.
[ Thu Feb  2 20:51:52 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 20:51:52 2023 ] Eval epoch: 53
[ Thu Feb  2 20:53:33 2023 ] 	Mean test loss of 930 batches: 0.7641962024553489.
[ Thu Feb  2 20:53:34 2023 ] 	Top1: 79.61%
[ Thu Feb  2 20:53:34 2023 ] 	Top5: 95.03%
[ Thu Feb  2 20:53:34 2023 ] Training epoch: 54
[ Thu Feb  2 20:57:00 2023 ] 	Mean training loss: 0.1741.  Mean training acc: 95.37%.
[ Thu Feb  2 20:57:00 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 20:57:00 2023 ] Eval epoch: 54
[ Thu Feb  2 20:58:43 2023 ] 	Mean test loss of 930 batches: 0.7848076326071575.
[ Thu Feb  2 20:58:44 2023 ] 	Top1: 79.17%
[ Thu Feb  2 20:58:44 2023 ] 	Top5: 94.79%
[ Thu Feb  2 20:58:44 2023 ] Training epoch: 55
[ Thu Feb  2 21:02:10 2023 ] 	Mean training loss: 0.1727.  Mean training acc: 95.45%.
[ Thu Feb  2 21:02:10 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:02:10 2023 ] Eval epoch: 55
[ Thu Feb  2 21:03:52 2023 ] 	Mean test loss of 930 batches: 0.7782254497210185.
[ Thu Feb  2 21:03:52 2023 ] 	Top1: 79.33%
[ Thu Feb  2 21:03:53 2023 ] 	Top5: 95.17%
[ Thu Feb  2 21:03:53 2023 ] Training epoch: 56
[ Thu Feb  2 21:07:19 2023 ] 	Mean training loss: 0.1027.  Mean training acc: 97.78%.
[ Thu Feb  2 21:07:19 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:07:19 2023 ] Eval epoch: 56
[ Thu Feb  2 21:09:02 2023 ] 	Mean test loss of 930 batches: 0.7045251428920736.
[ Thu Feb  2 21:09:02 2023 ] 	Top1: 81.16%
[ Thu Feb  2 21:09:03 2023 ] 	Top5: 95.67%
[ Thu Feb  2 21:09:03 2023 ] Training epoch: 57
[ Thu Feb  2 21:12:29 2023 ] 	Mean training loss: 0.0802.  Mean training acc: 98.41%.
[ Thu Feb  2 21:12:29 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:12:29 2023 ] Eval epoch: 57
[ Thu Feb  2 21:14:12 2023 ] 	Mean test loss of 930 batches: 0.7282470188874711.
[ Thu Feb  2 21:14:13 2023 ] 	Top1: 80.61%
[ Thu Feb  2 21:14:13 2023 ] 	Top5: 95.49%
[ Thu Feb  2 21:14:13 2023 ] Training epoch: 58
[ Thu Feb  2 21:17:40 2023 ] 	Mean training loss: 0.0726.  Mean training acc: 98.64%.
[ Thu Feb  2 21:17:40 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:17:40 2023 ] Eval epoch: 58
[ Thu Feb  2 21:19:22 2023 ] 	Mean test loss of 930 batches: 0.7045948623649536.
[ Thu Feb  2 21:19:23 2023 ] 	Top1: 81.34%
[ Thu Feb  2 21:19:23 2023 ] 	Top5: 95.57%
[ Thu Feb  2 21:19:24 2023 ] Training epoch: 59
[ Thu Feb  2 21:22:49 2023 ] 	Mean training loss: 0.0667.  Mean training acc: 98.82%.
[ Thu Feb  2 21:22:49 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:22:50 2023 ] Eval epoch: 59
[ Thu Feb  2 21:24:32 2023 ] 	Mean test loss of 930 batches: 0.6856313859503116.
[ Thu Feb  2 21:24:32 2023 ] 	Top1: 81.74%
[ Thu Feb  2 21:24:33 2023 ] 	Top5: 95.81%
[ Thu Feb  2 21:24:33 2023 ] Training epoch: 60
[ Thu Feb  2 21:27:59 2023 ] 	Mean training loss: 0.0623.  Mean training acc: 98.90%.
[ Thu Feb  2 21:27:59 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:27:59 2023 ] Eval epoch: 60
[ Thu Feb  2 21:29:40 2023 ] 	Mean test loss of 930 batches: 0.6935786461477639.
[ Thu Feb  2 21:29:40 2023 ] 	Top1: 81.65%
[ Thu Feb  2 21:29:41 2023 ] 	Top5: 95.75%
[ Thu Feb  2 21:29:41 2023 ] Training epoch: 61
[ Thu Feb  2 21:33:07 2023 ] 	Mean training loss: 0.0610.  Mean training acc: 98.90%.
[ Thu Feb  2 21:33:07 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 21:33:07 2023 ] Eval epoch: 61
[ Thu Feb  2 21:35:03 2023 ] 	Mean test loss of 930 batches: 0.7008254806360891.
[ Thu Feb  2 21:35:03 2023 ] 	Top1: 81.43%
[ Thu Feb  2 21:35:04 2023 ] 	Top5: 95.66%
[ Thu Feb  2 21:35:04 2023 ] Training epoch: 62
[ Thu Feb  2 21:40:20 2023 ] 	Mean training loss: 0.0567.  Mean training acc: 99.00%.
[ Thu Feb  2 21:40:20 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 21:40:20 2023 ] Eval epoch: 62
[ Thu Feb  2 21:42:48 2023 ] 	Mean test loss of 930 batches: 0.68994755779383.
[ Thu Feb  2 21:42:48 2023 ] 	Top1: 81.76%
[ Thu Feb  2 21:42:48 2023 ] 	Top5: 95.78%
[ Thu Feb  2 21:42:49 2023 ] Training epoch: 63
[ Thu Feb  2 21:48:02 2023 ] 	Mean training loss: 0.0536.  Mean training acc: 99.11%.
[ Thu Feb  2 21:48:02 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 21:48:02 2023 ] Eval epoch: 63
[ Thu Feb  2 21:50:27 2023 ] 	Mean test loss of 930 batches: 0.7026845589440356.
[ Thu Feb  2 21:50:27 2023 ] 	Top1: 81.50%
[ Thu Feb  2 21:50:28 2023 ] 	Top5: 95.66%
[ Thu Feb  2 21:50:28 2023 ] Training epoch: 64
[ Thu Feb  2 21:55:41 2023 ] 	Mean training loss: 0.0526.  Mean training acc: 99.11%.
[ Thu Feb  2 21:55:41 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Feb  2 21:55:41 2023 ] Eval epoch: 64
[ Thu Feb  2 21:58:07 2023 ] 	Mean test loss of 930 batches: 0.6907939275346135.
[ Thu Feb  2 21:58:08 2023 ] 	Top1: 81.74%
[ Thu Feb  2 21:58:08 2023 ] 	Top5: 95.78%
[ Thu Feb  2 21:58:08 2023 ] Training epoch: 65
[ Thu Feb  2 22:01:36 2023 ] 	Mean training loss: 0.0506.  Mean training acc: 99.20%.
[ Thu Feb  2 22:01:36 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Feb  2 22:01:36 2023 ] Eval epoch: 65
[ Thu Feb  2 22:03:20 2023 ] 	Mean test loss of 930 batches: 0.6894326808071265.
[ Thu Feb  2 22:03:20 2023 ] 	Top1: 81.97%
[ Thu Feb  2 22:03:21 2023 ] 	Top5: 95.81%
[ Thu Feb  2 22:05:11 2023 ] Best accuracy: 0.8196613817105772
[ Thu Feb  2 22:05:11 2023 ] Epoch number: 65
[ Thu Feb  2 22:05:11 2023 ] Model name: work_dir/cset/local_SHT_vel_BL
[ Thu Feb  2 22:05:11 2023 ] Model total number of params: 2141090
[ Thu Feb  2 22:05:11 2023 ] Weight decay: 0.0004
[ Thu Feb  2 22:05:11 2023 ] Base LR: 0.1
[ Thu Feb  2 22:05:11 2023 ] Batch Size: 64
[ Thu Feb  2 22:05:11 2023 ] Test Batch Size: 64
[ Thu Feb  2 22:05:11 2023 ] seed: 1
