[ Tue Jan  3 17:09:07 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:09:47 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHTg_vel_BL', 'model_saved_name': 'work_dir/cset/local_SHTg_vel_BL/runs', 'config': 'config/nturgbd120-cross-set/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.local_SHTg_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 17:09:47 2023 ] # Parameters: 2141090
[ Tue Jan  3 17:09:47 2023 ] Training epoch: 1
[ Tue Jan  3 17:18:43 2023 ] 	Mean training loss: 3.1801.  Mean training acc: 21.97%.
[ Tue Jan  3 17:18:43 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan  3 17:18:43 2023 ] Eval epoch: 1
[ Tue Jan  3 17:22:17 2023 ] 	Mean test loss of 930 batches: 2.8341921831971857.
[ Tue Jan  3 17:22:17 2023 ] 	Top1: 26.53%
[ Tue Jan  3 17:22:18 2023 ] 	Top5: 58.74%
[ Tue Jan  3 17:22:18 2023 ] Training epoch: 2
[ Tue Jan  3 17:31:21 2023 ] 	Mean training loss: 2.1795.  Mean training acc: 40.27%.
[ Tue Jan  3 17:31:21 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:31:21 2023 ] Eval epoch: 2
[ Tue Jan  3 17:35:15 2023 ] 	Mean test loss of 930 batches: 2.693994427624569.
[ Tue Jan  3 17:35:15 2023 ] 	Top1: 34.41%
[ Tue Jan  3 17:35:16 2023 ] 	Top5: 64.55%
[ Tue Jan  3 17:35:16 2023 ] Training epoch: 3
[ Tue Jan  3 17:44:20 2023 ] 	Mean training loss: 1.7937.  Mean training acc: 49.47%.
[ Tue Jan  3 17:44:20 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:44:20 2023 ] Eval epoch: 3
[ Tue Jan  3 17:48:22 2023 ] 	Mean test loss of 930 batches: 2.699910136704804.
[ Tue Jan  3 17:48:23 2023 ] 	Top1: 37.10%
[ Tue Jan  3 17:48:24 2023 ] 	Top5: 69.51%
[ Tue Jan  3 17:48:24 2023 ] Training epoch: 4
[ Tue Jan  3 17:57:13 2023 ] 	Mean training loss: 1.5797.  Mean training acc: 54.83%.
[ Tue Jan  3 17:57:13 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 17:57:14 2023 ] Eval epoch: 4
[ Tue Jan  3 18:01:12 2023 ] 	Mean test loss of 930 batches: 1.579490105823804.
[ Tue Jan  3 18:01:13 2023 ] 	Top1: 54.32%
[ Tue Jan  3 18:01:13 2023 ] 	Top5: 85.05%
[ Tue Jan  3 18:01:13 2023 ] Training epoch: 5
[ Tue Jan  3 18:10:16 2023 ] 	Mean training loss: 1.4501.  Mean training acc: 58.07%.
[ Tue Jan  3 18:10:16 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:10:16 2023 ] Eval epoch: 5
[ Tue Jan  3 18:14:20 2023 ] 	Mean test loss of 930 batches: 1.5332911421534836.
[ Tue Jan  3 18:14:21 2023 ] 	Top1: 56.77%
[ Tue Jan  3 18:14:21 2023 ] 	Top5: 86.37%
[ Tue Jan  3 18:14:22 2023 ] Training epoch: 6
[ Tue Jan  3 18:23:10 2023 ] 	Mean training loss: 1.3194.  Mean training acc: 61.26%.
[ Tue Jan  3 18:23:10 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:23:10 2023 ] Eval epoch: 6
[ Tue Jan  3 18:27:09 2023 ] 	Mean test loss of 930 batches: 1.439417528401139.
[ Tue Jan  3 18:27:09 2023 ] 	Top1: 59.22%
[ Tue Jan  3 18:27:10 2023 ] 	Top5: 86.46%
[ Tue Jan  3 18:27:10 2023 ] Training epoch: 7
[ Tue Jan  3 18:35:45 2023 ] 	Mean training loss: 1.2332.  Mean training acc: 63.79%.
[ Tue Jan  3 18:35:45 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:35:45 2023 ] Eval epoch: 7
[ Tue Jan  3 18:39:51 2023 ] 	Mean test loss of 930 batches: 1.5929295900688376.
[ Tue Jan  3 18:39:52 2023 ] 	Top1: 55.63%
[ Tue Jan  3 18:39:53 2023 ] 	Top5: 85.50%
[ Tue Jan  3 18:39:53 2023 ] Training epoch: 8
[ Tue Jan  3 18:48:32 2023 ] 	Mean training loss: 1.1693.  Mean training acc: 65.56%.
[ Tue Jan  3 18:48:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 18:48:32 2023 ] Eval epoch: 8
[ Tue Jan  3 18:52:43 2023 ] 	Mean test loss of 930 batches: 1.2178891410430273.
[ Tue Jan  3 18:52:44 2023 ] 	Top1: 64.20%
[ Tue Jan  3 18:52:45 2023 ] 	Top5: 90.22%
[ Tue Jan  3 18:52:45 2023 ] Training epoch: 9
[ Tue Jan  3 19:01:18 2023 ] 	Mean training loss: 1.1294.  Mean training acc: 66.66%.
[ Tue Jan  3 19:01:18 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 19:01:18 2023 ] Eval epoch: 9
[ Tue Jan  3 19:05:36 2023 ] 	Mean test loss of 930 batches: 1.5297645569488567.
[ Tue Jan  3 19:05:37 2023 ] 	Top1: 57.72%
[ Tue Jan  3 19:05:37 2023 ] 	Top5: 85.99%
[ Tue Jan  3 19:05:37 2023 ] Training epoch: 10
[ Tue Jan  3 19:14:09 2023 ] 	Mean training loss: 1.0904.  Mean training acc: 67.62%.
[ Tue Jan  3 19:14:09 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:14:09 2023 ] Eval epoch: 10
[ Tue Jan  3 19:18:22 2023 ] 	Mean test loss of 930 batches: 1.3516850954742843.
[ Tue Jan  3 19:18:23 2023 ] 	Top1: 61.82%
[ Tue Jan  3 19:18:24 2023 ] 	Top5: 87.78%
[ Tue Jan  3 19:18:24 2023 ] Training epoch: 11
[ Tue Jan  3 19:26:48 2023 ] 	Mean training loss: 1.0555.  Mean training acc: 68.58%.
[ Tue Jan  3 19:26:48 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:26:49 2023 ] Eval epoch: 11
[ Tue Jan  3 19:31:05 2023 ] 	Mean test loss of 930 batches: 1.4589986561447061.
[ Tue Jan  3 19:31:06 2023 ] 	Top1: 59.63%
[ Tue Jan  3 19:31:07 2023 ] 	Top5: 85.37%
[ Tue Jan  3 19:31:07 2023 ] Training epoch: 12
[ Tue Jan  3 19:39:26 2023 ] 	Mean training loss: 1.0396.  Mean training acc: 69.13%.
[ Tue Jan  3 19:39:26 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 19:39:26 2023 ] Eval epoch: 12
[ Tue Jan  3 19:43:52 2023 ] 	Mean test loss of 930 batches: 1.4363692763351625.
[ Tue Jan  3 19:43:53 2023 ] 	Top1: 60.40%
[ Tue Jan  3 19:43:54 2023 ] 	Top5: 86.86%
[ Tue Jan  3 19:43:54 2023 ] Training epoch: 13
[ Tue Jan  3 19:52:16 2023 ] 	Mean training loss: 1.0070.  Mean training acc: 69.88%.
[ Tue Jan  3 19:52:16 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 19:52:16 2023 ] Eval epoch: 13
[ Tue Jan  3 19:56:39 2023 ] 	Mean test loss of 930 batches: 1.2240192689241902.
[ Tue Jan  3 19:56:40 2023 ] 	Top1: 64.74%
[ Tue Jan  3 19:56:41 2023 ] 	Top5: 89.86%
[ Tue Jan  3 19:56:41 2023 ] Training epoch: 14
[ Tue Jan  3 20:04:59 2023 ] 	Mean training loss: 0.9902.  Mean training acc: 70.60%.
[ Tue Jan  3 20:04:59 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 20:04:59 2023 ] Eval epoch: 14
[ Tue Jan  3 20:09:15 2023 ] 	Mean test loss of 930 batches: 1.4964336596829917.
[ Tue Jan  3 20:09:16 2023 ] 	Top1: 58.64%
[ Tue Jan  3 20:09:17 2023 ] 	Top5: 86.09%
[ Tue Jan  3 20:09:17 2023 ] Training epoch: 15
[ Tue Jan  3 20:17:27 2023 ] 	Mean training loss: 0.9689.  Mean training acc: 71.22%.
[ Tue Jan  3 20:17:27 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 20:17:27 2023 ] Eval epoch: 15
[ Tue Jan  3 20:22:02 2023 ] 	Mean test loss of 930 batches: 1.234603476203898.
[ Tue Jan  3 20:22:03 2023 ] 	Top1: 64.47%
[ Tue Jan  3 20:22:03 2023 ] 	Top5: 90.12%
[ Tue Jan  3 20:22:03 2023 ] Training epoch: 16
[ Tue Jan  3 20:30:10 2023 ] 	Mean training loss: 0.9609.  Mean training acc: 71.34%.
[ Tue Jan  3 20:30:10 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:30:10 2023 ] Eval epoch: 16
[ Tue Jan  3 20:34:36 2023 ] 	Mean test loss of 930 batches: 1.2710621165972884.
[ Tue Jan  3 20:34:37 2023 ] 	Top1: 63.68%
[ Tue Jan  3 20:34:37 2023 ] 	Top5: 89.14%
[ Tue Jan  3 20:34:38 2023 ] Training epoch: 17
[ Tue Jan  3 20:42:54 2023 ] 	Mean training loss: 0.9458.  Mean training acc: 71.84%.
[ Tue Jan  3 20:42:54 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:42:54 2023 ] Eval epoch: 17
[ Tue Jan  3 20:47:35 2023 ] 	Mean test loss of 930 batches: 1.2526798194775017.
[ Tue Jan  3 20:47:36 2023 ] 	Top1: 64.83%
[ Tue Jan  3 20:47:37 2023 ] 	Top5: 90.07%
[ Tue Jan  3 20:47:37 2023 ] Training epoch: 18
[ Tue Jan  3 20:55:50 2023 ] 	Mean training loss: 0.9334.  Mean training acc: 72.12%.
[ Tue Jan  3 20:55:50 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 20:55:50 2023 ] Eval epoch: 18
[ Tue Jan  3 21:00:14 2023 ] 	Mean test loss of 930 batches: 1.1715455299744042.
[ Tue Jan  3 21:00:14 2023 ] 	Top1: 67.09%
[ Tue Jan  3 21:00:15 2023 ] 	Top5: 89.94%
[ Tue Jan  3 21:00:15 2023 ] Training epoch: 19
[ Tue Jan  3 21:08:35 2023 ] 	Mean training loss: 0.9221.  Mean training acc: 72.51%.
[ Tue Jan  3 21:08:35 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 21:08:35 2023 ] Eval epoch: 19
[ Tue Jan  3 21:13:00 2023 ] 	Mean test loss of 930 batches: 1.303867579531926.
[ Tue Jan  3 21:13:00 2023 ] 	Top1: 63.00%
[ Tue Jan  3 21:13:01 2023 ] 	Top5: 89.63%
[ Tue Jan  3 21:13:01 2023 ] Training epoch: 20
[ Tue Jan  3 21:21:21 2023 ] 	Mean training loss: 0.9161.  Mean training acc: 72.50%.
[ Tue Jan  3 21:21:21 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 21:21:22 2023 ] Eval epoch: 20
[ Tue Jan  3 21:25:40 2023 ] 	Mean test loss of 930 batches: 1.6050905831398503.
[ Tue Jan  3 21:25:40 2023 ] 	Top1: 56.49%
[ Tue Jan  3 21:25:41 2023 ] 	Top5: 84.20%
[ Tue Jan  3 21:25:41 2023 ] Training epoch: 21
[ Tue Jan  3 21:34:01 2023 ] 	Mean training loss: 0.9050.  Mean training acc: 73.05%.
[ Tue Jan  3 21:34:02 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:34:02 2023 ] Eval epoch: 21
[ Tue Jan  3 21:38:26 2023 ] 	Mean test loss of 930 batches: 1.3442849749198524.
[ Tue Jan  3 21:38:27 2023 ] 	Top1: 63.56%
[ Tue Jan  3 21:38:28 2023 ] 	Top5: 88.56%
[ Tue Jan  3 21:38:28 2023 ] Training epoch: 22
[ Tue Jan  3 21:47:03 2023 ] 	Mean training loss: 0.8950.  Mean training acc: 73.11%.
[ Tue Jan  3 21:47:03 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 21:47:04 2023 ] Eval epoch: 22
[ Tue Jan  3 21:51:37 2023 ] 	Mean test loss of 930 batches: 1.617811579345375.
[ Tue Jan  3 21:51:38 2023 ] 	Top1: 56.88%
[ Tue Jan  3 21:51:39 2023 ] 	Top5: 86.01%
[ Tue Jan  3 21:51:39 2023 ] Training epoch: 23
[ Tue Jan  3 22:00:08 2023 ] 	Mean training loss: 0.8882.  Mean training acc: 73.34%.
[ Tue Jan  3 22:00:08 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:00:08 2023 ] Eval epoch: 23
[ Tue Jan  3 22:04:24 2023 ] 	Mean test loss of 930 batches: 1.7125658953061669.
[ Tue Jan  3 22:04:25 2023 ] 	Top1: 57.41%
[ Tue Jan  3 22:04:26 2023 ] 	Top5: 85.47%
[ Tue Jan  3 22:04:26 2023 ] Training epoch: 24
[ Tue Jan  3 22:12:49 2023 ] 	Mean training loss: 0.8778.  Mean training acc: 73.50%.
[ Tue Jan  3 22:12:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:12:49 2023 ] Eval epoch: 24
[ Tue Jan  3 22:17:00 2023 ] 	Mean test loss of 930 batches: 1.2287496099548956.
[ Tue Jan  3 22:17:00 2023 ] 	Top1: 66.02%
[ Tue Jan  3 22:17:01 2023 ] 	Top5: 90.01%
[ Tue Jan  3 22:17:01 2023 ] Training epoch: 25
[ Tue Jan  3 22:25:36 2023 ] 	Mean training loss: 0.8758.  Mean training acc: 73.62%.
[ Tue Jan  3 22:25:36 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 22:25:37 2023 ] Eval epoch: 25
[ Tue Jan  3 22:29:56 2023 ] 	Mean test loss of 930 batches: 1.1509917827383165.
[ Tue Jan  3 22:29:56 2023 ] 	Top1: 67.05%
[ Tue Jan  3 22:29:57 2023 ] 	Top5: 90.69%
[ Tue Jan  3 22:29:57 2023 ] Training epoch: 26
[ Tue Jan  3 22:38:32 2023 ] 	Mean training loss: 0.8676.  Mean training acc: 73.87%.
[ Tue Jan  3 22:38:32 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Jan  3 22:38:33 2023 ] Eval epoch: 26
[ Tue Jan  3 22:42:46 2023 ] 	Mean test loss of 930 batches: 1.3519699721567093.
[ Tue Jan  3 22:42:47 2023 ] 	Top1: 62.81%
[ Tue Jan  3 22:42:48 2023 ] 	Top5: 88.30%
[ Tue Jan  3 22:42:48 2023 ] Training epoch: 27
[ Tue Jan  3 22:51:26 2023 ] 	Mean training loss: 0.8716.  Mean training acc: 73.87%.
[ Tue Jan  3 22:51:26 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 22:51:27 2023 ] Eval epoch: 27
[ Tue Jan  3 22:55:45 2023 ] 	Mean test loss of 930 batches: 1.268751597212207.
[ Tue Jan  3 22:55:46 2023 ] 	Top1: 65.42%
[ Tue Jan  3 22:55:47 2023 ] 	Top5: 89.36%
[ Tue Jan  3 22:55:47 2023 ] Training epoch: 28
[ Tue Jan  3 23:04:28 2023 ] 	Mean training loss: 0.8531.  Mean training acc: 74.20%.
[ Tue Jan  3 23:04:28 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:04:29 2023 ] Eval epoch: 28
[ Tue Jan  3 23:08:48 2023 ] 	Mean test loss of 930 batches: 1.1951237941621453.
[ Tue Jan  3 23:08:50 2023 ] 	Top1: 65.97%
[ Tue Jan  3 23:08:50 2023 ] 	Top5: 90.29%
[ Tue Jan  3 23:08:51 2023 ] Training epoch: 29
[ Tue Jan  3 23:17:41 2023 ] 	Mean training loss: 0.8576.  Mean training acc: 74.21%.
[ Tue Jan  3 23:17:41 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:17:41 2023 ] Eval epoch: 29
[ Tue Jan  3 23:22:06 2023 ] 	Mean test loss of 930 batches: 1.1224218841201516.
[ Tue Jan  3 23:22:07 2023 ] 	Top1: 68.08%
[ Tue Jan  3 23:22:08 2023 ] 	Top5: 91.46%
[ Tue Jan  3 23:22:08 2023 ] Training epoch: 30
[ Tue Jan  3 23:31:08 2023 ] 	Mean training loss: 0.8545.  Mean training acc: 74.34%.
[ Tue Jan  3 23:31:08 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jan  3 23:31:08 2023 ] Eval epoch: 30
[ Tue Jan  3 23:35:10 2023 ] 	Mean test loss of 930 batches: 1.0112908865495394.
[ Tue Jan  3 23:35:11 2023 ] 	Top1: 70.23%
[ Tue Jan  3 23:35:12 2023 ] 	Top5: 92.52%
[ Tue Jan  3 23:35:12 2023 ] Training epoch: 31
[ Tue Jan  3 23:44:00 2023 ] 	Mean training loss: 0.8385.  Mean training acc: 74.85%.
[ Tue Jan  3 23:44:00 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 23:44:00 2023 ] Eval epoch: 31
[ Tue Jan  3 23:47:54 2023 ] 	Mean test loss of 930 batches: 1.5137153426485677.
[ Tue Jan  3 23:47:56 2023 ] 	Top1: 61.08%
[ Tue Jan  3 23:47:57 2023 ] 	Top5: 86.37%
[ Tue Jan  3 23:47:57 2023 ] Training epoch: 32
[ Tue Jan  3 23:56:49 2023 ] 	Mean training loss: 0.8522.  Mean training acc: 74.42%.
[ Tue Jan  3 23:56:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan  3 23:56:49 2023 ] Eval epoch: 32
[ Wed Jan  4 00:00:49 2023 ] 	Mean test loss of 930 batches: 1.3460728165603453.
[ Wed Jan  4 00:00:50 2023 ] 	Top1: 62.07%
[ Wed Jan  4 00:00:51 2023 ] 	Top5: 89.76%
[ Wed Jan  4 00:00:51 2023 ] Training epoch: 33
[ Wed Jan  4 00:09:33 2023 ] 	Mean training loss: 0.8377.  Mean training acc: 75.00%.
[ Wed Jan  4 00:09:34 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:09:34 2023 ] Eval epoch: 33
[ Wed Jan  4 00:13:37 2023 ] 	Mean test loss of 930 batches: 1.2089465669726813.
[ Wed Jan  4 00:13:38 2023 ] 	Top1: 66.42%
[ Wed Jan  4 00:13:39 2023 ] 	Top5: 90.10%
[ Wed Jan  4 00:13:39 2023 ] Training epoch: 34
[ Wed Jan  4 00:22:19 2023 ] 	Mean training loss: 0.8363.  Mean training acc: 74.91%.
[ Wed Jan  4 00:22:20 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 00:22:20 2023 ] Eval epoch: 34
[ Wed Jan  4 00:26:31 2023 ] 	Mean test loss of 930 batches: 1.2147187267259885.
[ Wed Jan  4 00:26:32 2023 ] 	Top1: 66.24%
[ Wed Jan  4 00:26:33 2023 ] 	Top5: 90.15%
[ Wed Jan  4 00:26:33 2023 ] Training epoch: 35
[ Wed Jan  4 00:35:11 2023 ] 	Mean training loss: 0.8354.  Mean training acc: 74.93%.
[ Wed Jan  4 00:35:11 2023 ] 	Time consumption: [Data]02%, [Network]96%
[ Wed Jan  4 00:35:11 2023 ] Eval epoch: 35
[ Wed Jan  4 00:39:20 2023 ] 	Mean test loss of 930 batches: 1.1585185093264425.
[ Wed Jan  4 00:39:21 2023 ] 	Top1: 67.91%
[ Wed Jan  4 00:39:21 2023 ] 	Top5: 90.50%
[ Wed Jan  4 00:39:21 2023 ] Training epoch: 36
[ Wed Jan  4 00:47:45 2023 ] 	Mean training loss: 0.4880.  Mean training acc: 85.48%.
[ Wed Jan  4 00:47:45 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 00:47:45 2023 ] Eval epoch: 36
[ Wed Jan  4 00:52:01 2023 ] 	Mean test loss of 930 batches: 0.6415949185929631.
[ Wed Jan  4 00:52:02 2023 ] 	Top1: 80.84%
[ Wed Jan  4 00:52:03 2023 ] 	Top5: 95.93%
[ Wed Jan  4 00:52:03 2023 ] Training epoch: 37
[ Wed Jan  4 01:00:18 2023 ] 	Mean training loss: 0.3917.  Mean training acc: 88.39%.
[ Wed Jan  4 01:00:18 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:00:19 2023 ] Eval epoch: 37
[ Wed Jan  4 01:04:43 2023 ] 	Mean test loss of 930 batches: 0.6263615305465395.
[ Wed Jan  4 01:04:43 2023 ] 	Top1: 81.44%
[ Wed Jan  4 01:04:44 2023 ] 	Top5: 96.09%
[ Wed Jan  4 01:04:44 2023 ] Training epoch: 38
[ Wed Jan  4 01:12:57 2023 ] 	Mean training loss: 0.3510.  Mean training acc: 89.54%.
[ Wed Jan  4 01:12:57 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 01:12:57 2023 ] Eval epoch: 38
[ Wed Jan  4 01:17:20 2023 ] 	Mean test loss of 930 batches: 0.6246155981895745.
[ Wed Jan  4 01:17:21 2023 ] 	Top1: 81.62%
[ Wed Jan  4 01:17:21 2023 ] 	Top5: 96.19%
[ Wed Jan  4 01:17:21 2023 ] Training epoch: 39
[ Wed Jan  4 01:25:25 2023 ] 	Mean training loss: 0.3188.  Mean training acc: 90.48%.
[ Wed Jan  4 01:25:25 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:25:25 2023 ] Eval epoch: 39
[ Wed Jan  4 01:29:51 2023 ] 	Mean test loss of 930 batches: 0.6468145332028788.
[ Wed Jan  4 01:29:52 2023 ] 	Top1: 81.05%
[ Wed Jan  4 01:29:53 2023 ] 	Top5: 95.99%
[ Wed Jan  4 01:29:53 2023 ] Training epoch: 40
[ Wed Jan  4 01:37:51 2023 ] 	Mean training loss: 0.2979.  Mean training acc: 91.31%.
[ Wed Jan  4 01:37:51 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:37:51 2023 ] Eval epoch: 40
[ Wed Jan  4 01:42:19 2023 ] 	Mean test loss of 930 batches: 0.635816650629364.
[ Wed Jan  4 01:42:20 2023 ] 	Top1: 81.46%
[ Wed Jan  4 01:42:21 2023 ] 	Top5: 96.02%
[ Wed Jan  4 01:42:21 2023 ] Training epoch: 41
[ Wed Jan  4 01:50:12 2023 ] 	Mean training loss: 0.2724.  Mean training acc: 92.14%.
[ Wed Jan  4 01:50:12 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 01:50:13 2023 ] Eval epoch: 41
[ Wed Jan  4 01:54:49 2023 ] 	Mean test loss of 930 batches: 0.6571534542947687.
[ Wed Jan  4 01:54:50 2023 ] 	Top1: 81.04%
[ Wed Jan  4 01:54:51 2023 ] 	Top5: 96.08%
[ Wed Jan  4 01:54:51 2023 ] Training epoch: 42
[ Wed Jan  4 02:02:36 2023 ] 	Mean training loss: 0.2541.  Mean training acc: 92.72%.
[ Wed Jan  4 02:02:36 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:02:36 2023 ] Eval epoch: 42
[ Wed Jan  4 02:07:08 2023 ] 	Mean test loss of 930 batches: 0.6531411626005685.
[ Wed Jan  4 02:07:08 2023 ] 	Top1: 81.33%
[ Wed Jan  4 02:07:09 2023 ] 	Top5: 95.83%
[ Wed Jan  4 02:07:09 2023 ] Training epoch: 43
[ Wed Jan  4 02:15:07 2023 ] 	Mean training loss: 0.2417.  Mean training acc: 93.14%.
[ Wed Jan  4 02:15:07 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:15:07 2023 ] Eval epoch: 43
[ Wed Jan  4 02:19:54 2023 ] 	Mean test loss of 930 batches: 0.6647214284026495.
[ Wed Jan  4 02:19:55 2023 ] 	Top1: 81.12%
[ Wed Jan  4 02:19:56 2023 ] 	Top5: 95.71%
[ Wed Jan  4 02:19:56 2023 ] Training epoch: 44
[ Wed Jan  4 02:27:35 2023 ] 	Mean training loss: 0.2268.  Mean training acc: 93.64%.
[ Wed Jan  4 02:27:35 2023 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jan  4 02:27:35 2023 ] Eval epoch: 44
[ Wed Jan  4 02:32:12 2023 ] 	Mean test loss of 930 batches: 0.658828459607978.
[ Wed Jan  4 02:32:12 2023 ] 	Top1: 81.51%
[ Wed Jan  4 02:32:13 2023 ] 	Top5: 95.84%
[ Wed Jan  4 02:32:13 2023 ] Training epoch: 45
[ Wed Jan  4 02:40:03 2023 ] 	Mean training loss: 0.2147.  Mean training acc: 94.07%.
[ Wed Jan  4 02:40:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 02:40:04 2023 ] Eval epoch: 45
[ Wed Jan  4 02:44:34 2023 ] 	Mean test loss of 930 batches: 0.6714187097245006.
[ Wed Jan  4 02:44:35 2023 ] 	Top1: 81.01%
[ Wed Jan  4 02:44:36 2023 ] 	Top5: 95.96%
[ Wed Jan  4 02:44:36 2023 ] Training epoch: 46
[ Wed Jan  4 02:52:24 2023 ] 	Mean training loss: 0.1985.  Mean training acc: 94.59%.
[ Wed Jan  4 02:52:24 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 02:52:24 2023 ] Eval epoch: 46
[ Wed Jan  4 02:56:40 2023 ] 	Mean test loss of 930 batches: 0.6982739195708305.
[ Wed Jan  4 02:56:41 2023 ] 	Top1: 80.70%
[ Wed Jan  4 02:56:41 2023 ] 	Top5: 95.63%
[ Wed Jan  4 02:56:42 2023 ] Training epoch: 47
[ Wed Jan  4 03:04:39 2023 ] 	Mean training loss: 0.1994.  Mean training acc: 94.48%.
[ Wed Jan  4 03:04:39 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:04:39 2023 ] Eval epoch: 47
[ Wed Jan  4 03:08:59 2023 ] 	Mean test loss of 930 batches: 0.7093822765334319.
[ Wed Jan  4 03:09:00 2023 ] 	Top1: 80.34%
[ Wed Jan  4 03:09:01 2023 ] 	Top5: 95.42%
[ Wed Jan  4 03:09:01 2023 ] Training epoch: 48
[ Wed Jan  4 03:17:06 2023 ] 	Mean training loss: 0.1944.  Mean training acc: 94.70%.
[ Wed Jan  4 03:17:06 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:17:07 2023 ] Eval epoch: 48
[ Wed Jan  4 03:21:24 2023 ] 	Mean test loss of 930 batches: 0.6977571702772571.
[ Wed Jan  4 03:21:26 2023 ] 	Top1: 80.47%
[ Wed Jan  4 03:21:26 2023 ] 	Top5: 95.60%
[ Wed Jan  4 03:21:26 2023 ] Training epoch: 49
[ Wed Jan  4 03:29:32 2023 ] 	Mean training loss: 0.1906.  Mean training acc: 94.73%.
[ Wed Jan  4 03:29:32 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:29:33 2023 ] Eval epoch: 49
[ Wed Jan  4 03:33:49 2023 ] 	Mean test loss of 930 batches: 0.731043587737186.
[ Wed Jan  4 03:33:49 2023 ] 	Top1: 79.99%
[ Wed Jan  4 03:33:50 2023 ] 	Top5: 95.59%
[ Wed Jan  4 03:33:50 2023 ] Training epoch: 50
[ Wed Jan  4 03:42:04 2023 ] 	Mean training loss: 0.1827.  Mean training acc: 95.17%.
[ Wed Jan  4 03:42:04 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:42:04 2023 ] Eval epoch: 50
[ Wed Jan  4 03:46:29 2023 ] 	Mean test loss of 930 batches: 0.7785884504997602.
[ Wed Jan  4 03:46:30 2023 ] 	Top1: 78.69%
[ Wed Jan  4 03:46:30 2023 ] 	Top5: 95.04%
[ Wed Jan  4 03:46:30 2023 ] Training epoch: 51
[ Wed Jan  4 03:54:33 2023 ] 	Mean training loss: 0.1818.  Mean training acc: 95.17%.
[ Wed Jan  4 03:54:33 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 03:54:33 2023 ] Eval epoch: 51
[ Wed Jan  4 03:58:53 2023 ] 	Mean test loss of 930 batches: 0.740078846613566.
[ Wed Jan  4 03:58:54 2023 ] 	Top1: 79.92%
[ Wed Jan  4 03:58:55 2023 ] 	Top5: 95.28%
[ Wed Jan  4 03:58:55 2023 ] Training epoch: 52
[ Wed Jan  4 04:06:58 2023 ] 	Mean training loss: 0.1805.  Mean training acc: 95.24%.
[ Wed Jan  4 04:06:58 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:06:58 2023 ] Eval epoch: 52
[ Wed Jan  4 04:11:16 2023 ] 	Mean test loss of 930 batches: 0.7824336846749629.
[ Wed Jan  4 04:11:17 2023 ] 	Top1: 79.06%
[ Wed Jan  4 04:11:17 2023 ] 	Top5: 95.01%
[ Wed Jan  4 04:11:17 2023 ] Training epoch: 53
[ Wed Jan  4 04:19:26 2023 ] 	Mean training loss: 0.1792.  Mean training acc: 95.14%.
[ Wed Jan  4 04:19:26 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:19:27 2023 ] Eval epoch: 53
[ Wed Jan  4 04:23:54 2023 ] 	Mean test loss of 930 batches: 0.7509462126080066.
[ Wed Jan  4 04:23:55 2023 ] 	Top1: 79.77%
[ Wed Jan  4 04:23:55 2023 ] 	Top5: 95.24%
[ Wed Jan  4 04:23:55 2023 ] Training epoch: 54
[ Wed Jan  4 04:32:03 2023 ] 	Mean training loss: 0.1768.  Mean training acc: 95.19%.
[ Wed Jan  4 04:32:03 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:32:04 2023 ] Eval epoch: 54
[ Wed Jan  4 04:36:30 2023 ] 	Mean test loss of 930 batches: 0.804243899801726.
[ Wed Jan  4 04:36:31 2023 ] 	Top1: 78.92%
[ Wed Jan  4 04:36:31 2023 ] 	Top5: 94.79%
[ Wed Jan  4 04:36:31 2023 ] Training epoch: 55
[ Wed Jan  4 04:44:30 2023 ] 	Mean training loss: 0.1796.  Mean training acc: 95.21%.
[ Wed Jan  4 04:44:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:44:30 2023 ] Eval epoch: 55
[ Wed Jan  4 04:48:52 2023 ] 	Mean test loss of 930 batches: 0.822960324505324.
[ Wed Jan  4 04:48:52 2023 ] 	Top1: 78.16%
[ Wed Jan  4 04:48:53 2023 ] 	Top5: 94.62%
[ Wed Jan  4 04:48:53 2023 ] Training epoch: 56
[ Wed Jan  4 04:56:52 2023 ] 	Mean training loss: 0.1098.  Mean training acc: 97.45%.
[ Wed Jan  4 04:56:52 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 04:56:53 2023 ] Eval epoch: 56
[ Wed Jan  4 05:01:12 2023 ] 	Mean test loss of 930 batches: 0.6898906964528304.
[ Wed Jan  4 05:01:12 2023 ] 	Top1: 81.46%
[ Wed Jan  4 05:01:13 2023 ] 	Top5: 95.67%
[ Wed Jan  4 05:01:13 2023 ] Training epoch: 57
[ Wed Jan  4 05:09:22 2023 ] 	Mean training loss: 0.0828.  Mean training acc: 98.35%.
[ Wed Jan  4 05:09:22 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:09:22 2023 ] Eval epoch: 57
[ Wed Jan  4 05:13:44 2023 ] 	Mean test loss of 930 batches: 0.7211287153664455.
[ Wed Jan  4 05:13:45 2023 ] 	Top1: 80.75%
[ Wed Jan  4 05:13:46 2023 ] 	Top5: 95.45%
[ Wed Jan  4 05:13:46 2023 ] Training epoch: 58
[ Wed Jan  4 05:21:49 2023 ] 	Mean training loss: 0.0754.  Mean training acc: 98.58%.
[ Wed Jan  4 05:21:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:21:49 2023 ] Eval epoch: 58
[ Wed Jan  4 05:26:06 2023 ] 	Mean test loss of 930 batches: 0.6936248554657864.
[ Wed Jan  4 05:26:06 2023 ] 	Top1: 81.57%
[ Wed Jan  4 05:26:07 2023 ] 	Top5: 95.69%
[ Wed Jan  4 05:26:07 2023 ] Training epoch: 59
[ Wed Jan  4 05:34:07 2023 ] 	Mean training loss: 0.0682.  Mean training acc: 98.73%.
[ Wed Jan  4 05:34:07 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:34:07 2023 ] Eval epoch: 59
[ Wed Jan  4 05:38:23 2023 ] 	Mean test loss of 930 batches: 0.6727192751182023.
[ Wed Jan  4 05:38:24 2023 ] 	Top1: 82.05%
[ Wed Jan  4 05:38:25 2023 ] 	Top5: 95.84%
[ Wed Jan  4 05:38:25 2023 ] Training epoch: 60
[ Wed Jan  4 05:46:29 2023 ] 	Mean training loss: 0.0644.  Mean training acc: 98.79%.
[ Wed Jan  4 05:46:30 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:46:30 2023 ] Eval epoch: 60
[ Wed Jan  4 05:50:54 2023 ] 	Mean test loss of 930 batches: 0.6805466804773577.
[ Wed Jan  4 05:50:55 2023 ] 	Top1: 81.85%
[ Wed Jan  4 05:50:56 2023 ] 	Top5: 95.73%
[ Wed Jan  4 05:50:56 2023 ] Training epoch: 61
[ Wed Jan  4 05:59:11 2023 ] 	Mean training loss: 0.0626.  Mean training acc: 98.90%.
[ Wed Jan  4 05:59:11 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 05:59:11 2023 ] Eval epoch: 61
[ Wed Jan  4 06:03:37 2023 ] 	Mean test loss of 930 batches: 0.6923758941392104.
[ Wed Jan  4 06:03:38 2023 ] 	Top1: 81.52%
[ Wed Jan  4 06:03:39 2023 ] 	Top5: 95.67%
[ Wed Jan  4 06:03:39 2023 ] Training epoch: 62
[ Wed Jan  4 06:11:49 2023 ] 	Mean training loss: 0.0575.  Mean training acc: 99.00%.
[ Wed Jan  4 06:11:49 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:11:49 2023 ] Eval epoch: 62
[ Wed Jan  4 06:15:57 2023 ] 	Mean test loss of 930 batches: 0.6842821652209887.
[ Wed Jan  4 06:15:57 2023 ] 	Top1: 81.89%
[ Wed Jan  4 06:15:58 2023 ] 	Top5: 95.75%
[ Wed Jan  4 06:15:58 2023 ] Training epoch: 63
[ Wed Jan  4 06:24:05 2023 ] 	Mean training loss: 0.0558.  Mean training acc: 99.05%.
[ Wed Jan  4 06:24:05 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:24:05 2023 ] Eval epoch: 63
[ Wed Jan  4 06:28:13 2023 ] 	Mean test loss of 930 batches: 0.6924446041064878.
[ Wed Jan  4 06:28:13 2023 ] 	Top1: 81.89%
[ Wed Jan  4 06:28:14 2023 ] 	Top5: 95.59%
[ Wed Jan  4 06:28:14 2023 ] Training epoch: 64
[ Wed Jan  4 06:36:29 2023 ] 	Mean training loss: 0.0538.  Mean training acc: 99.11%.
[ Wed Jan  4 06:36:29 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:36:29 2023 ] Eval epoch: 64
[ Wed Jan  4 06:40:33 2023 ] 	Mean test loss of 930 batches: 0.6796768307926193.
[ Wed Jan  4 06:40:34 2023 ] 	Top1: 82.02%
[ Wed Jan  4 06:40:34 2023 ] 	Top5: 95.78%
[ Wed Jan  4 06:40:35 2023 ] Training epoch: 65
[ Wed Jan  4 06:48:56 2023 ] 	Mean training loss: 0.0519.  Mean training acc: 99.20%.
[ Wed Jan  4 06:48:56 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan  4 06:48:56 2023 ] Eval epoch: 65
[ Wed Jan  4 06:52:55 2023 ] 	Mean test loss of 930 batches: 0.6810338290628567.
[ Wed Jan  4 06:52:56 2023 ] 	Top1: 82.01%
[ Wed Jan  4 06:52:57 2023 ] 	Top5: 95.79%
[ Wed Jan  4 06:57:06 2023 ] Best accuracy: 0.8205356692502984
[ Wed Jan  4 06:57:06 2023 ] Epoch number: 1
[ Wed Jan  4 06:57:06 2023 ] Model name: work_dir/cset/local_SHTg_vel_BL
[ Wed Jan  4 06:57:06 2023 ] Model total number of params: 2141090
[ Wed Jan  4 06:57:06 2023 ] Weight decay: 0.0004
[ Wed Jan  4 06:57:06 2023 ] Base LR: 0.1
[ Wed Jan  4 06:57:06 2023 ] Batch Size: 64
[ Wed Jan  4 06:57:06 2023 ] Test Batch Size: 64
[ Wed Jan  4 06:57:06 2023 ] seed: 1
