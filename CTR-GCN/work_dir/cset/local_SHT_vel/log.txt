[ Sun Nov  6 22:49:09 2022 ] using warm up, epoch: 5
[ Sun Nov  6 22:53:06 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/cset/local_SHTg_vel', 'model_saved_name': 'work_dir/ntu120/cset/local_SHTg_vel/runs', 'config': 'config/nturgbd120-cross-set/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.local_SHTg.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [5], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Sun Nov  6 22:53:06 2022 ] # Parameters: 2141090
[ Sun Nov  6 22:53:06 2022 ] Training epoch: 1
[ Sun Nov  6 23:30:01 2022 ] 	Mean training loss: 3.0803.  Mean training acc: 23.52%.
[ Sun Nov  6 23:30:01 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Sun Nov  6 23:30:01 2022 ] Eval epoch: 1
[ Mon Nov  7 00:07:26 2022 ] 	Mean test loss of 930 batches: 2.7051138688159244.
[ Mon Nov  7 00:07:28 2022 ] 	Top1: 28.43%
[ Mon Nov  7 00:07:29 2022 ] 	Top5: 63.07%
[ Mon Nov  7 00:07:30 2022 ] Training epoch: 2
[ Mon Nov  7 00:43:21 2022 ] 	Mean training loss: 2.1555.  Mean training acc: 40.77%.
[ Mon Nov  7 00:43:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 00:43:21 2022 ] Eval epoch: 2
[ Mon Nov  7 01:21:29 2022 ] 	Mean test loss of 930 batches: 2.0490228479908357.
[ Mon Nov  7 01:21:30 2022 ] 	Top1: 43.28%
[ Mon Nov  7 01:21:32 2022 ] 	Top5: 78.20%
[ Mon Nov  7 01:21:32 2022 ] Training epoch: 3
[ Mon Nov  7 01:58:54 2022 ] 	Mean training loss: 1.7636.  Mean training acc: 49.94%.
[ Mon Nov  7 01:58:54 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 01:58:54 2022 ] Eval epoch: 3
[ Mon Nov  7 02:36:04 2022 ] 	Mean test loss of 930 batches: 1.7478289406145773.
[ Mon Nov  7 02:36:05 2022 ] 	Top1: 50.27%
[ Mon Nov  7 02:36:06 2022 ] 	Top5: 82.46%
[ Mon Nov  7 02:36:06 2022 ] Training epoch: 4
[ Mon Nov  7 03:12:11 2022 ] 	Mean training loss: 1.5618.  Mean training acc: 55.01%.
[ Mon Nov  7 03:12:11 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 03:12:11 2022 ] Eval epoch: 4
[ Mon Nov  7 03:47:45 2022 ] 	Mean test loss of 930 batches: 1.7373623165392107.
[ Mon Nov  7 03:47:46 2022 ] 	Top1: 51.32%
[ Mon Nov  7 03:47:47 2022 ] 	Top5: 83.92%
[ Mon Nov  7 03:47:47 2022 ] Training epoch: 5
[ Mon Nov  7 04:22:13 2022 ] 	Mean training loss: 1.4527.  Mean training acc: 57.89%.
[ Mon Nov  7 04:22:13 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 04:22:13 2022 ] Eval epoch: 5
[ Mon Nov  7 04:57:41 2022 ] 	Mean test loss of 930 batches: 1.3787213540846301.
[ Mon Nov  7 04:57:42 2022 ] 	Top1: 60.43%
[ Mon Nov  7 04:57:44 2022 ] 	Top5: 87.68%
[ Mon Nov  7 04:57:44 2022 ] Training epoch: 6
[ Mon Nov  7 05:31:59 2022 ] 	Mean training loss: 1.3216.  Mean training acc: 61.57%.
[ Mon Nov  7 05:31:59 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 05:31:59 2022 ] Eval epoch: 6
[ Mon Nov  7 06:07:00 2022 ] 	Mean test loss of 930 batches: 1.6577017548263715.
[ Mon Nov  7 06:07:01 2022 ] 	Top1: 56.05%
[ Mon Nov  7 06:07:02 2022 ] 	Top5: 83.59%
[ Mon Nov  7 06:07:02 2022 ] Training epoch: 7
[ Mon Nov  7 06:45:01 2022 ] 	Mean training loss: 1.2268.  Mean training acc: 64.08%.
[ Mon Nov  7 06:45:01 2022 ] 	Time consumption: [Data]01%, [Network]89%
[ Mon Nov  7 06:45:01 2022 ] Eval epoch: 7
[ Mon Nov  7 07:19:54 2022 ] 	Mean test loss of 930 batches: 1.3670171128165338.
[ Mon Nov  7 07:19:55 2022 ] 	Top1: 61.76%
[ Mon Nov  7 07:19:57 2022 ] 	Top5: 88.04%
[ Mon Nov  7 07:19:57 2022 ] Training epoch: 8
[ Mon Nov  7 07:54:15 2022 ] 	Mean training loss: 1.1749.  Mean training acc: 65.35%.
[ Mon Nov  7 07:54:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 07:54:15 2022 ] Eval epoch: 8
[ Mon Nov  7 08:30:03 2022 ] 	Mean test loss of 930 batches: 1.2665149041401442.
[ Mon Nov  7 08:30:04 2022 ] 	Top1: 63.22%
[ Mon Nov  7 08:30:05 2022 ] 	Top5: 89.70%
[ Mon Nov  7 08:30:06 2022 ] Training epoch: 9
[ Mon Nov  7 09:06:00 2022 ] 	Mean training loss: 1.1286.  Mean training acc: 66.61%.
[ Mon Nov  7 09:06:00 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 09:06:00 2022 ] Eval epoch: 9
[ Mon Nov  7 09:41:42 2022 ] 	Mean test loss of 930 batches: 1.2457337712408394.
[ Mon Nov  7 09:41:44 2022 ] 	Top1: 64.61%
[ Mon Nov  7 09:41:45 2022 ] 	Top5: 89.54%
[ Mon Nov  7 09:41:45 2022 ] Training epoch: 10
[ Mon Nov  7 10:19:16 2022 ] 	Mean training loss: 1.0832.  Mean training acc: 68.10%.
[ Mon Nov  7 10:19:16 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 10:19:16 2022 ] Eval epoch: 10
[ Mon Nov  7 10:57:26 2022 ] 	Mean test loss of 930 batches: 1.329459358158932.
[ Mon Nov  7 10:57:28 2022 ] 	Top1: 61.63%
[ Mon Nov  7 10:57:29 2022 ] 	Top5: 88.74%
[ Mon Nov  7 10:57:29 2022 ] Training epoch: 11
[ Mon Nov  7 11:37:52 2022 ] 	Mean training loss: 1.0538.  Mean training acc: 68.72%.
[ Mon Nov  7 11:37:52 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 11:37:52 2022 ] Eval epoch: 11
[ Mon Nov  7 12:17:08 2022 ] 	Mean test loss of 930 batches: 1.5116461421853753.
[ Mon Nov  7 12:17:09 2022 ] 	Top1: 58.47%
[ Mon Nov  7 12:17:10 2022 ] 	Top5: 86.00%
[ Mon Nov  7 12:17:10 2022 ] Training epoch: 12
[ Mon Nov  7 12:55:48 2022 ] 	Mean training loss: 1.0320.  Mean training acc: 69.02%.
[ Mon Nov  7 12:55:48 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 12:55:48 2022 ] Eval epoch: 12
[ Mon Nov  7 13:36:05 2022 ] 	Mean test loss of 930 batches: 1.1641362272283082.
[ Mon Nov  7 13:36:06 2022 ] 	Top1: 66.44%
[ Mon Nov  7 13:36:07 2022 ] 	Top5: 90.45%
[ Mon Nov  7 13:36:07 2022 ] Training epoch: 13
[ Mon Nov  7 14:14:46 2022 ] 	Mean training loss: 0.9941.  Mean training acc: 70.20%.
[ Mon Nov  7 14:14:46 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 14:14:46 2022 ] Eval epoch: 13
[ Mon Nov  7 14:54:03 2022 ] 	Mean test loss of 930 batches: 1.1977853344332787.
[ Mon Nov  7 14:54:04 2022 ] 	Top1: 65.51%
[ Mon Nov  7 14:54:06 2022 ] 	Top5: 90.55%
[ Mon Nov  7 14:54:06 2022 ] Training epoch: 14
[ Mon Nov  7 15:33:57 2022 ] 	Mean training loss: 0.9740.  Mean training acc: 70.72%.
[ Mon Nov  7 15:33:57 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 15:33:57 2022 ] Eval epoch: 14
[ Mon Nov  7 16:13:05 2022 ] 	Mean test loss of 930 batches: 1.2205218863423153.
[ Mon Nov  7 16:13:07 2022 ] 	Top1: 64.52%
[ Mon Nov  7 16:13:08 2022 ] 	Top5: 90.53%
[ Mon Nov  7 16:13:08 2022 ] Training epoch: 15
[ Mon Nov  7 16:51:35 2022 ] 	Mean training loss: 0.9648.  Mean training acc: 70.98%.
[ Mon Nov  7 16:51:35 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 16:51:35 2022 ] Eval epoch: 15
[ Mon Nov  7 17:30:58 2022 ] 	Mean test loss of 930 batches: 1.2252090567863116.
[ Mon Nov  7 17:30:59 2022 ] 	Top1: 65.67%
[ Mon Nov  7 17:31:01 2022 ] 	Top5: 89.71%
[ Mon Nov  7 17:31:01 2022 ] Training epoch: 16
[ Mon Nov  7 18:11:38 2022 ] 	Mean training loss: 0.9515.  Mean training acc: 71.54%.
[ Mon Nov  7 18:11:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 18:11:38 2022 ] Eval epoch: 16
[ Mon Nov  7 18:52:37 2022 ] 	Mean test loss of 930 batches: 1.2461959014336268.
[ Mon Nov  7 18:52:39 2022 ] 	Top1: 64.52%
[ Mon Nov  7 18:52:40 2022 ] 	Top5: 89.55%
[ Mon Nov  7 18:52:40 2022 ] Training epoch: 17
[ Mon Nov  7 19:33:15 2022 ] 	Mean training loss: 0.9374.  Mean training acc: 71.98%.
[ Mon Nov  7 19:33:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 19:33:15 2022 ] Eval epoch: 17
[ Mon Nov  7 20:14:52 2022 ] 	Mean test loss of 930 batches: 1.296295936517818.
[ Mon Nov  7 20:14:53 2022 ] 	Top1: 64.41%
[ Mon Nov  7 20:14:55 2022 ] 	Top5: 89.40%
[ Mon Nov  7 20:14:55 2022 ] Training epoch: 18
[ Mon Nov  7 20:59:27 2022 ] 	Mean training loss: 0.9196.  Mean training acc: 72.47%.
[ Mon Nov  7 20:59:27 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 20:59:27 2022 ] Eval epoch: 18
[ Mon Nov  7 21:45:08 2022 ] 	Mean test loss of 930 batches: 1.0925105395496533.
[ Mon Nov  7 21:45:10 2022 ] 	Top1: 68.76%
[ Mon Nov  7 21:45:11 2022 ] 	Top5: 91.25%
[ Mon Nov  7 21:45:11 2022 ] Training epoch: 19
[ Mon Nov  7 22:28:00 2022 ] 	Mean training loss: 0.9118.  Mean training acc: 72.66%.
[ Mon Nov  7 22:28:00 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 22:28:00 2022 ] Eval epoch: 19
[ Mon Nov  7 23:11:11 2022 ] 	Mean test loss of 930 batches: 1.4455322968062534.
[ Mon Nov  7 23:11:13 2022 ] 	Top1: 61.44%
[ Mon Nov  7 23:11:15 2022 ] 	Top5: 88.03%
[ Mon Nov  7 23:11:15 2022 ] Training epoch: 20
[ Mon Nov  7 23:51:06 2022 ] 	Mean training loss: 0.9034.  Mean training acc: 72.77%.
[ Mon Nov  7 23:51:06 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Nov  7 23:51:06 2022 ] Eval epoch: 20
[ Tue Nov  8 00:33:04 2022 ] 	Mean test loss of 930 batches: 1.2306663606115567.
[ Tue Nov  8 00:33:06 2022 ] 	Top1: 65.04%
[ Tue Nov  8 00:33:08 2022 ] 	Top5: 89.63%
[ Tue Nov  8 00:33:08 2022 ] Training epoch: 21
[ Tue Nov  8 01:14:54 2022 ] 	Mean training loss: 0.8872.  Mean training acc: 73.30%.
[ Tue Nov  8 01:14:54 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 01:14:54 2022 ] Eval epoch: 21
[ Tue Nov  8 01:57:45 2022 ] 	Mean test loss of 930 batches: 1.074414744107954.
[ Tue Nov  8 01:57:46 2022 ] 	Top1: 68.88%
[ Tue Nov  8 01:57:47 2022 ] 	Top5: 91.59%
[ Tue Nov  8 01:57:47 2022 ] Training epoch: 22
[ Tue Nov  8 02:39:20 2022 ] 	Mean training loss: 0.8835.  Mean training acc: 73.66%.
[ Tue Nov  8 02:39:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 02:39:20 2022 ] Eval epoch: 22
[ Tue Nov  8 03:22:05 2022 ] 	Mean test loss of 930 batches: 1.1167078175211465.
[ Tue Nov  8 03:22:07 2022 ] 	Top1: 67.38%
[ Tue Nov  8 03:22:09 2022 ] 	Top5: 91.70%
[ Tue Nov  8 03:22:09 2022 ] Training epoch: 23
[ Tue Nov  8 04:03:55 2022 ] 	Mean training loss: 0.8780.  Mean training acc: 73.70%.
[ Tue Nov  8 04:03:55 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 04:03:55 2022 ] Eval epoch: 23
[ Tue Nov  8 04:46:52 2022 ] 	Mean test loss of 930 batches: 1.1253265621200685.
[ Tue Nov  8 04:46:54 2022 ] 	Top1: 67.78%
[ Tue Nov  8 04:46:55 2022 ] 	Top5: 90.96%
[ Tue Nov  8 04:46:55 2022 ] Training epoch: 24
[ Tue Nov  8 05:29:02 2022 ] 	Mean training loss: 0.8629.  Mean training acc: 74.10%.
[ Tue Nov  8 05:29:02 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 05:29:02 2022 ] Eval epoch: 24
[ Tue Nov  8 06:11:07 2022 ] 	Mean test loss of 930 batches: 1.0645955205604594.
[ Tue Nov  8 06:11:09 2022 ] 	Top1: 68.72%
[ Tue Nov  8 06:11:11 2022 ] 	Top5: 92.01%
[ Tue Nov  8 06:11:11 2022 ] Training epoch: 25
[ Tue Nov  8 06:52:41 2022 ] 	Mean training loss: 0.8633.  Mean training acc: 74.08%.
[ Tue Nov  8 06:52:41 2022 ] 	Time consumption: [Data]01%, [Network]95%
[ Tue Nov  8 06:52:41 2022 ] Eval epoch: 25
[ Tue Nov  8 07:33:46 2022 ] 	Mean test loss of 930 batches: 1.1287853786701798.
[ Tue Nov  8 07:33:47 2022 ] 	Top1: 68.18%
[ Tue Nov  8 07:33:49 2022 ] 	Top5: 90.27%
[ Tue Nov  8 07:33:49 2022 ] Training epoch: 26
[ Tue Nov  8 08:15:11 2022 ] 	Mean training loss: 0.8624.  Mean training acc: 74.05%.
[ Tue Nov  8 08:15:11 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 08:15:11 2022 ] Eval epoch: 26
[ Tue Nov  8 08:58:28 2022 ] 	Mean test loss of 930 batches: 1.0185737258644514.
[ Tue Nov  8 08:58:30 2022 ] 	Top1: 70.55%
[ Tue Nov  8 08:58:31 2022 ] 	Top5: 92.40%
[ Tue Nov  8 08:58:32 2022 ] Training epoch: 27
[ Tue Nov  8 09:39:59 2022 ] 	Mean training loss: 0.8462.  Mean training acc: 74.55%.
[ Tue Nov  8 09:39:59 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 09:39:59 2022 ] Eval epoch: 27
[ Tue Nov  8 10:22:25 2022 ] 	Mean test loss of 930 batches: 1.2092710715147756.
[ Tue Nov  8 10:22:27 2022 ] 	Top1: 65.68%
[ Tue Nov  8 10:22:28 2022 ] 	Top5: 90.31%
[ Tue Nov  8 10:22:28 2022 ] Training epoch: 28
[ Tue Nov  8 11:02:18 2022 ] 	Mean training loss: 0.8461.  Mean training acc: 74.73%.
[ Tue Nov  8 11:02:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 11:02:18 2022 ] Eval epoch: 28
[ Tue Nov  8 11:43:53 2022 ] 	Mean test loss of 930 batches: 1.1953572328052213.
[ Tue Nov  8 11:43:55 2022 ] 	Top1: 66.58%
[ Tue Nov  8 11:43:58 2022 ] 	Top5: 90.68%
[ Tue Nov  8 11:43:58 2022 ] Training epoch: 29
[ Tue Nov  8 12:27:23 2022 ] 	Mean training loss: 0.8430.  Mean training acc: 74.56%.
[ Tue Nov  8 12:27:23 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 12:27:23 2022 ] Eval epoch: 29
[ Tue Nov  8 13:12:22 2022 ] 	Mean test loss of 930 batches: 1.3619405752869063.
[ Tue Nov  8 13:12:23 2022 ] 	Top1: 63.82%
[ Tue Nov  8 13:12:25 2022 ] 	Top5: 89.24%
[ Tue Nov  8 13:12:25 2022 ] Training epoch: 30
[ Tue Nov  8 13:57:08 2022 ] 	Mean training loss: 0.8347.  Mean training acc: 75.07%.
[ Tue Nov  8 13:57:08 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 13:57:08 2022 ] Eval epoch: 30
[ Tue Nov  8 14:42:36 2022 ] 	Mean test loss of 930 batches: 1.3041930316596904.
[ Tue Nov  8 14:42:38 2022 ] 	Top1: 63.85%
[ Tue Nov  8 14:42:40 2022 ] 	Top5: 88.17%
[ Tue Nov  8 14:42:41 2022 ] Training epoch: 31
[ Tue Nov  8 15:24:53 2022 ] 	Mean training loss: 0.8372.  Mean training acc: 74.68%.
[ Tue Nov  8 15:24:53 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 15:24:53 2022 ] Eval epoch: 31
[ Tue Nov  8 16:07:13 2022 ] 	Mean test loss of 930 batches: 1.1522010398167435.
[ Tue Nov  8 16:07:14 2022 ] 	Top1: 67.24%
[ Tue Nov  8 16:07:16 2022 ] 	Top5: 90.76%
[ Tue Nov  8 16:07:16 2022 ] Training epoch: 32
[ Tue Nov  8 16:47:12 2022 ] 	Mean training loss: 0.8368.  Mean training acc: 75.02%.
[ Tue Nov  8 16:47:12 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 16:47:12 2022 ] Eval epoch: 32
[ Tue Nov  8 17:30:13 2022 ] 	Mean test loss of 930 batches: 1.0580374473846086.
[ Tue Nov  8 17:30:15 2022 ] 	Top1: 70.00%
[ Tue Nov  8 17:30:18 2022 ] 	Top5: 91.68%
[ Tue Nov  8 17:30:19 2022 ] Training epoch: 33
[ Tue Nov  8 18:12:04 2022 ] 	Mean training loss: 0.8256.  Mean training acc: 75.19%.
[ Tue Nov  8 18:12:04 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 18:12:04 2022 ] Eval epoch: 33
[ Tue Nov  8 18:54:10 2022 ] 	Mean test loss of 930 batches: 1.0545567598714622.
[ Tue Nov  8 18:54:11 2022 ] 	Top1: 70.23%
[ Tue Nov  8 18:54:12 2022 ] 	Top5: 91.72%
[ Tue Nov  8 18:54:13 2022 ] Training epoch: 34
[ Tue Nov  8 19:33:03 2022 ] 	Mean training loss: 0.8209.  Mean training acc: 75.28%.
[ Tue Nov  8 19:33:03 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 19:33:03 2022 ] Eval epoch: 34
[ Tue Nov  8 20:11:49 2022 ] 	Mean test loss of 930 batches: 1.113610174322641.
[ Tue Nov  8 20:11:50 2022 ] 	Top1: 68.13%
[ Tue Nov  8 20:11:52 2022 ] 	Top5: 90.97%
[ Tue Nov  8 20:11:52 2022 ] Training epoch: 35
[ Tue Nov  8 20:49:21 2022 ] 	Mean training loss: 0.8209.  Mean training acc: 75.31%.
[ Tue Nov  8 20:49:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 20:49:21 2022 ] Eval epoch: 35
[ Tue Nov  8 21:27:52 2022 ] 	Mean test loss of 930 batches: 1.113213171305195.
[ Tue Nov  8 21:27:53 2022 ] 	Top1: 68.35%
[ Tue Nov  8 21:27:54 2022 ] 	Top5: 90.92%
[ Tue Nov  8 21:27:55 2022 ] Training epoch: 36
[ Tue Nov  8 22:06:53 2022 ] 	Mean training loss: 0.4839.  Mean training acc: 85.70%.
[ Tue Nov  8 22:06:53 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 22:06:53 2022 ] Eval epoch: 36
[ Tue Nov  8 22:52:04 2022 ] 	Mean test loss of 930 batches: 0.6782839669014817.
[ Tue Nov  8 22:52:05 2022 ] 	Top1: 80.12%
[ Tue Nov  8 22:52:07 2022 ] 	Top5: 95.59%
[ Tue Nov  8 22:52:07 2022 ] Training epoch: 37
[ Tue Nov  8 23:34:17 2022 ] 	Mean training loss: 0.3834.  Mean training acc: 88.51%.
[ Tue Nov  8 23:34:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Nov  8 23:34:17 2022 ] Eval epoch: 37
[ Wed Nov  9 00:13:38 2022 ] 	Mean test loss of 930 batches: 0.6439118419683749.
[ Wed Nov  9 00:13:40 2022 ] 	Top1: 80.89%
[ Wed Nov  9 00:13:41 2022 ] 	Top5: 95.92%
[ Wed Nov  9 00:13:41 2022 ] Training epoch: 38
[ Wed Nov  9 00:51:39 2022 ] 	Mean training loss: 0.3451.  Mean training acc: 89.82%.
[ Wed Nov  9 00:51:39 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 00:51:39 2022 ] Eval epoch: 38
[ Wed Nov  9 01:31:17 2022 ] 	Mean test loss of 930 batches: 0.619429946418411.
[ Wed Nov  9 01:31:18 2022 ] 	Top1: 81.80%
[ Wed Nov  9 01:31:19 2022 ] 	Top5: 96.12%
[ Wed Nov  9 01:31:19 2022 ] Training epoch: 39
[ Wed Nov  9 02:11:07 2022 ] 	Mean training loss: 0.3120.  Mean training acc: 90.78%.
[ Wed Nov  9 02:11:07 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 02:11:07 2022 ] Eval epoch: 39
[ Wed Nov  9 02:51:44 2022 ] 	Mean test loss of 930 batches: 0.611226628945079.
[ Wed Nov  9 02:51:44 2022 ] 	Top1: 82.15%
[ Wed Nov  9 02:51:45 2022 ] 	Top5: 96.15%
[ Wed Nov  9 02:51:46 2022 ] Training epoch: 40
[ Wed Nov  9 03:30:49 2022 ] 	Mean training loss: 0.2881.  Mean training acc: 91.63%.
[ Wed Nov  9 03:30:49 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 03:30:49 2022 ] Eval epoch: 40
[ Wed Nov  9 04:10:38 2022 ] 	Mean test loss of 930 batches: 0.6263936331435558.
[ Wed Nov  9 04:10:39 2022 ] 	Top1: 81.61%
[ Wed Nov  9 04:10:40 2022 ] 	Top5: 96.14%
[ Wed Nov  9 04:10:40 2022 ] Training epoch: 41
[ Wed Nov  9 04:47:35 2022 ] 	Mean training loss: 0.2662.  Mean training acc: 92.39%.
[ Wed Nov  9 04:47:35 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 04:47:35 2022 ] Eval epoch: 41
[ Wed Nov  9 05:24:32 2022 ] 	Mean test loss of 930 batches: 0.6281161751878518.
[ Wed Nov  9 05:24:33 2022 ] 	Top1: 81.94%
[ Wed Nov  9 05:24:35 2022 ] 	Top5: 96.05%
[ Wed Nov  9 05:24:35 2022 ] Training epoch: 42
[ Wed Nov  9 05:57:11 2022 ] 	Mean training loss: 0.2460.  Mean training acc: 93.01%.
[ Wed Nov  9 05:57:11 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 05:57:11 2022 ] Eval epoch: 42
[ Wed Nov  9 06:31:14 2022 ] 	Mean test loss of 930 batches: 0.6532457216452526.
[ Wed Nov  9 06:32:52 2022 ] 	Top1: 81.30%
[ Wed Nov  9 06:32:54 2022 ] 	Top5: 96.00%
[ Wed Nov  9 06:32:54 2022 ] Training epoch: 43
[ Wed Nov  9 07:11:07 2022 ] 	Mean training loss: 0.2303.  Mean training acc: 93.43%.
[ Wed Nov  9 07:11:08 2022 ] 	Time consumption: [Data]01%, [Network]86%
[ Wed Nov  9 07:11:08 2022 ] Eval epoch: 43
[ Wed Nov  9 07:45:36 2022 ] 	Mean test loss of 930 batches: 0.6444560805075271.
[ Wed Nov  9 07:45:37 2022 ] 	Top1: 81.75%
[ Wed Nov  9 07:45:38 2022 ] 	Top5: 95.94%
[ Wed Nov  9 07:45:38 2022 ] Training epoch: 44
[ Wed Nov  9 08:18:56 2022 ] 	Mean training loss: 0.2125.  Mean training acc: 94.21%.
[ Wed Nov  9 08:18:56 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 08:18:56 2022 ] Eval epoch: 44
[ Wed Nov  9 08:53:31 2022 ] 	Mean test loss of 930 batches: 0.6888747347859285.
[ Wed Nov  9 08:53:32 2022 ] 	Top1: 80.62%
[ Wed Nov  9 08:53:33 2022 ] 	Top5: 95.76%
[ Wed Nov  9 08:53:33 2022 ] Training epoch: 45
[ Wed Nov  9 09:27:14 2022 ] 	Mean training loss: 0.2024.  Mean training acc: 94.37%.
[ Wed Nov  9 09:27:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 09:27:15 2022 ] Eval epoch: 45
[ Wed Nov  9 10:01:49 2022 ] 	Mean test loss of 930 batches: 0.6746139844018285.
[ Wed Nov  9 10:01:50 2022 ] 	Top1: 81.20%
[ Wed Nov  9 10:01:51 2022 ] 	Top5: 95.73%
[ Wed Nov  9 10:01:51 2022 ] Training epoch: 46
[ Wed Nov  9 10:36:12 2022 ] 	Mean training loss: 0.1968.  Mean training acc: 94.66%.
[ Wed Nov  9 10:36:12 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 10:36:12 2022 ] Eval epoch: 46
[ Wed Nov  9 11:13:16 2022 ] 	Mean test loss of 930 batches: 0.6828710982075301.
[ Wed Nov  9 11:13:17 2022 ] 	Top1: 81.00%
[ Wed Nov  9 11:13:18 2022 ] 	Top5: 95.92%
[ Wed Nov  9 11:13:18 2022 ] Training epoch: 47
[ Wed Nov  9 11:49:12 2022 ] 	Mean training loss: 0.1880.  Mean training acc: 94.97%.
[ Wed Nov  9 11:49:12 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 11:49:12 2022 ] Eval epoch: 47
[ Wed Nov  9 12:26:34 2022 ] 	Mean test loss of 930 batches: 0.6826501305144961.
[ Wed Nov  9 12:26:35 2022 ] 	Top1: 81.19%
[ Wed Nov  9 12:26:36 2022 ] 	Top5: 95.68%
[ Wed Nov  9 12:26:37 2022 ] Training epoch: 48
[ Wed Nov  9 13:02:28 2022 ] 	Mean training loss: 0.1824.  Mean training acc: 95.19%.
[ Wed Nov  9 13:02:28 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 13:02:28 2022 ] Eval epoch: 48
[ Wed Nov  9 13:39:37 2022 ] 	Mean test loss of 930 batches: 0.7128144661184921.
[ Wed Nov  9 13:39:39 2022 ] 	Top1: 80.46%
[ Wed Nov  9 13:39:40 2022 ] 	Top5: 95.34%
[ Wed Nov  9 13:39:41 2022 ] Training epoch: 49
[ Wed Nov  9 14:15:41 2022 ] 	Mean training loss: 0.1785.  Mean training acc: 95.33%.
[ Wed Nov  9 14:15:41 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  9 14:15:41 2022 ] Eval epoch: 49
[ Wed Nov  9 14:53:10 2022 ] 	Mean test loss of 930 batches: 0.7269857834904424.
[ Wed Nov  9 14:53:11 2022 ] 	Top1: 80.16%
[ Wed Nov  9 14:53:12 2022 ] 	Top5: 95.59%
[ Wed Nov  9 14:53:12 2022 ] Training epoch: 50
[ Tue Jan  3 17:21:36 2023 ] Load weights from work_dir/cset/local_SHTg_vel/runs-49-41699.pt.
[ Tue Jan  3 17:21:40 2023 ] using warm up, epoch: 5
[ Tue Jan  3 17:21:58 2023 ] Parameters:
{'work_dir': 'work_dir/cset/local_SHTg_vel', 'model_saved_name': 'work_dir/cset/local_SHTg_vel/runs', 'config': 'work_dir/cset/local_SHTg_vel/config.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'bone': False, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'normalization': False, 'p_interval': [0.5, 1], 'random_choose': False, 'random_move': False, 'random_rot': True, 'random_shift': False, 'split': 'train', 'vel': True, 'window_size': 64}, 'test_feeder_args': {'bone': False, 'data_path': 'data/ntu120/NTU120_CSet.npz', 'debug': False, 'p_interval': [0.95], 'split': 'test', 'vel': True, 'window_size': 64}, 'model': 'model.local_SHTg.Model', 'model_args': {'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}, 'num_class': 120, 'num_person': 2, 'num_point': 25}, 'weights': 'work_dir/cset/local_SHTg_vel/runs-49-41699.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 49, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan  3 17:21:58 2023 ] # Parameters: 2141090
[ Tue Jan  3 17:21:58 2023 ] Training epoch: 50
[ Tue Jan  3 17:45:55 2023 ] 	Mean training loss: 0.1726.  Mean training acc: 95.48%.
[ Tue Jan  3 17:45:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 17:45:55 2023 ] Eval epoch: 50
[ Tue Jan  3 18:12:21 2023 ] 	Mean test loss of 930 batches: 0.7577249070168823.
[ Tue Jan  3 18:12:22 2023 ] 	Top1: 79.44%
[ Tue Jan  3 18:12:23 2023 ] 	Top5: 95.10%
[ Tue Jan  3 18:12:23 2023 ] Training epoch: 51
[ Tue Jan  3 18:40:47 2023 ] 	Mean training loss: 0.1684.  Mean training acc: 95.58%.
[ Tue Jan  3 18:40:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 18:40:47 2023 ] Eval epoch: 51
[ Tue Jan  3 19:08:03 2023 ] 	Mean test loss of 930 batches: 0.7710035019504127.
[ Tue Jan  3 19:08:04 2023 ] 	Top1: 79.61%
[ Tue Jan  3 19:08:04 2023 ] 	Top5: 94.82%
[ Tue Jan  3 19:08:05 2023 ] Training epoch: 52
[ Tue Jan  3 19:36:48 2023 ] 	Mean training loss: 0.1788.  Mean training acc: 95.14%.
[ Tue Jan  3 19:36:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 19:36:48 2023 ] Eval epoch: 52
[ Tue Jan  3 20:04:13 2023 ] 	Mean test loss of 930 batches: 0.7342044228507626.
[ Tue Jan  3 20:04:14 2023 ] 	Top1: 80.21%
[ Tue Jan  3 20:04:15 2023 ] 	Top5: 95.33%
[ Tue Jan  3 20:04:15 2023 ] Training epoch: 53
[ Tue Jan  3 20:32:51 2023 ] 	Mean training loss: 0.1692.  Mean training acc: 95.49%.
[ Tue Jan  3 20:32:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 20:32:51 2023 ] Eval epoch: 53
[ Tue Jan  3 21:00:49 2023 ] 	Mean test loss of 930 batches: 0.8210401791077788.
[ Tue Jan  3 21:00:50 2023 ] 	Top1: 78.17%
[ Tue Jan  3 21:00:51 2023 ] 	Top5: 94.63%
[ Tue Jan  3 21:00:51 2023 ] Training epoch: 54
[ Tue Jan  3 21:28:24 2023 ] 	Mean training loss: 0.1717.  Mean training acc: 95.40%.
[ Tue Jan  3 21:28:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 21:28:24 2023 ] Eval epoch: 54
[ Tue Jan  3 21:56:31 2023 ] 	Mean test loss of 930 batches: 0.7515540453695482.
[ Tue Jan  3 21:56:32 2023 ] 	Top1: 79.91%
[ Tue Jan  3 21:56:33 2023 ] 	Top5: 95.07%
[ Tue Jan  3 21:56:33 2023 ] Training epoch: 55
[ Tue Jan  3 22:24:24 2023 ] 	Mean training loss: 0.1706.  Mean training acc: 95.50%.
[ Tue Jan  3 22:24:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 22:24:24 2023 ] Eval epoch: 55
[ Tue Jan  3 22:52:29 2023 ] 	Mean test loss of 930 batches: 0.7577224284090022.
[ Tue Jan  3 22:52:29 2023 ] 	Top1: 79.93%
[ Tue Jan  3 22:52:30 2023 ] 	Top5: 95.00%
[ Tue Jan  3 22:52:30 2023 ] Training epoch: 56
[ Tue Jan  3 23:22:10 2023 ] 	Mean training loss: 0.1002.  Mean training acc: 97.77%.
[ Tue Jan  3 23:22:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan  3 23:22:10 2023 ] Eval epoch: 56
[ Tue Jan  3 23:49:37 2023 ] 	Mean test loss of 930 batches: 0.675528499756449.
[ Tue Jan  3 23:49:38 2023 ] 	Top1: 81.91%
[ Tue Jan  3 23:49:39 2023 ] 	Top5: 95.69%
[ Tue Jan  3 23:49:39 2023 ] Training epoch: 57
[ Wed Jan  4 00:14:56 2023 ] 	Mean training loss: 0.0773.  Mean training acc: 98.47%.
[ Wed Jan  4 00:14:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 00:14:57 2023 ] Eval epoch: 57
[ Wed Jan  4 00:40:35 2023 ] 	Mean test loss of 930 batches: 0.6755978553605977.
[ Wed Jan  4 00:40:35 2023 ] 	Top1: 82.01%
[ Wed Jan  4 00:40:36 2023 ] 	Top5: 95.78%
[ Wed Jan  4 00:40:36 2023 ] Training epoch: 58
[ Wed Jan  4 01:06:12 2023 ] 	Mean training loss: 0.0684.  Mean training acc: 98.77%.
[ Wed Jan  4 01:06:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 01:06:12 2023 ] Eval epoch: 58
[ Wed Jan  4 01:31:50 2023 ] 	Mean test loss of 930 batches: 0.6873269787438775.
[ Wed Jan  4 01:31:51 2023 ] 	Top1: 81.72%
[ Wed Jan  4 01:31:52 2023 ] 	Top5: 95.76%
[ Wed Jan  4 01:31:52 2023 ] Training epoch: 59
[ Wed Jan  4 01:57:30 2023 ] 	Mean training loss: 0.0666.  Mean training acc: 98.72%.
[ Wed Jan  4 01:57:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 01:57:31 2023 ] Eval epoch: 59
[ Wed Jan  4 02:23:12 2023 ] 	Mean test loss of 930 batches: 0.6888433544626159.
[ Wed Jan  4 02:23:13 2023 ] 	Top1: 81.82%
[ Wed Jan  4 02:23:14 2023 ] 	Top5: 95.64%
[ Wed Jan  4 02:23:14 2023 ] Training epoch: 60
[ Wed Jan  4 02:47:59 2023 ] 	Mean training loss: 0.0597.  Mean training acc: 98.94%.
[ Wed Jan  4 02:47:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 02:47:59 2023 ] Eval epoch: 60
[ Wed Jan  4 03:09:03 2023 ] 	Mean test loss of 930 batches: 0.6831007010513737.
[ Wed Jan  4 03:09:04 2023 ] 	Top1: 82.00%
[ Wed Jan  4 03:09:05 2023 ] 	Top5: 95.73%
[ Wed Jan  4 03:09:05 2023 ] Training epoch: 61
[ Wed Jan  4 03:30:34 2023 ] 	Mean training loss: 0.0565.  Mean training acc: 99.01%.
[ Wed Jan  4 03:30:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 03:30:34 2023 ] Eval epoch: 61
[ Wed Jan  4 03:51:14 2023 ] 	Mean test loss of 930 batches: 0.6765373115938518.
[ Wed Jan  4 03:51:15 2023 ] 	Top1: 82.20%
[ Wed Jan  4 03:51:15 2023 ] 	Top5: 95.79%
[ Wed Jan  4 03:51:15 2023 ] Training epoch: 62
[ Wed Jan  4 04:12:48 2023 ] 	Mean training loss: 0.0566.  Mean training acc: 99.05%.
[ Wed Jan  4 04:12:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 04:12:48 2023 ] Eval epoch: 62
[ Wed Jan  4 04:33:26 2023 ] 	Mean test loss of 930 batches: 0.675029651287903.
[ Wed Jan  4 04:33:27 2023 ] 	Top1: 82.20%
[ Wed Jan  4 04:33:27 2023 ] 	Top5: 95.83%
[ Wed Jan  4 04:33:27 2023 ] Training epoch: 63
[ Wed Jan  4 04:54:51 2023 ] 	Mean training loss: 0.0523.  Mean training acc: 99.15%.
[ Wed Jan  4 04:54:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 04:54:51 2023 ] Eval epoch: 63
[ Wed Jan  4 05:15:30 2023 ] 	Mean test loss of 930 batches: 0.6808054057781094.
[ Wed Jan  4 05:15:31 2023 ] 	Top1: 82.17%
[ Wed Jan  4 05:15:32 2023 ] 	Top5: 95.73%
[ Wed Jan  4 05:15:32 2023 ] Training epoch: 64
[ Wed Jan  4 05:36:54 2023 ] 	Mean training loss: 0.0513.  Mean training acc: 99.18%.
[ Wed Jan  4 05:36:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 05:36:55 2023 ] Eval epoch: 64
[ Wed Jan  4 05:59:22 2023 ] 	Mean test loss of 930 batches: 0.6790191879355779.
[ Wed Jan  4 05:59:23 2023 ] 	Top1: 82.19%
[ Wed Jan  4 05:59:24 2023 ] 	Top5: 95.76%
[ Wed Jan  4 05:59:24 2023 ] Training epoch: 65
[ Wed Jan  4 06:20:20 2023 ] 	Mean training loss: 0.0495.  Mean training acc: 99.19%.
[ Wed Jan  4 06:20:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jan  4 06:20:20 2023 ] Eval epoch: 65
[ Wed Jan  4 06:39:48 2023 ] 	Mean test loss of 930 batches: 0.6997657673173053.
[ Wed Jan  4 06:39:49 2023 ] 	Top1: 81.58%
[ Wed Jan  4 06:39:49 2023 ] 	Top5: 95.49%
[ Wed Jan  4 06:58:20 2023 ] Best accuracy: 0.8220488592228928
[ Wed Jan  4 06:58:20 2023 ] Epoch number: 61
[ Wed Jan  4 06:58:20 2023 ] Model name: work_dir/cset/local_SHTg_vel
[ Wed Jan  4 06:58:20 2023 ] Model total number of params: 2141090
[ Wed Jan  4 06:58:20 2023 ] Weight decay: 0.0004
[ Wed Jan  4 06:58:20 2023 ] Base LR: 0.1
[ Wed Jan  4 06:58:20 2023 ] Batch Size: 64
[ Wed Jan  4 06:58:20 2023 ] Test Batch Size: 64
[ Wed Jan  4 06:58:20 2023 ] seed: 1
