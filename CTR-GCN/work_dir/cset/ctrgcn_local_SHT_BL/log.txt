[ Tue Jan 10 13:41:25 2023 ] using warm up, epoch: 5
[ Tue Jan 10 13:43:55 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan 10 13:44:02 2023 ] # Parameters: 1508876
[ Tue Jan 10 13:44:02 2023 ] Training epoch: 1
[ Tue Jan 10 13:46:52 2023 ] using warm up, epoch: 5
[ Tue Jan 10 13:47:18 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [6], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jan 10 13:47:18 2023 ] # Parameters: 1508876
[ Tue Jan 10 13:47:18 2023 ] Training epoch: 1
[ Tue Jan 10 13:57:12 2023 ] 	Mean training loss: 3.2578.  Mean training acc: 19.43%.
[ Tue Jan 10 13:57:15 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 13:57:20 2023 ] Eval epoch: 1
[ Tue Jan 10 14:02:22 2023 ] 	Mean test loss of 930 batches: 2.501939121497575.
[ Tue Jan 10 14:02:25 2023 ] 	Top1: 33.03%
[ Tue Jan 10 14:02:26 2023 ] 	Top5: 67.25%
[ Tue Jan 10 14:02:29 2023 ] Training epoch: 2
[ Tue Jan 10 14:16:23 2023 ] 	Mean training loss: 2.1702.  Mean training acc: 39.20%.
[ Tue Jan 10 14:16:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 14:16:30 2023 ] Eval epoch: 2
[ Tue Jan 10 14:21:56 2023 ] 	Mean test loss of 930 batches: 1.8632101628088182.
[ Tue Jan 10 14:22:00 2023 ] 	Top1: 47.68%
[ Tue Jan 10 14:22:01 2023 ] 	Top5: 80.16%
[ Tue Jan 10 14:22:04 2023 ] Training epoch: 3
[ Tue Jan 10 14:33:49 2023 ] 	Mean training loss: 1.7295.  Mean training acc: 49.81%.
[ Tue Jan 10 14:33:52 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 14:33:55 2023 ] Eval epoch: 3
[ Tue Jan 10 14:38:36 2023 ] 	Mean test loss of 930 batches: 1.725350082369261.
[ Tue Jan 10 14:38:39 2023 ] 	Top1: 50.01%
[ Tue Jan 10 14:38:39 2023 ] 	Top5: 82.64%
[ Tue Jan 10 14:38:42 2023 ] Training epoch: 4
[ Tue Jan 10 14:50:07 2023 ] 	Mean training loss: 1.5420.  Mean training acc: 55.08%.
[ Tue Jan 10 14:50:09 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 14:50:12 2023 ] Eval epoch: 4
[ Tue Jan 10 14:55:02 2023 ] 	Mean test loss of 930 batches: 1.572603597243627.
[ Tue Jan 10 14:55:04 2023 ] 	Top1: 55.73%
[ Tue Jan 10 14:55:05 2023 ] 	Top5: 85.05%
[ Tue Jan 10 14:55:06 2023 ] Training epoch: 5
[ Tue Jan 10 15:08:32 2023 ] 	Mean training loss: 1.4111.  Mean training acc: 58.40%.
[ Tue Jan 10 15:08:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 15:08:37 2023 ] Eval epoch: 5
[ Tue Jan 10 15:13:31 2023 ] 	Mean test loss of 930 batches: 1.472136611835931.
[ Tue Jan 10 15:13:34 2023 ] 	Top1: 57.73%
[ Tue Jan 10 15:13:35 2023 ] 	Top5: 86.74%
[ Tue Jan 10 15:13:37 2023 ] Training epoch: 6
[ Tue Jan 10 15:25:15 2023 ] 	Mean training loss: 1.2618.  Mean training acc: 62.53%.
[ Tue Jan 10 15:25:17 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 15:25:21 2023 ] Eval epoch: 6
[ Tue Jan 10 15:30:34 2023 ] 	Mean test loss of 930 batches: 1.4541761432924578.
[ Tue Jan 10 15:30:36 2023 ] 	Top1: 57.66%
[ Tue Jan 10 15:30:37 2023 ] 	Top5: 86.85%
[ Tue Jan 10 15:30:39 2023 ] Training epoch: 7
[ Tue Jan 10 15:42:26 2023 ] 	Mean training loss: 1.1449.  Mean training acc: 65.86%.
[ Tue Jan 10 15:42:28 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 15:42:32 2023 ] Eval epoch: 7
[ Tue Jan 10 15:47:29 2023 ] 	Mean test loss of 930 batches: 1.219524317306857.
[ Tue Jan 10 15:47:31 2023 ] 	Top1: 64.05%
[ Tue Jan 10 15:47:32 2023 ] 	Top5: 90.06%
[ Tue Jan 10 15:47:34 2023 ] Training epoch: 8
[ Tue Jan 10 16:00:02 2023 ] 	Mean training loss: 1.0673.  Mean training acc: 67.74%.
[ Tue Jan 10 16:00:04 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 16:00:09 2023 ] Eval epoch: 8
[ Tue Jan 10 16:05:05 2023 ] 	Mean test loss of 930 batches: 1.2889784034541858.
[ Tue Jan 10 16:05:08 2023 ] 	Top1: 63.33%
[ Tue Jan 10 16:05:09 2023 ] 	Top5: 89.47%
[ Tue Jan 10 16:05:11 2023 ] Training epoch: 9
[ Tue Jan 10 16:17:15 2023 ] 	Mean training loss: 1.0132.  Mean training acc: 69.42%.
[ Tue Jan 10 16:17:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jan 10 16:17:21 2023 ] Eval epoch: 9
[ Tue Jan 10 16:22:57 2023 ] 	Mean test loss of 930 batches: 1.231924289945633.
[ Tue Jan 10 16:23:00 2023 ] 	Top1: 64.28%
[ Tue Jan 10 16:23:00 2023 ] 	Top5: 90.47%
[ Tue Jan 10 16:23:01 2023 ] Training epoch: 10
[ Tue Jan 10 16:35:01 2023 ] 	Mean training loss: 0.9615.  Mean training acc: 70.96%.
[ Tue Jan 10 16:35:04 2023 ] 	Time consumption: [Data]01%, [Network]94%
[ Tue Jan 10 16:35:05 2023 ] Eval epoch: 10
[ Tue Jan 10 16:39:59 2023 ] 	Mean test loss of 930 batches: 1.1653047979198476.
[ Tue Jan 10 16:40:01 2023 ] 	Top1: 66.34%
[ Tue Jan 10 16:40:02 2023 ] 	Top5: 91.27%
[ Tue Jan 10 16:40:04 2023 ] Training epoch: 11
[ Tue Jan 10 16:51:54 2023 ] 	Mean training loss: 0.9320.  Mean training acc: 71.64%.
[ Tue Jan 10 16:51:56 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 16:52:01 2023 ] Eval epoch: 11
[ Tue Jan 10 16:56:49 2023 ] 	Mean test loss of 930 batches: 1.197015391017801.
[ Tue Jan 10 17:00:04 2023 ] 	Top1: 65.21%
[ Tue Jan 10 17:00:04 2023 ] 	Top5: 90.47%
[ Tue Jan 10 17:00:10 2023 ] Training epoch: 12
[ Tue Jan 10 17:13:44 2023 ] 	Mean training loss: 0.9047.  Mean training acc: 72.45%.
[ Tue Jan 10 17:13:46 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 17:13:52 2023 ] Eval epoch: 12
[ Tue Jan 10 17:19:25 2023 ] 	Mean test loss of 930 batches: 1.3654627592973811.
[ Tue Jan 10 17:19:29 2023 ] 	Top1: 61.05%
[ Tue Jan 10 17:19:30 2023 ] 	Top5: 88.80%
[ Tue Jan 10 17:19:32 2023 ] Training epoch: 13
[ Tue Jan 10 17:31:06 2023 ] 	Mean training loss: 0.8841.  Mean training acc: 73.11%.
[ Tue Jan 10 17:31:10 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 17:31:20 2023 ] Eval epoch: 13
[ Tue Jan 10 17:35:52 2023 ] 	Mean test loss of 930 batches: 1.0504305506906202.
[ Tue Jan 10 17:36:01 2023 ] 	Top1: 69.78%
[ Tue Jan 10 17:36:02 2023 ] 	Top5: 92.04%
[ Tue Jan 10 17:36:05 2023 ] Training epoch: 14
[ Tue Jan 10 17:47:38 2023 ] 	Mean training loss: 0.8593.  Mean training acc: 73.85%.
[ Tue Jan 10 17:47:40 2023 ] 	Time consumption: [Data]01%, [Network]96%
[ Tue Jan 10 17:47:44 2023 ] Eval epoch: 14
[ Tue Jan 10 17:53:02 2023 ] 	Mean test loss of 930 batches: 1.2148144124015685.
[ Tue Jan 10 17:53:02 2023 ] 	Top1: 67.20%
[ Tue Jan 10 17:53:03 2023 ] 	Top5: 90.29%
[ Tue Jan 10 17:53:05 2023 ] Training epoch: 15
[ Tue Jan 10 18:06:42 2023 ] 	Mean training loss: 0.8453.  Mean training acc: 74.08%.
[ Tue Jan 10 18:06:44 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 18:06:45 2023 ] Eval epoch: 15
[ Tue Jan 10 18:11:22 2023 ] 	Mean test loss of 930 batches: 1.151825816817181.
[ Tue Jan 10 18:11:23 2023 ] 	Top1: 66.24%
[ Tue Jan 10 18:11:24 2023 ] 	Top5: 91.15%
[ Tue Jan 10 18:11:25 2023 ] Training epoch: 16
[ Tue Jan 10 18:23:05 2023 ] 	Mean training loss: 0.8319.  Mean training acc: 74.67%.
[ Tue Jan 10 18:23:08 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 18:23:11 2023 ] Eval epoch: 16
[ Tue Jan 10 18:27:49 2023 ] 	Mean test loss of 930 batches: 0.9823284863143839.
[ Tue Jan 10 18:29:40 2023 ] 	Top1: 70.69%
[ Tue Jan 10 18:29:49 2023 ] 	Top5: 93.38%
[ Tue Jan 10 18:29:51 2023 ] Training epoch: 17
[ Tue Jan 10 18:40:23 2023 ] 	Mean training loss: 0.8289.  Mean training acc: 74.47%.
[ Tue Jan 10 18:40:26 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan 10 18:40:29 2023 ] Eval epoch: 17
[ Tue Jan 10 18:45:50 2023 ] 	Mean test loss of 930 batches: 1.0369344190243752.
[ Tue Jan 10 18:45:53 2023 ] 	Top1: 69.46%
[ Tue Jan 10 18:45:53 2023 ] 	Top5: 92.65%
[ Tue Jan 10 18:45:55 2023 ] Training epoch: 18
[ Tue Jan 10 18:59:10 2023 ] 	Mean training loss: 0.8160.  Mean training acc: 74.87%.
[ Tue Jan 10 18:59:24 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 18:59:28 2023 ] Eval epoch: 18
[ Tue Jan 10 19:05:11 2023 ] 	Mean test loss of 930 batches: 0.9127110342505158.
[ Tue Jan 10 19:05:13 2023 ] 	Top1: 73.16%
[ Tue Jan 10 19:05:14 2023 ] 	Top5: 93.62%
[ Tue Jan 10 19:05:15 2023 ] Training epoch: 19
[ Tue Jan 10 19:17:41 2023 ] 	Mean training loss: 0.7980.  Mean training acc: 75.60%.
[ Tue Jan 10 19:17:44 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 19:17:46 2023 ] Eval epoch: 19
[ Tue Jan 10 19:22:24 2023 ] 	Mean test loss of 930 batches: 1.0016179100800586.
[ Tue Jan 10 19:22:26 2023 ] 	Top1: 71.46%
[ Tue Jan 10 19:22:27 2023 ] 	Top5: 92.32%
[ Tue Jan 10 19:22:29 2023 ] Training epoch: 20
[ Tue Jan 10 19:32:33 2023 ] 	Mean training loss: 0.7943.  Mean training acc: 75.72%.
[ Tue Jan 10 19:32:37 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan 10 19:32:39 2023 ] Eval epoch: 20
[ Tue Jan 10 19:37:25 2023 ] 	Mean test loss of 930 batches: 1.0557624668203374.
[ Tue Jan 10 19:37:29 2023 ] 	Top1: 68.48%
[ Tue Jan 10 19:37:29 2023 ] 	Top5: 91.90%
[ Tue Jan 10 19:37:30 2023 ] Training epoch: 21
[ Tue Jan 10 19:50:40 2023 ] 	Mean training loss: 0.7920.  Mean training acc: 75.87%.
[ Tue Jan 10 19:50:41 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 19:50:43 2023 ] Eval epoch: 21
[ Tue Jan 10 19:56:21 2023 ] 	Mean test loss of 930 batches: 1.0124802163531703.
[ Tue Jan 10 19:56:23 2023 ] 	Top1: 71.10%
[ Tue Jan 10 19:56:23 2023 ] 	Top5: 92.44%
[ Tue Jan 10 19:56:24 2023 ] Training epoch: 22
[ Tue Jan 10 20:09:40 2023 ] 	Mean training loss: 0.7803.  Mean training acc: 76.28%.
[ Tue Jan 10 20:09:42 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 20:09:46 2023 ] Eval epoch: 22
[ Tue Jan 10 20:14:55 2023 ] 	Mean test loss of 930 batches: 0.9334996653179969.
[ Tue Jan 10 20:14:57 2023 ] 	Top1: 72.52%
[ Tue Jan 10 20:14:58 2023 ] 	Top5: 93.63%
[ Tue Jan 10 20:14:59 2023 ] Training epoch: 23
[ Tue Jan 10 20:25:08 2023 ] 	Mean training loss: 0.7735.  Mean training acc: 76.37%.
[ Tue Jan 10 20:25:08 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jan 10 20:25:08 2023 ] Eval epoch: 23
[ Tue Jan 10 20:29:51 2023 ] 	Mean test loss of 930 batches: 0.9613537315399416.
[ Tue Jan 10 20:29:52 2023 ] 	Top1: 72.40%
[ Tue Jan 10 20:29:53 2023 ] 	Top5: 93.33%
[ Tue Jan 10 20:29:53 2023 ] Training epoch: 24
[ Tue Jan 10 20:41:22 2023 ] 	Mean training loss: 0.7652.  Mean training acc: 76.53%.
[ Tue Jan 10 20:41:25 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 20:41:26 2023 ] Eval epoch: 24
[ Tue Jan 10 20:47:09 2023 ] 	Mean test loss of 930 batches: 0.957677300674941.
[ Tue Jan 10 20:47:11 2023 ] 	Top1: 72.04%
[ Tue Jan 10 20:47:12 2023 ] 	Top5: 93.37%
[ Tue Jan 10 20:47:13 2023 ] Training epoch: 25
[ Tue Jan 10 21:00:38 2023 ] 	Mean training loss: 0.7669.  Mean training acc: 76.64%.
[ Tue Jan 10 21:00:38 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 21:00:40 2023 ] Eval epoch: 25
[ Tue Jan 10 21:06:12 2023 ] 	Mean test loss of 930 batches: 0.9576674545323977.
[ Tue Jan 10 21:06:14 2023 ] 	Top1: 72.06%
[ Tue Jan 10 21:06:15 2023 ] 	Top5: 93.02%
[ Tue Jan 10 21:06:15 2023 ] Training epoch: 26
[ Tue Jan 10 21:17:33 2023 ] 	Mean training loss: 0.7524.  Mean training acc: 76.97%.
[ Tue Jan 10 21:17:33 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 21:17:35 2023 ] Eval epoch: 26
[ Tue Jan 10 21:22:20 2023 ] 	Mean test loss of 930 batches: 0.9472869628860104.
[ Tue Jan 10 21:22:21 2023 ] 	Top1: 72.37%
[ Tue Jan 10 21:22:22 2023 ] 	Top5: 93.37%
[ Tue Jan 10 21:22:23 2023 ] Training epoch: 27
[ Tue Jan 10 21:33:10 2023 ] 	Mean training loss: 0.7550.  Mean training acc: 76.79%.
[ Tue Jan 10 21:33:21 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 21:33:22 2023 ] Eval epoch: 27
[ Tue Jan 10 21:38:28 2023 ] 	Mean test loss of 930 batches: 1.0000866275641227.
[ Tue Jan 10 21:38:28 2023 ] 	Top1: 70.49%
[ Tue Jan 10 21:38:29 2023 ] 	Top5: 93.25%
[ Tue Jan 10 21:38:29 2023 ] Training epoch: 28
[ Tue Jan 10 21:51:44 2023 ] 	Mean training loss: 0.7477.  Mean training acc: 77.19%.
[ Tue Jan 10 21:51:45 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jan 10 21:51:46 2023 ] Eval epoch: 28
[ Tue Jan 10 21:57:31 2023 ] 	Mean test loss of 930 batches: 1.0962277903992643.
[ Tue Jan 10 21:57:32 2023 ] 	Top1: 68.09%
[ Tue Jan 10 21:57:33 2023 ] 	Top5: 92.05%
[ Tue Jan 10 21:57:34 2023 ] Training epoch: 29
[ Tue Jan 10 22:09:00 2023 ] 	Mean training loss: 0.7418.  Mean training acc: 77.33%.
[ Tue Jan 10 22:09:00 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 22:09:02 2023 ] Eval epoch: 29
[ Tue Jan 10 22:14:00 2023 ] 	Mean test loss of 930 batches: 0.9370535302867171.
[ Tue Jan 10 22:14:01 2023 ] 	Top1: 72.61%
[ Tue Jan 10 22:14:02 2023 ] 	Top5: 93.39%
[ Tue Jan 10 22:14:03 2023 ] Training epoch: 30
[ Tue Jan 10 22:25:01 2023 ] 	Mean training loss: 0.7347.  Mean training acc: 77.36%.
[ Tue Jan 10 22:25:02 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 22:25:03 2023 ] Eval epoch: 30
[ Tue Jan 10 22:30:11 2023 ] 	Mean test loss of 930 batches: 0.9908465642762441.
[ Tue Jan 10 22:30:13 2023 ] 	Top1: 71.03%
[ Tue Jan 10 22:30:14 2023 ] 	Top5: 93.07%
[ Tue Jan 10 22:30:14 2023 ] Training epoch: 31
[ Tue Jan 10 22:42:04 2023 ] 	Mean training loss: 0.7364.  Mean training acc: 77.50%.
[ Tue Jan 10 22:42:06 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 22:42:08 2023 ] Eval epoch: 31
[ Tue Jan 10 22:47:46 2023 ] 	Mean test loss of 930 batches: 0.9242263229623917.
[ Tue Jan 10 22:47:48 2023 ] 	Top1: 73.51%
[ Tue Jan 10 22:47:49 2023 ] 	Top5: 93.28%
[ Tue Jan 10 22:47:50 2023 ] Training epoch: 32
[ Tue Jan 10 22:59:52 2023 ] 	Mean training loss: 0.7327.  Mean training acc: 77.78%.
[ Tue Jan 10 22:59:53 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 22:59:56 2023 ] Eval epoch: 32
[ Tue Jan 10 23:04:56 2023 ] 	Mean test loss of 930 batches: 0.933035320492201.
[ Tue Jan 10 23:04:58 2023 ] 	Top1: 72.54%
[ Tue Jan 10 23:04:59 2023 ] 	Top5: 93.64%
[ Tue Jan 10 23:05:00 2023 ] Training epoch: 33
[ Tue Jan 10 23:16:25 2023 ] 	Mean training loss: 0.7243.  Mean training acc: 77.67%.
[ Tue Jan 10 23:16:26 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 23:16:29 2023 ] Eval epoch: 33
[ Tue Jan 10 23:21:39 2023 ] 	Mean test loss of 930 batches: 0.9058740060816529.
[ Tue Jan 10 23:21:40 2023 ] 	Top1: 73.24%
[ Tue Jan 10 23:21:41 2023 ] 	Top5: 93.87%
[ Tue Jan 10 23:21:42 2023 ] Training epoch: 34
[ Tue Jan 10 23:33:15 2023 ] 	Mean training loss: 0.7235.  Mean training acc: 77.63%.
[ Tue Jan 10 23:33:16 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 23:33:18 2023 ] Eval epoch: 34
[ Tue Jan 10 23:38:22 2023 ] 	Mean test loss of 930 batches: 1.0177974279529305.
[ Tue Jan 10 23:38:23 2023 ] 	Top1: 70.79%
[ Tue Jan 10 23:38:24 2023 ] 	Top5: 93.42%
[ Tue Jan 10 23:38:25 2023 ] Training epoch: 35
[ Tue Jan 10 23:50:43 2023 ] 	Mean training loss: 0.7175.  Mean training acc: 77.96%.
[ Tue Jan 10 23:50:43 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jan 10 23:50:44 2023 ] Eval epoch: 35
[ Tue Jan 10 23:55:14 2023 ] 	Mean test loss of 930 batches: 0.8804959459650901.
[ Wed Jan 11 00:01:10 2023 ] 	Top1: 74.03%
[ Wed Jan 11 00:01:11 2023 ] 	Top5: 93.83%
[ Wed Jan 11 00:01:11 2023 ] Training epoch: 36
[ Wed Jan 11 00:13:55 2023 ] 	Mean training loss: 0.4164.  Mean training acc: 87.18%.
[ Wed Jan 11 00:13:55 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 00:13:56 2023 ] Eval epoch: 36
[ Wed Jan 11 00:19:36 2023 ] 	Mean test loss of 930 batches: 0.5051252689573072.
[ Wed Jan 11 00:19:37 2023 ] 	Top1: 84.66%
[ Wed Jan 11 00:19:38 2023 ] 	Top5: 97.08%
[ Wed Jan 11 00:19:39 2023 ] Training epoch: 37
[ Wed Jan 11 00:31:40 2023 ] 	Mean training loss: 0.3333.  Mean training acc: 89.66%.
[ Wed Jan 11 00:31:40 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 11 00:31:41 2023 ] Eval epoch: 37
[ Wed Jan 11 00:36:31 2023 ] 	Mean test loss of 930 batches: 0.4995476137245855.
[ Wed Jan 11 00:36:32 2023 ] 	Top1: 85.04%
[ Wed Jan 11 00:36:32 2023 ] 	Top5: 97.11%
[ Wed Jan 11 00:36:33 2023 ] Training epoch: 38
[ Wed Jan 11 00:46:33 2023 ] 	Mean training loss: 0.2989.  Mean training acc: 90.84%.
[ Wed Jan 11 00:46:33 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 00:46:35 2023 ] Eval epoch: 38
[ Wed Jan 11 00:51:29 2023 ] 	Mean test loss of 930 batches: 0.488882819362866.
[ Wed Jan 11 00:51:29 2023 ] 	Top1: 85.34%
[ Wed Jan 11 00:51:30 2023 ] 	Top5: 97.20%
[ Wed Jan 11 00:51:30 2023 ] Training epoch: 39
[ Wed Jan 11 01:02:59 2023 ] 	Mean training loss: 0.2750.  Mean training acc: 91.58%.
[ Wed Jan 11 01:02:59 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 01:03:00 2023 ] Eval epoch: 39
[ Wed Jan 11 01:08:24 2023 ] 	Mean test loss of 930 batches: 0.48171202996244994.
[ Wed Jan 11 01:08:26 2023 ] 	Top1: 85.67%
[ Wed Jan 11 01:08:27 2023 ] 	Top5: 97.30%
[ Wed Jan 11 01:08:28 2023 ] Training epoch: 40
[ Wed Jan 11 01:21:39 2023 ] 	Mean training loss: 0.2583.  Mean training acc: 92.24%.
[ Wed Jan 11 01:21:39 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 11 01:21:41 2023 ] Eval epoch: 40
[ Wed Jan 11 01:26:36 2023 ] 	Mean test loss of 930 batches: 0.503694312699059.
[ Wed Jan 11 01:26:50 2023 ] 	Top1: 85.22%
[ Wed Jan 11 01:26:50 2023 ] 	Top5: 97.18%
[ Wed Jan 11 01:26:51 2023 ] Training epoch: 41
[ Wed Jan 11 01:37:23 2023 ] 	Mean training loss: 0.2392.  Mean training acc: 92.75%.
[ Wed Jan 11 01:37:23 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 01:37:25 2023 ] Eval epoch: 41
[ Wed Jan 11 01:41:57 2023 ] 	Mean test loss of 930 batches: 0.495705615568866.
[ Wed Jan 11 01:41:58 2023 ] 	Top1: 85.36%
[ Wed Jan 11 01:41:59 2023 ] 	Top5: 97.12%
[ Wed Jan 11 01:41:59 2023 ] Training epoch: 42
[ Wed Jan 11 01:53:18 2023 ] 	Mean training loss: 0.2273.  Mean training acc: 93.24%.
[ Wed Jan 11 01:53:19 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 01:53:20 2023 ] Eval epoch: 42
[ Wed Jan 11 01:58:14 2023 ] 	Mean test loss of 930 batches: 0.49320456593107154.
[ Wed Jan 11 01:58:24 2023 ] 	Top1: 85.51%
[ Wed Jan 11 01:58:24 2023 ] 	Top5: 97.22%
[ Wed Jan 11 01:58:25 2023 ] Training epoch: 43
[ Wed Jan 11 02:11:22 2023 ] 	Mean training loss: 0.2153.  Mean training acc: 93.67%.
[ Wed Jan 11 02:11:30 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 11 02:11:31 2023 ] Eval epoch: 43
[ Wed Jan 11 02:16:58 2023 ] 	Mean test loss of 930 batches: 0.5065402344189665.
[ Wed Jan 11 02:17:06 2023 ] 	Top1: 85.11%
[ Wed Jan 11 02:17:07 2023 ] 	Top5: 97.09%
[ Wed Jan 11 02:17:08 2023 ] Training epoch: 44
[ Wed Jan 11 02:28:20 2023 ] 	Mean training loss: 0.2051.  Mean training acc: 93.99%.
[ Wed Jan 11 02:28:22 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 02:28:23 2023 ] Eval epoch: 44
[ Wed Jan 11 02:33:07 2023 ] 	Mean test loss of 930 batches: 0.5098175789239586.
[ Wed Jan 11 02:33:09 2023 ] 	Top1: 85.25%
[ Wed Jan 11 02:33:09 2023 ] 	Top5: 97.03%
[ Wed Jan 11 02:33:10 2023 ] Training epoch: 45
[ Wed Jan 11 02:43:46 2023 ] 	Mean training loss: 0.2002.  Mean training acc: 94.06%.
[ Wed Jan 11 02:43:58 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 02:44:01 2023 ] Eval epoch: 45
[ Wed Jan 11 02:49:03 2023 ] 	Mean test loss of 930 batches: 0.5189825184322814.
[ Wed Jan 11 02:49:04 2023 ] 	Top1: 85.03%
[ Wed Jan 11 02:49:04 2023 ] 	Top5: 97.04%
[ Wed Jan 11 02:49:13 2023 ] Training epoch: 46
[ Wed Jan 11 03:01:09 2023 ] 	Mean training loss: 0.1890.  Mean training acc: 94.41%.
[ Wed Jan 11 03:01:14 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 03:01:15 2023 ] Eval epoch: 46
[ Wed Jan 11 03:06:48 2023 ] 	Mean test loss of 930 batches: 0.5246220914346557.
[ Wed Jan 11 03:06:49 2023 ] 	Top1: 85.21%
[ Wed Jan 11 03:06:50 2023 ] 	Top5: 96.92%
[ Wed Jan 11 03:06:50 2023 ] Training epoch: 47
[ Wed Jan 11 03:19:22 2023 ] 	Mean training loss: 0.1845.  Mean training acc: 94.70%.
[ Wed Jan 11 03:19:23 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 03:19:23 2023 ] Eval epoch: 47
[ Wed Jan 11 03:24:24 2023 ] 	Mean test loss of 930 batches: 0.5438973259741581.
[ Wed Jan 11 03:24:25 2023 ] 	Top1: 84.57%
[ Wed Jan 11 03:24:25 2023 ] 	Top5: 96.89%
[ Wed Jan 11 03:24:26 2023 ] Training epoch: 48
[ Wed Jan 11 03:34:45 2023 ] 	Mean training loss: 0.1793.  Mean training acc: 94.81%.
[ Wed Jan 11 03:34:46 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan 11 03:34:46 2023 ] Eval epoch: 48
[ Wed Jan 11 03:39:38 2023 ] 	Mean test loss of 930 batches: 0.5416596702189855.
[ Wed Jan 11 03:39:40 2023 ] 	Top1: 84.53%
[ Wed Jan 11 03:39:40 2023 ] 	Top5: 96.95%
[ Wed Jan 11 03:39:41 2023 ] Training epoch: 49
[ Wed Jan 11 03:50:58 2023 ] 	Mean training loss: 0.1783.  Mean training acc: 94.93%.
[ Wed Jan 11 03:50:59 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 03:50:59 2023 ] Eval epoch: 49
[ Wed Jan 11 03:56:31 2023 ] 	Mean test loss of 930 batches: 0.5402692640340456.
[ Wed Jan 11 03:56:32 2023 ] 	Top1: 84.75%
[ Wed Jan 11 03:56:32 2023 ] 	Top5: 96.87%
[ Wed Jan 11 03:56:33 2023 ] Training epoch: 50
[ Wed Jan 11 04:09:48 2023 ] 	Mean training loss: 0.1712.  Mean training acc: 95.16%.
[ Wed Jan 11 04:09:49 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 11 04:09:50 2023 ] Eval epoch: 50
[ Wed Jan 11 04:15:16 2023 ] 	Mean test loss of 930 batches: 0.5578247652979949.
[ Wed Jan 11 04:15:18 2023 ] 	Top1: 84.35%
[ Wed Jan 11 04:15:18 2023 ] 	Top5: 96.87%
[ Wed Jan 11 04:15:20 2023 ] Training epoch: 51
[ Wed Jan 11 04:26:02 2023 ] 	Mean training loss: 0.1709.  Mean training acc: 95.09%.
[ Wed Jan 11 04:26:02 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 04:26:03 2023 ] Eval epoch: 51
[ Wed Jan 11 04:30:34 2023 ] 	Mean test loss of 930 batches: 0.5558621862682924.
[ Wed Jan 11 04:30:36 2023 ] 	Top1: 84.45%
[ Wed Jan 11 04:30:36 2023 ] 	Top5: 96.73%
[ Wed Jan 11 04:30:36 2023 ] Training epoch: 52
[ Wed Jan 11 04:41:02 2023 ] 	Mean training loss: 0.1696.  Mean training acc: 95.18%.
[ Wed Jan 11 04:41:02 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 04:41:03 2023 ] Eval epoch: 52
[ Wed Jan 11 04:46:07 2023 ] 	Mean test loss of 930 batches: 0.5799248029688193.
[ Wed Jan 11 04:46:08 2023 ] 	Top1: 83.86%
[ Wed Jan 11 04:46:09 2023 ] 	Top5: 96.74%
[ Wed Jan 11 04:46:09 2023 ] Training epoch: 53
[ Wed Jan 11 04:59:26 2023 ] 	Mean training loss: 0.1655.  Mean training acc: 95.30%.
[ Wed Jan 11 04:59:26 2023 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jan 11 04:59:27 2023 ] Eval epoch: 53
[ Wed Jan 11 05:05:00 2023 ] 	Mean test loss of 930 batches: 0.5923735425076497.
[ Wed Jan 11 05:05:06 2023 ] 	Top1: 83.64%
[ Wed Jan 11 05:05:07 2023 ] 	Top5: 96.52%
[ Wed Jan 11 05:05:07 2023 ] Training epoch: 54
[ Wed Jan 11 05:17:49 2023 ] 	Mean training loss: 0.1678.  Mean training acc: 95.24%.
[ Wed Jan 11 05:17:49 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 05:17:50 2023 ] Eval epoch: 54
[ Wed Jan 11 05:22:34 2023 ] 	Mean test loss of 930 batches: 0.5914151430570631.
[ Wed Jan 11 05:22:35 2023 ] 	Top1: 83.66%
[ Wed Jan 11 05:22:35 2023 ] 	Top5: 96.71%
[ Wed Jan 11 05:22:36 2023 ] Training epoch: 55
[ Wed Jan 11 05:32:28 2023 ] 	Mean training loss: 0.1668.  Mean training acc: 95.19%.
[ Wed Jan 11 05:32:28 2023 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jan 11 05:32:29 2023 ] Eval epoch: 55
[ Wed Jan 11 05:37:06 2023 ] 	Mean test loss of 930 batches: 0.5633937375599979.
[ Wed Jan 11 05:37:07 2023 ] 	Top1: 84.41%
[ Wed Jan 11 05:37:07 2023 ] 	Top5: 96.65%
[ Wed Jan 11 05:37:08 2023 ] Training epoch: 56
[ Wed Jan 11 05:49:55 2023 ] 	Mean training loss: 0.0998.  Mean training acc: 97.68%.
[ Wed Jan 11 05:50:03 2023 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jan 11 05:50:04 2023 ] Eval epoch: 56
[ Wed Jan 11 05:55:39 2023 ] 	Mean test loss of 930 batches: 0.5029970252265533.
[ Wed Jan 11 05:55:41 2023 ] 	Top1: 86.11%
[ Wed Jan 11 05:55:41 2023 ] 	Top5: 97.05%
[ Wed Jan 11 05:55:42 2023 ] Training epoch: 57
[ Thu Jan 12 09:29:25 2023 ] Load weights from work_dir/cset/ctrgcn_local_SHT_BL/runs-56-47656.pt.
[ Thu Jan 12 09:29:28 2023 ] using warm up, epoch: 0
[ Thu Jan 12 09:31:10 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/cset/ctrgcn_local_SHT_BL/runs-56-47656.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 56, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Thu Jan 12 09:31:10 2023 ] # Parameters: 1508876
[ Thu Jan 12 09:31:10 2023 ] Training epoch: 57
[ Thu Jan 12 09:32:22 2023 ] Load weights from work_dir/cset/ctrgcn_local_SHT_BL/runs-56-47656.pt.
[ Thu Jan 12 09:32:25 2023 ] using warm up, epoch: 0
[ Thu Jan 12 09:32:38 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/cset/ctrgcn_local_SHT_BL/runs-56-47656.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 56, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 0}

[ Thu Jan 12 09:32:38 2023 ] # Parameters: 1508876
[ Thu Jan 12 09:32:38 2023 ] Training epoch: 57
[ Thu Jan 12 09:39:28 2023 ] 	Mean training loss: 0.0777.  Mean training acc: 98.39%.
[ Thu Jan 12 09:39:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 09:39:29 2023 ] Eval epoch: 57
[ Thu Jan 12 09:42:15 2023 ] 	Mean test loss of 930 batches: 0.5005631928562477.
[ Thu Jan 12 09:42:16 2023 ] 	Top1: 86.38%
[ Thu Jan 12 09:42:16 2023 ] 	Top5: 97.09%
[ Thu Jan 12 09:42:17 2023 ] Training epoch: 58
[ Thu Jan 12 09:49:07 2023 ] 	Mean training loss: 0.0668.  Mean training acc: 98.73%.
[ Thu Jan 12 09:49:08 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 09:49:08 2023 ] Eval epoch: 58
[ Thu Jan 12 09:51:56 2023 ] 	Mean test loss of 930 batches: 0.5054167271621766.
[ Thu Jan 12 09:51:59 2023 ] 	Top1: 86.32%
[ Thu Jan 12 09:52:00 2023 ] 	Top5: 97.04%
[ Thu Jan 12 09:52:00 2023 ] Training epoch: 59
[ Thu Jan 12 09:58:51 2023 ] 	Mean training loss: 0.0605.  Mean training acc: 98.92%.
[ Thu Jan 12 09:58:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 09:58:51 2023 ] Eval epoch: 59
[ Thu Jan 12 10:01:39 2023 ] 	Mean test loss of 930 batches: 0.5064373254976285.
[ Thu Jan 12 10:01:39 2023 ] 	Top1: 86.36%
[ Thu Jan 12 10:01:40 2023 ] 	Top5: 97.03%
[ Thu Jan 12 10:01:40 2023 ] Training epoch: 60
[ Thu Jan 12 10:08:31 2023 ] 	Mean training loss: 0.0568.  Mean training acc: 98.98%.
[ Thu Jan 12 10:08:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:08:31 2023 ] Eval epoch: 60
[ Thu Jan 12 10:11:14 2023 ] 	Mean test loss of 930 batches: 0.5071689820377737.
[ Thu Jan 12 10:11:14 2023 ] 	Top1: 86.38%
[ Thu Jan 12 10:11:15 2023 ] 	Top5: 97.08%
[ Thu Jan 12 10:11:21 2023 ] Training epoch: 61
[ Thu Jan 12 10:18:09 2023 ] 	Mean training loss: 0.0539.  Mean training acc: 99.08%.
[ Thu Jan 12 10:18:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:18:10 2023 ] Eval epoch: 61
[ Thu Jan 12 10:20:51 2023 ] 	Mean test loss of 930 batches: 0.5115861859613209.
[ Thu Jan 12 10:20:53 2023 ] 	Top1: 86.29%
[ Thu Jan 12 10:20:53 2023 ] 	Top5: 97.07%
[ Thu Jan 12 10:20:53 2023 ] Training epoch: 62
[ Thu Jan 12 10:27:43 2023 ] 	Mean training loss: 0.0506.  Mean training acc: 99.15%.
[ Thu Jan 12 10:27:43 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:27:43 2023 ] Eval epoch: 62
[ Thu Jan 12 10:30:26 2023 ] 	Mean test loss of 930 batches: 0.514239660299994.
[ Thu Jan 12 10:30:26 2023 ] 	Top1: 86.31%
[ Thu Jan 12 10:30:27 2023 ] 	Top5: 97.05%
[ Thu Jan 12 10:30:27 2023 ] Training epoch: 63
[ Thu Jan 12 10:37:16 2023 ] 	Mean training loss: 0.0491.  Mean training acc: 99.21%.
[ Thu Jan 12 10:37:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:37:16 2023 ] Eval epoch: 63
[ Thu Jan 12 10:39:58 2023 ] 	Mean test loss of 930 batches: 0.5138605105540445.
[ Thu Jan 12 10:39:58 2023 ] 	Top1: 86.42%
[ Thu Jan 12 10:39:59 2023 ] 	Top5: 97.02%
[ Thu Jan 12 10:39:59 2023 ] Training epoch: 64
[ Thu Jan 12 10:46:48 2023 ] 	Mean training loss: 0.0462.  Mean training acc: 99.27%.
[ Thu Jan 12 10:46:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:46:49 2023 ] Eval epoch: 64
[ Thu Jan 12 10:49:31 2023 ] 	Mean test loss of 930 batches: 0.5131192103669208.
[ Thu Jan 12 10:49:32 2023 ] 	Top1: 86.45%
[ Thu Jan 12 10:49:33 2023 ] 	Top5: 97.08%
[ Thu Jan 12 10:49:33 2023 ] Training epoch: 65
[ Thu Jan 12 10:56:22 2023 ] 	Mean training loss: 0.0455.  Mean training acc: 99.28%.
[ Thu Jan 12 10:56:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 12 10:56:22 2023 ] Eval epoch: 65
[ Thu Jan 12 10:59:04 2023 ] 	Mean test loss of 930 batches: 0.5210947762413691.
[ Thu Jan 12 10:59:05 2023 ] 	Top1: 86.27%
[ Thu Jan 12 10:59:05 2023 ] 	Top5: 96.98%
[ Thu Jan 12 11:01:49 2023 ] Best accuracy: 0.8644686181212906
[ Thu Jan 12 11:01:50 2023 ] Epoch number: 64
[ Thu Jan 12 11:01:50 2023 ] Model name: work_dir/cset/ctrgcn_local_SHT_BL
[ Thu Jan 12 11:01:50 2023 ] Model total number of params: 1508876
[ Thu Jan 12 11:01:50 2023 ] Weight decay: 0.0004
[ Thu Jan 12 11:01:50 2023 ] Base LR: 0.1
[ Thu Jan 12 11:01:50 2023 ] Batch Size: 64
[ Thu Jan 12 11:01:50 2023 ] Test Batch Size: 64
[ Thu Jan 12 11:01:50 2023 ] seed: 1
[ Wed Jan 18 15:37:39 2023 ] using warm up, epoch: 5
[ Wed Jan 18 15:39:21 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jan 18 15:39:21 2023 ] # Parameters: 1508876
[ Wed Jan 18 15:39:21 2023 ] Training epoch: 1
[ Wed Jan 18 15:53:24 2023 ] 	Mean training loss: 3.2549.  Mean training acc: 19.63%.
[ Wed Jan 18 15:53:24 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Jan 18 15:53:25 2023 ] Eval epoch: 1
[ Wed Jan 18 16:03:18 2023 ] 	Mean test loss of 930 batches: 2.5425211093759024.
[ Wed Jan 18 16:03:18 2023 ] 	Top1: 31.41%
[ Wed Jan 18 16:03:19 2023 ] 	Top5: 66.26%
[ Wed Jan 18 16:03:19 2023 ] Training epoch: 2
[ Wed Jan 18 16:17:53 2023 ] 	Mean training loss: 2.1875.  Mean training acc: 38.68%.
[ Wed Jan 18 16:17:53 2023 ] 	Time consumption: [Data]00%, [Network]100%
[ Wed Jan 18 16:17:53 2023 ] Eval epoch: 2
[ Wed Jan 18 16:28:15 2023 ] 	Mean test loss of 930 batches: 1.8859699424876961.
[ Wed Jan 18 16:28:16 2023 ] 	Top1: 46.53%
[ Wed Jan 18 16:28:16 2023 ] 	Top5: 80.08%
[ Wed Jan 18 16:28:16 2023 ] Training epoch: 3
[ Wed Jan 18 16:42:54 2023 ] 	Mean training loss: 1.7728.  Mean training acc: 48.99%.
[ Wed Jan 18 16:42:54 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 16:42:54 2023 ] Eval epoch: 3
[ Wed Jan 18 16:53:09 2023 ] 	Mean test loss of 930 batches: 1.6875925869070074.
[ Wed Jan 18 16:53:09 2023 ] 	Top1: 51.30%
[ Wed Jan 18 16:53:10 2023 ] 	Top5: 83.52%
[ Wed Jan 18 16:53:10 2023 ] Training epoch: 4
[ Wed Jan 18 17:07:47 2023 ] 	Mean training loss: 1.5527.  Mean training acc: 54.83%.
[ Wed Jan 18 17:07:47 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 17:07:47 2023 ] Eval epoch: 4
[ Wed Jan 18 17:18:04 2023 ] 	Mean test loss of 930 batches: 1.6980406803469503.
[ Wed Jan 18 17:18:04 2023 ] 	Top1: 51.21%
[ Wed Jan 18 17:18:05 2023 ] 	Top5: 82.58%
[ Wed Jan 18 17:18:05 2023 ] Training epoch: 5
[ Wed Jan 18 17:32:41 2023 ] 	Mean training loss: 1.4245.  Mean training acc: 58.13%.
[ Wed Jan 18 17:32:41 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 17:32:41 2023 ] Eval epoch: 5
[ Wed Jan 18 17:42:58 2023 ] 	Mean test loss of 930 batches: 1.5708941021273213.
[ Wed Jan 18 17:42:59 2023 ] 	Top1: 55.05%
[ Wed Jan 18 17:42:59 2023 ] 	Top5: 85.04%
[ Wed Jan 18 17:42:59 2023 ] Training epoch: 6
[ Wed Jan 18 17:57:37 2023 ] 	Mean training loss: 1.2823.  Mean training acc: 61.81%.
[ Wed Jan 18 17:57:37 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 17:57:37 2023 ] Eval epoch: 6
[ Wed Jan 18 18:07:53 2023 ] 	Mean test loss of 930 batches: 1.433630666040605.
[ Wed Jan 18 18:07:53 2023 ] 	Top1: 58.36%
[ Wed Jan 18 18:07:54 2023 ] 	Top5: 87.33%
[ Wed Jan 18 18:07:54 2023 ] Training epoch: 7
[ Wed Jan 18 18:22:33 2023 ] 	Mean training loss: 1.1711.  Mean training acc: 64.88%.
[ Wed Jan 18 18:22:33 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 18:22:34 2023 ] Eval epoch: 7
[ Wed Jan 18 18:32:50 2023 ] 	Mean test loss of 930 batches: 1.614363939980025.
[ Wed Jan 18 18:32:51 2023 ] 	Top1: 56.02%
[ Wed Jan 18 18:32:51 2023 ] 	Top5: 85.94%
[ Wed Jan 18 18:32:51 2023 ] Training epoch: 8
[ Wed Jan 18 18:47:45 2023 ] 	Mean training loss: 1.0979.  Mean training acc: 66.97%.
[ Wed Jan 18 18:47:45 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 18:47:46 2023 ] Eval epoch: 8
[ Wed Jan 18 18:58:07 2023 ] 	Mean test loss of 930 batches: 1.4181825123166525.
[ Wed Jan 18 18:58:08 2023 ] 	Top1: 60.56%
[ Wed Jan 18 18:58:08 2023 ] 	Top5: 87.57%
[ Wed Jan 18 18:58:08 2023 ] Training epoch: 9
[ Wed Jan 18 19:12:46 2023 ] 	Mean training loss: 1.0369.  Mean training acc: 68.75%.
[ Wed Jan 18 19:12:46 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 19:12:46 2023 ] Eval epoch: 9
[ Wed Jan 18 19:23:04 2023 ] 	Mean test loss of 930 batches: 1.232453009582335.
[ Wed Jan 18 19:23:04 2023 ] 	Top1: 64.87%
[ Wed Jan 18 19:23:05 2023 ] 	Top5: 90.19%
[ Wed Jan 18 19:23:05 2023 ] Training epoch: 10
[ Wed Jan 18 19:37:42 2023 ] 	Mean training loss: 0.9842.  Mean training acc: 70.25%.
[ Wed Jan 18 19:37:42 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 19:37:43 2023 ] Eval epoch: 10
[ Wed Jan 18 19:48:00 2023 ] 	Mean test loss of 930 batches: 1.142046598465212.
[ Wed Jan 18 19:48:01 2023 ] 	Top1: 67.67%
[ Wed Jan 18 19:48:01 2023 ] 	Top5: 90.81%
[ Wed Jan 18 19:48:01 2023 ] Training epoch: 11
[ Wed Jan 18 20:02:36 2023 ] 	Mean training loss: 0.9525.  Mean training acc: 71.01%.
[ Wed Jan 18 20:02:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 20:02:36 2023 ] Eval epoch: 11
[ Wed Jan 18 20:12:55 2023 ] 	Mean test loss of 930 batches: 1.26941898997112.
[ Wed Jan 18 20:12:55 2023 ] 	Top1: 63.38%
[ Wed Jan 18 20:12:56 2023 ] 	Top5: 89.62%
[ Wed Jan 18 20:12:56 2023 ] Training epoch: 12
[ Wed Jan 18 20:27:30 2023 ] 	Mean training loss: 0.9200.  Mean training acc: 71.98%.
[ Wed Jan 18 20:27:30 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 20:27:30 2023 ] Eval epoch: 12
[ Wed Jan 18 20:37:48 2023 ] 	Mean test loss of 930 batches: 1.3389246641628203.
[ Wed Jan 18 20:37:48 2023 ] 	Top1: 62.65%
[ Wed Jan 18 20:37:48 2023 ] 	Top5: 88.40%
[ Wed Jan 18 20:37:49 2023 ] Training epoch: 13
[ Wed Jan 18 20:52:26 2023 ] 	Mean training loss: 0.9097.  Mean training acc: 72.25%.
[ Wed Jan 18 20:52:26 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 20:52:26 2023 ] Eval epoch: 13
[ Wed Jan 18 21:02:45 2023 ] 	Mean test loss of 930 batches: 1.1289837369995732.
[ Wed Jan 18 21:02:45 2023 ] 	Top1: 67.65%
[ Wed Jan 18 21:02:46 2023 ] 	Top5: 90.90%
[ Wed Jan 18 21:02:46 2023 ] Training epoch: 14
[ Wed Jan 18 21:17:23 2023 ] 	Mean training loss: 0.8743.  Mean training acc: 73.22%.
[ Wed Jan 18 21:17:23 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 21:17:23 2023 ] Eval epoch: 14
[ Wed Jan 18 21:27:42 2023 ] 	Mean test loss of 930 batches: 1.1361840181132798.
[ Wed Jan 18 21:27:43 2023 ] 	Top1: 68.10%
[ Wed Jan 18 21:27:43 2023 ] 	Top5: 91.00%
[ Wed Jan 18 21:27:43 2023 ] Training epoch: 15
[ Wed Jan 18 21:42:18 2023 ] 	Mean training loss: 0.8602.  Mean training acc: 73.91%.
[ Wed Jan 18 21:42:18 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 21:42:18 2023 ] Eval epoch: 15
[ Wed Jan 18 21:52:35 2023 ] 	Mean test loss of 930 batches: 1.1150881980055123.
[ Wed Jan 18 21:52:35 2023 ] 	Top1: 68.05%
[ Wed Jan 18 21:52:36 2023 ] 	Top5: 91.93%
[ Wed Jan 18 21:52:36 2023 ] Training epoch: 16
[ Wed Jan 18 22:07:12 2023 ] 	Mean training loss: 0.8733.  Mean training acc: 73.34%.
[ Wed Jan 18 22:07:12 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 22:07:12 2023 ] Eval epoch: 16
[ Wed Jan 18 22:17:29 2023 ] 	Mean test loss of 930 batches: 1.1431916334616241.
[ Wed Jan 18 22:17:30 2023 ] 	Top1: 67.89%
[ Wed Jan 18 22:17:30 2023 ] 	Top5: 91.74%
[ Wed Jan 18 22:17:30 2023 ] Training epoch: 17
[ Wed Jan 18 22:32:06 2023 ] 	Mean training loss: 0.8573.  Mean training acc: 73.68%.
[ Wed Jan 18 22:32:06 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 22:32:06 2023 ] Eval epoch: 17
[ Wed Jan 18 22:42:24 2023 ] 	Mean test loss of 930 batches: 1.189997578083828.
[ Wed Jan 18 22:42:24 2023 ] 	Top1: 65.57%
[ Wed Jan 18 22:42:25 2023 ] 	Top5: 91.58%
[ Wed Jan 18 22:42:25 2023 ] Training epoch: 18
[ Wed Jan 18 22:57:03 2023 ] 	Mean training loss: 0.8502.  Mean training acc: 74.08%.
[ Wed Jan 18 22:57:03 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 22:57:03 2023 ] Eval epoch: 18
[ Wed Jan 18 23:07:20 2023 ] 	Mean test loss of 930 batches: 1.0610532052254165.
[ Wed Jan 18 23:07:20 2023 ] 	Top1: 69.38%
[ Wed Jan 18 23:07:21 2023 ] 	Top5: 92.38%
[ Wed Jan 18 23:07:21 2023 ] Training epoch: 19
[ Wed Jan 18 23:21:57 2023 ] 	Mean training loss: 0.8284.  Mean training acc: 74.52%.
[ Wed Jan 18 23:21:57 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 23:21:57 2023 ] Eval epoch: 19
[ Wed Jan 18 23:32:15 2023 ] 	Mean test loss of 930 batches: 1.1641488522291183.
[ Wed Jan 18 23:32:15 2023 ] 	Top1: 66.73%
[ Wed Jan 18 23:32:16 2023 ] 	Top5: 90.93%
[ Wed Jan 18 23:32:16 2023 ] Training epoch: 20
[ Wed Jan 18 23:46:52 2023 ] 	Mean training loss: 0.8276.  Mean training acc: 74.67%.
[ Wed Jan 18 23:46:52 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Wed Jan 18 23:46:52 2023 ] Eval epoch: 20
[ Wed Jan 18 23:57:07 2023 ] 	Mean test loss of 930 batches: 1.0991271234968658.
[ Wed Jan 18 23:57:08 2023 ] 	Top1: 67.93%
[ Wed Jan 18 23:57:08 2023 ] 	Top5: 91.64%
[ Wed Jan 18 23:57:08 2023 ] Training epoch: 21
[ Thu Jan 19 00:11:46 2023 ] 	Mean training loss: 0.8206.  Mean training acc: 74.98%.
[ Thu Jan 19 00:11:46 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 00:11:46 2023 ] Eval epoch: 21
[ Thu Jan 19 00:22:04 2023 ] 	Mean test loss of 930 batches: 1.0112636794005672.
[ Thu Jan 19 00:22:05 2023 ] 	Top1: 70.80%
[ Thu Jan 19 00:22:05 2023 ] 	Top5: 92.51%
[ Thu Jan 19 00:22:05 2023 ] Training epoch: 22
[ Thu Jan 19 00:36:42 2023 ] 	Mean training loss: 0.8017.  Mean training acc: 75.24%.
[ Thu Jan 19 00:36:42 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 00:36:42 2023 ] Eval epoch: 22
[ Thu Jan 19 00:47:02 2023 ] 	Mean test loss of 930 batches: 1.085248817711748.
[ Thu Jan 19 00:47:02 2023 ] 	Top1: 67.82%
[ Thu Jan 19 00:47:02 2023 ] 	Top5: 92.05%
[ Thu Jan 19 00:47:02 2023 ] Training epoch: 23
[ Thu Jan 19 01:01:40 2023 ] 	Mean training loss: 0.8080.  Mean training acc: 75.30%.
[ Thu Jan 19 01:01:40 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 01:01:40 2023 ] Eval epoch: 23
[ Thu Jan 19 01:11:57 2023 ] 	Mean test loss of 930 batches: 1.0855453169794493.
[ Thu Jan 19 01:11:57 2023 ] 	Top1: 68.21%
[ Thu Jan 19 01:11:58 2023 ] 	Top5: 91.93%
[ Thu Jan 19 01:11:58 2023 ] Training epoch: 24
[ Thu Jan 19 01:26:33 2023 ] 	Mean training loss: 0.8000.  Mean training acc: 75.62%.
[ Thu Jan 19 01:26:33 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 01:26:33 2023 ] Eval epoch: 24
[ Thu Jan 19 01:36:54 2023 ] 	Mean test loss of 930 batches: 0.9983294397913.
[ Thu Jan 19 01:36:54 2023 ] 	Top1: 71.38%
[ Thu Jan 19 01:36:54 2023 ] 	Top5: 93.03%
[ Thu Jan 19 01:36:55 2023 ] Training epoch: 25
[ Thu Jan 19 01:51:33 2023 ] 	Mean training loss: 0.7883.  Mean training acc: 75.94%.
[ Thu Jan 19 01:51:33 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 01:51:33 2023 ] Eval epoch: 25
[ Thu Jan 19 02:01:57 2023 ] 	Mean test loss of 930 batches: 0.9341247343568392.
[ Thu Jan 19 02:01:57 2023 ] 	Top1: 72.43%
[ Thu Jan 19 02:01:57 2023 ] 	Top5: 93.76%
[ Thu Jan 19 02:01:57 2023 ] Training epoch: 26
[ Thu Jan 19 02:16:35 2023 ] 	Mean training loss: 0.7837.  Mean training acc: 76.00%.
[ Thu Jan 19 02:16:35 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 02:16:35 2023 ] Eval epoch: 26
[ Thu Jan 19 02:26:55 2023 ] 	Mean test loss of 930 batches: 0.978899962831569.
[ Thu Jan 19 02:26:56 2023 ] 	Top1: 71.14%
[ Thu Jan 19 02:26:56 2023 ] 	Top5: 93.29%
[ Thu Jan 19 02:26:56 2023 ] Training epoch: 27
[ Thu Jan 19 02:41:36 2023 ] 	Mean training loss: 0.7829.  Mean training acc: 75.94%.
[ Thu Jan 19 02:41:36 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 02:41:36 2023 ] Eval epoch: 27
[ Thu Jan 19 02:51:54 2023 ] 	Mean test loss of 930 batches: 0.9893812962757644.
[ Thu Jan 19 02:51:54 2023 ] 	Top1: 70.72%
[ Thu Jan 19 02:51:54 2023 ] 	Top5: 93.05%
[ Thu Jan 19 02:51:54 2023 ] Training epoch: 28
[ Thu Jan 19 03:06:30 2023 ] 	Mean training loss: 0.7722.  Mean training acc: 76.36%.
[ Thu Jan 19 03:06:30 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 03:06:30 2023 ] Eval epoch: 28
[ Thu Jan 19 03:16:51 2023 ] 	Mean test loss of 930 batches: 1.7077495578796633.
[ Thu Jan 19 03:16:51 2023 ] 	Top1: 53.87%
[ Thu Jan 19 03:16:52 2023 ] 	Top5: 84.04%
[ Thu Jan 19 03:16:52 2023 ] Training epoch: 29
[ Thu Jan 19 03:31:27 2023 ] 	Mean training loss: 0.7707.  Mean training acc: 76.21%.
[ Thu Jan 19 03:31:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 03:31:27 2023 ] Eval epoch: 29
[ Thu Jan 19 03:41:44 2023 ] 	Mean test loss of 930 batches: 1.0502396998226002.
[ Thu Jan 19 03:41:45 2023 ] 	Top1: 68.94%
[ Thu Jan 19 03:41:45 2023 ] 	Top5: 92.79%
[ Thu Jan 19 03:41:45 2023 ] Training epoch: 30
[ Thu Jan 19 03:56:25 2023 ] 	Mean training loss: 0.7638.  Mean training acc: 76.47%.
[ Thu Jan 19 03:56:25 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 03:56:25 2023 ] Eval epoch: 30
[ Thu Jan 19 04:06:44 2023 ] 	Mean test loss of 930 batches: 0.9890209289007289.
[ Thu Jan 19 04:06:44 2023 ] 	Top1: 70.34%
[ Thu Jan 19 04:06:45 2023 ] 	Top5: 93.18%
[ Thu Jan 19 04:06:45 2023 ] Training epoch: 31
[ Thu Jan 19 04:21:23 2023 ] 	Mean training loss: 0.7602.  Mean training acc: 76.71%.
[ Thu Jan 19 04:21:23 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 04:21:23 2023 ] Eval epoch: 31
[ Thu Jan 19 04:31:42 2023 ] 	Mean test loss of 930 batches: 0.9951725284899434.
[ Thu Jan 19 04:31:42 2023 ] 	Top1: 71.26%
[ Thu Jan 19 04:31:43 2023 ] 	Top5: 92.84%
[ Thu Jan 19 04:31:43 2023 ] Training epoch: 32
[ Thu Jan 19 04:46:17 2023 ] 	Mean training loss: 0.7637.  Mean training acc: 76.64%.
[ Thu Jan 19 04:46:17 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 04:46:17 2023 ] Eval epoch: 32
[ Thu Jan 19 04:56:35 2023 ] 	Mean test loss of 930 batches: 1.017937657108871.
[ Thu Jan 19 04:56:35 2023 ] 	Top1: 70.38%
[ Thu Jan 19 04:56:35 2023 ] 	Top5: 92.79%
[ Thu Jan 19 04:56:36 2023 ] Training epoch: 33
[ Thu Jan 19 05:11:12 2023 ] 	Mean training loss: 0.7476.  Mean training acc: 77.16%.
[ Thu Jan 19 05:11:12 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 05:11:12 2023 ] Eval epoch: 33
[ Thu Jan 19 05:21:31 2023 ] 	Mean test loss of 930 batches: 0.9495032008617155.
[ Thu Jan 19 05:21:31 2023 ] 	Top1: 72.15%
[ Thu Jan 19 05:21:32 2023 ] 	Top5: 93.88%
[ Thu Jan 19 05:21:32 2023 ] Training epoch: 34
[ Thu Jan 19 05:36:18 2023 ] 	Mean training loss: 0.7486.  Mean training acc: 76.91%.
[ Thu Jan 19 05:36:18 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 05:36:18 2023 ] Eval epoch: 34
[ Thu Jan 19 05:46:37 2023 ] 	Mean test loss of 930 batches: 0.9925698736982961.
[ Thu Jan 19 05:46:38 2023 ] 	Top1: 71.34%
[ Thu Jan 19 05:46:38 2023 ] 	Top5: 92.99%
[ Thu Jan 19 05:46:38 2023 ] Training epoch: 35
[ Thu Jan 19 06:01:08 2023 ] 	Mean training loss: 0.7414.  Mean training acc: 77.31%.
[ Thu Jan 19 06:01:08 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 06:01:08 2023 ] Eval epoch: 35
[ Thu Jan 19 06:11:25 2023 ] 	Mean test loss of 930 batches: 1.0244835979675735.
[ Thu Jan 19 06:11:26 2023 ] 	Top1: 70.14%
[ Thu Jan 19 06:11:26 2023 ] 	Top5: 92.46%
[ Thu Jan 19 06:11:26 2023 ] Training epoch: 36
[ Thu Jan 19 06:26:04 2023 ] 	Mean training loss: 0.4366.  Mean training acc: 86.68%.
[ Thu Jan 19 06:26:05 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 06:26:05 2023 ] Eval epoch: 36
[ Thu Jan 19 06:36:22 2023 ] 	Mean test loss of 930 batches: 0.5166749020497645.
[ Thu Jan 19 06:36:23 2023 ] 	Top1: 84.27%
[ Thu Jan 19 06:36:23 2023 ] 	Top5: 97.01%
[ Thu Jan 19 06:36:24 2023 ] Training epoch: 37
[ Thu Jan 19 06:51:01 2023 ] 	Mean training loss: 0.3536.  Mean training acc: 89.18%.
[ Thu Jan 19 06:51:02 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 06:51:02 2023 ] Eval epoch: 37
[ Thu Jan 19 07:01:21 2023 ] 	Mean test loss of 930 batches: 0.5038602191193771.
[ Thu Jan 19 07:01:21 2023 ] 	Top1: 84.76%
[ Thu Jan 19 07:01:22 2023 ] 	Top5: 97.04%
[ Thu Jan 19 07:01:22 2023 ] Training epoch: 38
[ Thu Jan 19 07:15:57 2023 ] 	Mean training loss: 0.3187.  Mean training acc: 90.17%.
[ Thu Jan 19 07:15:57 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 07:15:57 2023 ] Eval epoch: 38
[ Thu Jan 19 07:26:16 2023 ] 	Mean test loss of 930 batches: 0.4939775792621477.
[ Thu Jan 19 07:26:17 2023 ] 	Top1: 85.07%
[ Thu Jan 19 07:26:17 2023 ] 	Top5: 97.14%
[ Thu Jan 19 07:26:17 2023 ] Training epoch: 39
[ Thu Jan 19 07:40:52 2023 ] 	Mean training loss: 0.2970.  Mean training acc: 90.76%.
[ Thu Jan 19 07:40:52 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 07:40:52 2023 ] Eval epoch: 39
[ Thu Jan 19 07:51:07 2023 ] 	Mean test loss of 930 batches: 0.49493375625661623.
[ Thu Jan 19 07:51:07 2023 ] 	Top1: 85.05%
[ Thu Jan 19 07:51:08 2023 ] 	Top5: 97.08%
[ Thu Jan 19 07:51:08 2023 ] Training epoch: 40
[ Thu Jan 19 08:05:52 2023 ] 	Mean training loss: 0.2801.  Mean training acc: 91.36%.
[ Thu Jan 19 08:05:52 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 08:05:53 2023 ] Eval epoch: 40
[ Thu Jan 19 08:16:15 2023 ] 	Mean test loss of 930 batches: 0.5073238466095219.
[ Thu Jan 19 08:16:15 2023 ] 	Top1: 84.95%
[ Thu Jan 19 08:16:16 2023 ] 	Top5: 97.16%
[ Thu Jan 19 08:16:16 2023 ] Training epoch: 41
[ Thu Jan 19 08:30:57 2023 ] 	Mean training loss: 0.2590.  Mean training acc: 92.16%.
[ Thu Jan 19 08:31:02 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 08:31:02 2023 ] Eval epoch: 41
[ Thu Jan 19 08:41:20 2023 ] 	Mean test loss of 930 batches: 0.506799707577754.
[ Thu Jan 19 08:41:21 2023 ] 	Top1: 85.05%
[ Thu Jan 19 08:41:21 2023 ] 	Top5: 97.15%
[ Thu Jan 19 08:41:21 2023 ] Training epoch: 42
[ Thu Jan 19 08:55:53 2023 ] 	Mean training loss: 0.2495.  Mean training acc: 92.31%.
[ Thu Jan 19 08:55:57 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 08:55:57 2023 ] Eval epoch: 42
[ Thu Jan 19 09:06:12 2023 ] 	Mean test loss of 930 batches: 0.5003294766510046.
[ Thu Jan 19 09:06:12 2023 ] 	Top1: 85.07%
[ Thu Jan 19 09:06:13 2023 ] 	Top5: 97.12%
[ Thu Jan 19 09:06:39 2023 ] Training epoch: 43
[ Thu Jan 19 09:21:16 2023 ] 	Mean training loss: 0.2322.  Mean training acc: 93.11%.
[ Thu Jan 19 09:21:16 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 09:21:16 2023 ] Eval epoch: 43
[ Thu Jan 19 09:31:32 2023 ] 	Mean test loss of 930 batches: 0.5127319471610169.
[ Thu Jan 19 09:31:33 2023 ] 	Top1: 84.90%
[ Thu Jan 19 09:31:33 2023 ] 	Top5: 97.12%
[ Thu Jan 19 09:31:34 2023 ] Training epoch: 44
[ Thu Jan 19 09:46:04 2023 ] 	Mean training loss: 0.2283.  Mean training acc: 93.13%.
[ Thu Jan 19 09:46:04 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 09:46:04 2023 ] Eval epoch: 44
[ Thu Jan 19 09:56:22 2023 ] 	Mean test loss of 930 batches: 0.5184703491147488.
[ Thu Jan 19 09:56:23 2023 ] 	Top1: 84.97%
[ Thu Jan 19 09:56:23 2023 ] 	Top5: 97.05%
[ Thu Jan 19 09:56:24 2023 ] Training epoch: 45
[ Thu Jan 19 10:11:02 2023 ] 	Mean training loss: 0.2210.  Mean training acc: 93.40%.
[ Thu Jan 19 10:11:02 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 10:12:59 2023 ] Eval epoch: 45
[ Thu Jan 19 10:23:12 2023 ] 	Mean test loss of 930 batches: 0.5335364373380779.
[ Thu Jan 19 10:23:14 2023 ] 	Top1: 84.62%
[ Thu Jan 19 10:23:15 2023 ] 	Top5: 97.03%
[ Thu Jan 19 10:23:15 2023 ] Training epoch: 46
[ Thu Jan 19 10:37:55 2023 ] 	Mean training loss: 0.2136.  Mean training acc: 93.58%.
[ Thu Jan 19 10:37:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 10:37:55 2023 ] Eval epoch: 46
[ Thu Jan 19 10:47:53 2023 ] 	Mean test loss of 930 batches: 0.543079976084572.
[ Thu Jan 19 10:49:53 2023 ] 	Top1: 84.42%
[ Thu Jan 19 10:49:53 2023 ] 	Top5: 96.85%
[ Thu Jan 19 10:49:53 2023 ] Training epoch: 47
[ Thu Jan 19 11:04:22 2023 ] 	Mean training loss: 0.2100.  Mean training acc: 93.70%.
[ Thu Jan 19 11:04:22 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 11:04:22 2023 ] Eval epoch: 47
[ Thu Jan 19 11:14:41 2023 ] 	Mean test loss of 930 batches: 0.5517277736537238.
[ Thu Jan 19 11:14:42 2023 ] 	Top1: 84.26%
[ Thu Jan 19 11:14:42 2023 ] 	Top5: 96.85%
[ Thu Jan 19 11:14:42 2023 ] Training epoch: 48
[ Thu Jan 19 11:30:03 2023 ] 	Mean training loss: 0.2041.  Mean training acc: 93.87%.
[ Thu Jan 19 11:30:03 2023 ] 	Time consumption: [Data]00%, [Network]94%
[ Thu Jan 19 11:30:03 2023 ] Eval epoch: 48
[ Thu Jan 19 11:40:13 2023 ] 	Mean test loss of 930 batches: 0.5401840034992464.
[ Thu Jan 19 11:40:13 2023 ] 	Top1: 84.48%
[ Thu Jan 19 11:40:14 2023 ] 	Top5: 96.81%
[ Thu Jan 19 11:40:14 2023 ] Training epoch: 49
[ Thu Jan 19 11:54:55 2023 ] 	Mean training loss: 0.1968.  Mean training acc: 94.17%.
[ Thu Jan 19 11:54:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 11:54:55 2023 ] Eval epoch: 49
[ Thu Jan 19 12:05:10 2023 ] 	Mean test loss of 930 batches: 0.5498415981890052.
[ Thu Jan 19 12:05:22 2023 ] 	Top1: 84.50%
[ Thu Jan 19 12:05:23 2023 ] 	Top5: 96.85%
[ Thu Jan 19 12:05:23 2023 ] Training epoch: 50
[ Thu Jan 19 12:19:50 2023 ] 	Mean training loss: 0.1954.  Mean training acc: 94.30%.
[ Thu Jan 19 12:19:51 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 12:19:51 2023 ] Eval epoch: 50
[ Thu Jan 19 12:30:04 2023 ] 	Mean test loss of 930 batches: 0.5662687056727947.
[ Thu Jan 19 12:30:04 2023 ] 	Top1: 84.10%
[ Thu Jan 19 12:30:05 2023 ] 	Top5: 96.81%
[ Thu Jan 19 12:30:05 2023 ] Training epoch: 51
[ Thu Jan 19 12:44:27 2023 ] 	Mean training loss: 0.1921.  Mean training acc: 94.25%.
[ Thu Jan 19 12:44:27 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 12:44:27 2023 ] Eval epoch: 51
[ Thu Jan 19 12:54:29 2023 ] 	Mean test loss of 930 batches: 0.6018580708772906.
[ Thu Jan 19 12:54:29 2023 ] 	Top1: 83.32%
[ Thu Jan 19 12:54:30 2023 ] 	Top5: 96.56%
[ Thu Jan 19 12:54:30 2023 ] Training epoch: 52
[ Thu Jan 19 13:09:07 2023 ] 	Mean training loss: 0.1922.  Mean training acc: 94.41%.
[ Thu Jan 19 13:09:07 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 13:09:07 2023 ] Eval epoch: 52
[ Thu Jan 19 13:19:20 2023 ] 	Mean test loss of 930 batches: 0.5621935183883354.
[ Thu Jan 19 13:19:21 2023 ] 	Top1: 84.28%
[ Thu Jan 19 13:19:21 2023 ] 	Top5: 96.69%
[ Thu Jan 19 13:19:21 2023 ] Training epoch: 53
[ Thu Jan 19 13:33:55 2023 ] 	Mean training loss: 0.1919.  Mean training acc: 94.33%.
[ Thu Jan 19 13:33:55 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 13:33:55 2023 ] Eval epoch: 53
[ Thu Jan 19 13:44:15 2023 ] 	Mean test loss of 930 batches: 0.5793751862260603.
[ Thu Jan 19 13:44:15 2023 ] 	Top1: 83.89%
[ Thu Jan 19 13:44:16 2023 ] 	Top5: 96.62%
[ Thu Jan 19 13:44:16 2023 ] Training epoch: 54
[ Thu Jan 19 13:58:47 2023 ] 	Mean training loss: 0.1897.  Mean training acc: 94.35%.
[ Thu Jan 19 13:58:47 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 13:58:47 2023 ] Eval epoch: 54
[ Thu Jan 19 14:09:01 2023 ] 	Mean test loss of 930 batches: 0.6064146725641143.
[ Thu Jan 19 14:09:02 2023 ] 	Top1: 83.09%
[ Thu Jan 19 14:09:02 2023 ] 	Top5: 96.55%
[ Thu Jan 19 14:09:02 2023 ] Training epoch: 55
[ Thu Jan 19 14:23:41 2023 ] 	Mean training loss: 0.1875.  Mean training acc: 94.48%.
[ Thu Jan 19 14:23:41 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 14:23:42 2023 ] Eval epoch: 55
[ Thu Jan 19 14:33:53 2023 ] 	Mean test loss of 930 batches: 0.5873978556083735.
[ Thu Jan 19 14:33:54 2023 ] 	Top1: 83.64%
[ Thu Jan 19 14:33:54 2023 ] 	Top5: 96.45%
[ Thu Jan 19 14:33:55 2023 ] Training epoch: 56
[ Thu Jan 19 14:48:31 2023 ] 	Mean training loss: 0.1167.  Mean training acc: 97.05%.
[ Thu Jan 19 14:48:31 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 14:48:31 2023 ] Eval epoch: 56
[ Thu Jan 19 14:58:56 2023 ] 	Mean test loss of 930 batches: 0.4959002954865335.
[ Thu Jan 19 14:58:57 2023 ] 	Top1: 86.09%
[ Thu Jan 19 14:58:57 2023 ] 	Top5: 97.15%
[ Thu Jan 19 14:58:57 2023 ] Training epoch: 57
[ Thu Jan 19 15:13:32 2023 ] 	Mean training loss: 0.0903.  Mean training acc: 97.99%.
[ Thu Jan 19 15:13:32 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 15:13:32 2023 ] Eval epoch: 57
[ Thu Jan 19 15:23:53 2023 ] 	Mean test loss of 930 batches: 0.49968306615307767.
[ Thu Jan 19 15:23:53 2023 ] 	Top1: 86.12%
[ Thu Jan 19 15:23:54 2023 ] 	Top5: 97.18%
[ Thu Jan 19 15:23:54 2023 ] Training epoch: 58
[ Thu Jan 19 15:38:37 2023 ] 	Mean training loss: 0.0788.  Mean training acc: 98.29%.
[ Thu Jan 19 15:38:37 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 15:38:37 2023 ] Eval epoch: 58
[ Thu Jan 19 15:48:55 2023 ] 	Mean test loss of 930 batches: 0.502535445823945.
[ Thu Jan 19 15:48:56 2023 ] 	Top1: 86.24%
[ Thu Jan 19 15:48:56 2023 ] 	Top5: 97.15%
[ Thu Jan 19 15:48:56 2023 ] Training epoch: 59
[ Thu Jan 19 16:03:36 2023 ] 	Mean training loss: 0.0753.  Mean training acc: 98.39%.
[ Thu Jan 19 16:03:37 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 16:03:37 2023 ] Eval epoch: 59
[ Thu Jan 19 16:13:57 2023 ] 	Mean test loss of 930 batches: 0.5078612044774076.
[ Thu Jan 19 16:13:57 2023 ] 	Top1: 86.27%
[ Thu Jan 19 16:13:58 2023 ] 	Top5: 97.16%
[ Thu Jan 19 16:13:58 2023 ] Training epoch: 60
[ Thu Jan 19 16:28:35 2023 ] 	Mean training loss: 0.0700.  Mean training acc: 98.58%.
[ Thu Jan 19 16:28:35 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 16:28:35 2023 ] Eval epoch: 60
[ Thu Jan 19 16:38:58 2023 ] 	Mean test loss of 930 batches: 0.5072812446423115.
[ Thu Jan 19 16:38:58 2023 ] 	Top1: 86.39%
[ Thu Jan 19 16:38:58 2023 ] 	Top5: 97.17%
[ Thu Jan 19 16:38:59 2023 ] Training epoch: 61
[ Thu Jan 19 16:53:46 2023 ] 	Mean training loss: 0.0655.  Mean training acc: 98.67%.
[ Thu Jan 19 16:53:46 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 16:53:46 2023 ] Eval epoch: 61
[ Thu Jan 19 17:04:06 2023 ] 	Mean test loss of 930 batches: 0.5091228775660037.
[ Thu Jan 19 17:04:06 2023 ] 	Top1: 86.22%
[ Thu Jan 19 17:04:07 2023 ] 	Top5: 97.13%
[ Thu Jan 19 17:04:07 2023 ] Training epoch: 62
[ Thu Jan 19 17:19:25 2023 ] 	Mean training loss: 0.0621.  Mean training acc: 98.81%.
[ Thu Jan 19 17:19:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Jan 19 17:19:25 2023 ] Eval epoch: 62
[ Thu Jan 19 17:30:21 2023 ] 	Mean test loss of 930 batches: 0.5130475595192884.
[ Thu Jan 19 17:30:22 2023 ] 	Top1: 86.18%
[ Thu Jan 19 17:30:22 2023 ] 	Top5: 97.18%
[ Thu Jan 19 17:30:22 2023 ] Training epoch: 63
[ Thu Jan 19 17:45:09 2023 ] 	Mean training loss: 0.0593.  Mean training acc: 98.88%.
[ Thu Jan 19 17:45:09 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 17:45:09 2023 ] Eval epoch: 63
[ Thu Jan 19 17:55:50 2023 ] 	Mean test loss of 930 batches: 0.516010783961223.
[ Thu Jan 19 17:55:50 2023 ] 	Top1: 86.30%
[ Thu Jan 19 17:55:51 2023 ] 	Top5: 97.13%
[ Thu Jan 19 17:55:51 2023 ] Training epoch: 64
[ Thu Jan 19 18:11:22 2023 ] 	Mean training loss: 0.0591.  Mean training acc: 98.85%.
[ Thu Jan 19 18:11:22 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 18:11:22 2023 ] Eval epoch: 64
[ Thu Jan 19 18:22:22 2023 ] 	Mean test loss of 930 batches: 0.5169578707146067.
[ Thu Jan 19 18:22:22 2023 ] 	Top1: 86.18%
[ Thu Jan 19 18:22:23 2023 ] 	Top5: 97.11%
[ Thu Jan 19 18:22:23 2023 ] Training epoch: 65
[ Thu Jan 19 18:37:14 2023 ] 	Mean training loss: 0.0551.  Mean training acc: 99.01%.
[ Thu Jan 19 18:37:14 2023 ] 	Time consumption: [Data]00%, [Network]99%
[ Thu Jan 19 18:37:14 2023 ] Eval epoch: 65
[ Thu Jan 19 18:47:52 2023 ] 	Mean test loss of 930 batches: 0.518709825652261.
[ Thu Jan 19 18:47:53 2023 ] 	Top1: 86.23%
[ Thu Jan 19 18:47:53 2023 ] 	Top5: 97.16%
[ Thu Jan 19 18:58:27 2023 ] Best accuracy: 0.8639305950199236
[ Thu Jan 19 18:58:27 2023 ] Epoch number: 60
[ Thu Jan 19 18:58:27 2023 ] Model name: work_dir/cset/ctrgcn_local_SHT_BL
[ Thu Jan 19 18:58:27 2023 ] Model total number of params: 1508876
[ Thu Jan 19 18:58:27 2023 ] Weight decay: 0.0004
[ Thu Jan 19 18:58:27 2023 ] Base LR: 0.1
[ Thu Jan 19 18:58:27 2023 ] Batch Size: 64
[ Thu Jan 19 18:58:27 2023 ] Test Batch Size: 64
[ Thu Jan 19 18:58:27 2023 ] seed: 1
[ Sat Feb 11 22:11:47 2023 ] using warm up, epoch: 5
[ Sat Feb 11 22:12:09 2023 ] Parameters:
{'work_dir': 'work_dir/cset/ctrgcn_local_SHT_BL', 'model_saved_name': 'work_dir/cset/ctrgcn_local_SHT_BL/runs', 'config': 'config/nturgbd120-cross-set/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSet.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn_local_SHT_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Sat Feb 11 22:12:09 2023 ] # Parameters: 1508876
[ Sat Feb 11 22:12:09 2023 ] Training epoch: 1
[ Sat Feb 11 22:20:40 2023 ] 	Mean training loss: 3.2665.  Mean training acc: 19.47%.
[ Sat Feb 11 22:20:40 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 22:20:40 2023 ] Eval epoch: 1
[ Sat Feb 11 22:24:36 2023 ] 	Mean test loss of 930 batches: 2.514529723249456.
[ Sat Feb 11 22:24:36 2023 ] 	Top1: 31.70%
[ Sat Feb 11 22:24:37 2023 ] 	Top5: 66.44%
[ Sat Feb 11 22:24:37 2023 ] Training epoch: 2
[ Sat Feb 11 22:33:07 2023 ] 	Mean training loss: 2.1837.  Mean training acc: 38.88%.
[ Sat Feb 11 22:33:07 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 22:33:07 2023 ] Eval epoch: 2
[ Sat Feb 11 22:37:02 2023 ] 	Mean test loss of 930 batches: 1.8932060883891197.
[ Sat Feb 11 22:37:02 2023 ] 	Top1: 46.50%
[ Sat Feb 11 22:37:03 2023 ] 	Top5: 79.56%
[ Sat Feb 11 22:37:03 2023 ] Training epoch: 3
[ Sat Feb 11 22:45:25 2023 ] 	Mean training loss: 1.7654.  Mean training acc: 49.33%.
[ Sat Feb 11 22:45:25 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 22:45:25 2023 ] Eval epoch: 3
[ Sat Feb 11 22:49:16 2023 ] 	Mean test loss of 930 batches: 1.7017915643030597.
[ Sat Feb 11 22:49:17 2023 ] 	Top1: 51.57%
[ Sat Feb 11 22:49:17 2023 ] 	Top5: 82.94%
[ Sat Feb 11 22:49:17 2023 ] Training epoch: 4
[ Sat Feb 11 22:57:41 2023 ] 	Mean training loss: 1.5490.  Mean training acc: 54.91%.
[ Sat Feb 11 22:57:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 22:57:41 2023 ] Eval epoch: 4
[ Sat Feb 11 23:01:33 2023 ] 	Mean test loss of 930 batches: 1.7450624757556505.
[ Sat Feb 11 23:01:34 2023 ] 	Top1: 49.58%
[ Sat Feb 11 23:01:34 2023 ] 	Top5: 82.34%
[ Sat Feb 11 23:01:35 2023 ] Training epoch: 5
[ Sat Feb 11 23:09:59 2023 ] 	Mean training loss: 1.4136.  Mean training acc: 58.45%.
[ Sat Feb 11 23:09:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 23:09:59 2023 ] Eval epoch: 5
[ Sat Feb 11 23:13:51 2023 ] 	Mean test loss of 930 batches: 1.5020494389918542.
[ Sat Feb 11 23:13:52 2023 ] 	Top1: 57.06%
[ Sat Feb 11 23:13:52 2023 ] 	Top5: 86.09%
[ Sat Feb 11 23:13:52 2023 ] Training epoch: 6
[ Sat Feb 11 23:22:16 2023 ] 	Mean training loss: 1.2608.  Mean training acc: 62.65%.
[ Sat Feb 11 23:22:16 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 23:22:16 2023 ] Eval epoch: 6
[ Sat Feb 11 23:26:08 2023 ] 	Mean test loss of 930 batches: 1.381282792360552.
[ Sat Feb 11 23:26:08 2023 ] 	Top1: 59.97%
[ Sat Feb 11 23:26:09 2023 ] 	Top5: 88.01%
[ Sat Feb 11 23:26:09 2023 ] Training epoch: 7
[ Sat Feb 11 23:34:32 2023 ] 	Mean training loss: 1.1445.  Mean training acc: 65.62%.
[ Sat Feb 11 23:34:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 23:34:32 2023 ] Eval epoch: 7
[ Sat Feb 11 23:38:22 2023 ] 	Mean test loss of 930 batches: 1.2910943181924923.
[ Sat Feb 11 23:38:22 2023 ] 	Top1: 62.43%
[ Sat Feb 11 23:38:23 2023 ] 	Top5: 89.11%
[ Sat Feb 11 23:38:23 2023 ] Training epoch: 8
[ Sat Feb 11 23:46:45 2023 ] 	Mean training loss: 1.0698.  Mean training acc: 67.82%.
[ Sat Feb 11 23:46:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 23:46:45 2023 ] Eval epoch: 8
[ Sat Feb 11 23:50:37 2023 ] 	Mean test loss of 930 batches: 1.3478484036461.
[ Sat Feb 11 23:50:38 2023 ] 	Top1: 61.70%
[ Sat Feb 11 23:50:38 2023 ] 	Top5: 88.30%
[ Sat Feb 11 23:50:38 2023 ] Training epoch: 9
[ Sat Feb 11 23:59:00 2023 ] 	Mean training loss: 1.0068.  Mean training acc: 69.65%.
[ Sat Feb 11 23:59:00 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sat Feb 11 23:59:00 2023 ] Eval epoch: 9
[ Sun Feb 12 00:02:52 2023 ] 	Mean test loss of 930 batches: 1.2072136983435642.
[ Sun Feb 12 00:02:52 2023 ] 	Top1: 64.97%
[ Sun Feb 12 00:02:53 2023 ] 	Top5: 90.33%
[ Sun Feb 12 00:02:53 2023 ] Training epoch: 10
[ Sun Feb 12 00:11:16 2023 ] 	Mean training loss: 0.9661.  Mean training acc: 70.73%.
[ Sun Feb 12 00:11:16 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 00:11:16 2023 ] Eval epoch: 10
[ Sun Feb 12 00:15:07 2023 ] 	Mean test loss of 930 batches: 1.1897540713510206.
[ Sun Feb 12 00:15:08 2023 ] 	Top1: 65.07%
[ Sun Feb 12 00:15:08 2023 ] 	Top5: 90.76%
[ Sun Feb 12 00:15:08 2023 ] Training epoch: 11
[ Sun Feb 12 00:23:30 2023 ] 	Mean training loss: 0.9283.  Mean training acc: 71.74%.
[ Sun Feb 12 00:23:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 00:23:30 2023 ] Eval epoch: 11
[ Sun Feb 12 00:27:21 2023 ] 	Mean test loss of 930 batches: 1.16505274801485.
[ Sun Feb 12 00:27:22 2023 ] 	Top1: 66.69%
[ Sun Feb 12 00:27:22 2023 ] 	Top5: 90.73%
[ Sun Feb 12 00:27:22 2023 ] Training epoch: 12
[ Sun Feb 12 00:35:44 2023 ] 	Mean training loss: 0.8984.  Mean training acc: 72.63%.
[ Sun Feb 12 00:35:44 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 00:35:44 2023 ] Eval epoch: 12
[ Sun Feb 12 00:39:35 2023 ] 	Mean test loss of 930 batches: 1.13628766305985.
[ Sun Feb 12 00:39:36 2023 ] 	Top1: 67.72%
[ Sun Feb 12 00:39:36 2023 ] 	Top5: 90.94%
[ Sun Feb 12 00:39:36 2023 ] Training epoch: 13
[ Sun Feb 12 00:47:58 2023 ] 	Mean training loss: 0.8772.  Mean training acc: 73.26%.
[ Sun Feb 12 00:47:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 00:47:58 2023 ] Eval epoch: 13
[ Sun Feb 12 00:51:49 2023 ] 	Mean test loss of 930 batches: 1.0917674886923965.
[ Sun Feb 12 00:51:49 2023 ] 	Top1: 68.94%
[ Sun Feb 12 00:51:50 2023 ] 	Top5: 91.56%
[ Sun Feb 12 00:51:50 2023 ] Training epoch: 14
[ Sun Feb 12 01:00:12 2023 ] 	Mean training loss: 0.8533.  Mean training acc: 73.82%.
[ Sun Feb 12 01:00:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 01:00:12 2023 ] Eval epoch: 14
[ Sun Feb 12 01:04:02 2023 ] 	Mean test loss of 930 batches: 1.0706666425351175.
[ Sun Feb 12 01:04:03 2023 ] 	Top1: 69.46%
[ Sun Feb 12 01:04:03 2023 ] 	Top5: 92.04%
[ Sun Feb 12 01:04:03 2023 ] Training epoch: 15
[ Sun Feb 12 01:12:24 2023 ] 	Mean training loss: 0.8472.  Mean training acc: 74.10%.
[ Sun Feb 12 01:12:24 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 01:12:24 2023 ] Eval epoch: 15
[ Sun Feb 12 01:16:15 2023 ] 	Mean test loss of 930 batches: 1.0873779389486518.
[ Sun Feb 12 01:16:16 2023 ] 	Top1: 68.60%
[ Sun Feb 12 01:16:16 2023 ] 	Top5: 92.05%
[ Sun Feb 12 01:16:16 2023 ] Training epoch: 16
[ Sun Feb 12 01:24:38 2023 ] 	Mean training loss: 0.8251.  Mean training acc: 74.79%.
[ Sun Feb 12 01:24:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 01:24:38 2023 ] Eval epoch: 16
[ Sun Feb 12 01:28:30 2023 ] 	Mean test loss of 930 batches: 1.1599079258659835.
[ Sun Feb 12 01:28:30 2023 ] 	Top1: 67.10%
[ Sun Feb 12 01:28:31 2023 ] 	Top5: 91.51%
[ Sun Feb 12 01:28:31 2023 ] Training epoch: 17
[ Sun Feb 12 01:36:52 2023 ] 	Mean training loss: 0.8286.  Mean training acc: 74.68%.
[ Sun Feb 12 01:36:52 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 01:36:52 2023 ] Eval epoch: 17
[ Sun Feb 12 01:40:42 2023 ] 	Mean test loss of 930 batches: 1.1031091417356205.
[ Sun Feb 12 01:40:43 2023 ] 	Top1: 67.92%
[ Sun Feb 12 01:40:43 2023 ] 	Top5: 92.21%
[ Sun Feb 12 01:40:43 2023 ] Training epoch: 18
[ Sun Feb 12 01:49:04 2023 ] 	Mean training loss: 0.8110.  Mean training acc: 75.15%.
[ Sun Feb 12 01:49:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 01:49:04 2023 ] Eval epoch: 18
[ Sun Feb 12 01:52:54 2023 ] 	Mean test loss of 930 batches: 1.0469767555434217.
[ Sun Feb 12 01:52:54 2023 ] 	Top1: 69.34%
[ Sun Feb 12 01:52:55 2023 ] 	Top5: 92.52%
[ Sun Feb 12 01:52:55 2023 ] Training epoch: 19
[ Sun Feb 12 02:01:18 2023 ] 	Mean training loss: 0.8028.  Mean training acc: 75.57%.
[ Sun Feb 12 02:01:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 02:01:18 2023 ] Eval epoch: 19
[ Sun Feb 12 02:05:11 2023 ] 	Mean test loss of 930 batches: 1.1156032448173852.
[ Sun Feb 12 02:05:11 2023 ] 	Top1: 69.06%
[ Sun Feb 12 02:05:12 2023 ] 	Top5: 91.64%
[ Sun Feb 12 02:05:12 2023 ] Training epoch: 20
[ Sun Feb 12 02:13:33 2023 ] 	Mean training loss: 0.7964.  Mean training acc: 75.64%.
[ Sun Feb 12 02:13:33 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 02:13:33 2023 ] Eval epoch: 20
[ Sun Feb 12 02:17:24 2023 ] 	Mean test loss of 930 batches: 1.1538680301879043.
[ Sun Feb 12 02:17:24 2023 ] 	Top1: 66.50%
[ Sun Feb 12 02:17:25 2023 ] 	Top5: 91.05%
[ Sun Feb 12 02:17:25 2023 ] Training epoch: 21
[ Sun Feb 12 02:25:47 2023 ] 	Mean training loss: 0.7922.  Mean training acc: 75.80%.
[ Sun Feb 12 02:25:47 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 02:25:47 2023 ] Eval epoch: 21
[ Sun Feb 12 02:29:37 2023 ] 	Mean test loss of 930 batches: 0.9622985663593456.
[ Sun Feb 12 02:29:38 2023 ] 	Top1: 72.00%
[ Sun Feb 12 02:29:38 2023 ] 	Top5: 93.24%
[ Sun Feb 12 02:29:38 2023 ] Training epoch: 22
[ Sun Feb 12 02:37:59 2023 ] 	Mean training loss: 0.7807.  Mean training acc: 75.87%.
[ Sun Feb 12 02:37:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 02:37:59 2023 ] Eval epoch: 22
[ Sun Feb 12 02:41:50 2023 ] 	Mean test loss of 930 batches: 0.9656367356097827.
[ Sun Feb 12 02:41:50 2023 ] 	Top1: 71.80%
[ Sun Feb 12 02:41:51 2023 ] 	Top5: 92.94%
[ Sun Feb 12 02:41:51 2023 ] Training epoch: 23
[ Sun Feb 12 02:50:12 2023 ] 	Mean training loss: 0.7721.  Mean training acc: 76.13%.
[ Sun Feb 12 02:50:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 02:50:12 2023 ] Eval epoch: 23
[ Sun Feb 12 02:54:03 2023 ] 	Mean test loss of 930 batches: 0.9689734672346423.
[ Sun Feb 12 02:54:03 2023 ] 	Top1: 71.57%
[ Sun Feb 12 02:54:04 2023 ] 	Top5: 93.23%
[ Sun Feb 12 02:54:04 2023 ] Training epoch: 24
[ Sun Feb 12 03:02:25 2023 ] 	Mean training loss: 0.7711.  Mean training acc: 76.33%.
[ Sun Feb 12 03:02:25 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 03:02:25 2023 ] Eval epoch: 24
[ Sun Feb 12 03:06:15 2023 ] 	Mean test loss of 930 batches: 1.2183437496423721.
[ Sun Feb 12 03:06:15 2023 ] 	Top1: 64.96%
[ Sun Feb 12 03:06:16 2023 ] 	Top5: 90.37%
[ Sun Feb 12 03:06:16 2023 ] Training epoch: 25
[ Sun Feb 12 03:14:36 2023 ] 	Mean training loss: 0.7700.  Mean training acc: 76.36%.
[ Sun Feb 12 03:14:36 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 03:14:36 2023 ] Eval epoch: 25
[ Sun Feb 12 03:18:26 2023 ] 	Mean test loss of 930 batches: 0.928692883221052.
[ Sun Feb 12 03:18:26 2023 ] 	Top1: 72.67%
[ Sun Feb 12 03:18:27 2023 ] 	Top5: 93.08%
[ Sun Feb 12 03:18:27 2023 ] Training epoch: 26
[ Sun Feb 12 03:26:48 2023 ] 	Mean training loss: 0.7614.  Mean training acc: 76.68%.
[ Sun Feb 12 03:26:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 03:26:48 2023 ] Eval epoch: 26
[ Sun Feb 12 03:30:39 2023 ] 	Mean test loss of 930 batches: 0.971981688404596.
[ Sun Feb 12 03:30:39 2023 ] 	Top1: 71.26%
[ Sun Feb 12 03:30:40 2023 ] 	Top5: 93.03%
[ Sun Feb 12 03:30:40 2023 ] Training epoch: 27
[ Sun Feb 12 03:39:00 2023 ] 	Mean training loss: 0.7599.  Mean training acc: 76.55%.
[ Sun Feb 12 03:39:00 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 03:39:00 2023 ] Eval epoch: 27
[ Sun Feb 12 03:42:50 2023 ] 	Mean test loss of 930 batches: 0.9298813460334655.
[ Sun Feb 12 03:42:50 2023 ] 	Top1: 72.64%
[ Sun Feb 12 03:42:51 2023 ] 	Top5: 93.85%
[ Sun Feb 12 03:42:51 2023 ] Training epoch: 28
[ Sun Feb 12 03:51:12 2023 ] 	Mean training loss: 0.7600.  Mean training acc: 76.74%.
[ Sun Feb 12 03:51:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 03:51:12 2023 ] Eval epoch: 28
[ Sun Feb 12 03:55:00 2023 ] 	Mean test loss of 930 batches: 1.2087289989635508.
[ Sun Feb 12 03:55:01 2023 ] 	Top1: 66.00%
[ Sun Feb 12 03:55:01 2023 ] 	Top5: 91.23%
[ Sun Feb 12 03:55:01 2023 ] Training epoch: 29
[ Sun Feb 12 04:03:21 2023 ] 	Mean training loss: 0.7589.  Mean training acc: 76.73%.
[ Sun Feb 12 04:03:21 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 04:03:21 2023 ] Eval epoch: 29
[ Sun Feb 12 04:07:09 2023 ] 	Mean test loss of 930 batches: 1.1546409410174174.
[ Sun Feb 12 04:07:10 2023 ] 	Top1: 66.67%
[ Sun Feb 12 04:07:10 2023 ] 	Top5: 90.88%
[ Sun Feb 12 04:07:10 2023 ] Training epoch: 30
[ Sun Feb 12 04:15:30 2023 ] 	Mean training loss: 0.7502.  Mean training acc: 76.88%.
[ Sun Feb 12 04:15:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 04:15:30 2023 ] Eval epoch: 30
[ Sun Feb 12 04:19:18 2023 ] 	Mean test loss of 930 batches: 0.9726021047881854.
[ Sun Feb 12 04:19:19 2023 ] 	Top1: 71.71%
[ Sun Feb 12 04:19:19 2023 ] 	Top5: 93.02%
[ Sun Feb 12 04:19:19 2023 ] Training epoch: 31
[ Sun Feb 12 04:27:38 2023 ] 	Mean training loss: 0.7476.  Mean training acc: 77.00%.
[ Sun Feb 12 04:27:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 04:27:38 2023 ] Eval epoch: 31
[ Sun Feb 12 04:31:26 2023 ] 	Mean test loss of 930 batches: 0.8674568073082995.
[ Sun Feb 12 04:31:27 2023 ] 	Top1: 74.28%
[ Sun Feb 12 04:31:27 2023 ] 	Top5: 93.89%
[ Sun Feb 12 04:31:27 2023 ] Training epoch: 32
[ Sun Feb 12 04:39:45 2023 ] 	Mean training loss: 0.7481.  Mean training acc: 77.34%.
[ Sun Feb 12 04:39:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 04:39:45 2023 ] Eval epoch: 32
[ Sun Feb 12 04:43:33 2023 ] 	Mean test loss of 930 batches: 0.9590824696325486.
[ Sun Feb 12 04:43:33 2023 ] 	Top1: 72.67%
[ Sun Feb 12 04:43:34 2023 ] 	Top5: 93.08%
[ Sun Feb 12 04:43:34 2023 ] Training epoch: 33
[ Sun Feb 12 04:51:53 2023 ] 	Mean training loss: 0.7424.  Mean training acc: 76.97%.
[ Sun Feb 12 04:51:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 04:51:53 2023 ] Eval epoch: 33
[ Sun Feb 12 04:55:39 2023 ] 	Mean test loss of 930 batches: 0.9775163958470027.
[ Sun Feb 12 04:55:40 2023 ] 	Top1: 70.85%
[ Sun Feb 12 04:55:40 2023 ] 	Top5: 93.43%
[ Sun Feb 12 04:55:40 2023 ] Training epoch: 34
[ Sun Feb 12 05:03:59 2023 ] 	Mean training loss: 0.7398.  Mean training acc: 77.21%.
[ Sun Feb 12 05:03:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 05:03:59 2023 ] Eval epoch: 34
[ Sun Feb 12 05:07:46 2023 ] 	Mean test loss of 930 batches: 0.9321522176265716.
[ Sun Feb 12 05:07:46 2023 ] 	Top1: 72.51%
[ Sun Feb 12 05:07:47 2023 ] 	Top5: 93.66%
[ Sun Feb 12 05:07:47 2023 ] Training epoch: 35
[ Sun Feb 12 05:16:06 2023 ] 	Mean training loss: 0.7360.  Mean training acc: 77.35%.
[ Sun Feb 12 05:16:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 05:16:06 2023 ] Eval epoch: 35
[ Sun Feb 12 05:19:53 2023 ] 	Mean test loss of 930 batches: 0.9276925096909205.
[ Sun Feb 12 05:19:54 2023 ] 	Top1: 72.69%
[ Sun Feb 12 05:19:54 2023 ] 	Top5: 93.62%
[ Sun Feb 12 05:19:55 2023 ] Training epoch: 36
[ Sun Feb 12 05:28:14 2023 ] 	Mean training loss: 0.4314.  Mean training acc: 86.82%.
[ Sun Feb 12 05:28:14 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 05:28:14 2023 ] Eval epoch: 36
[ Sun Feb 12 05:32:02 2023 ] 	Mean test loss of 930 batches: 0.5144869799174929.
[ Sun Feb 12 05:32:03 2023 ] 	Top1: 84.59%
[ Sun Feb 12 05:32:03 2023 ] 	Top5: 96.97%
[ Sun Feb 12 05:32:03 2023 ] Training epoch: 37
[ Sun Feb 12 05:40:22 2023 ] 	Mean training loss: 0.3518.  Mean training acc: 89.21%.
[ Sun Feb 12 05:40:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 05:40:22 2023 ] Eval epoch: 37
[ Sun Feb 12 05:44:08 2023 ] 	Mean test loss of 930 batches: 0.5077893347349218.
[ Sun Feb 12 05:44:08 2023 ] 	Top1: 84.92%
[ Sun Feb 12 05:44:09 2023 ] 	Top5: 96.99%
[ Sun Feb 12 05:44:09 2023 ] Training epoch: 38
[ Sun Feb 12 05:52:27 2023 ] 	Mean training loss: 0.3166.  Mean training acc: 90.25%.
[ Sun Feb 12 05:52:27 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 05:52:27 2023 ] Eval epoch: 38
[ Sun Feb 12 05:56:15 2023 ] 	Mean test loss of 930 batches: 0.49678744771067174.
[ Sun Feb 12 05:56:15 2023 ] 	Top1: 85.34%
[ Sun Feb 12 05:56:16 2023 ] 	Top5: 97.10%
[ Sun Feb 12 05:56:16 2023 ] Training epoch: 39
[ Sun Feb 12 06:04:34 2023 ] 	Mean training loss: 0.2923.  Mean training acc: 90.98%.
[ Sun Feb 12 06:04:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 06:04:34 2023 ] Eval epoch: 39
[ Sun Feb 12 06:08:21 2023 ] 	Mean test loss of 930 batches: 0.498093215075712.
[ Sun Feb 12 06:08:22 2023 ] 	Top1: 85.17%
[ Sun Feb 12 06:08:22 2023 ] 	Top5: 97.14%
[ Sun Feb 12 06:08:22 2023 ] Training epoch: 40
[ Sun Feb 12 06:16:41 2023 ] 	Mean training loss: 0.2760.  Mean training acc: 91.54%.
[ Sun Feb 12 06:16:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 06:16:41 2023 ] Eval epoch: 40
[ Sun Feb 12 06:20:29 2023 ] 	Mean test loss of 930 batches: 0.49662600349514713.
[ Sun Feb 12 06:20:29 2023 ] 	Top1: 85.30%
[ Sun Feb 12 06:20:30 2023 ] 	Top5: 97.10%
[ Sun Feb 12 06:20:30 2023 ] Training epoch: 41
[ Sun Feb 12 06:28:47 2023 ] 	Mean training loss: 0.2594.  Mean training acc: 91.95%.
[ Sun Feb 12 06:28:47 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 06:28:47 2023 ] Eval epoch: 41
[ Sun Feb 12 06:32:33 2023 ] 	Mean test loss of 930 batches: 0.5000280946052523.
[ Sun Feb 12 06:32:34 2023 ] 	Top1: 85.18%
[ Sun Feb 12 06:32:34 2023 ] 	Top5: 97.09%
[ Sun Feb 12 06:32:34 2023 ] Training epoch: 42
[ Sun Feb 12 06:40:53 2023 ] 	Mean training loss: 0.2492.  Mean training acc: 92.38%.
[ Sun Feb 12 06:40:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 06:40:53 2023 ] Eval epoch: 42
[ Sun Feb 12 06:44:40 2023 ] 	Mean test loss of 930 batches: 0.5022440030369707.
[ Sun Feb 12 06:44:40 2023 ] 	Top1: 85.16%
[ Sun Feb 12 06:44:41 2023 ] 	Top5: 97.08%
[ Sun Feb 12 06:44:41 2023 ] Training epoch: 43
[ Sun Feb 12 06:52:58 2023 ] 	Mean training loss: 0.2317.  Mean training acc: 92.97%.
[ Sun Feb 12 06:52:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 06:52:58 2023 ] Eval epoch: 43
[ Sun Feb 12 06:56:45 2023 ] 	Mean test loss of 930 batches: 0.5029759085346615.
[ Sun Feb 12 06:56:46 2023 ] 	Top1: 85.23%
[ Sun Feb 12 06:56:46 2023 ] 	Top5: 97.13%
[ Sun Feb 12 06:56:46 2023 ] Training epoch: 44
[ Sun Feb 12 07:05:04 2023 ] 	Mean training loss: 0.2255.  Mean training acc: 93.14%.
[ Sun Feb 12 07:05:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 07:05:04 2023 ] Eval epoch: 44
[ Sun Feb 12 07:08:50 2023 ] 	Mean test loss of 930 batches: 0.5063802904859986.
[ Sun Feb 12 07:08:51 2023 ] 	Top1: 85.30%
[ Sun Feb 12 07:08:51 2023 ] 	Top5: 97.00%
[ Sun Feb 12 07:08:51 2023 ] Training epoch: 45
[ Sun Feb 12 07:17:10 2023 ] 	Mean training loss: 0.2228.  Mean training acc: 93.22%.
[ Sun Feb 12 07:17:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 07:17:10 2023 ] Eval epoch: 45
[ Sun Feb 12 07:20:57 2023 ] 	Mean test loss of 930 batches: 0.5222734857911384.
[ Sun Feb 12 07:20:57 2023 ] 	Top1: 84.98%
[ Sun Feb 12 07:20:58 2023 ] 	Top5: 96.96%
[ Sun Feb 12 07:20:58 2023 ] Training epoch: 46
[ Sun Feb 12 07:29:16 2023 ] 	Mean training loss: 0.2113.  Mean training acc: 93.71%.
[ Sun Feb 12 07:29:16 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 07:29:16 2023 ] Eval epoch: 46
[ Sun Feb 12 07:33:02 2023 ] 	Mean test loss of 930 batches: 0.5305426370793133.
[ Sun Feb 12 07:33:03 2023 ] 	Top1: 84.85%
[ Sun Feb 12 07:33:03 2023 ] 	Top5: 96.92%
[ Sun Feb 12 07:33:03 2023 ] Training epoch: 47
[ Sun Feb 12 07:41:21 2023 ] 	Mean training loss: 0.2090.  Mean training acc: 93.74%.
[ Sun Feb 12 07:41:21 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 07:41:21 2023 ] Eval epoch: 47
[ Sun Feb 12 07:45:06 2023 ] 	Mean test loss of 930 batches: 0.5554295931131609.
[ Sun Feb 12 07:45:07 2023 ] 	Top1: 84.22%
[ Sun Feb 12 07:45:07 2023 ] 	Top5: 96.88%
[ Sun Feb 12 07:45:08 2023 ] Training epoch: 48
[ Sun Feb 12 07:53:26 2023 ] 	Mean training loss: 0.2067.  Mean training acc: 93.75%.
[ Sun Feb 12 07:53:26 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 07:53:26 2023 ] Eval epoch: 48
[ Sun Feb 12 07:57:11 2023 ] 	Mean test loss of 930 batches: 0.5439306125605619.
[ Sun Feb 12 07:57:12 2023 ] 	Top1: 84.24%
[ Sun Feb 12 07:57:12 2023 ] 	Top5: 96.88%
[ Sun Feb 12 07:57:12 2023 ] Training epoch: 49
[ Sun Feb 12 08:05:31 2023 ] 	Mean training loss: 0.1999.  Mean training acc: 94.13%.
[ Sun Feb 12 08:05:31 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 08:05:31 2023 ] Eval epoch: 49
[ Sun Feb 12 08:09:17 2023 ] 	Mean test loss of 930 batches: 0.5385403897252775.
[ Sun Feb 12 08:09:18 2023 ] 	Top1: 84.68%
[ Sun Feb 12 08:09:18 2023 ] 	Top5: 96.94%
[ Sun Feb 12 08:09:18 2023 ] Training epoch: 50
[ Sun Feb 12 08:17:36 2023 ] 	Mean training loss: 0.1999.  Mean training acc: 94.05%.
[ Sun Feb 12 08:17:36 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 08:17:36 2023 ] Eval epoch: 50
[ Sun Feb 12 08:21:22 2023 ] 	Mean test loss of 930 batches: 0.5506280368414297.
[ Sun Feb 12 08:21:23 2023 ] 	Top1: 84.47%
[ Sun Feb 12 08:21:23 2023 ] 	Top5: 96.71%
[ Sun Feb 12 08:21:23 2023 ] Training epoch: 51
[ Sun Feb 12 08:29:41 2023 ] 	Mean training loss: 0.1954.  Mean training acc: 94.25%.
[ Sun Feb 12 08:29:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 08:29:41 2023 ] Eval epoch: 51
[ Sun Feb 12 08:33:27 2023 ] 	Mean test loss of 930 batches: 0.5594627860733258.
[ Sun Feb 12 08:33:28 2023 ] 	Top1: 84.16%
[ Sun Feb 12 08:33:28 2023 ] 	Top5: 96.84%
[ Sun Feb 12 08:33:29 2023 ] Training epoch: 52
[ Sun Feb 12 08:41:46 2023 ] 	Mean training loss: 0.1946.  Mean training acc: 94.23%.
[ Sun Feb 12 08:41:46 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 08:41:46 2023 ] Eval epoch: 52
[ Sun Feb 12 08:45:32 2023 ] 	Mean test loss of 930 batches: 0.5720664521779424.
[ Sun Feb 12 08:45:33 2023 ] 	Top1: 83.97%
[ Sun Feb 12 08:45:33 2023 ] 	Top5: 96.80%
[ Sun Feb 12 08:45:33 2023 ] Training epoch: 53
[ Sun Feb 12 08:53:51 2023 ] 	Mean training loss: 0.1885.  Mean training acc: 94.37%.
[ Sun Feb 12 08:53:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 08:53:51 2023 ] Eval epoch: 53
[ Sun Feb 12 08:57:37 2023 ] 	Mean test loss of 930 batches: 0.6015492813160983.
[ Sun Feb 12 08:57:38 2023 ] 	Top1: 83.53%
[ Sun Feb 12 08:57:38 2023 ] 	Top5: 96.44%
[ Sun Feb 12 08:57:38 2023 ] Training epoch: 54
[ Sun Feb 12 09:05:55 2023 ] 	Mean training loss: 0.1923.  Mean training acc: 94.31%.
[ Sun Feb 12 09:05:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 09:05:55 2023 ] Eval epoch: 54
[ Sun Feb 12 09:09:40 2023 ] 	Mean test loss of 930 batches: 0.581577772266602.
[ Sun Feb 12 09:09:40 2023 ] 	Top1: 83.64%
[ Sun Feb 12 09:09:41 2023 ] 	Top5: 96.70%
[ Sun Feb 12 09:09:41 2023 ] Training epoch: 55
[ Sun Feb 12 09:17:58 2023 ] 	Mean training loss: 0.1893.  Mean training acc: 94.50%.
[ Sun Feb 12 09:17:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 09:17:58 2023 ] Eval epoch: 55
[ Sun Feb 12 09:21:44 2023 ] 	Mean test loss of 930 batches: 0.6014379263004308.
[ Sun Feb 12 09:21:45 2023 ] 	Top1: 83.47%
[ Sun Feb 12 09:21:45 2023 ] 	Top5: 96.31%
[ Sun Feb 12 09:21:45 2023 ] Training epoch: 56
[ Sun Feb 12 09:30:03 2023 ] 	Mean training loss: 0.1215.  Mean training acc: 96.83%.
[ Sun Feb 12 09:30:03 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 09:30:03 2023 ] Eval epoch: 56
[ Sun Feb 12 09:33:48 2023 ] 	Mean test loss of 930 batches: 0.4973473385797553.
[ Sun Feb 12 09:33:48 2023 ] 	Top1: 86.09%
[ Sun Feb 12 09:33:49 2023 ] 	Top5: 97.17%
[ Sun Feb 12 09:33:49 2023 ] Training epoch: 57
[ Sun Feb 12 09:42:06 2023 ] 	Mean training loss: 0.0933.  Mean training acc: 97.84%.
[ Sun Feb 12 09:42:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 09:42:06 2023 ] Eval epoch: 57
[ Sun Feb 12 09:45:52 2023 ] 	Mean test loss of 930 batches: 0.5025221970753484.
[ Sun Feb 12 09:45:52 2023 ] 	Top1: 86.12%
[ Sun Feb 12 09:45:53 2023 ] 	Top5: 97.19%
[ Sun Feb 12 09:45:53 2023 ] Training epoch: 58
[ Sun Feb 12 09:54:10 2023 ] 	Mean training loss: 0.0826.  Mean training acc: 98.15%.
[ Sun Feb 12 09:54:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 09:54:10 2023 ] Eval epoch: 58
[ Sun Feb 12 09:57:55 2023 ] 	Mean test loss of 930 batches: 0.5059121606370774.
[ Sun Feb 12 09:57:56 2023 ] 	Top1: 86.19%
[ Sun Feb 12 09:57:56 2023 ] 	Top5: 97.14%
[ Sun Feb 12 09:57:56 2023 ] Training epoch: 59
[ Sun Feb 12 10:06:13 2023 ] 	Mean training loss: 0.0767.  Mean training acc: 98.33%.
[ Sun Feb 12 10:06:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 10:06:14 2023 ] Eval epoch: 59
[ Sun Feb 12 10:09:58 2023 ] 	Mean test loss of 930 batches: 0.5079366989133339.
[ Sun Feb 12 10:09:59 2023 ] 	Top1: 86.13%
[ Sun Feb 12 10:09:59 2023 ] 	Top5: 97.12%
[ Sun Feb 12 10:09:59 2023 ] Training epoch: 60
[ Sun Feb 12 10:18:17 2023 ] 	Mean training loss: 0.0731.  Mean training acc: 98.49%.
[ Sun Feb 12 10:18:17 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 10:18:17 2023 ] Eval epoch: 60
[ Sun Feb 12 10:22:02 2023 ] 	Mean test loss of 930 batches: 0.5086347866242611.
[ Sun Feb 12 10:22:02 2023 ] 	Top1: 86.27%
[ Sun Feb 12 10:22:03 2023 ] 	Top5: 97.18%
[ Sun Feb 12 10:22:03 2023 ] Training epoch: 61
[ Sun Feb 12 10:30:19 2023 ] 	Mean training loss: 0.0678.  Mean training acc: 98.62%.
[ Sun Feb 12 10:30:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 10:30:20 2023 ] Eval epoch: 61
[ Sun Feb 12 10:34:05 2023 ] 	Mean test loss of 930 batches: 0.5155671981513821.
[ Sun Feb 12 10:34:05 2023 ] 	Top1: 86.23%
[ Sun Feb 12 10:34:06 2023 ] 	Top5: 97.14%
[ Sun Feb 12 10:34:06 2023 ] Training epoch: 62
[ Sun Feb 12 10:42:23 2023 ] 	Mean training loss: 0.0667.  Mean training acc: 98.63%.
[ Sun Feb 12 10:42:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 10:42:23 2023 ] Eval epoch: 62
[ Sun Feb 12 10:46:08 2023 ] 	Mean test loss of 930 batches: 0.519183392069673.
[ Sun Feb 12 10:46:08 2023 ] 	Top1: 86.18%
[ Sun Feb 12 10:46:08 2023 ] 	Top5: 97.08%
[ Sun Feb 12 10:46:09 2023 ] Training epoch: 63
[ Sun Feb 12 10:54:27 2023 ] 	Mean training loss: 0.0627.  Mean training acc: 98.79%.
[ Sun Feb 12 10:54:27 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 10:54:27 2023 ] Eval epoch: 63
[ Sun Feb 12 10:58:12 2023 ] 	Mean test loss of 930 batches: 0.5194628296840575.
[ Sun Feb 12 10:58:13 2023 ] 	Top1: 86.15%
[ Sun Feb 12 10:58:13 2023 ] 	Top5: 97.11%
[ Sun Feb 12 10:58:13 2023 ] Training epoch: 64
[ Sun Feb 12 11:06:32 2023 ] 	Mean training loss: 0.0616.  Mean training acc: 98.77%.
[ Sun Feb 12 11:06:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 11:06:32 2023 ] Eval epoch: 64
[ Sun Feb 12 11:10:18 2023 ] 	Mean test loss of 930 batches: 0.519010684080422.
[ Sun Feb 12 11:10:19 2023 ] 	Top1: 86.15%
[ Sun Feb 12 11:10:19 2023 ] 	Top5: 97.08%
[ Sun Feb 12 11:10:19 2023 ] Training epoch: 65
[ Sun Feb 12 11:18:37 2023 ] 	Mean training loss: 0.0587.  Mean training acc: 98.87%.
[ Sun Feb 12 11:18:37 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Sun Feb 12 11:18:37 2023 ] Eval epoch: 65
[ Sun Feb 12 11:22:23 2023 ] 	Mean test loss of 930 batches: 0.5235819095325085.
[ Sun Feb 12 11:22:24 2023 ] 	Top1: 86.12%
[ Sun Feb 12 11:22:24 2023 ] 	Top5: 97.11%
[ Sun Feb 12 11:26:12 2023 ] Best accuracy: 0.8635607041377339
[ Sun Feb 12 11:26:12 2023 ] Epoch number: 1
[ Sun Feb 12 11:26:12 2023 ] Model name: work_dir/cset/ctrgcn_local_SHT_BL
[ Sun Feb 12 11:26:12 2023 ] Model total number of params: 1508876
[ Sun Feb 12 11:26:12 2023 ] Weight decay: 0.0004
[ Sun Feb 12 11:26:12 2023 ] Base LR: 0.1
[ Sun Feb 12 11:26:12 2023 ] Batch Size: 64
[ Sun Feb 12 11:26:12 2023 ] Test Batch Size: 64
[ Sun Feb 12 11:26:12 2023 ] seed: 1
